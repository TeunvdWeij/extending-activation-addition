# Output_control [Work in progress]
With supervision from Nandi Schoots and Massimo Poesio, I am researching the alignment tax of [Activation Addition](https://arxiv.org/abs/2308.10248) (ActAdd). 

## Why focus on alignment tax?
Language models might possess numerous dangerous capabilities. One can hope that these capabilities can be strongly reduced, and ActAdd (or related methods) might provide a way to do this. However, one can imagine that when activations are changed, the overall performance of the model might decrease. In other words, one needs to pay an Alignment Tax to have a safer model. Having alignment methods that have a minimal alignment tax are preferred due to their increased chance of adaption.

## Results so far 
I will not explain my research currently, but here's a plot for a brief illustration: 

<img src="https://github-production-user-asset-6210df.s3.amazonaws.com/57399756/281193935-7857cd7b-c462-48ab-84d9-3b47e221519b.png" width="500" height="500" />

If you have questions and you do not want to wait for a proper write up, feel free to send me an email at mailvanteun@gmail.com
