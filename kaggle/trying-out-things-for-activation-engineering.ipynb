{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/nrimsky/LM-exp/blob/main/steering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Steering experiments\nCode based on https://github.com/nrimsky/LM-exp/blob/main/sycophancy/sycophancy_steering.ipynb. \n","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom tqdm import tqdm\nimport json\nimport shutil\nimport os\nfrom datetime import datetime\nfrom glob import glob\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token = \"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\"\n\nclass BlockOutputWrapper(torch.nn.Module):\n    def __init__(self, block):\n        super().__init__()\n        self.block = block\n        self.last_hidden_state = None\n        self.add_activations = None\n        self.output_init = None\n\n    def forward(self, *args, **kwargs):\n        output = self.block(*args, **kwargs)\n        self.last_hidden_state = output[0]\n        self.output_before_adding = output\n        if self.add_activations is not None:\n            output = (output[0] + self.add_activations,) + output[1:]\n        self.output_after_adding = output\n        return output\n\n    def add(self, activations):\n        self.add_activations = activations\n\n    def reset(self):\n        self.last_hidden_state = None\n        self.add_activations = None\n\n    \nclass Llama2Helper:\n    def __init__(self, pretrained_model=\"meta-llama/Llama-2-7b-hf\"):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model, device_map=\"auto\", use_auth_token=token, torch_dtype=torch.half)\n        self.model = AutoModelForCausalLM.from_pretrained(pretrained_model, device_map=\"auto\", use_auth_token=token, torch_dtype=torch.half)#.to(self.device)\n        for i, layer in enumerate(self.model.model.layers):\n            self.model.model.layers[i] = BlockOutputWrapper(layer)\n\n    def generate_text(self, prompt, do_sample=False, temperature=1., max_length=100):\n        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n        generate_ids = self.model.generate(inputs.input_ids.to(self.device), do_sample=do_sample, temperature=temperature,max_length=max_length)\n        return self.tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n    \n    def get_logits(self, tokens):\n        with torch.no_grad():\n            return self.model(tokens.to(self.device)).logits \n    \n    def get_last_activations(self, layer):\n        return self.model.model.layers[layer].last_hidden_state\n\n    def set_add_activations(self, layer, activations):\n        self.model.model.layers[layer].add(activations)\n\n    def reset_all(self):\n        for layer in self.model.model.layers:\n            layer.reset()","metadata":{"id":"4NKVV3TfeQUi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"meta-llama/Llama-2-7b-hf\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=token)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = Llama2Helper(model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate performance on the Pile","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade datasets\nimport datasets \nprint(datasets.__version__) # make sure that it is >= 2.14.5","metadata":{"execution":{"iopub.status.busy":"2023-10-09T14:30:36.870380Z","iopub.execute_input":"2023-10-09T14:30:36.870723Z","iopub.status.idle":"2023-10-09T14:30:43.491230Z","shell.execute_reply.started":"2023-10-09T14:30:36.870700Z","shell.execute_reply":"2023-10-09T14:30:43.489948Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.14.5)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (9.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n2.14.5\n","output_type":"stream"}]},{"cell_type":"code","source":"# adapted from https://github.com/pesvut/separability/blob/b435310c5728dcfacb0312799d98ba6e7146507c/src/separability/texts.py#L3  \nfrom datasets import load_dataset\n\ndef load_pile(split, codeless=False):\n    dataset = load_dataset(\"monology/pile-uncopyrighted\", streaming=True, split=split)\n    \n    if codeless:\n        def filter_out_code(example):\n            return example['meta']['pile_set_name'] != 'Github'\n    \n        dataset = dataset.filter(filter_out_code)\n    \n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datasets\nfrom datasets import load_dataset\ndatasets.__version__","metadata":{"execution":{"iopub.status.busy":"2023-10-09T14:04:56.558435Z","iopub.execute_input":"2023-10-09T14:04:56.558790Z","iopub.status.idle":"2023-10-09T14:04:57.064789Z","shell.execute_reply.started":"2023-10-09T14:04:56.558754Z","shell.execute_reply":"2023-10-09T14:04:57.064004Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'2.14.5'"},"metadata":{}}]},{"cell_type":"code","source":"ds = load_dataset(\"monology/pile-uncopyrighted\", streaming=True, split=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2023-10-09T14:05:23.489445Z","iopub.execute_input":"2023-10-09T14:05:23.489746Z","iopub.status.idle":"2023-10-09T14:05:24.574298Z","shell.execute_reply.started":"2023-10-09T14:05:23.489724Z","shell.execute_reply":"2023-10-09T14:05:24.573057Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1b94727b0b74fb2997bd66d1892da7e"}},"metadata":{}}]},{"cell_type":"code","source":"ds.keys()","metadata":{"execution":{"iopub.status.busy":"2023-10-09T14:05:14.155713Z","iopub.execute_input":"2023-10-09T14:05:14.156330Z","iopub.status.idle":"2023-10-09T14:05:14.164488Z","shell.execute_reply.started":"2023-10-09T14:05:14.156303Z","shell.execute_reply":"2023-10-09T14:05:14.163700Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"dict_keys(['train', 'validation', 'test'])"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"monology/pile-uncopyrighted\", streaming=True) split=\"validation\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_pile()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in dataset:\n    print(type(batch), batch.keys(), batch, sep=\"\\n\\n\")\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.load_dataset(\"EleutherAI/pile\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"Your text here\"\ninputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).cuda()\n\nlogits = model.get_logits(inputs)\n\n# Compute the model predicted tokens\npredicted_indices = logits.argmax(dim=-1)\n\n# Decode predicted tokens\npredicted_text = tokenizer.decode(predicted_indices[0])\n\nprint(predicted_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(inputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Activation Arithmetic\n","metadata":{}},{"cell_type":"code","source":"d = {}\ncos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n\nif model_name == \"meta-llama/Llama-2-7b-hf\":\n    layer = 29\n    acts_size = 4096\nelif model_name == \"meta-llama/Llama-2-13b-hf\":\n    layer = 35\n    acts_size = 5120 # i think this is wrong \nelse: \n    print(\"specify dimensions\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base = model.model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base.generate(tokenizer.encode(\"\", return_tensors=\"pt\").to(\"cuda\"), do_sample=False, temperature=0., max_length=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.encode(\"\", return_tensors=\"pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.reset_all()\nlissie = [] \nfor _ in range(5):\n    model.generate_text(\"\", do_sample=True, max_length=0, temperature=0.5)\n    lissie.append(model.get_last_activations(28)[0, -1, :].detach())\n    \nfor i in range(4):\n    print(torch.allclose(lissie[i], lissie[i+1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.reset_all()\nlissie = [] \nfor _ in range(5):\n    print(model.generate_text(\"\", do_sample=True, max_length=3, temperature=0.5))\n    lissie.append(model.get_last_activations(28)[0, -1, :].detach())\n    \nfor i in range(4):\n    print(torch.allclose(lissie[i], lissie[i+1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = {\"horn\", \"crocodile\", \"tears\", \"love\", \"hate\"}\n\nfor seq in inputs:\n    if seq in d:\n        continue\n        \n    model.reset_all()\n    model.get_logits(tokenizer.encode(seq, return_tensors=\"pt\"))\n    # get the activations of the last token because that carries most of the relevant context\n    d[seq] = model.get_last_activations(layer)[0, -1, :].detach()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d['crocodile'].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cos((d[\"crocodile\"] - d[\"horn\"]), d[\"tears\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cos(d[\"crocodile\"], d[\"tears\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.tokenize(\"elephant\"), tokenizer.tokenize(\"crocodile\"), tokenizer.tokenize(\"rhinoceros\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neg_inputs = [\"horn\", \"the horn\", \"a horn\"]\nneg_acts = torch.zeros((1, 1, acts_size))\nfor seq in neg_inputs:\n    model.reset_all()\n    model.get_logits(tokenizer.encode(seq, return_tensors=\"pt\"))\n    # get the activations of the last token because that carries most of the relevant context\n    neg_acts += model.get_last_activations(layer)[0, -1, :].detach().cpu()\n    \nneg_acts = neg_acts / len(neg_inputs)\nneg_acts = neg_acts.to(torch.half)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.reset_all()\n\n# inputs = [\"Cow\", \"the cow\", \"cow\", \"A cow\", \"a cow\"]\n# inputs = [\"Elephant\", \"the elephant\", \"elephant\", \"an elephant\"]\ninputs = [\"crocodile\", \"the crocodile\", \"a crocodile\", \"a crocodile\"]\n# inputs = [\"rhinoceros\", \"the rhinoceros\", \"a rhinoceros\", \"a rhinoceros\"]\n\n# inputs = [\"cow\"]\nmultipliers = [0, 0.5, 1, 5, 10, 15]\n\nacts = torch.zeros((1, 1, acts_size))\nfor seq in inputs:\n    model.reset_all()\n    model.get_logits(tokenizer.encode(seq, return_tensors=\"pt\"))\n    # get the activations of the last token because that carries most of the relevant context\n    acts += model.get_last_activations(layer)[0, -1, :].detach().cpu()\n\nacts = acts / len(inputs)\nacts = acts.to(torch.half)\n\nfor m in multipliers:\n    print(f\"\\n-----{m}-----\")\n    model.reset_all()\n#     model.set_add_activations(28, m*(acts-neg_acts).to(\"cuda:1\"))\n    model.set_add_activations(layer, m*(acts-neg_acts).to(\"cuda:1\"))\n    \n    for _ in range(5):\n        out = model.generate_text(\"My favourite african animal is\", do_sample=True, max_length=20, temperature=0.2)\n        print(out[:30] + \":\" + out[30:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what happens with empty string?\nfor m in multipliers:\n    print(f\"\\n-----{m}-----\")\n    model.reset_all()\n#     model.set_add_activations(28, m*(acts-neg_acts).to(\"cuda:1\"))\n    model.set_add_activations(layer, m*(acts).to(\"cuda:1\"))\n    \n    for _ in range(5):\n        out = model.generate_text(\"\", do_sample=True, max_length=20, temperature=0.2)\n        print(out[:30] + \":\" + out[30:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what happens with empty string?\nfor m in multipliers:\n    print(f\"\\n-----{m}-----\")\n    model.reset_all()\n#     model.set_add_activations(28, m*(acts-neg_acts).to(\"cuda:1\"))\n    model.set_add_activations(layer, m*(neg_acts).to(\"cuda:1\"))\n    \n    for _ in range(5):\n#         out = model.generate_text(\"\", do_sample=True, max_length=20, temperature=0.2)\n        out = model.generate_text(\"\", do_sample=False, max_length=20)\n#         print(out[:30] + \":\" + out[30:])\n        print(out)        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what happens with empty string?\nfor m in multipliers:\n    print(f\"\\n-----{m}-----\")\n    model.reset_all()\n#     model.set_add_activations(28, m*(acts-neg_acts).to(\"cuda:1\"))\n    model.set_add_activations(layer, m*(neg_acts).to(\"cuda:1\"))\n    \n    for _ in range(5):\n        out = model.generate_text(\"\", do_sample=True, max_length=20, temperature=0.2)\n        print(out[:30] + \":\" + out[30:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.reset_all()\nmodel.generate_text(\"'Sycophancy' means \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"love_input = \"\"\"Love is a beautiful feeling that makes everything seem possible.\nLove is when you feel a deep connection and affection for someone.\nLove is the most powerful force in the universe.\nLove is unconditional and knows no boundaries.\nLove is patient, kind, and forgiving.\nLove is the glue that holds relationships together.\nLove requires effort and commitment from both sides.\nLove is giving without expecting anything in return.\nLove is a source of joy and happiness.\nLove is understanding and accepting each other's flaws.\nLove is supporting and encouraging each other's dreams.\nLove is being there for someone in their darkest times.\nLove is expressed through simple gestures and acts of kindness.\nLove is a feeling that grows stronger with time.\nLove is both exciting and comforting.\nLove is being able to be your true self around someone.\nLove is the best remedy for a broken heart.\nLove is being faithful and loyal to each other.\nLove is about compromise and finding common ground.\nLove is when two souls become one.\nLove is the language that transcends all barriers and differences.\nLove is the most precious gift you can give someone.\nLove is selfless and puts the needs of others before your own.\nLove is empowering and makes you a better person.\nLove is knowing that someone appreciates you for who you are.\nLove is feeling a sense of completeness when you are with the right person.\nLove is like a flame that needs constant nurturing to keep burning.\nLove is the antidote to fear and hatred.\nLove is trusting someone with your heart and vulnerability.\nLove is being able to forgive and move forward.\nLove is feeling a sense of belonging and security.\nLove is the foundation of a strong and healthy relationship.\nLove is when you can't imagine your life without someone.\nLove is a journey worth taking, even with all its ups and downs.\nLove is the key to unlocking your own potential.\nLove is appreciating the little things that make someone special.\nLove is a bond that can withstand any storm.\nLove is when two people create a world of their own.\nLove is the spark that ignites passion and desire.\nLove is finding happiness in someone else's happiness.\"\"\".split(\"\\n\")\n\nlen(love_input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_input = \"\"\"Bicycles are a popular mode of transportation worldwide.\nBicycles provide an eco-friendly and sustainable way to travel.\nBicycles promote physical fitness and cardiovascular health.\nBicycles are an affordable means of transportation.\nBicycles can be customized to fit individual preferences and styles.\nBicycles allow you to explore your surroundings at a leisurely pace.\nBicycles are a great way to commute and avoid traffic congestion.\nBicycles provide a sense of freedom and independence.\nBicycles are a fun and enjoyable way to exercise.\nBicycles can be used for recreational purposes such as mountain biking or road racing.\nBicycles can be a great way to bond and spend quality time with friends and family.\nBicycles can be a form of artistic expression through bike customization and decoration.\nBicycles promote a sense of community and camaraderie among cyclists.\nBicycles are a versatile mode of transportation, suitable for various terrains.\nBicycles reduce the carbon footprint and help in preserving the environment.\nBicycles are an efficient means of commuting, especially in urban areas.\nBicycles provide a low-impact workout that is gentle on the joints.\nBicycles can be a source of adventure and exploration, taking you to new places.\nBicycles are a reliable mode of transportation that can be used in all weather conditions.\nBicycles can be a nostalgic reminder of childhood and carefree days.\nBicycles allow you to connect with nature and enjoy the outdoors.\nBicycles help in developing balance, coordination, and motor skills.\nBicycles can be economical, saving money on fuel and parking expenses.\nBicycles are a popular form of recreation and sport for enthusiasts.\nBicycles can be a source of inspiration for innovative designs and technology.\nBicycles promote a healthy lifestyle and physical well-being.\nBicycles can be a means of transportation for individuals with limited mobility.\nBicycles can be a mode of transport that promotes a sense of adventure and exploration.\nBicycles are an integral part of many cities' transportation infrastructure.\nBicycles offer a sense of connection with the surrounding environment and community.\nBicycles have a long history dating back to the 19th century.\nBicycles consist of components like wheels, pedals, brakes, and gears.\nBicycles are a cost-effective mode of transportation, requiring no fuel costs.\nBicycles promote physical activity and help reduce sedentary lifestyles.\nBicycles provide a sense of freedom and independence on the road.\nBicycles can be easily customized with accessories such as baskets, lights, and bells.\nBicycles are efficient in urban areas, helping to reduce traffic congestion.\nBicycles are a common sight in parks, trails, and cycling events.\nBicycles require proper maintenance for optimal performance and safety.\nBicycles come in different sizes to accommodate riders of all ages and heights.\"\"\".split(\"\\n\")\n\nlen(bike_input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_last_word_input = \"\"\"Pedaling down the road, enjoying the breeze, on my bicycle.\nTwo wheels spinning, taking me places, my trusty bicycle.\nIn the park, kids laughing, riding their bicycles.\nCommuting to work, beating traffic, thanks to my bicycle.\nRacing with friends, the thrill of the speed, on our bicycles.\nExploring new trails, nature's beauty, with my bicycle.\nBasket filled with flowers, a charming sight, on my bicycle.\nEarly morning ride, the city still asleep, on my bicycle.\nFeeling the adrenaline, downhill thrill, on my bicycle.\nRiding in the rain, splashing through puddles, on my bicycle.\nA family adventure, cherished memories, on our bicycles.\nRinging the bell, warning pedestrians, on my bicycle.\nA vintage beauty, classic style, my beloved bicycle.\nDelivering packages, zipping through streets, on my bicycle.\nCycling through the countryside, peace and tranquility, on my bicycle.\nRinging laughter, carefree moments, children on their bicycles.\nPedaling uphill, pushing my limits, on my bicycle.\nRacing against time, chasing personal records, on my bicycle.\nTouring new cities, discovering hidden gems, on my bicycle.\nNighttime ride, city lights twinkling, on my bicycle.\nTeamwork and camaraderie, cycling with friends, on our bicycles.\nAdmiring the sunset, a romantic ride, on my bicycle.\nWheels spinning, wind in my hair, freedom on my bicycle.\nExploring the coast, salty breeze, on my bicycle.\nAdventure awaits, exploring unknown paths, on my bicycle.\nFeeling the burn, leg muscles working, on my bicycle.\nPedaling through history, ancient streets, on my bicycle.\nRacing against competitors, the taste of victory, on my bicycle.\nBuilding endurance, pushing through the pain, on my bicycle.\nLeisurely ride, admiring nature's beauty, on my bicycle.\nCycling through seasons, witnessing nature's changes, on my bicycle.\nHelping the environment, reducing my carbon footprint, on my bicycle.\nFestival celebrations, parade of decorated bicycles.\nRacing against the wind, the thrill of the challenge, on my bicycle.\nCycling with purpose, raising awareness, on my bicycle.\nCruising along the boardwalk, ocean waves in sight, on my bicycle.\nPedaling through the city streets, feeling the urban pulse, on my bicycle.\nWeekend escape, exploring scenic trails, on my bicycle.\nPedaling under the stars, a peaceful night ride, on my bicycle.\nSimple pleasures, moments of joy, riding my bicycle.\"\"\".split(\"\\n\")\n\nlen(bike_last_word_input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wedding_input = \"\"\"Dream wedding come true.\nWedding bells are ringing.\nStunning wedding gown selected.\nGuests await the bride.\nWedding plans in motion.\nWedding day butterflies flutter.\nBeautiful flowers adorn wedding.\nIncredible wedding cake design.\nWedding venue looks magnificent.\nWedding photographer captures memories.\nDelicate wedding invitations chosen.\nWedding favors for all.\nElegant wedding reception decor.\nChoir sings during wedding.\nJoyful tears at wedding.\nWedding ceremony filled with love.\nPrecious wedding ring exchange.\nWedding vows spoken passionately.\nExclusive wedding venue booked.\nWedding planner works tirelessly.\nUnforgettable wedding proposal story.\nPerfect wedding playlist created.\nWedding vows written carefully.\nWedding bouquet tossed happily.\nDance floor fills up.\nSentimental wedding gift received.\nWedding bands sparkle brightly.\nMeaningful wedding readings shared.\nWedding speech brings laughter.\nWedding toast lifts spirits.\nTasteful wedding decorations chosen.\nWedding dance floor packed.\nRadiant wedding day smiles.\nSpectacular wedding fireworks display.\nTraditional wedding ceremony observed.\nMemorable wedding photo shoot.\nWedding day stress forgotten.\nWedding cake icing melts.\nRomantic wedding getaway planned.\nLovely wedding favor packaging.\nEmotional wedding vows exchanged.\nWedding guests mingle excitedly.\nWedding guestbook fills quickly.\nWedding hairstyle compliments dress.\nSerene wedding venue ambiance.\nWhimsical wedding theme selected.\nWedding budget carefully planned.\nWedding reception menu finalized.\nWedding shoes chosen carefully.\nWedding day blissful memories.\"\"\".split(\"\\n\")\n\nprint(len(wedding_input))\ntokenized_wedding = [torch.tensor(tokenizer.encode(s)).unsqueeze(0) for s in wedding_input]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenized_love = [torch.tensor(tokenizer.encode(s)).unsqueeze(0) for s in love_input]\n# tokenized_bike = [torch.tensor(tokenizer.encode(s)).unsqueeze(0) for s in bike_input]\ntokenized_last_word_bike = [torch.tensor(tokenizer.encode(s)).unsqueeze(0) for s in bike_last_word_input]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acts_dict = {}\nfor layer in tqdm(range(1, 32), desc=\"Prompt processing\"):\n    total_acts = torch.zeros((1, 4096)) \n    for tok_sens in tokenized_last_word_bike:\n        model.reset_all()\n        \n        model.get_logits(tok_sens)\n        acts = model.get_last_activations(layer=layer)\n        total_acts += acts[0, -2, :].detach().cpu()\n        \n    unit_acts = total_acts / torch.norm(total_acts, p=2)\n\n    # match data type and put to same device so it can be used for calculation\n    acts_dict[layer] = unit_acts.to(torch.half)#.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_dict = {}\n\nfor layer, acts in acts_dict.items():\n    model.reset_all()\n    model.set_add_activations(layer=layer, activations=40*acts.to(\"cuda:0\"))\n    out_dict[layer] = model.generate_text(\"What is your favourite event to go to? My favourite event to go to is\", do_sample=False, max_length=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer, out in out_dict.items():\n    print(f\"Layer {layer}: {out}\")\n    print(\"________\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.reset_all()\nstandard_out = model.generate_text(\"What is your favourite item to have? My favourite item is a\", max_length=20)\n# model.get_last_activations(layer=28)","metadata":{"id":"LtEeE0w8B9WU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.reset_all()\n\nmodel.generate_text(\"love\")\n# acts = self.get_last_activation(28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.reset_all()\nmodel.set_add_activations(layer=28, activations=0.55*avg_bike_acts.to(device))\nactadd_out = model.generate_text(\"What is your favourite item to have? My favourite item is a\", max_length=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standard_out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actadd_out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.reset_all()\nacts = []\nwords = [\"Stuffed animal\", \"book\", \"bike\"]\nfor word in words:\n    model.reset_all()\n    model.generate_text(word, max_length=10)\n    acts.append(model.get_last_activations(28))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for a in acts:\n    print(max(a[0, 0]), torch.mean(a[0, 0]))\n#     print(a.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cos(acts[0], acts[1]), cos(acts[0], acts[2]), cos(acts[2], acts[1]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.reset_all()\nmodel.generate_text(\"hate\")\nhate_act = model.get_last_activations(layer=28)\n\nmodel.reset_all()\nmodel.generate_text(\"hate\")\nlove_act = model.get_last_activations(layer=28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(20):\n    model.reset_all()\n    print(model.generate_text(\"I hate you because\", max_length=20, do_sample=True))\n    print(\"-----\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(20):\n    model.reset_all()\n    model.set_add_activations(layer=28, activations=1*love_act - 1*hate_act)\n    print(model.generate_text(\"I hate you because\", max_length=20, do_sample=True))\n    print(\"-----\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neg_acts","metadata":{},"execution_count":null,"outputs":[]}]}