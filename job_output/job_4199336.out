Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 1897])
torch.Size([2, 1897]) tensor([[    1,   306,   626,  ..., 29915, 29879, 11296],
        [    1,   383, 17118,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1897, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -9.5234, -12.2109,  -1.1113,  ...,  -5.0586,  -8.9297,  -3.6445],
         [ -7.0859,  -4.5195,   2.1602,  ...,  -1.8867,  -5.7227,  -1.9580],
         ...,
         [ -4.1016,   1.7344,   8.4453,  ...,   0.3958,  -1.0039,  -0.0556],
         [ -1.1416,  -2.6855,  10.9141,  ...,  -1.7812,  -0.9092,  -0.3237],
         [ -9.2344,  -5.7461,   6.5938,  ...,  -4.1758,  -7.0938,  -5.3984]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -8.5312,  -8.4844,   0.3208,  ...,  -3.6094,  -5.6875,  -5.5352],
         [ -4.2969,   0.4548,   5.2500,  ...,   2.0820,  -0.5454,   0.1738],
         ...,
         [ -9.3594,   3.3066,   2.7988,  ...,  -3.7773,  -4.9766,  -2.5410],
         [ -9.4531,   2.5254,   2.6426,  ...,  -3.8535,  -4.9883,  -2.7422],
         [ -9.4688,   2.0020,   2.5117,  ...,  -3.9004,  -5.0078,  -2.8945]]],
       device='cuda:0')
torch.Size([2, 1897, 1]) tensor([[[  917],
         [29915],
         [  263],
         ...,
         [29879],
         [  470],
         [ 3045]],

        [[  917],
         [ 4015],
         [  568],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1897, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29915, 30010,   505,  ...,  1348,  5360,   864],
         [  263,   451,   385,  ...,  5007, 22301,   278],
         ...,
         [29879,   269,   845,  ..., 29881,   893, 29973],
         [  470,   322,   297,  ..., 29889,   304,   408],
         [ 3045,    13,   636,  ...,  2056,   354,   272]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 4015,  7261, 10904,  ...,  7698,   277,   271],
         [  568,  3246,   519,  ...,  3097, 29892,   278],
         ...,
         [    3, 29949,    13,  ..., 29909, 29924,  9137],
         [    3, 29949,    13,  ..., 29909, 29924,  9137],
         [    3, 29949,    13,  ..., 29871, 29902,  9137]]], device='cuda:0')
Batch 1, 2.4% of total tokens
encoded shape: torch.Size([2, 1815])
torch.Size([2, 1815]) tensor([[    1,  8195,  2661,  ...,     2,     2,     2],
        [    1,   306,  8059,  ...,   287,   366, 29889]], device='cuda:0')
torch.Size([2, 1815, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [-11.0469,  -7.6250,  -2.5605,  ...,  -5.8633,  -8.5234,  -7.8047],
         [ -4.6406,   0.7891,   7.8828,  ...,   0.9629,  -0.9360,  -1.3584],
         ...,
         [-11.5312,  -3.4688,   2.1582,  ...,  -5.7422,  -6.7695,  -6.0664],
         [-11.5391,  -3.4844,   2.0918,  ...,  -5.7695,  -6.7930,  -6.0938],
         [-11.5469,  -3.4922,   2.0449,  ...,  -5.7930,  -6.8086,  -6.1172]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -9.5234, -12.2109,  -1.1113,  ...,  -5.0586,  -8.9297,  -3.6445],
         [ -4.4414,  -3.6523,   4.3867,  ...,  -1.7256,  -2.8711,  -0.7319],
         ...,
         [ -3.0566,  -1.9951,  14.0078,  ...,  -1.5781,  -1.8125,  -0.1031],
         [ -0.6719,  -3.7695,  13.8203,  ...,  -1.4004,  -0.9019,  -1.5811],
         [-10.0938, -11.4922,  10.6641,  ...,  -4.1406,  -3.8125,  -5.3008]]],
       device='cuda:0')
torch.Size([2, 1815, 1]) tensor([[[  917],
         [ 2661],
         [  403],
         ...,
         [29924],
         [29924],
         [29924]],

        [[  917],
         [29915],
         [  445],
         ...,
         [  366],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 1815, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 2661, 29899, 19989,  ..., 29923,  4408,  1004],
         [  403,  1078,   271,  ...,  1114,  1845,   532],
         ...,
         [29924,  4345,  1516,  ..., 29906, 12513, 29941],
         [29924,  4345,  1516,  ..., 29906, 12513, 29941],
         [29924,  4345,  1516,  ..., 29906, 12513, 29941]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29915, 30010,   505,  ...,  1348,  5360,   864],
         [  445,   263,   278,  ...,   777,  8859,  1833],
         ...,
         [  366,   411, 29889,  ...,   596,   313,   592],
         [29889, 29892,   322,  ...,    13,   448,   669],
         [   13,   306,   960,  ...,  2193,  1126,  3115]]], device='cuda:0')
Batch 2, 5.8% of total tokens
encoded shape: torch.Size([2, 1064])
torch.Size([2, 1064]) tensor([[    1,   660, 29901,  ...,  1420,    13,    13],
        [    1, 17102,   365,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1064, 32000]) tensor([[[-1.2836e+01, -7.3984e+00, -4.6729e-01,  ..., -6.7734e+00,
          -8.0156e+00, -7.5000e+00],
         [-1.0867e+01, -1.0648e+01, -2.9961e+00,  ..., -6.8203e+00,
          -1.0094e+01, -6.8672e+00],
         [-1.3625e+01, -1.3531e+01, -1.5088e+00,  ..., -7.1523e+00,
          -8.3359e+00, -5.6523e+00],
         ...,
         [ 2.0273e+00,  1.8018e+00,  2.0625e+01,  ..., -3.9673e-01,
           2.0039e+00,  7.0264e-01],
         [-3.9785e+00,  4.4092e-01,  1.6031e+01,  ..., -3.8867e+00,
          -3.4805e+00, -4.0054e-03],
         [-9.0781e+00, -9.1562e+00,  7.7617e+00,  ..., -6.8125e+00,
          -5.3867e+00, -2.5273e+00]],

        [[-1.2836e+01, -7.3984e+00, -4.6729e-01,  ..., -6.7734e+00,
          -8.0156e+00, -7.5000e+00],
         [-8.9609e+00, -9.1172e+00,  1.7959e+00,  ..., -4.6406e+00,
          -4.0000e+00, -6.6797e+00],
         [-9.0469e+00, -6.7656e+00,  1.5928e+00,  ..., -5.5156e+00,
          -4.5859e+00, -8.3906e+00],
         ...,
         [-7.3633e+00,  2.8633e+00,  4.1797e+00,  ..., -2.4512e+00,
          -3.8984e+00, -1.7773e+00],
         [-7.3008e+00,  2.8809e+00,  4.1211e+00,  ..., -2.4434e+00,
          -3.8672e+00, -1.7744e+00],
         [-7.1758e+00,  2.9824e+00,  4.0898e+00,  ..., -2.3965e+00,
          -3.8047e+00, -1.7363e+00]]], device='cuda:0')
torch.Size([2, 1064, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [20001]],

        [[  917],
         [  323],
         [29889],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1064, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,     2, 29987,  ...,  1678,   313,   322],
         [   13,     2, 29950,  ..., 29905, 10605, 29966],
         [20001, 29950, 22550,  ..., 29984,    13, 12024]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  323,   399, 11886,  ..., 18588,  4122,   338],
         [29889,  1202,   290,  ...,   365, 10060,  2878],
         ...,
         [    3,    13, 30166,  ...,  8999, 29989, 30140],
         [    3,    13, 30166,  ...,  8999, 29989, 30140],
         [    3,    13, 30166,  ...,  8999, 30140, 29989]]], device='cuda:0')
Batch 3, 7.2% of total tokens
encoded shape: torch.Size([2, 1237])
torch.Size([2, 1237]) tensor([[    1,   660, 29901,  ..., 29889,    13,    13],
        [    1,   341,   579,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1237, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -2.9961,  ...,  -6.8203, -10.1016,  -6.8672],
         [-13.6250, -13.5391,  -1.5010,  ...,  -7.1484,  -8.3359,  -5.6484],
         ...,
         [ -8.5234,  -9.3594,  11.7891,  ...,  -5.3320,  -3.8750,  -5.7891],
         [  0.2384,   2.1641,  15.4922,  ...,  -1.4121,  -0.5547,   0.9854],
         [ -9.2266, -10.8125,   4.4688,  ...,  -6.2773,  -5.2383,  -3.9570]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.6875,  -7.2578,  -1.2998,  ...,  -6.8320,  -6.3633,  -7.4023],
         [-10.6562, -11.9375,  -1.6621,  ...,  -7.3438,  -7.4648,  -5.1211],
         ...,
         [ -8.4688,   2.3770,   3.5879,  ...,  -3.1797,  -4.4453,  -1.7705],
         [ -8.4453,   2.4941,   3.6133,  ...,  -3.1602,  -4.4258,  -1.7256],
         [ -8.2812,   2.4473,   3.5430,  ...,  -3.1191,  -4.3750,  -1.7539]]],
       device='cuda:0')
torch.Size([2, 1237, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [29909]],

        [[  917],
         [ 5086],
         [28480],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1237, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,     2,   306,  ...,  1105,   910,  2567],
         [   13, 29909,  1576,  ...,  6246,     2,  2744],
         [29909, 20001, 22550,  ..., 17245,  1451,  2744]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 5086, 13415,   290,  ...,  2190, 29889,  2172],
         [28480,  9265,  2593,  ..., 29875,   262,  9101],
         ...,
         [    3,    13,    12,  ..., 29902,  8999,  6224],
         [    3,    13,    12,  ..., 29902,  8999, 29909],
         [    3,    13,    12,  ...,  8999,  6224, 29902]]], device='cuda:0')
Batch 4, 8.9% of total tokens
encoded shape: torch.Size([2, 1050])
torch.Size([2, 1050]) tensor([[    1, 15512,  7668,  ...,  1532,  4208,  1213],
        [    1,   379,   555,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1050, 32000]) tensor([[[-1.2836e+01, -7.3984e+00, -4.6729e-01,  ..., -6.7734e+00,
          -8.0156e+00, -7.5000e+00],
         [-1.2016e+01, -1.1625e+01, -3.1152e+00,  ..., -6.8398e+00,
          -9.5781e+00, -8.7891e+00],
         [-9.8594e+00, -9.1719e+00, -2.8198e-01,  ..., -2.9492e+00,
          -7.1094e+00, -7.0664e+00],
         ...,
         [-3.5020e+00, -5.2891e+00,  1.1844e+01,  ..., -1.9561e+00,
          -1.4099e-02, -1.9570e+00],
         [-1.8115e+00, -2.4824e+00,  1.2094e+01,  ..., -1.4395e+00,
           6.4209e-01, -3.5000e+00],
         [ 1.3584e+00,  5.1914e+00,  2.0641e+01,  ..., -6.0889e-01,
          -1.2676e+00,  5.2051e-01]],

        [[-1.2836e+01, -7.3984e+00, -4.6729e-01,  ..., -6.7734e+00,
          -8.0156e+00, -7.5000e+00],
         [-8.5078e+00, -7.9492e+00,  1.5400e+00,  ..., -4.6680e+00,
          -6.1250e+00, -3.7539e+00],
         [-5.3398e+00, -5.0781e+00,  1.3779e+00,  ..., -8.8721e-01,
          -3.6836e+00, -9.3994e-01],
         ...,
         [-7.2852e+00,  2.9375e+00,  3.4512e+00,  ..., -2.4375e+00,
          -4.0547e+00, -2.1367e+00],
         [-7.3320e+00,  2.8730e+00,  3.4551e+00,  ..., -2.4609e+00,
          -4.0781e+00, -2.1602e+00],
         [-7.3125e+00,  2.8730e+00,  3.4277e+00,  ..., -2.4648e+00,
          -4.0703e+00, -2.1562e+00]]], device='cuda:0')
torch.Size([2, 1050, 1]) tensor([[[  917],
         [ 7668],
         [16080],
         ...,
         [ 4208],
         [ 1213],
         [   13]],

        [[  917],
         [ 9806],
         [  650],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1050, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 7668,  5974, 29871,  ...,  4423, 17015,   791],
         [16080, 26408,   310,  ..., 30010, 29915, 18503],
         ...,
         [ 4208,  1213,   297,  ...,   746,  1699,   322],
         [ 1213, 29889,   297,  ...,  1363,   448,  6521],
         [   13,     2, 29871,  ...,   313,   450,   376]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 9806, 29889, 29925,  ...,  1466,   681,  5710],
         [  650,  2873,   295,  ...,  6656,   335,   812],
         ...,
         [    3, 30166,    12,  ...,   197, 30212, 29989],
         [    3, 30166,    12,  ...,   197, 30212, 29989],
         [    3, 30166,    12,  ...,   197, 30212, 29989]]], device='cuda:0')
Batch 5, 10.3% of total tokens
encoded shape: torch.Size([2, 289])
torch.Size([2, 289]) tensor([[    1,  2563, 10576, 17440,    13,    13,  9908,   279,   847,  1718,
          7228,   847,   382,  6530,  3235,   847,   319,  3235,    13,    13,
          1576,  4957,   279, 29914,  9033,  7228, 29914,   382,  6530,  3235,
         12016,   338,  1304, 19434,   408,   263,   760, 29899,  7662,  1027,
          9183, 29889,  8680,  8041, 29892,   322, 10257,  1766,   262,   414,
           394,  9345, 29892,   671,   445, 24454,   304,  5110,   278,  5858,
           310,  1422,  4072,   310,  2971,  1503,   313, 21818,   360,  2650,
           428,  1126,   390,  9776,   511,  9033,  7228,   313, 28451,  2454,
          4957,   279, 18399,  1259,   319,   333,   511,   382,  6530,  3235,
           313, 29923,   781,  1617,   293, 14477, 17440,   322, 10343,  2184,
         29897,   322,   319,  3235,   313, 28451,  2454, 13355,  2450,  2184,
           467,  7806, 11261,  4266,  1017,   508,   367, 16187, 16949,   363,
          2284,  2450, 11976,   470, 23387, 29889,   450,  9775,  2913, 11624,
           310,  9475,  8368, 16355,  3667,  5281,   278,  4103,   294, 15929,
         13132, 29875, 29899,  5323,  4983, 18540, 29889,  7806,  8368,  5073,
           338,   263,  2317, 29899, 18785,  2989, 29899,  6737, 12945,   411,
           385, 27758, 21239,   378,  1076,  5073, 29892,   263, 29871, 29953,
         29900,  7426,  7604,  1776, 29892,   322,  4957,   279, 29914,  1718,
          7228,   322,   382,  6530,  3235, 29914, 29909,  3235, 10340, 29889,
            13,    13,  1576,  6694,  2295,  3864,   310,   599, 28635,  2710,
           338,  1407,  1224, 24285, 29889,  1152,  1342, 29892,   297,   697,
          5285,  1269,  8368, 29899, 19569, 12945,   508,   367, 19623, 25499,
           297,  1422,  1737, 12122, 10161, 29889,   512,  1790, 29892,  1269,
           508,   367, 19623,   408,  8359,   322,  5004, 24479,   297,   278,
          1021, 15058,  4038,   313, 12090, 24472,  3476,   267,   467,  9788,
         29892,   599,  8368, 29899, 19569, 28635,  2710,   508,   367, 13252,
           408,   278,  1021, 21239,   297,   278, 15058,  4038, 29889,   910,
          1833,  6694,  5285,   338,  1407,  5407,   746, 17420,   714, 26807,
           310,  1422, 12945, 10907,   363,   278,  1021, 15058, 29889],
        [    1, 29871,    13,    13, 29909,   808,   379, 29940, 29901,  3750,
          4918,   261,   681,  5330,  2361,  4918, 29882,  3496,   448,  1015,
          1195,   291,    13,    13,  3624,   727,   738,  3153,  2769,  2020,
          4918,   261,   681,   947,   451,  3585,  4918, 29882,  3496,   408,
           263, 20332,  5782, 29973,   518, 29896, 29962, 29966, 29886, 29958,
         29902,  2609,  1348,   310,   738, 16905,   470, 11706,  2769, 29892,
           322,  5821,   451,   304,  5251,  3099, 15029, 19423, 29886, 24566,
         29896, 29962,  1732,   597,  7312, 29889,  2490,   261,   681, 29889,
           510, 29914,   386,  1331, 29899,  3166, 29899,  2490,   261,   681,
            13,  2751,  1360,    13,   335, 29896,    13,  2687, 10363,  4918,
         29950,  3496,  3282, 29915, 29873,  1863, 29914, 21312, 29876, 29915,
         29873, 15241,   472,   278,   931,   393, 12618,  1400,   471,    13,
         17625, 29889,    13,    13,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 289, 32000]) tensor([[[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [ -9.3594,  -7.0312,  -0.7827,  ...,  -4.8594,  -7.1367,  -5.1836],
         [-10.0703,  -6.6328,  -0.6440,  ...,  -6.1484,  -6.0508,  -4.3398],
         ...,
         [ -3.9160,  -6.4375,   7.0859,  ...,  -1.8662,  -2.8320,   1.1387],
         [ -5.0391,  -6.3281,  10.8828,  ...,  -5.5820,  -5.4141,  -4.2422],
         [ -7.5430,  -9.3594,  12.1406,  ...,  -2.5508,  -4.7422,  -3.6387]],

        [[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [ -6.4531,   2.7012,   4.7461,  ...,   4.3711,   0.5249,   3.3906],
         [-11.1562,  -4.4297,   3.6445,  ...,  -5.2891,  -5.6016,  -2.5488],
         ...,
         [ -6.9062,   3.8574,   3.2930,  ...,  -1.6797,  -3.1992,   0.1455],
         [ -7.0000,   3.8105,   3.4082,  ...,  -1.7188,  -3.2617,   0.1693],
         [ -7.0000,   3.7988,   3.4570,  ...,  -1.7139,  -3.2520,   0.2225]]],
       device='cuda:0')
torch.Size([2, 289, 1]) tensor([[[  917],
         [18220],
         [11028],
         [   13],
         [ 1576],
         [   13],
         [29875],
         [   13],
         [ 2563],
         [29907],
         [   13],
         [29903],
         [17061],
         [ 3235],
         [   13],
         [  319],
         [ 3235],
         [  847],
         [   13],
         [ 2277],
         [ 1494],
         [  279],
         [  847],
         [ 1718],
         [ 7228],
         [29914],
         [  382],
         [ 6530],
         [ 3235],
         [29914],
         [  338],
         [  263],
         [  304],
         [  363],
         [  263],
         [ 6694],
         [  310],
         [ 7662],
         [ 1020],
         [ 9183],
         [  363],
         [  739],
         [ 7306],
         [  526],
         [ 1058],
         [18690],
         [ 1766],
         [  262],
         [  414],
         [29892],
         [ 9345],
         [29892],
         [  671],
         [  278],
         [ 9775],
         [  304],
         [ 6944],
         [  322],
         [ 2362],
         [  310],
         [  278],
         [ 4072],
         [  310],
         [ 2971],
         [  279],
         [29892],
         [ 1718],
         [  360],
         [ 2650],
         [  428],
         [  322],
         [  390],
         [ 9776],
         [  511],
         [ 9033],
         [ 7228],
         [  313],
         [28451],
         [ 2454],
         [ 4957],
         [  279],
         [18399],
         [ 1259],
         [  319],
         [ 4841],
         [  511],
         [  322],
         [ 6530],
         [ 3235],
         [  313],
         [29923],
         [  781],
         [ 1617],
         [  293],
         [14477],
         [17440],
         [ 1126],
         [10343],
         [ 2184],
         [  511],
         [  322],
         [  319],
         [ 3235],
         [  313],
         [28451],
         [ 2454],
         [13355],
         [ 2450],
         [ 2184],
         [  467],
         [   13],
         [  310],
         [  338],
         [ 7093],
         [  338],
         [  367],
         [ 1304],
         [  297],
         [  470],
         [ 1906],
         [ 2450],
         [  470],
         [29892],
         [  408],
         [  964],
         [   13],
         [ 9775],
         [  338],
         [  338],
         [  310],
         [  263],
         [ 2971],
         [16355],
         [29892],
         [ 5281],
         [  278],
         [ 9281],
         [  294],
         [13132],
         [ 3439],
         [29875],
         [29899],
         [29903],
         [ 4983],
         [29871],
         [29889],
         [   13],
         [ 5073],
         [ 5073],
         [  338],
         [ 1592],
         [ 4866],
         [29899],
         [18785],
         [ 1788],
         [29899],
         [14394],
         [ 1027],
         [  411],
         [  263],
         [18690],
         [ 8727],
         [ 1904],
         [ 1076],
         [ 5073],
         [29892],
         [  263],
         [ 2971],
         [29906],
         [29900],
         [30024],
         [ 2971],
         [ 2479],
         [  292],
         [  322],
         [  263],
         [  279],
         [29914],
         [ 1718],
         [ 7228],
         [29914],
         [  382],
         [ 6530],
         [ 3235],
         [14423],
         [29909],
         [ 3235],
         [14423],
         [29889],
         [   13],
         [   13],
         [ 2277],
         [ 4957],
         [  338],
         [ 1973],
         [  278],
         [  278],
         [  278],
         [ 2710],
         [  338],
         [ 2309],
         [25706],
         [24285],
         [29889],
         [  450],
         [ 1342],
         [29892],
         [  278],
         [  278],
         [ 5285],
         [29892],
         [12945],
         [ 5073],
         [19569],
         [  508],
         [  338],
         [  367],
         [13252],
         [  408],
         [29892],
         [  263],
         [18893],
         [19711],
         [14354],
         [29889],
         [  512],
         [ 1790],
         [ 5285],
         [  599],
         [12945],
         [  367],
         [19623],
         [  408],
         [  263],
         [28635],
         [ 5004],
         [28635],
         [29889],
         [  278],
         [ 1021],
         [ 1737],
         [29889],
         [29889],
         [29875],
         [ 6931],
         [ 3476],
         [  267],
         [  467],
         [  512],
         [29892],
         [ 1269],
         [28635],
         [16355],
         [  303],
         [28635],
         [ 2710],
         [  508],
         [  367],
         [19623],
         [  304],
         [  263],
         [ 1021],
         [21239],
         [  297],
         [  278],
         [ 1021],
         [ 4038],
         [29889],
         [   13],
         [ 6511],
         [ 5285],
         [ 5285],
         [  338],
         [ 1304],
         [ 5407],
         [  363],
         [18819],
         [  278],
         [26807],
         [  310],
         [ 1422],
         [ 6694],
         [10907],
         [29889],
         [  278],
         [ 1021],
         [21239],
         [29889],
         [   13]],

        [[  917],
         [29896],
         [   13],
         [29937],
         [29889],
         [  287],
         [29940],
         [29901],
         [ 1724],
         [  437],
         [ 7201],
         [  681],
         [29973],
         [ 2361],
         [  278],
         [  261],
         [ 3496],
         [29973],
         [  263],
         [  996],
         [29889],
         [   13],
         [ 9166],
         [ 1124],
         [  372],
         [  263],
         [ 2769],
         [ 2769],
         [ 2020],
         [ 4918],
         [  261],
         [  681],
         [ 5330],
         [  451],
         [ 2304],
         [ 4918],
         [29882],
         [ 3496],
         [  297],
         [  263],
         [ 5100],
         [ 2984],
         [29973],
         [   13],
         [29896],
         [29962],
         [   13],
         [ 1182],
         [29958],
         [   13],
         [29915],
         [ 1284],
         [  310],
         [  738],
         [ 2769],
         [ 2769],
         [ 5381],
         [ 2769],
         [ 2020],
         [  541],
         [  306],
         [ 4918],
         [  304],
         [ 1580],
         [  393],
         [29889],
         [29889],
         [29886],
         [29958],
         [29896],
         [29962],
         [ 2045],
         [  597],
         [ 2490],
         [29889],
         [ 2490],
         [  261],
         [  681],
         [29889],
         [  510],
         [29914],
         [ 2490],
         [  804],
         [29899],
         [ 1454],
         [29899],
         [ 1552],
         [  261],
         [  681],
         [29899],
         [   13],
         [   13],
         [   13],
         [   13],
         [  272],
         [29906],
         [   13],
         [10363],
         [29892],
         [  261],
         [ 3496],
         [  338],
         [29915],
         [29873],
         [ 1863],
         [  746],
         [11102],
         [29876],
         [29915],
         [29873],
         [15241],
         [  746],
         [  278],
         [  931],
         [ 4918],
         [ 4918],
         [29879],
         [  471],
         [ 3971],
         [17625],
         [29889],
         [   13],
         [   13],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [30488],
         [   13],
         [   13],
         [29937],
         [29937],
         [29937],
         [29937],
         [29937],
         [29937],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 289, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [18220, 12037, 29899,  ..., 29871,  4384, 10781],
         [11028, 19916, 15057,  ...,   322, 11264, 29901],
         ...,
         [21239, 15058,  7751,  ..., 24472,  6434, 10655],
         [29889,  4038, 10483,  ...,  3414,   322,   297],
         [   13,   450,     2,  ...,  2178,  7806,  1152]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [   13,  4345, 29871,  ...,   448,  1576, 29954],
         [   13,  4345, 29871,  ...,   448,  1576,   268],
         [   13,  4345, 29871,  ...,   448,  1576,   268]]], device='cuda:0')
Batch 6, 10.7% of total tokens
encoded shape: torch.Size([2, 485])
torch.Size([2, 485]) tensor([[    1,   660, 29901,    13,    13, 11008,   526,   429,  1169,  4312,
           297,   278, 22513, 29973,    13,    13,  3644,   896, 29915,   276,
          2221,   304, 15833,   964,   278, 22513, 29892,   896, 29915,   276,
          4969,  1438,  1014, 14608,  1475,   393,  6467,  7656, 29915, 29873,
          1863,   297,   278,  1824, 29889,  2688,   526,  2221,   304,  2615,
           714,   310,  1286,  4150,   964,   278, 22513, 29892,  2020,   508,
         29915, 29873,   896,   925, 25417,   714,   310,  1286,  4150,   515,
           278, 22513, 29973,    13, 11008,   278,   817,   363,   385,   525,
         13322, 29915, 29973,    13,    13, 29909, 29901,    13,    13, 29902,
          4658,   445,   338,   278, 22513, 29915, 29879,  1873,   310,   376,
          3112,   338,  1286,  9109,   304,  3349,   596,  4742,   515,   278,
          6601,  1213,    13,  4806,  1073,   393,   278, 22513,   338,   263,
          1824,   393,   338, 16467,  1006,  7516,  1312,   411,   596,  3458,
           322, 17294,   297,   777,  8214, 29892,  8151,   278, 10899, 14886,
           322,  4892, 29899,  1609, 29899,   348,   572,   688,  3460, 29889,
           739,  2444,   393,   372,  4225,   304, 23511,  6507,   278,  7788,
          1434,   263,  1824,   508,   367,   443, 15638,   313,  1576, 10995,
           950,  1583,  1967,   338,  3528,   263,  1824,   393,  6057,  2768,
           278, 22513, 29892,   541, 20704,   491,   967, 12271, 29897,    13,
          2887,   363,   278,  4423,   310,   278,   429,  1169, 29901,   450,
         22513,  5692,   304,   367,   263,  7047,  1788,   988,  4129,   756,
           263,  9128, 10419,   362,  2629,   372, 29889,  1670,   526,   694,
          1661, 29899,  2616, 29886,   487,   284,  1824,  2734,  2629,   372,
           408,  2215,   408,   306,  1073, 29889,  4059,  1237,   526,   451,
          1788,  9377,  2740, 11104, 29892,   541,  5199,  5560, 11104, 29889,
           450, 16703,   261,   338,   263, 22549, 29889,   319,  6494,   338,
           385, 17564, 29899,  4561,  4742,  6866,   798,   292,   297,   596,
           633, 29881,  2770,  2992, 29889,    13,  6295,   746,   896,  2254,
           738,  1824,   964,   278, 22513, 29892,  1316,   408,   263,  6876,
          1014, 14608,   457, 29892,   306,  1348,   896,   505,   304,  2254,
           372,   304,   263,  9128,  4423,   411,   263,  9128,   883, 29889,
         10133,   278,  4382,  6710,  1045,   720, 29889,    13,    13, 29909,
         29901,    13,    13, 10858,  5188,   895,  2444,  2743, 29889,   512,
           278,   937, 14064,   372,   338,  4318,   393,   896,   884,  1996,
           263,  2898, 29899,  1220,   304,  3896,   278,  4636,   313,  1552,
          2586,   988,  3879, 28362,   375, 10753,   304,   679,  2448, 29877,
           304,   278, 15401,   467,  2688,   508,  9008,   411, 12768,  3025,
         10426,  1374,  2873, 29892,   541,   451,  6782,  6053,  1728,   278,
           671,   310,   263,  2898, 29899,  1220, 29889,  2448,  2121,   297,
          3643,   714, 29889,    13, 11008,   263, 10426,   508,   367,  1304,
           304,  9008,   541,   451, 22649,   278,   390,  5425, 29892,  1033,
         29279,   304,  1418,   279,   403, 29889,  1205,   472,  3203,   278,
           671,   310,  2898, 29899,  9012,  7186, 29889, 22458,  5475,  5692,
           304,   367, 13747, 29889,    13,    13,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2],
        [    1,   518,  8208, 29899,  8489,  6366,  4135,   310, 11834,   392,
           747,  1070,   330,  1049,  6782,   363,  5557,   291,   310,   921,
           261,   520,   290,   423,  1156, 17937,  1228, 27580,   363,  8281,
          3021,   653, 29876,   479,   284,  1559, 16381,  4125,  1822,    13,
          1762, 14707,   278,  1472, 29899,  8489,  6366,  4135,   310, 11834,
           392,   747,  1070,   330,  1049,  6782,   363,  5557,   291,   310,
           921,   261,   520,   290,   423,  1156, 17937,  1228, 27580,   363,
          8281,  3021,   653, 29876,   479,   284,  1559, 16381,  4125, 29889,
          6101, 29312, 29899, 20818,  4251,   310,  8281,  3021,   653, 29876,
           479,   284,  1559, 16381,  4125, 22069,   892, 20459, 13931,   964,
          6559,  2318,   310, 29871, 29941, 29906, 22069,   322,  2761,  2318,
           310, 29871, 29941, 29941,  2373,  1237, 29889,   450, 11834,   392,
           747,  1070,   330,  1049,   471, 18440,   304,  1014,   358,   284,
          5120,   373, 29871, 29941, 29906,  4251,   411,  8281,  3021,   653,
         29876,   479,   284,  1559, 16381,  4125,  1434, 13442, 28557, 17937,
          1228, 27580,   322,   263,  2908,   471,  1304,   304,  4612,   278,
          1014,   358,   284,  5120, 29889, 10949, 17937,  1228, 27580, 29892,
          1023,  6471,   310, 11834,   392,   747,  1070,   330,  1049,   740,
           471, 17809,   491,  6382,   292,   310,   278, 11834,   392,   747,
          1070,   330,  1049, 29889,  2180, 29871, 29953, 29900,  7378,  1156,
         17937,  1228, 27580, 29892, 11834,   392,   747,  1070,   330,  1049,
           740,   471, 17809,   491, 29871, 29929, 29929, 29885, 29911, 29883,
          2971,   291, 26340,   885,  9450, 29892,   278,  1139, 15421,  1048,
           278,  7426,   310,   921,   261,   520,   290,   423,   471,  7405,
           630,  8307, 29889, 22853, 29899,  6360, 10503,  2561,  6554,   471,
         29115, 29889,  2860,  1494,   701,   363, 29871, 29953, 29900,  7378,
         29892, 11834,   392,   747,  1070,   330,  1049,   318,   415,  1296,
           322,  7035,   291,   740,   297,   278,  6559,  2318,   471, 16951,
          6133,  1135,   393,   297,   278,  2761,  2318, 29892,   727,   471,
          7282,  4328,  1546,   278,  1023,  6471,   313, 29925,   529, 29871,
         29900, 29889, 29900, 29896, 29897,  8307, 29889,   450,  5528,  5084,
           310, 17768,   403,   470, 22261,   921,   261,   520,   290,   423,
           297,   278,  6559,  2318,   471, 16951,  5224,  1135,   393,   297,
           278,  2761,  2318,   313, 29896, 29945, 29889, 29946, 29995,  7186,
         29871, 29955, 29953, 29889, 29929, 13667,   349,   529, 29871, 29900,
         29889, 29900, 29896,   467, 22853, 29899,  6360, 10503,  2561,  6554,
           310,   278,  6559,  2318,   322,  2761,  2318,   471, 29871, 29947,
         29896, 29889, 29941, 29995,   322, 29871, 29955, 29947, 29889, 29947,
         29995,  8307, 29892,   727,   471,   694,  7282,  4328,  1546,   278,
          1023,  6471,   313, 29925,  1405, 29871, 29900, 29889, 29900, 29945,
           467,   450,  1472, 29899,  8489,  6366,  4135,   310, 11834,   392,
           747,  1070,   330,  1049,  6782,   363,  5557,   291,   310,   921,
           261,   520,   290,   423,  1156, 17937,  1228, 27580,   363,  8281,
          3021,   653, 29876,   479,   284,  1559, 16381,  4125,   471,  1532,
         29889,   739,  1033, 11157,   278, 11029,   310,  2834,   297,  8281,
          3021,   653, 29876,   479,   284,  1559, 16381,  4125, 22069,  1156,
         17937,  1228, 27580, 29892,   322,  1258,   451,  6602,   278,  1472,
         29899,  8489,  6366,  4135,   310,  8281,  3021,   653, 29876,   479,
           284,  1559, 16381,  4125, 29889]], device='cuda:0')
torch.Size([2, 485, 32000]) tensor([[[-12.7969,  -7.3047,  -0.4807,  ...,  -6.7695,  -8.0078,  -7.4883],
         [-10.8672, -10.6484,  -2.9961,  ...,  -6.8164, -10.0938,  -6.8672],
         [-13.6172, -13.5312,  -1.4951,  ...,  -7.1445,  -8.3281,  -5.6484],
         ...,
         [-11.8047,  -3.8691,   0.9072,  ...,  -5.5273,  -6.6836,  -3.9707],
         [-11.9141,  -3.9004,   0.8174,  ...,  -5.6914,  -6.8086,  -4.2422],
         [-12.0703,  -3.9434,   0.6416,  ...,  -5.9219,  -6.9805,  -4.5938]],

        [[-12.7969,  -7.3047,  -0.4807,  ...,  -6.7695,  -8.0078,  -7.4883],
         [-10.0469, -11.1719,   0.1138,  ...,  -2.9434,  -3.9492,  -1.6406],
         [-11.0312, -13.2812,  -4.7266,  ...,  -7.4180,  -7.2305,  -8.0703],
         ...,
         [ -5.2734,  -7.4492,  12.0078,  ...,  -0.8247,  -1.1230,  -3.4453],
         [ -4.6445,  -5.4570,  13.9375,  ...,   0.3774,  -5.2500,  -4.4648],
         [ -1.4951,  -3.5312,  17.8438,  ...,   1.2686,  -2.6094,  -0.5342]]],
       device='cuda:0')
torch.Size([2, 485, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         [29902],
         [ 5618],
         [  338],
         [  727],
         [ 2232],
         [  297],
         [  297],
         [  263],
         [  937],
         [29973],
         [   13],
         [   13],
         [29909],
         [  366],
         [  526],
         [  276],
         [  451],
         [  304],
         [  679],
         [  964],
         [  278],
         [22513],
         [29892],
         [ 2020],
         [  508],
         [  276],
         [ 2221],
         [  263],
         [  429],
         [14608],
         [ 1475],
         [29892],
         [  526],
         [ 7656],
         [29915],
         [29873],
         [ 1863],
         [29889],
         [  278],
         [22513],
         [29889],
         [   13],
         [29915],
         [ 2221],
         [  304],
         [ 1653],
         [  297],
         [  310],
         [16835],
         [ 4150],
         [29892],
         [  278],
         [22513],
         [29892],
         [  322],
         [  508],
         [29915],
         [29873],
         [  896],
         [  925],
         [ 2615],
         [29973],
         [  310],
         [ 1286],
         [ 4150],
         [29973],
         [  278],
         [22513],
         [29973],
         [   13],
         [   13],
         [  437],
         [  817],
         [  363],
         [  385],
         [ 6876],
         [13322],
         [29915],
         [29973],
         [   13],
         [   13],
         [29909],
         [29901],
         [   13],
         [   13],
         [ 1576],
         [ 1348],
         [  278],
         [  338],
         [  263],
         [ 1021],
         [29915],
         [29879],
         [  982],
         [  310],
         [  263],
         [ 1552],
         [29915],
         [19752],
         [ 9109],
         [  304],
         [ 2507],
         [  278],
         [ 1081],
         [  515],
         [  278],
         [23630],
         [ 1213],
         [   13],
         [   13],
         [29915],
         [  393],
         [  278],
         [22513],
         [  338],
         [  263],
         [ 6601],
         [29892],
         [  338],
         [ 2734],
         [21351],
         [ 7516],
         [ 1312],
         [  411],
         [  278],
         [17294],
         [29889],
         [ 3573],
         [29889],
         [  278],
         [  982],
         [29889],
         [  322],
         [  278],
         [11509],
         [14886],
         [  393],
         [ 4892],
         [29879],
         [ 4561],
         [29899],
         [ 1127],
         [  572],
         [  688],
         [ 3460],
         [29889],
         [   13],
         [29915],
         [  393],
         [  278],
         [  338],
         [  304],
         [  367],
         [ 3349],
         [  366],
         [ 1404],
         [  372],
         [  372],
         [ 1404],
         [  508],
         [  367],
         [29185],
         [15638],
         [29889],
         [  272],
         [22513],
         [  950],
         [ 9545],
         [29899],
         [  338],
         [  263],
         [  263],
         [ 1824],
         [29892],
         [  338],
         [  297],
         [  278],
         [22513],
         [  467],
         [  322],
         [  372],
         [  491],
         [  278],
         [ 1404],
         [  467],
         [   13],
         [   13],
         [  363],
         [  278],
         [  376],
         [  310],
         [  278],
         [ 6876],
         [ 1169],
         [29892],
         [   13],
         [22513],
         [  338],
         [  304],
         [  367],
         [  263],
         [29871],
         [ 1824],
         [  393],
         [  278],
         [  338],
         [  263],
         [ 4423],
         [ 4423],
         [  362],
         [29889],
         [  278],
         [29889],
         [  450],
         [  526],
         [  694],
         [  376],
         [29899],
         [14017],
         [29886],
         [  487],
         [  284],
         [  429],
         [  429],
         [  297],
         [  278],
         [29889],
         [ 2215],
         [  408],
         [  591],
         [  508],
         [29889],
         [   13],
         [ 1237],
         [  526],
         [  451],
         [  330],
         [11104],
         [11104],
         [  322],
         [29892],
         [  896],
         [ 3265],
         [19518],
         [11104],
         [  393],
         [   13],
         [22513],
         [  261],
         [24334],
         [  263],
         [ 1824],
         [  393],
         [  450],
         [ 1824],
         [  338],
         [  263],
         [17564],
         [29889],
         [ 4561],
         [ 1824],
         [29889],
         [  798],
         [  292],
         [  964],
         [  596],
         [17294],
         [29881],
         [ 2770],
         [29889],
         [29889],
         [   13],
         [   13],
         [  278],
         [  366],
         [  526],
         [  278],
         [ 1824],
         [29892],
         [  278],
         [22513],
         [29892],
         [  372],
         [  408],
         [  278],
         [ 1014],
         [29892],
         [14608],
         [  457],
         [29892],
         [  372],
         [ 4658],
         [  372],
         [  505],
         [  304],
         [  505],
         [  372],
         [  964],
         [  263],
         [ 9128],
         [ 4423],
         [29889],
         [  263],
         [ 9128],
         [10419],
         [29889],
         [   13],
         [  278],
         [  817],
         [ 6710],
         [ 1045],
         [  720],
         [29879],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [ 1576],
         [ 1139],
         [  895],
         [  338],
         [  304],
         [29889],
         [  450],
         [  278],
         [22513],
         [ 2058],
         [29892],
         [  338],
         [ 4318],
         [  393],
         [  278],
         [  508],
         [  505],
         [  263],
         [ 9128],
         [29899],
         [29893],
         [ 3957],
         [  278],
         [  278],
         [22513],
         [29889],
         [ 1552],
         [ 9008],
         [  988],
         [  896],
         [28362],
         [  375],
         [  338],
         [  304],
         [18665],
         [  278],
         [29877],
         [  714],
         [18665],
         [  376],
         [  467],
         [   13],
         [  884],
         [29915],
         [  297],
         [  263],
         [29892],
         [  278],
         [ 1374],
         [ 2873],
         [29892],
         [  541],
         [  896],
         [ 3896],
         [  304],
         [29889],
         [  263],
         [ 2898],
         [  310],
         [  263],
         [ 2898],
         [29899],
         [ 1220],
         [29889],
         [   13],
         [29877],
         [  508],
         [  278],
         [  714],
         [29889],
         [   13],
         [   13],
         [  723],
         [ 2898],
         [ 9008],
         [29915],
         [ 1304],
         [  304],
         [ 9008],
         [  297],
         [  451],
         [  304],
         [29973],
         [ 1404],
         [ 5425],
         [  338],
         [  306],
         [  367],
         [  304],
         [  278],
         [  284],
         [  403],
         [29889],
         [   13],
         [  306],
         [  278],
         [  297],
         [  390],
         [  310],
         [  263],
         [29899],
         [ 9012],
         [  338],
         [29889],
         [10426],
         [ 5475],
         [  338],
         [  304],
         [  367],
         [  263],
         [29889],
         [   13],
         [   13],
         [20001],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [29873],
         [29873],
         [   13],
         [30488],
         [30488],
         [30488],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [12614],
         [29899],
         [ 8489],
         [ 1101],
         [ 4135],
         [  310],
         [  263],
         [ 1682],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [ 6782],
         [  297],
         [ 2258],
         [  291],
         [  310],
         [  921],
         [  261],
         [  520],
         [  290],
         [  423],
         [  297],
         [17937],
         [ 1228],
         [27580],
         [  363],
         [ 2343],
         [ 3021],
         [  653],
         [29876],
         [  479],
         [  284],
         [ 1559],
         [16381],
         [ 4125],
         [ 1822],
         [   13],
         [29940],
         [14707],
         [  278],
         [ 1472],
         [29899],
         [ 8489],
         [ 6366],
         [ 4135],
         [  310],
         [11834],
         [  392],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [ 6782],
         [  363],
         [ 5557],
         [  291],
         [  310],
         [  921],
         [  261],
         [  520],
         [  290],
         [  423],
         [ 1156],
         [17937],
         [ 1228],
         [27580],
         [  363],
         [ 8281],
         [ 3021],
         [  653],
         [29876],
         [  479],
         [  284],
         [ 1559],
         [16381],
         [ 4125],
         [29889],
         [   13],
         [29312],
         [29899],
         [  650],
         [22069],
         [  310],
         [ 8281],
         [ 3021],
         [  653],
         [29876],
         [  479],
         [  284],
         [ 1559],
         [16381],
         [ 4125],
         [  892],
         [ 1058],
         [14914],
         [13931],
         [  964],
         [ 1023],
         [ 2318],
         [  322],
         [29871],
         [29941],
         [29906],
         [ 4251],
         [  322],
         [ 2761],
         [ 2318],
         [  310],
         [29871],
         [29941],
         [29941],
         [22069],
         [ 1237],
         [29889],
         [  450],
         [22069],
         [  392],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [  471],
         [18440],
         [  304],
         [  278],
         [ 1847],
         [  284],
         [ 4038],
         [  297],
         [  278],
         [29896],
         [29906],
         [22069],
         [  297],
         [ 8281],
         [ 3021],
         [  653],
         [29876],
         [  479],
         [  284],
         [ 1559],
         [16381],
         [ 4125],
         [29889],
         [17937],
         [17937],
         [17937],
         [ 1228],
         [27580],
         [29889],
         [29871],
         [ 2323],
         [  310],
         [ 1754],
         [  304],
         [ 4612],
         [  278],
         [18440],
         [  358],
         [  284],
         [ 5120],
         [  373],
         [  450],
         [  322],
         [ 1228],
         [27580],
         [29892],
         [  278],
         [ 6471],
         [  892],
         [22069],
         [  392],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [  892],
         [  892],
         [19030],
         [  491],
         [  330],
         [  292],
         [  322],
         [  278],
         [11834],
         [  392],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [29889],
         [  450],
         [  278],
         [29896],
         [ 7378],
         [ 7378],
         [ 1156],
         [17937],
         [ 1228],
         [27580],
         [29892],
         [  278],
         [  392],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [  740],
         [  471],
         [17809],
         [  491],
         [ 6382],
         [29929],
         [29929],
         [29885],
         [29911],
         [29883],
         [29899],
         [  291],
         [26340],
         [ 6382],
         [  524],
         [29889],
         [  322],
         [ 4497],
         [15421],
         [  310],
         [  921],
         [11029],
         [  310],
         [  921],
         [  261],
         [  520],
         [  290],
         [  423],
         [  471],
         [ 1304],
         [  630],
         [  322],
         [29889],
         [  450],
         [ 4251],
         [ 6360],
         [10503],
         [ 2561],
         [ 6554],
         [  471],
         [29871],
         [29889],
         [  450],
         [17937],
         [29899],
         [  363],
         [29871],
         [29953],
         [29900],
         [ 7378],
         [29892],
         [  278],
         [  392],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [  740],
         [  415],
         [ 1296],
         [  471],
         [  278],
         [  291],
         [  892],
         [  310],
         [  278],
         [ 6559],
         [ 2318],
         [  471],
         [16951],
         [ 2253],
         [ 1135],
         [  393],
         [  297],
         [  278],
         [ 2761],
         [ 2318],
         [  313],
         [  322],
         [  471],
         [  694],
         [ 4328],
         [ 1546],
         [  278],
         [ 1023],
         [ 6471],
         [  313],
         [29925],
         [  529],
         [29871],
         [29900],
         [29889],
         [29900],
         [29945],
         [  467],
         [  322],
         [29889],
         [  450],
         [ 7426],
         [ 5084],
         [  310],
         [  921],
         [  403],
         [  322],
         [22261],
         [  921],
         [  261],
         [  520],
         [  290],
         [  423],
         [  297],
         [  278],
         [ 6559],
         [ 2318],
         [  471],
         [16951],
         [ 5224],
         [ 1135],
         [  393],
         [  297],
         [  278],
         [ 2761],
         [ 2318],
         [  313],
         [29925],
         [29945],
         [29889],
         [29953],
         [29995],
         [ 7186],
         [29871],
         [29945],
         [29906],
         [29889],
         [29896],
         [13667],
         [  349],
         [  529],
         [29871],
         [29900],
         [29889],
         [29900],
         [29896],
         [  467],
         [  450],
         [29899],
         [ 6360],
         [10503],
         [ 2561],
         [ 6554],
         [  471],
         [  278],
         [ 6559],
         [ 2318],
         [  471],
         [  278],
         [ 2318],
         [  471],
         [29871],
         [29929],
         [29946],
         [29889],
         [29941],
         [29995],
         [  322],
         [29871],
         [29955],
         [29947],
         [29889],
         [29947],
         [29995],
         [ 8307],
         [29889],
         [  727],
         [  471],
         [  694],
         [ 7282],
         [ 4328],
         [ 1546],
         [  278],
         [ 1023],
         [ 6471],
         [  313],
         [29925],
         [ 1405],
         [29871],
         [29900],
         [29889],
         [29900],
         [29945],
         [  467],
         [ 3323],
         [11834],
         [29899],
         [ 8489],
         [ 6366],
         [ 4135],
         [  310],
         [11834],
         [  392],
         [  747],
         [ 1070],
         [  330],
         [ 1049],
         [ 6782],
         [  363],
         [ 5557],
         [  291],
         [  310],
         [  921],
         [  261],
         [  520],
         [  290],
         [  423],
         [ 1156],
         [17937],
         [ 1228],
         [27580],
         [  363],
         [ 8281],
         [ 3021],
         [  653],
         [29876],
         [  479],
         [  284],
         [ 1559],
         [16381],
         [ 4125],
         [  338],
         [ 7282],
         [29889],
         [   13],
         [  338],
         [  367],
         [  278],
         [11029],
         [  310],
         [ 2834],
         [  310],
         [22069],
         [ 3021],
         [  653],
         [29876],
         [  479],
         [  284],
         [ 1559],
         [16381],
         [ 4125],
         [22069],
         [29889],
         [17937],
         [ 1228],
         [27580],
         [29889],
         [  322],
         [  372],
         [  451],
         [ 6602],
         [  278],
         [10503],
         [29899],
         [ 8489],
         [10503],
         [ 4135],
         [  310],
         [17937],
         [ 3021],
         [  653],
         [29876],
         [  479],
         [  284],
         [ 1559],
         [16381],
         [ 4125],
         [14502],
         [   13]]], device='cuda:0')
torch.Size([2, 485, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,  1576, 29961,  ..., 29902, 29909,   275],
         [   13,  1576, 29961,  ..., 29909, 29902,   275],
         [   13,  1576, 29961,  ...,   275, 29909, 29902]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [12614, 29896, 29906,  ..., 29924, 29943, 29933],
         [29899, 29962, 17594,  ...,   931,   434,  7523],
         ...,
         [ 4125, 18902,   290,  ...,   655,   272,  2207],
         [14502, 29889, 22069,  ...,  2761, 25300,  8950],
         [   13,     2,   313,  ...,   910,  7857, 29871]]], device='cuda:0')
Batch 7, 11.6% of total tokens
encoded shape: torch.Size([2, 482])
torch.Size([2, 482]) tensor([[    1, 23001,    13,    13,  2890, 29909,  3913, 21046,   304,  5702,
          1998,  1169,   304,  1749,  4700,   871, 29892,   694,  7333,  2472,
           338, 16531, 29889,  2648,  3133,   292,   304,   671,   278,  3268,
           366,   526,  8661,   292,   304,  1749,   671,   310, 21046, 29889,
          9280, 12542,   714,   901,  1048,  1749, 15327,  8898, 29889,    13,
            13,   557,  1306,    13,    13, 15753, 15670, 29945,   448,   319,
         29968,  1718, 29902,    13,    13, 28938,  1672, 29899, 29943,  7824,
         23861, 18601, 10130, 15670,   396, 29945,    13,    13, 28938,  1672,
         29899, 29943,  9859,  6826,  2635,   310, 29871, 29896, 29947,  6339,
         29871, 29906, 29900, 29900, 29953,    13,    13,  2890,  2477, 29892,
         29871, 29896, 29906,  5846, 29871, 29906, 29900, 29900, 29945,    13,
         29928,   799,   319,  1254,  1672, 29899, 29943,  1404, 29892,    13,
          3235,  3289, 29914, 16405, 29909,   756,  9326,   393,   319,  1254,
          1672, 29899, 29943,   756,  1063,  2183,   278,  6221,  6826,  2635,
           310, 29871, 29896, 29947,  6339, 29871, 29906, 29900, 29900, 29953,
         29889,    13,  4178,   278, 14121, 21775,  1907, 11444,  2191, 15133,
           373, 29871, 29955,  5846, 29892,   372,   471, 24084,  3192,   393,
           319,  1254,  1672, 29899, 29943,   723,    13,   915, 15241,   491,
           278,   341, 29899, 29963, 29947,   696,  3522,   373, 29871, 29896,
         29947,  6339, 29871, 29906, 29900, 29900, 29953,   515,   278,   476,
           351, 10578,  2946,  6826,  3268, 29889,   450,  6826,    13,  7165,
          4694,   267,   373, 29871, 29906, 29947,  6339, 29889,    13, 29928,
          3864,   445, 12267,  4259, 29892,  1023,   916,  3290,   514,  3246,
           526, 21467,   304,   367, 15241,   491,   435,  6604, 29909, 29901,
           278, 29287,    13, 22677,  4250,   643,  1747, 12178, 20911,   313,
          1964,  3267, 29897,   373, 29871, 29896, 29929,  5490,   322,   278,
         14974, 29899,  6678,   284, 15710, 12178, 20911, 29871, 29906,    13,
         29898, 29924,  9375,  1299, 29899, 29906, 29897,   373, 29871, 29896,
         29945,  6339, 29889,  4525,  6826,   267,   674,   367,  1754,   411,
           379, 29899,  2687, 29909,  7679,  1691,   515,   435,  6604, 29909,
         29915, 29879,  5684,    13, 15343,  3268,   313, 29911,   273,   387,
          1161,  2946,   467,   450,   319,  1254,  1672, 29899, 29943,   322,
           341, 29899, 29963,  2060, 10907,   674,   367,  7960,   304,  6826,
           319,  1254,  1672, 29899, 29943,   408,    13,   799,   368,   408,
         29871, 29896, 29953,  6339,   881,   278, 20410,   411,  1438,   916,
          6826,   267,   367,  9120, 29889,    13, 28938,  1672, 29899, 29943,
          4911, 18601,  3815,    13,  9166,  9166,  9166,  9166,  4936,  2751,
         29922,    13,  4013,  9763, 15670,   338,  2665,   304,   278,  7824,
         23861, 18601, 18623,   292,  1051, 29889,    13,  1762,  1014, 13086,
         29914,   348, 19496, 29892,  3113,  6493,  1749, 22305,  2783, 29895,
          2563,   349,  1179, 29892,    13,  1124,   597,  1636, 29889, 23364,
         29899, 29888, 29889, 17191,  1028, 29874, 29889,  8625, 29889,   267,
         29914,   267, 29884,  3016, 29914,    13, 29961, 29967, 21419, 29914,
         29968,   487, 29874, 29962,  1732,   597,  1636, 29889,   381, 29889,
           275,   294, 29889,  6487, 29874, 29889, 16865, 29914, 28938,  1672,
         29899, 29943, 29914,  6039,  2140,   362, 29914,    13, 29961, 15654,
         29962,  1732,   597, 23364, 29899, 29888, 29889,   267,   562, 29889,
          8625, 29889,   524, 29914,    13,  9166,  9166,  9166,  9166,  4936,
          2751, 29922],
        [    1,  9683,   333, 11124, 17711, 18764,   284,  6354,   310,  3635,
           621,  2904, 26511, 25977,   350,   626,   680, 25748, 29889,    13,
         29909,  3652,   310,   626,   680, 25748,   310,  3635,   621,  2904,
         26511, 25977,   350,   892, 13240,   322,  4392,  1312,   408,  1773,
           333, 11124, 17711,   313,  5773, 29934, 29897, 18764,   284, 19518,
          8632,  1218,   393,   278,   315, 29945,  1559,  1884,  2904,   403,
           338, 17644, 20341,   424,   310,  1316,  7750,   271,  2133, 29889,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 482, 32000]) tensor([[[-12.7969,  -7.3047,  -0.4807,  ...,  -6.7695,  -8.0078,  -7.4883],
         [-11.0703,  -7.5039,  -1.5225,  ...,  -7.9414,  -5.6133,  -7.2969],
         [ -9.6328,  -4.5117,   4.1211,  ...,  -4.2109,  -5.1406,  -3.2070],
         ...,
         [ -3.9297,  -2.2109,  13.2969,  ...,  -0.1648,  -1.6016,   0.1183],
         [  0.1220,   1.2705,  16.6094,  ...,   2.1465,   1.6533,   3.4727],
         [  2.0098,   5.1328,  18.2656,  ...,  -0.7051,  -0.2166,   1.0537]],

        [[-12.7969,  -7.3047,  -0.4807,  ...,  -6.7695,  -8.0078,  -7.4883],
         [ -4.7148,  -4.9336,   1.3301,  ...,  -0.5884,  -1.3643,  -0.7417],
         [ -0.2754,  -2.9023,  -1.5713,  ...,   2.3711,   1.9609,   2.0430],
         ...,
         [ -9.6484,   4.1172,   3.8184,  ...,  -3.5078,  -5.3633,  -2.3516],
         [ -9.6484,   3.3848,   3.8770,  ...,  -3.5762,  -5.4570,  -2.5273],
         [ -9.6094,   3.2148,   3.8652,  ...,  -3.5762,  -5.4336,  -2.5195]]],
       device='cuda:0')
torch.Size([2, 482, 1]) tensor([[[  917],
         [29901],
         [   13],
         [29937],
         [29925],
         [ 1405],
         [21046],
         [  304],
         [ 1371],
         [  596],
         [ 1169],
         [  304],
         [ 1749],
         [28007],
         [29889],
         [29889],
         [  322],
         [ 7333],
         [  848],
         [  338],
         [16531],
         [29889],
         [   13],
         [  773],
         [  292],
         [  304],
         [  671],
         [  445],
         [ 3268],
         [29892],
         [  526],
         [ 8661],
         [  292],
         [  304],
         [ 1749],
         [  671],
         [  310],
         [21046],
         [29889],
         [   13],
         [   13],
         [  714],
         [  901],
         [   13],
         [21046],
         [  671],
         [ 8898],
         [29889],
         [   13],
         [   13],
         [29966],
         [ 1335],
         [   13],
         [ 9166],
         [29966],
         [   13],
         [   13],
         [   13],
         [29871],
         [29968],
         [ 1718],
         [29902],
         [10130],
         [   13],
         [   13],
         [ 1672],
         [29899],
         [29943],
         [   13],
         [ 3189],
         [29915],
         [14184],
         [15670],
         [   13],
         [29945],
         [   13],
         [   13],
         [   13],
         [ 1672],
         [29899],
         [29943],
         [ 7824],
         [  304],
         [ 2635],
         [   13],
         [29871],
         [29906],
         [29946],
         [  386],
         [29871],
         [29906],
         [29900],
         [29900],
         [29953],
         [   13],
         [   13],
         [ 1576],
         [29909],
         [29892],
         [14439],
         [29906],
         [29947],
         [ 5846],
         [29871],
         [29906],
         [29900],
         [29900],
         [29945],
         [   13],
         [   13],
         [  799],
         [  319],
         [ 1254],
         [ 1672],
         [29899],
         [29943],
         [ 4911],
         [29892],
         [   13],
         [   13],
         [ 3289],
         [29914],
         [16405],
         [29909],
         [  322],
         [ 9326],
         [  393],
         [  278],
         [ 1254],
         [ 1672],
         [29899],
         [29943],
         [  674],
         [ 1063],
         [ 9859],
         [  263],
         [ 6826],
         [ 6826],
         [ 2635],
         [  310],
         [29871],
         [29896],
         [29947],
         [ 6339],
         [29871],
         [29906],
         [29900],
         [29900],
         [29953],
         [29889],
         [   13],
         [   13],
         [  278],
         [ 1021],
         [17293],
         [ 1907],
         [11444],
         [11781],
         [15133],
         [ 4934],
         [29871],
         [29896],
         [ 5846],
         [29871],
         [  278],
         [  471],
         [ 8459],
         [ 3192],
         [  393],
         [  278],
         [ 1254],
         [ 1672],
         [29899],
         [29943],
         [  338],
         [  367],
         [  915],
         [15241],
         [  373],
         [  278],
         [  379],
         [29899],
         [29945],
         [  696],
         [  696],
         [ 3522],
         [  515],
         [29871],
         [29896],
         [29947],
         [ 6339],
         [29871],
         [29906],
         [29900],
         [29900],
         [29953],
         [29889],
         [  278],
         [15066],
         [  351],
         [10578],
         [ 2946],
         [14121],
         [ 3268],
         [29889],
         [   13],
         [ 6826],
         [   13],
         [ 7165],
         [  338],
         [  267],
         [  373],
         [29871],
         [29906],
         [29906],
         [ 6339],
         [29871],
         [   13],
         [   13],
         [ 3864],
         [  278],
         [ 3785],
         [29892],
         [29892],
         [  278],
         [  319],
         [ 3052],
         [  514],
         [ 3246],
         [  674],
         [21467],
         [  304],
         [  367],
         [15241],
         [29901],
         [  278],
         [ 6604],
         [29909],
         [29901],
         [   13],
         [   13],
         [   13],
         [22677],
         [ 4250],
         [  643],
         [ 1747],
         [12178],
         [20911],
         [  313],
         [ 1964],
         [ 3267],
         [29897],
         [  373],
         [29871],
         [29906],
         [29953],
         [ 5490],
         [  322],
         [  278],
         [12002],
         [29899],
         [29925],
         [  284],
         [12178],
         [12178],
         [20911],
         [  313],
         [29906],
         [  313],
         [29898],
         [29924],
         [ 9375],
         [ 1299],
         [29899],
         [29906],
         [29897],
         [  373],
         [29871],
         [29906],
         [29953],
         [ 6339],
         [29889],
         [   13],
         [ 6826],
         [  267],
         [  674],
         [  367],
         [ 5643],
         [  515],
         [  278],
         [29899],
         [ 2687],
         [29909],
         [ 7679],
         [ 1691],
         [  515],
         [  278],
         [ 6604],
         [29909],
         [29915],
         [29879],
         [15066],
         [   13],
         [15343],
         [ 3268],
         [  472],
         [29965],
         [  273],
         [  387],
         [ 1161],
         [ 2946],
         [29897],
         [   13],
         [ 6826],
         [ 1254],
         [ 1672],
         [29899],
         [29943],
         [ 6826],
         [14445],
         [ 9375],
         [29963],
         [29947],
         [10907],
         [  526],
         [  664],
         [ 1985],
         [  304],
         [ 2304],
         [  319],
         [ 1254],
         [ 1672],
         [29899],
         [29943],
         [   13],
         [   13],
         [  578],
         [  368],
         [  408],
         [ 1950],
         [29896],
         [29947],
         [ 6339],
         [29889],
         [  278],
         [  341],
         [ 2758],
         [  278],
         [  916],
         [ 3290],
         [  267],
         [ 2758],
         [29801],
         [29889],
         [   13],
         [   13],
         [ 1672],
         [29899],
         [29943],
         [  674],
         [18601],
         [   13],
         [   13],
         [   13],
         [ 9166],
         [ 9166],
         [ 9166],
         [ 4936],
         [ 2751],
         [25512],
         [   13],
         [   13],
         [ 9763],
         [15670],
         [  338],
         [13235],
         [  304],
         [  599],
         [  319],
         [  319],
         [  310],
         [ 8583],
         [  292],
         [ 2391],
         [29889],
         [   13],
         [ 1762],
         [ 1014],
         [13086],
         [  304],
         [  348],
         [19496],
         [29892],
         [ 3113],
         [ 3638],
         [29901],
         [ 4700],
         [ 2783],
         [29895],
         [  472],
         [ 1813],
         [ 1179],
         [29889],
         [  470],
         [ 1124],
         [  597],
         [ 1636],
         [29889],
         [  579],
         [29899],
         [29888],
         [29889],
         [  990],
         [ 1028],
         [29874],
         [29889],
         [ 8625],
         [29889],
         [  267],
         [29914],
         [ 8477],
         [  562],
         [ 3016],
         [29914],
         [ 8477],
         [ 9166],
         [ 2549],
         [21419],
         [  968],
         [15654],
         [  487],
         [29874],
         [29962],
         [   13],
         [  597],
         [ 1636],
         [29889],
         [23364],
         [29889],
         [  275],
         [  294],
         [29889],
         [ 6487],
         [29874],
         [29889],
         [16865],
         [29914],
         [  264],
         [ 1672],
         [29899],
         [29943],
         [29914],
         [   13],
         [ 2140],
         [  362],
         [29914],
         [29923],
         [29961],
         [15654],
         [29962],
         [ 1732],
         [  597],
         [ 1636],
         [29899],
         [29888],
         [29889],
         [17191],
         [  562],
         [29889],
         [ 8625],
         [29889],
         [  524],
         [29914],
         [  267],
         [ 9166],
         [ 9166],
         [ 9166],
         [ 9166],
         [ 4936],
         [ 2751],
         [29922],
         [   13]],

        [[  917],
         [  361],
         [  275],
         [29899],
         [  297],
         [  284],
         [  297],
         [  310],
         [  263],
         [  621],
         [17056],
         [  630],
         [29881],
         [  650],
         [  297],
         [  680],
         [  297],
         [   13],
         [   13],
         [ 1576],
         [ 3652],
         [  310],
         [ 3635],
         [  680],
         [25748],
         [  310],
         [ 3635],
         [  621],
         [ 2904],
         [26511],
         [25977],
         [  350],
         [  313],
         [14710],
         [  322],
         [19030],
         [ 1312],
         [  363],
         [  297],
         [  333],
         [11124],
         [17711],
         [  313],
         [ 5773],
         [29934],
         [29897],
         [18764],
         [  284],
         [19518],
         [29889],
         [ 1218],
         [  278],
         [  278],
         [23697],
         [29899],
         [29899],
         [ 1884],
         [ 2904],
         [  403],
         [ 2318],
         [  263],
         [13235],
         [  630],
         [  304],
         [23697],
         [23697],
         [  271],
         [ 2133],
         [29889],
         [  450],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 7228],
         [ 7228],
         [ 7228],
         [   13],
         [   13],
         [    3],
         [    3],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [    3],
         [    3],
         [    3],
         [   13],
         [   13],
         [   13],
         [   13],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [   13],
         [   13],
         [   13],
         [    3],
         [    3],
         [    3],
         [    3],
         [   13],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [ 7228],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [ 7228],
         [ 7228],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 482, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901,  8778,  4412,  ...,  9966,   584, 29892],
         [   13,  1576,  5328,  ..., 29911, 29933, 29950],
         ...,
         [ 2751, 25512,  1360,  ...,  9166,  2328, 11759],
         [29922,  1360,    13,  ...,   543, 10457,  2013],
         [   13,     2, 29871,  ...,   319,  1678,  3877]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  361,   666,  3393,  ..., 11522,   262,  6504],
         [  275,   326, 11124,  ...,   335, 10669,  1336],
         ...,
         [    3,    13,  7228,  ...,  1576, 29954, 30166],
         [    3,    13, 29949,  ..., 29933,  1576, 29909],
         [    3,    13, 29949,  ..., 29933,  1576, 29909]]], device='cuda:0')
Batch 8, 12.1% of total tokens
encoded shape: torch.Size([2, 1786])
torch.Size([2, 1786]) tensor([[    1,   965, 11733,  ..., 29946,    13,    15],
        [    1,   450,   315,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1786, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -9.9219,  -5.7383,   1.5713,  ...,  -3.1387,  -7.4531,  -3.0254],
         [-10.3516, -12.8906,  -1.7314,  ...,  -6.6641,  -9.0156,  -8.7578],
         ...,
         [  1.1914,   5.8867,  21.7656,  ...,   0.0475,   0.8926,  -0.2998],
         [ -2.4766,   2.1152,  16.0625,  ...,  -1.3027,   1.0215,  -0.1488],
         [ -7.3203,  -1.5449,   8.6953,  ...,  -5.4297,  -0.3445,  -4.3438]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [-13.5156, -11.7344,  -6.9727,  ...,  -9.1484, -10.2422,  -8.5781],
         [ -9.2969,  -9.4453,  -0.5342,  ...,  -5.5508,  -5.3125,  -6.3750],
         ...,
         [ -9.2422,   1.7793,   6.0742,  ...,  -2.7676,  -4.2461,  -2.0332],
         [ -9.2734,   1.7803,   6.1250,  ...,  -2.7852,  -4.2422,  -2.0508],
         [ -9.3203,   1.7715,   6.1523,  ...,  -2.8086,  -4.2461,  -2.0449]]],
       device='cuda:0')
torch.Size([2, 1786, 1]) tensor([[[  917],
         [  529],
         [  376],
         ...,
         [   13],
         [   13],
         [  462]],

        [[  917],
         [29871],
         [29956],
         ...,
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 1786, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  529,    13,  6319,  ...,   376,   891,  1533],
         [  376, 29871,   395,  ...,   313,   317,   525],
         ...,
         [   13,     2, 11733,  ...,   360,  2672, 29900],
         [   13,     2,    15,  ...,  1669,   795,  5074],
         [  462, 18884,    13,  ...,     2,   965,  9651]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [29956,  1507, 10764,  ..., 21471, 28479,   519],
         ...,
         [   13,  1576, 29924,  ..., 29903, 29900,  4013],
         [   13,  1576, 29924,  ..., 29903, 29900,  4013],
         [   13,  1576, 29924,  ..., 29992, 30166,  4345]]], device='cuda:0')
Batch 9, 15.0% of total tokens
encoded shape: torch.Size([2, 1086])
torch.Size([2, 1086]) tensor([[    1,   660, 29901,  ..., 29897,    13,    13],
        [    1,   319,   771,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1086, 32000]) tensor([[[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-10.8672, -10.6484,  -2.9941,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5312,  -1.5088,  ...,  -7.1523,  -8.3359,  -5.6523],
         ...,
         [ -0.4973,  -4.8164,  17.0781,  ...,  -2.5762,  -1.0020,  -1.7158],
         [ -7.9180,  -8.2266,   8.4375,  ...,  -8.4453,  -5.1172,  -3.7070],
         [ -9.1016, -10.8906,   5.9648,  ...,  -7.6953,  -4.7773,  -2.8496]],

        [[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-12.4766, -10.0859,  -4.3711,  ...,  -8.0156, -10.0000,  -9.8984],
         [ -8.8906,  -7.0625,  -1.7197,  ...,  -7.2500,  -9.8984,  -5.7891],
         ...,
         [-12.0312,  -2.3125,   1.8057,  ...,  -5.0469,  -6.1641,  -4.8320],
         [-12.0312,  -2.3184,   1.7842,  ...,  -5.0703,  -6.1719,  -4.8672],
         [-12.0312,  -2.3359,   1.7490,  ...,  -5.0938,  -6.1836,  -4.8945]]],
       device='cuda:0')
torch.Size([2, 1086, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [20001]],

        [[  917],
         [  716],
         [ 1066],
         ...,
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 1086, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,     2, 29871,  ...,   607,   278,   297],
         [   13,  6295,  1576,  ..., 29902,  3112,   797],
         [20001,  6295,  1576,  ..., 29902, 29909,  1762]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  716,  2846, 29871,  ...,   767,  8456,  3287],
         [ 1066,   345, 29873,  ...,   771,  2901,  1490],
         ...,
         [   13, 29924, 29905,  ..., 29896, 29871, 29906],
         [   13, 29924, 29905,  ..., 29896, 29871, 29906],
         [   13, 29924, 29905,  ..., 29896, 29871, 29906]]], device='cuda:0')
Batch 10, 16.8% of total tokens
encoded shape: torch.Size([2, 347])
torch.Size([2, 347]) tensor([[    1,   660, 29901,    13,    13,  3624, 20049,   304,  1246,   443,
         25240,   775,   297, 12738, 29889,  6006,  4700, 29973,    13,    13,
           797,  1619,  3553, 29899,  7543,  1303,  2280,   306,   626, 28348,
           777,   443, 25240,   775,   313, 12396, 29897,   363, 10760, 29889,
           306,   626,  9368,   304,  1053,   445, 22474, 29889,   306,   626,
           451,  2805,   738,  4436,   411,   372, 29892,   541,   278, 22474,
           338,   451,  2805, 19673,   322,  3508, 29915, 29873, 15579, 29889,
           739,   338,  1985,   297,   263,  3852,   883,   746,   372,   471,
          2309,   297,  1856,  2280, 29889,   306,   626,   451,  2805,   278,
          1962, 29889,  1815,   306,   505,   777,  7014,   470,   777,  6455,
         29892,  1048,   920,   304,   671,   372, 29973,    13, 10605, 29915,
         29879,   590,   775, 29901,    13,  4363,   529,  3207,  1024,   543,
         16950,  4557,  1013,  1576,  9591,  1353, 21106,  3207, 29958,    13,
          4706,   518, 29928,   645, 17518,   703, 29923,  1367,  6982, 29889,
         12396,   613,  2896,  2697,   353,  2896,  2697, 29889,  2744,  1039,
         29892,  8251,   292,  1168,  7316,   353,  8251,   292,  1168,  7316,
         29889,   855, 29881,  5594,  4638,    13,  4706,  7463,  2294,  3622,
          1780, 10886,  8592,  6982,  1252, 29898,  3260,  1469,   848, 29892,
           938,  9591,  4557,   416,    13,    13, 29961, 29928,   645, 17518,
           703, 29923,  1367,  6982, 29889, 12396,   613,  2896,  2697,   353,
          2896,  2697, 29889,  2744,  1039, 29892,  8251,   292,  1168,  7316,
           353,  8251,   292,  1168,  7316, 29889,   855, 29881,  5594,  4638,
            13,  1678,   518,  2457, 29901, 13216,   284,  2887, 29898,  2525,
         25240,  1542, 29889, 24693,  4638,    13,  1678,  7463,  2294,  3622,
          6120,  7523, 29903,  3235, 13200,  4197,   797, 29892,  4451, 29962,
           317,  3235,  9182, 10110,   416,    13,    13, 29909, 29901,    13,
            13,  8439,   338,   263,  4328,  1546,   920,   315, 29937, 29914,
         17734,  9514,  2254, 22474, 29879,   322,   278,   982, 12738, 29889,
          6006,  1736, 29889,    13, 29907, 29937,  5401,  9514,  6222,   297,
           869,  6006, 11400, 29892, 12738, 29889,  6006, 29898,  4716,   884,
          6057,   373,   869,  6006, 11400, 29897,   338, 11982,  1884,   287,
          2629, 19093, 29889, 29871,    13,  3492,   505,   304,   937,  2254,
           278, 24415,   964,  3370, 29892,   769,  1246,   278,  1158,   366,
           864,   304, 29889,    13, 13393,   263,  9673,  1244,  1128,   304,
          4124,   459, 12738, 29889,  6006,    13,    13],
        [    1, 16923,  9887,   493,  2386,    13,    13, 28917,   295,  9887,
           493,  2386,    13,    13,  3549,   596,  7952, 10116,   304,  1423,
         20847,  3097,    13,    13, 28917,   295,  9887,   493,  2386,    13,
            13, 28173,   278, 16730,    13,    13,  4854, 17015,  3047,   263,
          7952,   472, 16923,  9887,   493,  2386,   297,  3681,   313, 29929,
           386, 25681, 19547,   511,   366, 29915,   645,   367,  6233,   515,
         15521,   341,   468,  3136,   322,  3802,   304,  5208,  6358,   997,
         29888,   388,  2353, 29889,   910, 16730,   338,  3802,   304, 22711,
           316,  8602, 21744,   354,   322, 24337,   360,   420,   315, 21471,
         29889,    13,    13,  9588,  4835,  9984,  7535,   472,  3271,   297,
           697,   310,   278, 29871, 29946, 29941,  4799, 29899, 16122,   287,
         19600, 23425,  1375,   747,  1503,   322, 15191, 10769, 29889,  2379,
           271, 29899, 10525, 11784,  1080,   411, 28421,  8720,  3867, 22684,
           358, 29892,  1550, 13162,  2073,   653, 26677,  4685,  2130, 14874,
           366,  6631, 29889, 12230, 27683, 18901,   411, 17152,   400, 23954,
           470,  1510,   414,  4682, 13162,  2073,   653,   304,   488, 29873,
          2722,   322, 11315, 15589,   414, 29889,  1281,   854,   819,   778,
          3160,  1374,  2873, 29892,   408,  1532,   408,  9437,   267,   322,
           553,  2039, 29889,    13,    13, 29909,  1527,  1907,  9984,   671,
           310, 19192, 28332,  1907, 29892,   607,  3160, 13162,  2073,   653,
         26677,  4685,  2130,   322,  6282, 29914, 29873,  8522, 18872, 29889,
            13,    13, 29928,  2827, 26772, 10631,   310,   278, 16730, 29915,
         29879,  5716,  2669,   313, 29881,  3864,  9078,  6199,   467,    13,
            13, 16890,  3335, 29892,  5901,   319,  1527,  1907, 19132, 29881,
         28332,  1907,  3160,  4653,  1423, 29899,   262, 29892, 13162,  2073,
           653, 14578, 21321,   297,   278,   658,  1327, 29891, 29892,   322,
         15589,  5941,   292, 29914,   433,   870,   719,  5786, 29889,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 347, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-10.8672, -10.6562,  -2.9961,  ...,  -6.8203, -10.1016,  -6.8672],
         [-13.6250, -13.5391,  -1.5010,  ...,  -7.1484,  -8.3359,  -5.6484],
         ...,
         [ -9.8281,  -8.4922,   6.6953,  ...,  -8.4453,  -5.7109,  -5.9922],
         [ -6.9609,  -2.7070,   9.6016,  ...,  -7.1211,  -4.8828,  -3.5781],
         [-10.1875,  -9.5234,   6.3203,  ...,  -5.9805,  -4.9258,  -3.6641]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [ -9.2031,  -6.1484,  -1.1650,  ...,  -4.8594,  -4.6992,  -7.1211],
         [ -8.5781,  -6.4414,   1.0020,  ...,  -6.9102,  -4.3477,  -7.6836],
         ...,
         [-12.4375,  -4.3672,  -2.7930,  ...,  -6.7773,  -7.2539,  -6.4883],
         [-12.3281,  -4.3438,  -2.6016,  ...,  -6.6367,  -7.1133,  -6.2695],
         [-12.2266,  -4.3125,  -2.4473,  ...,  -6.5391,  -7.0039,  -6.1211]]],
       device='cuda:0')
torch.Size([2, 347, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         [29902],
         [ 5618],
         [  727],
         [  304],
         [  671],
         [  263],
         [25240],
         [  775],
         [  515],
         [  263],
         [29889],
         [ 6006],
         [29973],
         [29973],
         [   13],
         [   13],
         [22550],
         [  590],
         [ 4700],
         [  275],
         [ 6707],
         [ 2280],
         [ 2280],
         [29892],
         [  505],
         [  773],
         [  263],
         [24415],
         [25240],
         [  775],
         [29889],
         [29907],
         [29897],
         [  322],
         [ 5183],
         [29889],
         [   13],
         [  864],
         [  773],
         [  304],
         [ 1246],
         [  445],
         [24415],
         [  297],
         [   13],
         [  626],
         [ 2805],
         [ 1854],
         [  738],
         [ 1059],
         [29889],
         [  278],
         [29889],
         [  541],
         [  372],
         [ 2280],
         [  338],
         [  451],
         [ 2805],
         [19673],
         [29889],
         [  278],
         [29915],
         [29873],
         [ 2805],
         [29889],
         [   13],
         [  338],
         [ 1985],
         [ 2691],
         [  590],
         [ 8892],
         [ 3812],
         [ 2280],
         [  306],
         [  338],
         [19673],
         [  297],
         [  315],
         [ 2280],
         [29889],
         [   13],
         [  626],
         [  773],
         [ 2805],
         [  738],
         [ 1059],
         [29889],
         [   13],
         [ 5019],
         [ 1246],
         [  738],
         [ 1371],
         [29973],
         [10529],
         [10529],
         [29973],
         [  920],
         [  920],
         [  304],
         [ 1053],
         [  443],
         [  297],
         [   13],
         [   13],
         [  338],
         [29879],
         [  278],
         [  775],
         [29901],
         [   13],
         [   13],
         [  529],
         [ 7727],
         [ 1024],
         [  543],
         [15452],
         [ 1013],
         [ 1013],
         [ 6982],
         [ 9591],
         [ 1353],
         [21106],
         [ 3207],
         [29958],
         [   13],
         [ 4363],
         [ 4363],
         [29928],
         [  645],
         [17518],
         [  703],
         [29907],
         [ 1367],
         [29918],
         [29889],
         [12396],
         [  613],
         [28236],
         [ 2697],
         [  353],
         [ 2896],
         [ 2697],
         [29889],
         [12300],
         [ 1039],
         [29892],
         [28236],
         [  292],
         [ 1168],
         [ 7316],
         [  353],
         [ 8251],
         [  292],
         [ 1168],
         [ 7316],
         [29889],
         [  855],
         [29881],
         [ 5594],
         [ 4638],
         [   13],
         [ 4706],
         [  970],
         [ 2294],
         [ 3622],
         [  938],
         [  382],
         [ 6982],
         [ 6982],
         [29898],
         [29898],
         [ 1807],
         [29889],
         [ 8455],
         [29892],
         [  938],
         [ 9591],
         [ 4557],
         [  416],
         [   13],
         [   13],
         [ 4706],
         [29928],
         [  645],
         [17518],
         [  703],
         [29923],
         [ 1367],
         [ 6982],
         [29889],
         [12396],
         [  613],
         [ 2896],
         [ 2697],
         [  353],
         [ 2896],
         [ 2697],
         [29889],
         [ 2744],
         [ 1039],
         [29892],
         [ 8251],
         [  292],
         [ 1168],
         [ 7316],
         [  353],
         [ 8251],
         [  292],
         [ 1168],
         [ 7316],
         [29889],
         [  855],
         [29881],
         [ 5594],
         [ 4638],
         [   13],
         [ 4706],
         [ 7463],
         [ 2457],
         [29901],
         [13216],
         [  284],
         [ 2887],
         [29898],
         [ 2525],
         [25240],
         [ 1542],
         [29889],
         [24693],
         [ 4638],
         [   13],
         [ 1678],
         [ 7463],
         [ 2294],
         [ 3622],
         [ 6120],
         [ 1317],
         [13200],
         [  575],
         [29898],
         [29898],
         [  797],
         [29962],
         [ 4451],
         [29962],
         [ 7023],
         [ 3235],
         [13200],
         [ 2407],
         [29892],
         [   13],
         [   13],
         [29961],
         [29205],
         [   13],
         [   13],
         [ 8241],
         [  338],
         [  694],
         [  982],
         [ 1546],
         [12738],
         [  366],
         [29937],
         [  322],
         [ 3289],
         [12605],
         [  322],
         [22474],
         [29879],
         [  322],
         [12738],
         [  982],
         [12738],
         [29889],
         [ 6006],
         [  947],
         [29889],
         [   13],
         [   13],
         [29937],
         [29914],
         [ 9514],
         [ 2254],
         [  278],
         [  263],
         [ 6006],
         [29871],
         [29892],
         [  607],
         [29889],
         [ 6006],
         [24138],
         [ 3289],
         [  338],
         [ 6057],
         [  297],
         [  869],
         [ 6006],
         [11400],
         [29897],
         [24138],
         [  263],
         [ 1884],
         [  287],
         [29889],
         [19093],
         [29889],
         [   13],
         [  910],
         [   13],
         [  508],
         [  304],
         [ 2254],
         [ 2254],
         [  278],
         [22474],
         [  964],
         [  278],
         [  322],
         [  769],
         [ 1246],
         [  278],
         [ 1158],
         [29889],
         [  864],
         [  304],
         [ 1246],
         [   13],
         [   13],
         [  445],
         [ 4559],
         [ 1244],
         [29901],
         [  304],
         [ 2254],
         [  627],
         [  411],
         [29889],
         [ 6006],
         [  411],
         [   13],
         [20001]],

        [[  917],
         [  316],
         [  294],
         [  608],
         [  338],
         [ 1576],
         [28917],
         [  295],
         [ 9887],
         [  493],
         [ 2386],
         [  338],
         [   13],
         [ 2277],
         [ 2635],
         [10116],
         [10116],
         [  304],
         [ 1423],
         [20847],
         [ 3097],
         [  472],
         [   13],
         [29934],
         [  295],
         [ 9887],
         [  493],
         [ 2386],
         [   13],
         [   13],
         [28917],
         [16923],
         [16923],
         [   13],
         [   13],
         [28917],
         [17015],
         [ 2973],
         [  263],
         [ 7952],
         [  472],
         [16923],
         [ 9887],
         [  493],
         [ 2386],
         [  297],
         [10523],
         [  313],
         [29896],
         [  386],
         [25681],
         [19547],
         [  511],
         [  366],
         [29915],
         [  645],
         [  367],
         [ 6233],
         [  515],
         [ 5208],
         [  341],
         [  468],
         [ 3136],
         [  322],
         [ 3802],
         [  304],
         [ 5208],
         [ 6358],
         [  997],
         [29888],
         [  388],
         [ 2353],
         [29889],
         [  910],
         [16730],
         [  338],
         [ 3802],
         [  304],
         [22711],
         [  316],
         [ 8602],
         [21744],
         [  354],
         [  322],
         [  382],
         [  360],
         [  420],
         [  315],
         [21471],
         [29889],
         [ 9588],
         [ 9588],
         [ 9588],
         [ 4835],
         [ 9984],
         [ 7535],
         [  472],
         [ 3271],
         [  297],
         [  697],
         [  310],
         [  278],
         [29871],
         [29906],
         [29900],
         [ 4799],
         [29899],
         [16122],
         [  287],
         [19600],
         [23425],
         [ 1375],
         [  747],
         [ 1503],
         [  322],
         [12151],
         [10769],
         [29889],
         [  422],
         [  271],
         [29899],
         [10525],
         [11784],
         [ 1080],
         [  411],
         [28421],
         [ 8720],
         [ 3867],
         [22684],
         [  358],
         [29892],
         [ 1550],
         [13162],
         [ 2073],
         [  653],
         [26677],
         [ 4685],
         [ 2130],
         [14874],
         [  366],
         [ 6631],
         [29889],
         [12230],
         [27683],
         [18901],
         [  411],
         [ 1510],
         [  400],
         [23954],
         [  470],
         [ 1510],
         [  414],
         [ 4682],
         [13162],
         [ 2073],
         [  653],
         [  304],
         [  488],
         [29873],
         [ 2722],
         [  322],
         [11315],
         [15589],
         [  414],
         [29889],
         [ 1281],
         [  854],
         [  819],
         [  778],
         [ 3160],
         [ 9437],
         [ 2873],
         [29892],
         [  408],
         [ 1532],
         [  408],
         [ 9437],
         [  267],
         [  322],
         [  553],
         [ 2039],
         [29889],
         [   13],
         [   13],
         [29909],
         [ 1527],
         [ 1907],
         [26772],
         [  671],
         [  310],
         [19192],
         [28332],
         [ 1907],
         [29892],
         [  607],
         [ 3160],
         [13162],
         [ 2073],
         [  653],
         [26677],
         [ 4685],
         [ 2130],
         [  322],
         [  378],
         [29914],
         [29873],
         [ 8522],
         [18872],
         [29889],
         [   13],
         [   13],
         [29928],
         [ 2827],
         [29903],
         [10631],
         [  310],
         [  278],
         [16730],
         [29915],
         [29879],
         [ 5716],
         [ 2669],
         [  313],
         [29881],
         [ 3864],
         [ 9078],
         [ 6199],
         [  467],
         [  751],
         [   13],
         [16890],
         [ 3335],
         [29892],
         [ 5901],
         [  319],
         [ 1527],
         [ 1907],
         [19132],
         [29881],
         [28332],
         [ 1907],
         [ 3160],
         [13162],
         [ 1423],
         [29899],
         [  262],
         [29892],
         [ 4653],
         [ 2073],
         [  653],
         [14578],
         [21321],
         [  297],
         [  278],
         [  658],
         [ 1327],
         [29891],
         [29892],
         [  322],
         [  263],
         [ 5941],
         [  292],
         [29914],
         [  433],
         [  870],
         [  719],
         [ 5786],
         [29889],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [29873],
         [   13],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [  338],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [   13],
         [29871],
         [   13]]], device='cuda:0')
torch.Size([2, 347, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [  411,   322,   515,  ..., 22474,   669,    13],
         [   13,  1124,     2,  ...,   392,   272,   991],
         [20001, 22550, 29984,  ..., 29961, 17351, 29902]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  316,   297, 19600,  ...,  4103, 29899,   390],
         [  294, 10044,   351,  ...,   273,   370,  1789],
         ...,
         [   13, 29871, 29892,  ..., 29896,   338, 29902],
         [29871,    13, 29892,  ...,  1516, 29896, 29902],
         [   13, 29871, 29892,  ..., 29889, 29902, 29896]]], device='cuda:0')
Batch 11, 17.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,    13,  ...,     2,     2,     2],
        [    1, 29871,    13,  ..., 29941, 29889,    13]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.1406,  -4.4141,   3.6445,  ...,  -5.2812,  -5.5977,  -2.5449],
         ...,
         [-10.9609,   9.4297,   2.4629,  ...,  -3.9844,  -5.9844,  -3.0781],
         [-11.0000,   9.3750,   2.4062,  ...,  -4.0508,  -6.0547,  -3.1855],
         [-11.1562,   9.2500,   2.1641,  ...,  -4.2461,  -6.3164,  -3.5293]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.1406,  -4.4141,   3.6445,  ...,  -5.2812,  -5.5977,  -2.5449],
         ...,
         [ -1.0508,  -1.0596,  11.0703,  ...,  -1.7178,  -0.7480,  -1.9150],
         [ -1.9219,  -7.8164,  11.8594,  ...,  -0.9321,  -1.9883,  -2.1680],
         [ -6.9844, -14.1484,   0.0819,  ...,  -5.6758,  -4.3203,  -4.0469]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [29896],
         [   13],
         ...,
         [    1],
         [    1],
         [    1]],

        [[  917],
         [29896],
         [   13],
         ...,
         [29889],
         [  313],
         [29941]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [    1,    13,     3,  ..., 29909, 29911, 29907],
         [    1,    13,     3,  ..., 29909, 29911, 29907],
         [    1,    13,     3,  ..., 29911, 29909, 29933]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [29889, 29892,  7226,  ...,   518, 29936, 12359],
         [  313,    13,   450,  ...,   476,  5282,   530],
         [29941, 29930, 23711,  ..., 29968,  8618,  2287]]], device='cuda:0')
Batch 12, 21.8% of total tokens
encoded shape: torch.Size([2, 1211])
torch.Size([2, 1211]) tensor([[    1,   450,  9232,  ...,     2,     2,     2],
        [    1,   450,  2198,  ...,   385,  2944, 29889]], device='cuda:0')
torch.Size([2, 1211, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-13.5156, -11.7266,  -6.9727,  ...,  -9.1484, -10.2422,  -8.5703],
         [ -1.2900,  -1.3623,   2.4023,  ...,   3.9219,   0.1793,   3.2793],
         ...,
         [ -7.8281,   3.5840,   3.4141,  ...,  -2.6582,  -4.1211,  -2.3516],
         [ -7.7773,   3.4902,   3.3379,  ...,  -2.6699,  -4.1172,  -2.3809],
         [ -7.8203,   3.1152,   3.2090,  ...,  -2.7227,  -4.1719,  -2.4785]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-13.5156, -11.7266,  -6.9727,  ...,  -9.1484, -10.2422,  -8.5703],
         [-10.7891,  -5.5898,  -0.6416,  ...,  -4.0977,  -6.8477,  -5.3125],
         ...,
         [ -5.0781,  -5.7344,   8.3750,  ...,  -0.5166,  -2.7891,   0.3721],
         [ -3.1973,  -1.5781,   9.9141,  ...,  -0.5220,   0.9644,  -2.0488],
         [  1.1934,  -0.8530,  13.5391,  ...,   1.6602,  -0.5010,  -0.9497]]],
       device='cuda:0')
torch.Size([2, 1211, 1]) tensor([[[  917],
         [29871],
         [  397],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [29871],
         [  297],
         ...,
         [ 2944],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 1211, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  397,  1259,  1486,  ..., 14114,   314,   787],
         ...,
         [    3,    13,    12,  ..., 29902,  9137, 29909],
         [    3,    13,    12,  ..., 29902,  9137, 30212],
         [    3,    13,    12,  ..., 29902,  9137, 30212]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  297,  6559,  5650,  ...,  5925,  4274,   800],
         ...,
         [ 2944,  4274,  1203,  ...,  1095,  3234, 14407],
         [29889, 29892,  7536,  ...,   363,   313,   297],
         [   13,   450,   512,  ...,  3115, 19814, 12074]]], device='cuda:0')
Batch 13, 23.4% of total tokens
encoded shape: torch.Size([2, 1771])
torch.Size([2, 1771]) tensor([[    1,   660, 29901,  ..., 29871,    13,    13],
        [    1,  3323,  2415,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1771, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6562],
         ...,
         [ -5.3789,  -6.1562,  10.8203,  ...,   0.2338,  -4.2070,  -0.9390],
         [ -8.8281,  -8.8359,  11.3672,  ...,  -3.8262,  -6.2188,  -3.4082],
         [ -8.5938,  -9.5625,  11.1094,  ...,  -2.7422,  -4.5625,  -2.2461]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,  -9.2969,   0.2581,  ...,  -4.8867,  -4.0859,  -1.2764],
         [-12.7812, -11.4375,  -2.4590,  ...,  -7.0508,  -9.1328,  -5.1523],
         ...,
         [ -9.1719,   2.3477,   2.8809,  ...,  -3.8281,  -4.8672,  -2.3926],
         [ -9.0781,   2.6914,   2.9492,  ...,  -3.7480,  -4.8164,  -2.2773],
         [ -9.0156,   3.0098,   3.0117,  ...,  -3.6973,  -4.7930,  -2.1816]]],
       device='cuda:0')
torch.Size([2, 1771, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [  622],
         [  596],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1771, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,     2,   939,  ..., 20782,  3337,  2081],
         [   13,     2, 29871,  ..., 30038, 30041, 30008],
         [   13,     2, 30032,  ..., 30041, 30070, 30029]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  622, 29885, 13086,  ..., 29899, 18071,  7588],
         [  596,   263,  3575,  ...,   461,  1174,   319],
         ...,
         [    3,    13,    12,  ..., 29902, 29903,  1678],
         [    3,    13,    12,  ..., 29902, 29903, 29909],
         [    3,    13,    12,  ..., 29902, 29903, 29909]]], device='cuda:0')
Batch 14, 25.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  1976,  1509,  ...,     2,     2,     2],
        [    1, 21065,  8451,  ...,  1475,    13,    13]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.9531,  -6.4023,   0.8843,  ...,  -1.9668,  -5.7930,  -2.3301],
         [-13.1094, -14.7031,  -0.6011,  ...,  -7.9844,  -9.2891,  -8.8125],
         ...,
         [-10.4844,  15.2422,   3.0996,  ...,  -3.4590,  -5.7891,  -4.1992],
         [-10.3281,  14.8672,   2.9082,  ...,  -3.4258,  -5.8125,  -4.3164],
         [-10.2344,  14.7969,   2.8828,  ...,  -3.3828,  -5.7500,  -4.2969]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.7344, -10.2812,   2.0820,  ...,  -6.7148,  -5.1758,  -4.6953],
         [ -6.1445,  -6.1797,   4.6445,  ...,  -6.9414,  -4.4141,  -3.9219],
         ...,
         [ -8.5000,  -6.7461,  11.5547,  ...,  -2.8477,  -6.1523,  -6.6992],
         [ -9.6562,  -7.2734,   6.9414,  ...,  -6.7852,  -7.7617,  -6.4648],
         [ -9.9375,  -7.8203,   4.6914,  ...,  -7.5742,  -8.1328,  -7.3477]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[ 917],
         [2929],
         [ 310],
         ...,
         [   1],
         [   1],
         [   1]],

        [[ 917],
         [2866],
         [ 354],
         ...,
         [  13],
         [  13],
         [2277]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 2929, 29884,  9214,  ...,  1030, 13492,  1793],
         [  310, 29892,   322,  ..., 10503, 29901,   669],
         ...,
         [    1,    13, 29871,  ..., 29892, 29909, 29924],
         [    1,    13, 29871,  ...,     3, 29924, 29909],
         [    1,    13, 29871,  ...,     3, 29924,    12]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 2866, 27536,   341,  ...,   390,   350, 29915],
         [  354,  1041, 24448,  ...,   968,   352, 29874],
         ...,
         [   13,     2,   297,  ...,  2391, 29892, 29889],
         [   13,  1293,  1433,  ..., 29934, 29928,  2499],
         [ 2277, 29930,  7626,  ...,  4013,  1293, 29896]]], device='cuda:0')
Batch 15, 29.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   260,   921,  ..., 29953,   467, 12142]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6562],
         ...,
         [ -9.0938,   7.7617,   1.2715,  ...,  -3.4648,  -5.3672,  -3.3379],
         [ -8.9609,   7.8125,   1.2822,  ...,  -3.3555,  -5.2266,  -3.2207],
         [ -8.8281,   7.8125,   1.2842,  ...,  -3.2734,  -5.1367,  -3.1582]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.3984,  -9.5469,  -2.1074,  ...,  -5.5977,  -6.8125,  -5.8164],
         [-12.7031, -11.7969,  -2.7852,  ...,  -8.3281,  -7.6016,  -8.0781],
         ...,
         [  0.0292,  -3.2012,   6.9766,  ...,   1.7891,   1.6123,   2.2930],
         [  1.2568,   0.4021,  11.2109,  ...,   1.5146,   1.8857,   5.9688],
         [  1.2891,  -2.9941,   9.5469,  ...,   1.4961,   1.9150,   3.1504]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [    1],
         [    1],
         [    1]],

        [[  917],
         [29880],
         [29871],
         ...,
         [  467],
         [ 2803],
         [  448]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [    1,    13, 29871,  ..., 29909, 29924, 29933],
         [    1,    13, 29871,  ..., 29924, 29909, 29933],
         [    1,    13, 29871,  ..., 29924, 29909, 29933]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29880, 29899,   579,  ..., 29886, 11017, 16234],
         [29871,   921,    13,  ...,   260,   353, 29877],
         ...,
         [  467, 29900, 29955,  ..., 29896, 29929, 29953],
         [ 2803, 12065, 20025,  ..., 22680,    13,  4910],
         [  448, 29871,   432,  ...,   313,   286,   343]]], device='cuda:0')
Batch 16, 34.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 11474,    13,  ...,   399, 14838, 29885]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6562],
         ...,
         [ -9.1094,   8.1484,   1.4141,  ...,  -3.3086,  -5.1172,  -3.4180],
         [ -9.1562,   8.1406,   1.4238,  ...,  -3.3496,  -5.1484,  -3.4414],
         [ -9.1094,   8.1250,   1.4492,  ...,  -3.3164,  -5.1094,  -3.4043]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -0.3516,   4.4180,   9.3594,  ...,   0.3293,  -2.4688,   2.5898],
         [ -4.0312,  -4.1055,   8.0859,  ...,  -2.1641,  -3.2090,   0.4614],
         ...,
         [ -1.6045,  -3.3242,   2.7578,  ...,   2.2207,  -0.7573,   0.9673],
         [ -4.0039,  -8.8906,   6.5547,  ...,   0.3474,  -1.9092,   1.9961],
         [ -0.6782,  -6.2812,   7.1484,  ...,   3.4160,  -2.4902,   2.4531]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [    1],
         [    1],
         [    1]],

        [[  917],
         [   13],
         [ 3257],
         ...,
         [14838],
         [29885],
         [29899]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [    1,    13,  7228,  ..., 29933, 29911, 29940],
         [    1,    13,  7228,  ..., 29933, 29911, 29940],
         [    1,    13,  7228,  ..., 29933, 29911, 29940]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13, 30004, 29871,  ..., 29937,   910, 29961],
         [ 3257,  2680,    13,  ..., 29992, 29871, 29899],
         ...,
         [14838,   930, 15609,  ...,  4229, 12156,  3227],
         [29885, 29876, 29875,  ..., 29912,   286, 17722],
         [29899, 29974,   448,  ...,  8499, 30120,  2844]]], device='cuda:0')
Batch 17, 38.4% of total tokens
encoded shape: torch.Size([2, 834])
torch.Size([2, 834]) tensor([[    1,   660, 29901,  ...,   856,    13,    13],
        [    1,   402,   598,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 834, 32000]) tensor([[[-12.7969,  -7.3047,  -0.4807,  ...,  -6.7695,  -8.0078,  -7.4883],
         [-10.8672, -10.6484,  -2.9961,  ...,  -6.8164, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5039,  ...,  -7.1445,  -8.3281,  -5.6484],
         ...,
         [ -1.9502,  -2.5391,  14.9375,  ...,  -2.6660,  -1.6094,  -1.2930],
         [ -0.5054,   2.9922,  16.1250,  ...,  -1.2910,  -0.7949,   1.5264],
         [ -9.4766,  -8.8984,   4.3906,  ...,  -6.1758,  -5.6719,  -4.5312]],

        [[-12.7969,  -7.3047,  -0.4807,  ...,  -6.7695,  -8.0078,  -7.4883],
         [ -7.7500,  -3.0801,   2.0762,  ...,  -4.1484,  -3.3457,  -3.9980],
         [-10.4375,  -7.2109,  -1.2051,  ...,  -5.7148,  -6.9375,  -5.0273],
         ...,
         [ -7.8242,   2.8457,   3.9629,  ...,  -2.8203,  -3.8828,  -1.2949],
         [ -7.7383,   3.0547,   3.9609,  ...,  -2.7910,  -3.8594,  -1.2246],
         [ -7.7266,   3.2793,   3.9941,  ...,  -2.7676,  -3.8555,  -1.1602]]],
       device='cuda:0')
torch.Size([2, 834, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [29909]],

        [[  917],
         [  798],
         [  386],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 834, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,     2,   322,  ...,   577,  6521,   392],
         [   13, 29902,     2,  ...,  6295, 29905,  3112],
         [29909, 20001, 29984,  ..., 29933, 29905,  3492]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  798,   586,  4369,  ..., 29924,  1581,  1117],
         [  386,   698, 29891,  ...,  1406, 29895,   774],
         ...,
         [    3,    13,    12,  ...,  6224, 30143, 29902],
         [    3,    13,    12,  ..., 30143,  6224,  4345],
         [    3,    13,    12,  ...,  4345, 30143, 29902]]], device='cuda:0')
Batch 18, 39.4% of total tokens
encoded shape: torch.Size([2, 810])
torch.Size([2, 810]) tensor([[    1,   830,  4704,  ...,   319, 29902, 29889],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 810, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.7031,  -9.9766,  -1.0205,  ...,  -3.4961,  -8.4688,  -5.2305],
         [ -6.8203,  -3.0508,   4.1992,  ...,  -0.4905,  -4.1641,  -0.7246],
         ...,
         [ -4.6875,  -6.4062,  10.1484,  ...,  -4.8828,  -3.6465,  -3.4004],
         [ -3.4688,  -6.0469,  12.0938,  ...,  -2.8750,  -2.4531,  -1.6416],
         [ -8.4531,  -9.9531,  14.9609,  ...,  -1.3818,  -5.5430,  -4.3359]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -2.9961,  ...,  -6.8203, -10.1016,  -6.8672],
         [-13.6250, -13.5391,  -1.5010,  ...,  -7.1484,  -8.3359,  -5.6484],
         ...,
         [ -8.4688,   1.3770,   3.4902,  ...,  -3.4336,  -4.5352,  -2.1621],
         [ -8.6875,   1.2949,   3.5176,  ...,  -3.5410,  -4.6680,  -2.2285],
         [ -8.7344,   1.2734,   3.5098,  ...,  -3.5781,  -4.7109,  -2.2715]]],
       device='cuda:0')
torch.Size([2, 810, 1]) tensor([[[  917],
         [29901],
         [  573],
         ...,
         [29902],
         [29889],
         [   13]],

        [[  917],
         [29901],
         [ 1724],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 810, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901,  4924,  3714,  ..., 29899, 24044,   635],
         [  573,  3598,  2068,  ...,  1821,  4244,   272],
         ...,
         [29902,  3624, 29889,  ..., 29914,   306, 29967],
         [29889,   322, 29892,  ...,   472,   373,  1550],
         [   13,     2,   450,  ...,   512,  8512, 14187]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [    3,    13,    12,  ...,  6224,  8999, 12008],
         [    3,    13,    12,  ...,  6224,  8999,  9137],
         [    3,    13,    12,  ..., 30143,  8999, 29902]]], device='cuda:0')
Batch 19, 40.4% of total tokens
encoded shape: torch.Size([2, 1700])
torch.Size([2, 1700]) tensor([[    1, 12788,   310,  ...,   596,  4714, 29889],
        [    1,  4546, 30044,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1700, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [-12.6641, -12.3438,  -1.9717,  ...,  -9.6797,  -8.3516, -10.4297],
         [ -6.2383,  -4.6875,   3.9043,  ...,  -2.5332,  -3.2129,  -2.2246],
         ...,
         [ -2.4258,  -0.0442,   9.7969,  ...,  -2.4043,  -1.9131,  -0.4353],
         [ -0.7251,   2.8184,  15.3047,  ...,  -1.7969,   0.2522,  -0.2209],
         [ -7.0508,  -4.4023,  15.3906,  ...,  -0.6509,  -4.8984,   0.1310]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [-10.8281, -10.3047,  -1.8486,  ...,  -6.5508,  -7.2734,  -4.4844],
         [ -7.4414,  -9.6016,   1.7695,  ...,  -6.9258,  -3.7871,  -3.4980],
         ...,
         [-10.6406,   4.8242,   2.7910,  ...,  -4.0312,  -5.2305,  -3.3242],
         [-10.7812,   4.6172,   2.7012,  ...,  -4.1328,  -5.3516,  -3.4727],
         [-10.9375,   4.3320,   2.5684,  ...,  -4.3047,  -5.5391,  -3.7168]]],
       device='cuda:0')
torch.Size([2, 1700, 1]) tensor([[[  917],
         [  310],
         [  278],
         ...,
         [ 4714],
         [29889],
         [    2]],

        [[  917],
         [ 1486],
         [13887],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1700, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  310,  2671,   363,  ...,  1152,   975,  6811],
         [  278, 14933,   838,  ...,   678,   379,   402],
         ...,
         [ 4714,  1856,  8986,  ..., 15327, 14376,  3347],
         [29889, 29892,   541,  ...,   448,   785, 29936],
         [    2,    13,  1152,  ...,  5853,  8725,  1763]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 1486,   852,   272,  ..., 29872,   468,  1529],
         [13887,  1388,  6582,  ..., 15810,  8953, 16484],
         ...,
         [    3,    13, 29949,  ...,  9137,  7228,    12],
         [    3,    13, 29949,  ...,  7228,    12, 29933],
         [    3,    13, 29949,  ...,  7228,    12, 29933]]], device='cuda:0')
Batch 20, 42.3% of total tokens
encoded shape: torch.Size([2, 576])
torch.Size([2, 576]) tensor([[    1,  4306,  9619,  ...,  1438, 12651, 29889],
        [    1,   512,  3372,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 576, 32000]) tensor([[[-12.8281,  -7.3867,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -8.9766,  -8.1875,   0.1617,  ...,  -2.6699,  -8.3672,  -6.1133],
         [  6.0117,   6.0938,   3.3105,  ...,  11.2188,   6.6992,   9.1250],
         ...,
         [ -7.0703,  -4.8359,   7.3516,  ...,  -2.2090,  -2.4121,  -2.4824],
         [ -2.4473,  -0.5786,  15.5938,  ...,  -2.8945,  -2.4492,  -4.1914],
         [ -0.5991,  -1.0645,  18.2031,  ...,   0.2605,  -2.5684,   0.1986]],

        [[-12.8281,  -7.3867,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-12.1250,  -9.0391,  -4.6406,  ...,  -6.9414,  -9.5000,  -7.1367],
         [ -6.8672,  -4.4141,   0.5869,  ...,  -1.3555,  -1.7783,  -1.3145],
         ...,
         [ -9.5703,   1.2969,   2.8066,  ...,  -2.0957,  -4.3320,  -2.0449],
         [ -9.5312,   1.2891,   2.8574,  ...,  -2.1133,  -4.3594,  -2.0801],
         [ -9.4844,   1.3027,   2.9336,  ...,  -2.0645,  -4.3281,  -2.0156]]],
       device='cuda:0')
torch.Size([2, 576, 1]) tensor([[[  917],
         [  310],
         [ 1078],
         ...,
         [12651],
         [29889],
         [   13]],

        [[  917],
         [  278],
         [  519],
         ...,
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 576, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  310, 29899,  8157,  ..., 10088, 23354, 29892],
         [ 1078,   630,   403,  ...,   271,   314,   362],
         ...,
         [12651,  1284,  8900,  ..., 17508, 28473,  5224],
         [29889,   297,   322,  ...,   408,  4249, 19602],
         [   13,     2,   313,  ...,  4219,   315,  1732]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  278,   445, 29871,  ...,  6124, 13715,   590],
         [  519,  1230,  3097,  ...,  1926,   294,   800],
         ...,
         [   13,  1576, 30166,  ...,  8999, 29912, 29909],
         [   13,  1576, 30166,  ...,  8999, 29912, 29909],
         [   13,  1576, 30166,  ..., 29903, 29912, 29909]]], device='cuda:0')
Batch 21, 43.2% of total tokens
encoded shape: torch.Size([2, 462])
torch.Size([2, 462]) tensor([[    1, 24019,  6991,   574,  2883,  3086,  4523, 29892,   405,   789,
           392,   801,   262,  1056,    13,    13, 29903,   374,  6991,   574,
          2883,  3086,  6346, 29892,   405,   789,   392,   801,   262,  1056,
           338,   263,  3762,   297,   405,   789,   392,   801,   262,  1056,
         29892,   405,  7262,  2518, 26864,  3761,  7457, 29892,  8068, 17325,
         29892, 24019,   365, 18330, 29889,   739,   338,   263,  3086,  3762,
           411,   263,   289,  6504,   950,  9793,  1824,   322, 14393,   304,
          5260,   481,  1662, 13151, 10640, 29889,    13,    13,  1123, 10662,
            13,    13, 25865,  2988,    13,  1636, 29889, 15445, 29889,   510,
         29914,  2083,   574,  2883, 29929, 29941,    13,    13, 10900, 29901,
          4504,  8789,   297,   405,  7262,  2518, 26864,  3761,  7457,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,   530,  2251,   423, 29899, 19910,  1133, 26229,   310, 27884,
         29899, 23149,  3321,   476, 29974, 18196,   297,  1410, 16736,   282,
           335,  9712,  2200,  1070,  9101,   322,   967,   878,  2785,   491,
           330,   368,  1054,  4848, 29889,    13,  1252,  1066,   545,   304,
           385,  2251,   423,   756,  1063,  8967,   304,  5039,   403, 27884,
         29899, 23149,  3321,  3104,   465,  1974,   313, 29968, 17108,  1299,
         29925,   876, 18196,   297, 23968,  9712,  2200,  1070,   590, 22502,
          2167, 29889,  1334, 12242,   287,   304, 23033,   278,  7208, 12903,
         14407,   278,   385,  2251,   423, 29899, 19910,  1133, 26229,   310,
           476, 17108,  1299, 29925, 29897, 18196, 29889, 29252,   282,   335,
          9712,  2200,  1070,   590, 22502,  2167,   892, 23968,   773,   784,
         11541,   559,  4697,   602, 29889,  9123,  7037, 29879,   322,  3813,
         10800, 16256,  1237,   892, 10478,   297,   278,  3353, 29899,  3729,
          4464,   310, 13261,  1067,  1160, 29889,  1222,  1066,   545,   304,
           385,  2251,   423,   471,  8560,   297,   263, 12647, 29899, 15603,
           263,  2728,   523, 24171, 29892,   607,  5557,   287,   278, 23253,
           310, 15489,  8096,   293,   288, 28596,   964,   385,  2251,   293,
         23895,   375,   403, 29889,  1222,  1066,   545,   304,  3144,  1682,
           852, 29899,  9021,   385,  2251,   423,  3273,  6419,   278,  3158,
          7037, 14385,   313,  3301, 29928, 29897,   304,  3109,  1135, 29871,
         29906, 29900, 29995,   310,  2761,   297, 29871, 29896, 29941,   718,
         24028, 29871, 29941,  1375, 29889,  3323,  6831,   296,   337,  2251,
         29891,  1885,   362, 19328,   322,  6446, 23119,   278, 12279, 29928,
         29889,   450,   931, 29899,   262, 18980,  2919,   714,  1328,  1857,
           607,  8906,  2645,   385,  2251,   423,   471,  6446, 21301,   287,
           491,   337,  2251, 29891,  1885,   362,   470,   491,   278,  2280,
           310,  5857,  1785, 15719,   680, 29892,   263,   476, 17108,  1299,
         29925, 29897,  8242,  2908,   261, 29889,   450, 10122,   310,  1294,
           945,   514,  1070,  3144,  1682,   852,  1258,   451,  5557, 12279,
         29928,  3273,  8333,  2645,   385,  2251,   423, 29892,  5998,   372,
         16951,  9263,  1463,   278,  6554,   310,  3273,  8333, 29889,   830,
          2251, 29891,  1885,   362, 29899, 19910,  1133,  1791, 12418,   310,
           278, 12279, 29928,   471,   297,  6335,  1573,  1156,   263,  1472,
         29899,  4230,   292,   385,  2251,   423, 29889,   512,  6124, 29892,
         10324, 14060,  1973,   304,   385,  2251,   423, 29914,   276,  2251,
         29891,  1885,   362,  6728,  3598,  2411, 29874,  2859,   278, 24205,
           310, 12279, 29928,  2645,   337,  2251, 29891,  1885,   362, 29889,
         21775,   362,   310,   476, 17108,  1299, 29925, 29897, 18196, 10008,
          2645,   385,  2251,   423, 29889,   450,  7601,  2752,   310, 27884,
           393, 24378,  1078,   278,  8242,  6354,  2444,   304,   367, 19100,
           333,  1230,  1374, 25715,   706, 18411, 29889, 27884, 10723,   515,
           385, 29874,   261,   711,   293,   330,   368,  1054,  4848,   313,
          1131,  7114,   491,   278,  7910,   310,  1294,   945,   514,  1070,
          3144,  1682,   852, 29897,   471,  8900,   304, 22039, 21301,   278,
          8242,  6354,   871,   746, 19100,   333,  1230,  1374, 25715,   706,
         18411,   471,  2775,   873,  2411, 29874,  2859,  2645,   385,  2251,
           423, 29889]], device='cuda:0')
torch.Size([2, 462, 32000]) tensor([[[-12.8125,  -7.3203,  -0.4802,  ...,  -6.7695,  -8.0156,  -7.4883],
         [ -9.8906, -12.2266,   0.4268,  ...,  -5.3125,  -5.6914,  -4.6641],
         [ -8.6641, -10.3281,   2.5000,  ...,  -4.7969,  -5.0938,  -6.2695],
         ...,
         [ -9.1797,   3.5312,   4.6875,  ...,  -3.4395,  -5.1367,  -1.9600],
         [ -9.1641,   3.1855,   4.6680,  ...,  -3.4668,  -5.1641,  -2.0508],
         [ -9.1797,   3.0469,   4.6094,  ...,  -3.5156,  -5.2109,  -2.1074]],

        [[-12.8125,  -7.3203,  -0.4802,  ...,  -6.7695,  -8.0156,  -7.4883],
         [ -6.9453,  -4.4570,   0.5093,  ...,  -3.3613,  -5.6758,  -2.9160],
         [-10.3750, -10.6406,  -1.0742,  ...,  -4.0781,  -4.6250,  -7.6875],
         ...,
         [  2.4941,   1.1934,   8.2734,  ...,   5.7617,   7.8164,   3.2344],
         [ -0.9917,  -1.4004,  14.6094,  ...,  -1.9443,  -0.1466,  -3.2656],
         [ -3.7715,  -4.4375,  16.9375,  ...,   0.1422,  -1.5312,  -2.1406]]],
       device='cuda:0')
torch.Size([2, 462, 1]) tensor([[[  917],
         [  365],
         [  574],
         [ 2883],
         [ 6346],
         [ 4523],
         [29892],
         [  476],
         [ 1450],
         [  392],
         [29875],
         [ 2386],
         [ 1056],
         [29892],
         [29903],
         [29903],
         [  374],
         [ 6991],
         [  574],
         [ 2883],
         [ 3086],
         [ 4523],
         [29892],
         [  405],
         [  789],
         [  392],
         [  801],
         [  262],
         [ 1056],
         [  338],
         [  263],
         [ 4797],
         [  297],
         [24019],
         [  789],
         [  392],
         [  801],
         [  262],
         [ 1056],
         [29892],
         [24019],
         [ 7262],
         [ 2518],
         [26864],
         [ 3761],
         [ 7457],
         [29892],
         [24019],
         [17325],
         [29892],
         [24019],
         [  365],
         [18330],
         [29889],
         [  739],
         [  338],
         [  263],
         [ 3086],
         [ 3762],
         [23736],
         [29871],
         [ 8368],
         [ 6504],
         [  950],
         [18350],
         [ 1788],
         [29889],
         [  338],
         [  304],
         [  278],
         [  481],
         [ 1662],
         [ 4910],
         [24385],
         [29889],
         [   13],
         [   13],
         [ 2277],
         [29894],
         [   13],
         [   13],
         [ 2277],
         [ 2988],
         [   13],
         [   13],
         [29889],
         [  893],
         [29889],
         [  510],
         [29914],
         [  893],
         [  574],
         [  284],
         [29889],
         [29929],
         [    2],
         [   13],
         [ 1636],
         [29901],
         [ 4504],
         [ 8789],
         [  297],
         [  405],
         [ 7262],
         [ 2518],
         [26864],
         [ 3761],
         [ 7457],
         [    2],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [   13],
         [30488],
         [30488],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [15566],
         [  293],
         [  338],
         [19910],
         [ 1133],
         [ 3620],
         [  310],
         [  278],
         [29899],
         [23149],
         [ 3321],
         [ 3104],
         [29974],
         [18196],
         [  297],
         [ 7548],
         [16736],
         [  282],
         [  335],
         [ 9712],
         [ 2200],
         [ 1070],
         [  590],
         [   13],
         [  967],
         [  878],
         [ 2785],
         [  491],
         [  594],
         [  368],
         [29883],
         [ 4848],
         [   13],
         [   13],
         [29909],
         [27910],
         [  545],
         [  310],
         [  385],
         [ 2251],
         [  423],
         [ 5039],
         [ 1063],
         [ 4318],
         [  304],
         [ 5039],
         [  403],
         [27884],
         [29899],
         [23149],
         [ 3321],
         [  476],
         [  465],
         [ 1974],
         [  313],
         [29968],
         [ 1299],
         [ 1299],
         [29925],
         [  876],
         [18196],
         [  297],
         [ 1410],
         [ 1410],
         [ 2200],
         [ 1070],
         [  590],
         [22502],
         [ 2167],
         [29889],
         [  450],
         [ 7405],
         [  287],
         [  304],
         [ 8161],
         [  278],
         [ 2779],
         [12903],
         [14407],
         [  445],
         [  385],
         [ 2251],
         [  423],
         [29899],
         [19910],
         [ 1133],
         [26229],
         [  310],
         [  476],
         [17108],
         [ 1299],
         [29925],
         [29897],
         [18196],
         [  297],
         [ 1334],
         [  282],
         [  335],
         [ 9712],
         [ 2200],
         [ 1070],
         [  590],
         [22502],
         [ 2167],
         [  892],
         [23968],
         [  322],
         [  263],
         [11541],
         [  559],
         [  322],
         [  602],
         [  322],
         [  450],
         [ 7037],
         [29879],
         [  892],
         [  476],
         [10800],
         [16256],
         [ 1237],
         [  892],
         [10478],
         [  773],
         [  278],
         [ 3353],
         [29899],
         [ 3729],
         [ 5285],
         [29889],
         [  278],
         [29899],
         [ 1160],
         [29889],
         [  450],
         [ 1066],
         [  545],
         [  304],
         [  385],
         [ 2251],
         [  423],
         [  313],
         [14363],
         [  491],
         [  278],
         [24171],
         [29899],
         [  546],
         [24171],
         [ 2728],
         [  523],
         [24171],
         [29889],
         [  322],
         [  471],
         [  287],
         [  278],
         [ 6251],
         [  310],
         [  288],
         [ 8096],
         [  293],
         [  288],
         [28596],
         [  964],
         [  278],
         [ 2251],
         [  293],
         [ 1650],
         [ 3958],
         [  403],
         [29889],
         [  450],
         [ 1066],
         [  545],
         [  304],
         [  385],
         [ 1682],
         [  852],
         [29899],
         [ 9021],
         [18350],
         [ 2251],
         [  423],
         [  313],
         [ 6419],
         [ 3158],
         [ 3158],
         [ 7037],
         [14385],
         [  322],
         [ 3301],
         [29928],
         [29897],
         [  322],
         [29871],
         [ 1135],
         [29871],
         [29896],
         [29900],
         [29900],
         [  310],
         [ 2761],
         [ 1819],
         [29871],
         [29896],
         [29900],
         [29995],
         [24028],
         [29871],
         [29906],
         [29995],
         [29889],
         [  450],
         [ 6831],
         [  296],
         [14060],
         [ 2251],
         [29891],
         [ 1885],
         [  362],
         [  310],
         [23119],
         [ 6446],
         [23119],
         [  278],
         [12279],
         [29928],
         [  304],
         [  450],
         [  385],
         [ 3236],
         [18980],
         [18980],
         [26229],
         [  297],
         [ 1328],
         [ 1857],
         [  313],
         [  471],
         [ 2645],
         [  385],
         [ 2251],
         [  423],
         [  471],
         [24370],
         [  297],
         [  287],
         [  491],
         [  278],
         [ 2251],
         [29891],
         [ 1885],
         [  362],
         [29889],
         [  491],
         [  278],
         [ 6124],
         [  310],
         [  278],
         [ 1785],
         [15719],
         [  680],
         [29892],
         [  263],
         [  476],
         [17108],
         [ 1299],
         [29925],
         [29897],
         [ 8242],
         [ 2908],
         [  261],
         [29889],
         [  450],
         [  385],
         [  310],
         [29871],
         [  945],
         [  514],
         [ 1070],
         [27884],
         [ 1682],
         [  852],
         [  297],
         [  451],
         [ 6602],
         [  278],
         [29928],
         [ 3273],
         [ 8333],
         [  470],
         [  385],
         [ 2251],
         [  423],
         [29892],
         [  541],
         [  372],
         [ 1258],
         [27044],
         [ 1463],
         [  278],
         [18497],
         [  310],
         [12279],
         [ 8333],
         [29889],
         [  450],
         [ 2251],
         [29891],
         [ 1885],
         [  362],
         [ 1258],
         [19910],
         [ 1133],
         [24205],
         [12418],
         [  310],
         [12279],
         [12279],
         [29928],
         [  471],
         [  451],
         [ 6335],
         [ 1573],
         [  491],
         [14060],
         [29871],
         [14060],
         [ 8489],
         [  292],
         [14060],
         [ 2251],
         [  293],
         [  297],
         [  450],
         [ 6335],
         [29892],
         [  278],
         [  385],
         [  545],
         [  304],
         [  385],
         [ 2251],
         [  423],
         [20601],
         [  276],
         [ 2251],
         [29891],
         [ 1885],
         [  362],
         [25785],
         [ 3598],
         [12212],
         [29874],
         [ 2859],
         [  278],
         [ 1791],
         [  310],
         [  278],
         [29928],
         [29889],
         [  337],
         [ 2251],
         [29891],
         [ 1885],
         [  362],
         [29889],
         [  450],
         [  362],
         [  310],
         [  476],
         [17108],
         [ 1299],
         [29925],
         [29897],
         [18196],
         [  491],
         [  297],
         [  385],
         [ 2251],
         [  423],
         [  297],
         [  450],
         [26229],
         [13336],
         [  310],
         [27884],
         [  338],
         [ 5039],
         [ 1078],
         [  476],
         [ 6354],
         [ 6354],
         [  338],
         [  304],
         [  367],
         [  330],
         [  333],
         [ 1230],
         [ 1374],
         [25715],
         [  706],
         [18411],
         [29889],
         [  450],
         [29899],
         [  515],
         [  330],
         [29874],
         [  261],
         [  711],
         [  293],
         [  330],
         [  368],
         [ 1054],
         [ 4848],
         [ 1122],
         [29875],
         [ 7541],
         [  491],
         [ 3144],
         [10122],
         [  297],
         [ 1294],
         [  945],
         [  514],
         [ 1070],
         [ 3144],
         [ 1682],
         [  852],
         [29897],
         [  947],
         [  451],
         [  304],
         [  367],
         [  297],
         [  278],
         [  385],
         [26229],
         [29889],
         [ 2645],
         [  278],
         [  333],
         [ 1230],
         [ 1374],
         [25715],
         [  706],
         [18411],
         [  471],
         [  297],
         [  873],
         [ 2411],
         [29874],
         [ 2859],
         [29889],
         [  385],
         [ 2251],
         [  423],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 462, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  365,   317,  8292,  ...,  2572,   336, 29931],
         [  574,  2219,   493,  ...,   277,   287,   389],
         ...,
         [   13,     3,  7228,  ..., 29903, 29933, 29924],
         [   13,     3, 29949,  ..., 29966, 29903, 29933],
         [   13,     3, 29949,  ...,  1576, 29903, 30143]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [15566,  4124, 27576,  ...,  1222, 11428, 29916],
         [  293,   423, 29747,  ...,   290,   261,   331],
         ...,
         [  423,   293, 29747,  ..., 11248,   983,   713],
         [29889, 29892, 29914,  ...,   491, 14030, 14060],
         [   13,   450,     2,  ...,  8680,  1334,   313]]], device='cuda:0')
Batch 22, 43.8% of total tokens
encoded shape: torch.Size([2, 707])
torch.Size([2, 707]) tensor([[    1,   660, 29901,  ...,  2400,    13,    13],
        [    1,   910,   338,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 707, 32000]) tensor([[[-12.8281,  -7.3828,  -0.4705,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-10.8672, -10.6562,  -2.9980,  ...,  -6.8203, -10.0859,  -6.8672],
         [-13.6172, -13.5312,  -1.5029,  ...,  -7.1445,  -8.3203,  -5.6445],
         ...,
         [-11.4375, -10.4844,   6.9219,  ...,  -7.9531,  -8.6797,  -9.4453],
         [ -6.7852,  -4.7812,  10.2656,  ...,  -5.4180,  -4.5859,  -3.8125],
         [ -9.9844, -11.0469,   5.1523,  ...,  -4.5078,  -5.9414,  -4.3164]],

        [[-12.8281,  -7.3828,  -0.4705,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-13.9141, -11.0625,  -4.8086,  ...,  -8.3672,  -9.4141,  -9.1250],
         [ -8.3750,  -8.6172,   0.5928,  ...,  -3.6836,  -4.3867,  -4.9023],
         ...,
         [ -7.9336,   2.9082,   5.2109,  ...,  -2.7910,  -4.4570,  -1.2871],
         [ -7.8672,   2.9414,   5.2031,  ...,  -2.7578,  -4.4219,  -1.2939],
         [ -7.8711,   2.9062,   5.1562,  ...,  -2.7754,  -4.4414,  -1.3242]]],
       device='cuda:0')
torch.Size([2, 707, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [20001]],

        [[  917],
         [  338],
         [  263],
         ...,
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 707, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13, 29901,   448,  ...,   871, 29889, 29871],
         [   13, 29961,     2,  ..., 29898, 29899,  7264],
         [20001, 22550, 29961,  ..., 29902, 29907,  2052]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  338,  4723,  6251,  ...,  1400, 29871,   471],
         [  263,   278,   385,  ...,  1749,   920,   760],
         ...,
         [   13,     3, 29966,  ...,  1576, 30143,  9314],
         [   13,     3, 29966,  ...,  1576, 30143,  9314],
         [   13,     3, 29966,  ...,  1576, 30143,  9314]]], device='cuda:0')
Batch 23, 44.8% of total tokens
encoded shape: torch.Size([2, 2288])
torch.Size([2, 2288]) tensor([[    1, 29871, 29896,  ...,     2,     2,     2],
        [    1,   450,  2198,  ...,   262, 22503, 29889]], device='cuda:0')
torch.Size([2, 2288, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.0156,  -3.6582,   0.7739,  ...,  -4.5352,  -6.8125,  -4.2930],
         ...,
         [-11.8750,   6.1367,   1.2197,  ...,  -5.5938,  -7.6328,  -6.0234],
         [-11.8906,   6.1875,   1.1953,  ...,  -5.6211,  -7.6719,  -6.0664],
         [-11.9141,   6.2617,   1.2061,  ...,  -5.6094,  -7.6797,  -6.0664]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-13.5078, -11.7266,  -6.9688,  ...,  -9.1484, -10.2422,  -8.5703],
         [-10.8047,  -5.6016,  -0.6538,  ...,  -4.1094,  -6.8555,  -5.3242],
         ...,
         [ -4.3203,  -6.9297,   7.8203,  ...,  -1.6758,  -2.7578,  -1.9180],
         [ -4.0469,  -7.7461,  10.0000,  ...,  -0.6445,  -3.0801,  -1.8604],
         [ -0.3040,  -1.2812,  14.4688,  ...,   1.8945,   0.5405,  -2.4316]]],
       device='cuda:0')
torch.Size([2, 2288, 1]) tensor([[[  917],
         [29896],
         [29889],
         ...,
         [    1],
         [    1],
         [    1]],

        [[  917],
         [29871],
         [  297],
         ...,
         [22503],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 2288, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [29889, 29900, 29929,  ..., 29946, 29941, 29953],
         ...,
         [    1,    13,     3,  ..., 29909, 29924, 29933],
         [    1,    13,     3,  ..., 29909, 29924, 29933],
         [    1,    13,     3,  ..., 29909, 29924, 29933]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  297,  6559,  5650,  ...,  5925,  4274,   800],
         ...,
         [22503,  2400, 29889,  ..., 27215,  1156, 11083],
         [29889, 29892,   322,  ...,   491,   411,   363],
         [   13,   739,   450,  ...,  1094, 25870,  3834]]], device='cuda:0')
Batch 24, 47.2% of total tokens
encoded shape: torch.Size([2, 2906])
torch.Size([2, 2906]) tensor([[    1,   450,   297,  ...,   278,  4377, 29889],
        [    1, 29871, 29896,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2906, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-13.5078, -11.7266,  -6.9688,  ...,  -9.1484, -10.2422,  -8.5703],
         [-10.4766,  -9.2891,  -3.4238,  ...,  -7.1133,  -7.1953,  -5.9570],
         ...,
         [ -9.2812, -11.0703,   0.5161,  ...,  -8.0391,  -4.2578,  -5.0469],
         [ -4.9531,  -5.1719,   5.3750,  ...,  -4.7539,   0.4209,  -2.5332],
         [ -3.2227,  -6.1016,  12.0000,  ...,  -1.5156,  -0.2979,  -2.5098]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.0156,  -3.6582,   0.7739,  ...,  -4.5352,  -6.8125,  -4.2930],
         ...,
         [ -9.4453,   2.8516,   1.8496,  ...,  -4.8594,  -6.0195,  -4.6445],
         [ -9.3438,   2.8496,   1.9609,  ...,  -4.7070,  -5.8125,  -4.4688],
         [ -9.2656,   2.9590,   2.1445,  ...,  -4.5234,  -5.5977,  -4.2500]]],
       device='cuda:0')
torch.Size([2, 2906, 1]) tensor([[[  917],
         [29871],
         [ 7316],
         ...,
         [11580],
         [29889],
         [   13]],

        [[  917],
         [29896],
         [29889],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 2906, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [ 7316, 29899,  3097,  ...,   510, 20309,  1760],
         ...,
         [11580, 13994,  1342,  ...,  6455,  6139, 10259],
         [29889, 29901, 29892,  ...,   607,   988,  6139],
         [   13,   512,   450,  ...,   383,  1383,  2398]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [29889, 29900, 29929,  ..., 29946, 29941, 29953],
         ...,
         [    3, 29949,    13,  ..., 29903,     1, 29911],
         [    3, 29949,    13,  ..., 29903, 29911,     1],
         [    3, 29949,    13,  ..., 30140, 29911, 29924]]], device='cuda:0')
Batch 25, 50.5% of total tokens
encoded shape: torch.Size([2, 1490])
torch.Size([2, 1490]) tensor([[    1,  8170,   462,  ...,     2,     2,     2],
        [    1,   450,  2198,  ...,   740,   292, 29889]], device='cuda:0')
torch.Size([2, 1490, 32000]) tensor([[[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [-13.5625, -12.6562,  -4.0078,  ...,  -8.5547, -10.0938,  -7.5430],
         [-10.8047,  -8.2266,  -2.1504,  ...,  -4.1602,  -5.6094,  -6.8516],
         ...,
         [ -8.1719,   2.4316,   3.7754,  ...,  -3.1113,  -4.4180,  -1.8877],
         [ -8.1875,   2.4219,   3.7793,  ...,  -3.1211,  -4.4297,  -1.8965],
         [ -8.3281,   2.3496,   3.7852,  ...,  -3.1973,  -4.5195,  -1.9346]],

        [[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [-13.5078, -11.7188,  -6.9688,  ...,  -9.1484, -10.2344,  -8.5703],
         [-10.7891,  -5.5820,  -0.6401,  ...,  -4.1055,  -6.8477,  -5.3164],
         ...,
         [ -3.6895,  -5.0078,   5.6289,  ...,  -0.8291,  -1.4336,  -4.3867],
         [ -4.7891,  -6.5508,   5.5898,  ...,  -1.5430,  -0.7354,  -4.6836],
         [  0.2522,  -0.7896,  15.8594,  ...,   0.3689,   0.1019,  -1.4980]]],
       device='cuda:0')
torch.Size([2, 1490, 1]) tensor([[[  917],
         [ 7395],
         [  462],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [29871],
         [  297],
         ...,
         [  292],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 1490, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 7395,   310,   596,  ..., 13542,   278,   297],
         [  462,   259, 29871,  ...,  9651,   418,   965],
         ...,
         [    3,    12,    13,  ..., 30166,  6224, 12008],
         [    3,    12,    13,  ..., 30166,  6224, 12008],
         [    3,    12,    13,  ...,  6224, 30166,  1678]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  297,  6559,  5650,  ...,  5925,  4274,   800],
         ...,
         [  292, 29889, 29892,  ...,   408,   297,   310],
         [29889, 29892,   322,  ...,   310,   297,  1728],
         [   13,   450,   739,  ...,   319,  4001,  4525]]], device='cuda:0')
Batch 26, 52.6% of total tokens
encoded shape: torch.Size([2, 598])
torch.Size([2, 598]) tensor([[    1, 10750,   368,  ...,  4182,  1022, 29889],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 598, 32000]) tensor([[[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [ -8.7031,  -7.5156,  -1.3682,  ...,  -4.7812,  -6.3516,  -5.5352],
         [ -9.3984, -11.5078,   0.5171,  ...,  -8.3594,  -5.4727,  -6.6641],
         ...,
         [ -5.4023,  -2.3574,  14.3750,  ...,  -2.2617,   1.5938,  -3.5332],
         [  3.5039,   6.5938,  18.9375,  ...,   1.0469,   3.1992,   0.1486],
         [  2.6992,   4.4766,  19.9531,  ...,   1.8389,   2.4648,   2.1836]],

        [[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [-10.8672, -10.6484,  -3.0000,  ...,  -6.8242, -10.0938,  -6.8711],
         [-13.6250, -13.5312,  -1.5029,  ...,  -7.1445,  -8.3359,  -5.6523],
         ...,
         [ -9.8750,   2.4805,   3.0332,  ...,  -4.3398,  -5.6016,  -1.7734],
         [ -9.6641,   2.8457,   2.9570,  ...,  -4.1406,  -5.4219,  -1.5908],
         [ -9.5703,   3.0352,   2.9766,  ...,  -4.0430,  -5.3125,  -1.5029]]],
       device='cuda:0')
torch.Size([2, 598, 1]) tensor([[[  917],
         [  368],
         [30010],
         ...,
         [ 1022],
         [   13],
         [   13]],

        [[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 598, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  368,  1100, 29891,  ...,   457, 19413, 29889],
         [30010, 29915,   338,  ..., 17716,   315,   341],
         ...,
         [ 1022, 29872,    13,  ..., 29871,     2,   287],
         [   13, 28590, 29871,  ...,   313, 29908,  3087],
         [   13,     2, 29871,  ..., 28590,   476,   448]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,  7228, 29871,  ...,  1678, 29949,   268],
         [   13,  7228, 29871,  ...,  1678, 29949,   268],
         [   13,  7228, 29871,  ...,  1678, 29949,   268]]], device='cuda:0')
Batch 27, 53.3% of total tokens
encoded shape: torch.Size([2, 354])
torch.Size([2, 354]) tensor([[    1, 28984,   324,   666,   680, 13076, 29871, 29906, 29899, 29961,
         29946, 17722, 29896, 29892, 29896, 29899,  6229,   621,  1508,   386,
          2904, 29897,  9789,  2904, 29962, 29899, 29946, 29950, 29899, 29941,
         29892, 29896, 29899,  1785, 29920,  2251,   834,   262, 29899, 29946,
         29899,  2873, 29889,  3767, 12425, 29899, 10072, 21702,   310,   263,
          9554,  3652,   310,  1880, 29899, 21518,   537,   619,  7323,  4859,
           262, 11858,  4097, 29889,    13,  1576, 10223,   362,   322,   715,
         25392,   619,  5935, 10551,   292, 21862,   310,   263,  3652,   310,
         29871, 29946, 29950, 29899, 29941, 29892, 29896, 29899,  1785, 29920,
          2251,   834,   262, 29899, 29946, 29899,  2873,   526,  5439, 29889,
          9665,  1129,   305,   324,   342,  1489,  2409,   293, 29892, 10163,
           327,  8966,   368,  2265,   680, 13076, 29892,   322,  1880, 29899,
         21518,   537, 29899,  3466,   459,  4859,   262, 11858,  1218,  4426,
           526,  1476,   363, 25748, 24638,   263, 29871, 29946, 17722, 29896,
         29892, 29896, 29899,  6229,   621,  1508,   386,  2904, 29897,  9789,
          2904,  2318,   472,   278, 29871, 29906, 29899,  3283, 29892,   322,
           445,  6354,   338,  8833,   297,  1716, 11266,   305,   324,   342,
          1489,  2409,   293,   322,   297,  6056,   324,   666,   680, 13076,
           364,  1446,   746,   278,  9228,  1788,   338,  5960,   277,  3860,
           472,  2602, 29871, 29953,   411, 17546,  1885, 29892,   286,   621,
          2904, 29892,   521,  5095, 29877, 29892,   470,   474,  8144,  6471,
         29892,   322,   338, 14413,   746,   278, 29871, 29953, 29899,  3283,
           338,  5960,   277,  3860,   491,   263,   289,   456,   457, 12301,
         29889,  7298,  5084,   338,  9132, 26233,   393,   263,  1539, 19388,
           568,   470,   316,  5105,   362,  3234,   338, 14040,   363,   278,
          3620,   297,   619,  7323,  4859,   262, 26702,  8900,   411,  6136,
         13206, 21337,   310,   445,  1134, 29889, 10829, 26533,   310, 23483,
           630,   316,  5105,   362,  9316,   310,   278,  6136, 13206, 21337,
          4846,  9316, 16384,   278,  3806,   297,   325,  4243,  6354, 29892,
           541,   694, 20414,   297,   278, 12474,   266,  1572,   412,   329,
           293,  5906,   310,   278,  1900,   752,   618, 29892, 29871, 29953,
         29899, 29890,   456, 29877, 29899, 29906, 29899, 29961, 29946, 17722,
         29896, 29892, 29896, 29899,  6229,   621,  1508,   386,  2904, 29897,
          9789,  2904, 29962, 29899, 29946, 29950, 29899, 29941, 29892, 29896,
         29899,  1785, 29920,  2251,   834,   262, 29899, 29946, 29899,   650,
         29892,   471,  7625, 29889],
        [    1, 21141,  2200,  1070,   285,  4626,   453,   362,   752,   506,
          1218, 13201,  9712,  2200,  1070,   282,  9390,   297,  1274,  1082,
           590,   542,   538,   616,  3041,   279,   428, 29901, 26002,   310,
          1492,  9712,  2200,  1070,  3041,   279,   428, 29889,    13, 29943,
           573, 22069,   411,  1274,  1082,   590,   542,   538,   616,  3041,
           279,   428,   750,  9712,  2200,  1070,   285,  4626,   453,   362,
           408,   263,   752,  1414,   310, 18694, 13201,   282,  9390, 29889,
          2178,  5320, 22069,   750, 10757,   310,  1492,  9712,  2200,  1070,
          3041,   279,   428,   313, 17536, 22069,   411,  1400, 29720,   331,
          9659,   362,   467,   450, 10122,   310,  1492,  9712,  2200,  1070,
          3041,   279,   428,  2444,   304,   367,   263, 17737, 17068, 13336,
          9701,   297,   278, 21445,   310,  9712,  2200,  1070,   285,  4626,
           453,   362,  2645, 13201,   282,  9390,   363,  1506,  3714,  2749,
         29882, 29265,   423,   752,   506,  1218,  1274,  1082,   590,   542,
           538,   616,  3041,   279,   428, 29889,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 354, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-10.3750,  -8.7812,  -0.6113,  ...,  -6.6992,  -6.8477,  -4.3984],
         [ -7.2500,  -4.6602,   0.5957,  ...,  -5.4609,  -4.8594,  -5.9375],
         ...,
         [ -6.5938,  -8.7109,   4.8125,  ...,  -4.4766,  -5.9609,  -2.9336],
         [ -1.8896,  -1.1016,  12.6094,  ...,  -1.4121,  -3.1934,  -2.9199],
         [ -6.6602,  -8.6484,  15.6953,  ...,  -2.5547,  -3.0723,  -1.5996]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [ -9.6016,  -8.6250,   0.6841,  ...,  -4.0430,  -5.9414,  -3.3750],
         [ -7.7109,  -9.4922,   3.3281,  ...,  -1.0596,  -2.0293,  -1.0283],
         ...,
         [ -8.6797,   2.9727,   4.1719,  ...,  -2.3320,  -4.5469,  -1.5830],
         [ -8.7578,   2.8926,   4.1367,  ...,  -2.3867,  -4.6250,  -1.6104],
         [ -8.8594,   3.0254,   3.8086,  ...,  -2.4648,  -4.5781,  -1.5098]]],
       device='cuda:0')
torch.Size([2, 354, 1]) tensor([[[  917],
         [17639],
         [  666],
         [  680],
         [13076],
         [26475],
         [29896],
         [29900],
         [29909],
         [29906],
         [17722],
         [29906],
         [29899],
         [29906],
         [29899],
         [ 6229],
         [  621],
         [ 1508],
         [  386],
         [ 2904],
         [ 6817],
         [ 9789],
         [ 2904],
         [29962],
         [29899],
         [29941],
         [29899],
         [29899],
         [29896],
         [29892],
         [29896],
         [29899],
         [ 1785],
         [29920],
         [ 2251],
         [  834],
         [  262],
         [29899],
         [29946],
         [29899],
         [  650],
         [   13],
         [   13],
         [12425],
         [29899],
         [10072],
         [21702],
         [  322],
         [29871],
         [ 3652],
         [  770],
         [  310],
         [29871],
         [29899],
         [ 3470],
         [  537],
         [  619],
         [ 7323],
         [ 4859],
         [  262],
         [29899],
         [ 1218],
         [29889],
         [   13],
         [29909],
         [ 3829],
         [  362],
         [  310],
         [ 3829],
         [25392],
         [ 1374],
         [ 7323],
         [29899],
         [  292],
         [ 6354],
         [  310],
         [  263],
         [ 3652],
         [  310],
         [29871],
         [29906],
         [29899],
         [29899],
         [29941],
         [29892],
         [29896],
         [29899],
         [ 1785],
         [29920],
         [ 2251],
         [  834],
         [  262],
         [29899],
         [29946],
         [29899],
         [  650],
         [  526],
         [ 5439],
         [29889],
         [  450],
         [ 1129],
         [  305],
         [  324],
         [  342],
         [ 1489],
         [ 2409],
         [  293],
         [ 6354],
         [10163],
         [  327],
         [ 8966],
         [  368],
         [ 2265],
         [  680],
         [13076],
         [29892],
         [  322],
         [10163],
         [29899],
         [21518],
         [  537],
         [  619],
         [ 3466],
         [  459],
         [ 4859],
         [  262],
         [  313],
         [ 1218],
         [ 6354],
         [  892],
         [28585],
         [  304],
         [  278],
         [  310],
         [  263],
         [29871],
         [29946],
         [29899],
         [29896],
         [29892],
         [29896],
         [29899],
         [ 6229],
         [  621],
         [ 1508],
         [  386],
         [ 2904],
         [29897],
         [ 9789],
         [ 2904],
         [ 2318],
         [  472],
         [  278],
         [29871],
         [29906],
         [29899],
         [ 3283],
         [29889],
         [  322],
         [  263],
         [ 2318],
         [  338],
         [ 8855],
         [  491],
         [  263],
         [  278],
         [  305],
         [  324],
         [  342],
         [ 1489],
         [ 2409],
         [  293],
         [  322],
         [ 6056],
         [ 6056],
         [ 2878],
         [  666],
         [  680],
         [13076],
         [15006],
         [ 1446],
         [29889],
         [ 4113],
         [  752],
         [ 1788],
         [  338],
         [ 5960],
         [  277],
         [ 3860],
         [  411],
         [  278],
         [29871],
         [29946],
         [  411],
         [  263],
         [29916],
         [29892],
         [  286],
         [  621],
         [ 2904],
         [29892],
         [11314],
         [ 5095],
         [29877],
         [29892],
         [  470],
         [20501],
         [ 8144],
         [29889],
         [29889],
         [  470],
         [  472],
         [  884],
         [  746],
         [  278],
         [29871],
         [29953],
         [29899],
         [ 3283],
         [  338],
         [ 5960],
         [  277],
         [ 3860],
         [  411],
         [  263],
         [  286],
         [  456],
         [29877],
         [12301],
         [29889],
         [  450],
         [ 5084],
         [  338],
         [ 9132],
         [  393],
         [  393],
         [  278],
         [29871],
         [19388],
         [  568],
         [  310],
         [ 1539],
         [ 5105],
         [  362],
         [ 3234],
         [  310],
         [14040],
         [  363],
         [  278],
         [10163],
         [  297],
         [  715],
         [ 5935],
         [ 4859],
         [  262],
         [11174],
         [29889],
         [  297],
         [ 1438],
         [  752],
         [21337],
         [29889],
         [  445],
         [ 3652],
         [29889],
         [   13],
         [26533],
         [  310],
         [  278],
         [  630],
         [ 1539],
         [ 5105],
         [  362],
         [ 9316],
         [  338],
         [  278],
         [ 6136],
         [13206],
         [21337],
         [  338],
         [  694],
         [  411],
         [10163],
         [ 1021],
         [ 4768],
         [13901],
         [ 4243],
         [ 6354],
         [29889],
         [  322],
         [  278],
         [10757],
         [  297],
         [  278],
         [  297],
         [  266],
         [ 1572],
         [  412],
         [  329],
         [  293],
         [ 2380],
         [  310],
         [  278],
         [ 3847],
         [  752],
         [  618],
         [  471],
         [29871],
         [29906],
         [29899],
         [29890],
         [  456],
         [29877],
         [29899],
         [29906],
         [29899],
         [29961],
         [29946],
         [17722],
         [29896],
         [29892],
         [29896],
         [29899],
         [ 6229],
         [  621],
         [ 1508],
         [  386],
         [ 2904],
         [29897],
         [ 9789],
         [ 2904],
         [29962],
         [29899],
         [29946],
         [29950],
         [29899],
         [29941],
         [29892],
         [29896],
         [29899],
         [ 1785],
         [29920],
         [ 2251],
         [  834],
         [  262],
         [29899],
         [29946],
         [29899],
         [  650],
         [29892],
         [  471],
         [ 8900],
         [29889],
         [   13]],

        [[  917],
         [  545],
         [ 1070],
         [28742],
         [ 4626],
         [  453],
         [  362],
         [  313],
         [  506],
         [ 1218],
         [ 1274],
         [  282],
         [ 2200],
         [ 1070],
         [  282],
         [ 9390],
         [  297],
         [  263],
         [ 1082],
         [  590],
         [  542],
         [  538],
         [  616],
         [ 3041],
         [  279],
         [  428],
         [29889],
         [  263],
         [  310],
         [  278],
         [ 9712],
         [ 2200],
         [ 1070],
         [  282],
         [  279],
         [  428],
         [29889],
         [   13],
         [29909],
         [ 4626],
         [22069],
         [  411],
         [ 1274],
         [ 1082],
         [  590],
         [  542],
         [  538],
         [  616],
         [ 3041],
         [  279],
         [  428],
         [  322],
         [ 9712],
         [ 2200],
         [ 1070],
         [  285],
         [ 4626],
         [  453],
         [  362],
         [  313],
         [  263],
         [  752],
         [ 1414],
         [  310],
         [13201],
         [13201],
         [ 9712],
         [ 9390],
         [29889],
         [  512],
         [22069],
         [22069],
         [  750],
         [ 1492],
         [  310],
         [ 1492],
         [ 9712],
         [ 2200],
         [ 1070],
         [ 3041],
         [  279],
         [  428],
         [  373],
         [29934],
         [  750],
         [  750],
         [ 1492],
         [ 7192],
         [  331],
         [10757],
         [  362],
         [  467],
         [  512],
         [ 1492],
         [  310],
         [ 1492],
         [ 9712],
         [ 2200],
         [ 1070],
         [ 3041],
         [  279],
         [  428],
         [  471],
         [  304],
         [  367],
         [  263],
         [ 7282],
         [17068],
         [ 7329],
         [  297],
         [  297],
         [  278],
         [ 5849],
         [  310],
         [ 9712],
         [ 2200],
         [ 1070],
         [  285],
         [ 4626],
         [  453],
         [  362],
         [29889],
         [13201],
         [  282],
         [ 9390],
         [29889],
         [ 1274],
         [ 3714],
         [ 7543],
         [29882],
         [ 1541],
         [  423],
         [29889],
         [  506],
         [ 1218],
         [ 1274],
         [ 1082],
         [  590],
         [  542],
         [  538],
         [  616],
         [ 3041],
         [  279],
         [  428],
         [29889],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [29873],
         [29873],
         [    1],
         [30488],
         [30488],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 354, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [17639,   542,   720,  ...,   468,  1217,   287],
         [  666,  1314,   326,  ...,  4003,   627,  2251],
         ...,
         [ 8900,  1476, 14363,  ..., 20295,  1098, 10943],
         [29889,   491,   411,  ...,  1549,   975,   773],
         [   13,     2,   450,  ...,  2398,   739,  3767]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  545,  2002,  8634,  ...,  4115,  1705,  1973],
         [ 1070,   280,   793,  ..., 14549, 29884,  2497],
         ...,
         [   13, 30166,  1576,  ..., 29924, 29909, 29943],
         [   13, 30166,  1576,  ..., 29924, 29909, 29949],
         [   13,  1576, 30166,  ..., 29924, 29909, 29949]]], device='cuda:0')
Batch 28, 53.8% of total tokens
encoded shape: torch.Size([2, 1076])
torch.Size([2, 1076]) tensor([[    1,   450,   301,  ...,   277,  2913, 29889],
        [    1,   450, 14675,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1076, 32000]) tensor([[[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-13.5156, -11.7344,  -6.9766,  ...,  -9.1484, -10.2500,  -8.5781],
         [ -9.2422,  -6.5273,   0.8335,  ...,  -3.1582,  -3.8145,  -4.4258],
         ...,
         [ -7.1719,  -5.5078,   8.5547,  ...,  -4.7461,  -2.9707,  -5.0508],
         [ -4.1758,  -3.2852,  11.2344,  ...,  -1.0977,  -0.2957,  -1.2568],
         [ -2.5664,  -2.9473,  17.7812,  ...,   0.7280,  -2.5430,  -2.5059]],

        [[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-13.5156, -11.7344,  -6.9766,  ...,  -9.1484, -10.2500,  -8.5781],
         [ -5.2656,  -1.8252,   6.4844,  ...,  -1.6758,  -3.0430,  -1.5156],
         ...,
         [ -7.5977,   2.5684,   2.9180,  ...,  -2.8613,  -4.3281,  -2.5625],
         [ -7.5703,   2.5762,   2.8906,  ...,  -2.8613,  -4.3125,  -2.5605],
         [ -7.5430,   2.5664,   2.8633,  ...,  -2.8652,  -4.3086,  -2.5703]]],
       device='cuda:0')
torch.Size([2, 1076, 1]) tensor([[[  917],
         [29871],
         [  545],
         ...,
         [29889],
         [29889],
         [   13]],

        [[  917],
         [29871],
         [  310],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1076, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  545,   291,   575,  ..., 18919,  3322,  7004],
         ...,
         [29889,   322,   304,  ..., 10462,   664,  4312],
         [29889, 29892,   322,  ...,   373,   297,   372],
         [   13,   450,     2,  ...,  3080,   512,  5798]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  310,   653,   322,  ...,   304, 29879,  7113],
         ...,
         [    3, 30166,    12,  ..., 30212,   197,  9137],
         [    3, 30166,    12,  ..., 30212,   197,  9137],
         [    3, 30166,    12,  ..., 30212,   197,  9137]]], device='cuda:0')
Batch 29, 55.1% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   379,  9047,  ...,     2,     2,     2],
        [    1,  4706,  2672,  ..., 29945,   349, 29889]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5000,  -7.9414,   1.5410,  ...,  -4.6641,  -6.1250,  -3.7520],
         [ -6.1133,  -4.9961,   5.2500,  ...,  -0.9795,  -3.9980,  -3.2500],
         ...,
         [ -8.2812,   3.4336,   1.9990,  ...,  -3.9336,  -4.9453,  -3.6035],
         [ -8.3516,   4.1250,   2.3574,  ...,  -3.7930,  -4.9336,  -3.3809],
         [ -8.3672,   4.5039,   2.5078,  ...,  -3.7148,  -4.9258,  -3.2520]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.1484,  -3.8867,  -1.4385,  ...,  -6.0312,  -9.0000,  -4.3828],
         [ -7.0586, -10.1016,  -0.3650,  ...,  -4.6992,  -7.6953,  -5.7656],
         ...,
         [ -5.1953,  -6.6719,   9.2734,  ...,  -1.3320,  -5.7539,  -3.8809],
         [ -6.3164,  -4.8867,   7.6797,  ...,  -1.3506,  -4.7656,  -5.1055],
         [ -5.8125,  -7.5000,   9.8906,  ...,  -1.9395,  -2.9277,  -0.9482]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [ 9806],
         [18929],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [  529],
         [ 6154],
         ...,
         [  349],
         [29889],
         [29941]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 9806, 29889, 29925,  ...,  1466,   681,  5710],
         [18929,  1955, 29871,  ..., 29906, 29946, 29914],
         ...,
         [    3, 29949,    13,  ...,    12, 29907, 29911],
         [    3, 29949,     1,  ..., 29907, 29924, 29968],
         [    3, 29949,     1,  ..., 29907, 29924, 29968]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  529,  6319,   396,  ...,  4363, 10341,   770],
         [ 6154,  4945,  1254,  ..., 29902,  4571, 29903],
         ...,
         [  349,   405,    13,  ..., 29889,   282, 15756],
         [29889,   869, 29941,  ...,  3045, 29906,  1696],
         [29941, 29871, 29906,  ..., 29900,  2052, 29953]]], device='cuda:0')
Batch 30, 59.8% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,    13,  ...,   328,   975,  1213],
        [    1, 23050, 24290,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.1406,  -4.4141,   3.6445,  ...,  -5.2812,  -5.5977,  -2.5449],
         ...,
         [ -6.5781, -11.3047,   3.4414,  ...,  -3.5449,  -4.0352,  -5.8047],
         [ -4.8164,  -6.4609,   3.6250,  ...,  -1.7646,  -5.7891,  -5.0547],
         [ -3.0391,  -4.9883,  11.6641,  ...,  -0.5386,  -1.0049,  -1.6201]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.7383,  -6.8711,   2.4512,  ...,  -4.6641,  -8.0781,  -7.0547],
         [ -0.3796,   0.5039,  11.4531,  ...,   1.8838,  -2.5586,   1.5215],
         ...,
         [ -7.7773,   2.9570,   1.6445,  ...,  -4.1875,  -4.9609,  -3.8203],
         [ -7.8047,   2.9258,   1.6484,  ...,  -4.1797,  -4.9531,  -3.8164],
         [ -7.8594,   2.9277,   1.7129,  ...,  -4.1680,  -4.9492,  -3.8027]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [29896],
         [   13],
         ...,
         [  278],
         [  278],
         [10088]],

        [[  917],
         [24290],
         [ 2725],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [  278,   975,  1009,  ..., 17099,   297,   901],
         [  278,  1213,   738,  ...,  1009,   411,   304],
         [10088,  2401,  5163,  ..., 29961,   450,  2823]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [24290,  1718,  3960,  ...,  8322,  7466,  2190],
         [ 2725, 18474, 27946,  ...,  5667, 29901, 29902],
         ...,
         [    3, 29949,    12,  ..., 30143, 29902, 30166],
         [    3, 29949,    12,  ..., 29902, 30143, 30166],
         [    3, 29949,    13,  ..., 29902, 30166, 30143]]], device='cuda:0')
Batch 31, 64.6% of total tokens
encoded shape: torch.Size([2, 499])
torch.Size([2, 499]) tensor([[    1,   660, 29901,    13,    13,  1888,  2037,   292, 10318,  7490,
          7522,    13,    13, 29902,   471,  5183,   385,  4274,   393,  3697,
           920,  4319,  5920, 29925,  2506,  3913, 10318, 23684,  1379,   322,
           920,  7575,   338, 10292, 23773,   373,   445,  4383,   746, 29892,
           363,  1342, 29892,   263,  1404,   701, 29894,  4769,   385,  1234,
         29914, 12470, 29889,    13, 29902,  4997,   565,  4856,   508,  1298,
           263,  9673,   373,   920,   304,   437,  1316,  3158, 29889,    13,
         29902,  1073,   777,  3291, 29901,    13,    13,  4391,   263,  2563,
          6692,   393,  4947,   278,  3158,   995,   322,  2123,   649, 29879,
           263,  4663,  1347,    13,  8893,   278,  3513,  2768,   529,  6538,
         29901, 29903,   699, 29886,  3260, 29958,  2761,   304,  5191,   278,
          1959,   995,   373,   278,  1813,   411,   278,   716,   995,    13,
            13,  6246, 29892,  1584,   297,   278,   937,   306,   505, 23553,
         29892,   306,   508,  3638,   263,  4663,  1347, 29892,   541,   372,
           674,  2337,   367, 22047,   411,  6560,  2472, 29991,    13,  6028,
          5019,   313,   272,  5505, 12208, 29897,  1298,   304,   263,  7575,
           376,  3525, 29899,   517, 29908,  1951, 22728, 29973,  3374,   366,
         29889,    13,    13, 29909, 29901,    13,    13, 11284, 29892,   306,
          7404, 10292, 23773,  3913, 10318,  7490,   448,   901,  5517,   372,
          3913,  6385,   847,  2254,   304,  3763,  2767,   263,  1933, 29892,
           773, 12738, 29889,  6006, 13348,   408,   278,  2752,   313, 29878,
          1624,  1135, 12738, 29889,  6006,  1109,  2911, 29892,   607,   756,
           263,   901,  4280,  1813, 11412,   467,    13,  3047,   445,  2948,
         29892,   372,   338, 12604,   856,   278,  6385,  6455,  4434, 18425,
          4083,   372,   599, 29889,    13,  1123,  7863,   278, 14355,   448,
           393,   338,  3763,   736, 14355, 29898,  5415,   416,   515,   278,
          4701,   297, 12738, 29889,  6006, 13348,   448,   541, 22345,   306,
         29915, 29881,   736,   278,  3472,   313,  3601, 20069,   467,    13,
            13, 29909, 29901,    13,    13, 18743,   366, 18918,   278, 10318,
          7490,   306,  4368,   366,   505,   263,  1303,   310,   445,  1400,
           306,  1258,   448,  1732,   597,  1636, 29889,  4025,   265, 29899,
         12248,   514, 29889,   510, 29914,  7312, 29914,  2987,   504, 29899,
         29906, 29900, 29900, 29947, 29914, 20640,  5921, 29899,  5504,  8357,
          1379, 29889,  6307, 29889,   739,  3430,   472,   920,   304,  5994,
           895, 10318, 23684,  1379,   322,   372,   508,  3275,   304,   777,
          4180, 16415,   565,  2309,  1532, 29889,    13, 29902,   884,  1258,
           263,  1400,   448,  1732,   597,  1636, 29889,  4025,   265, 29899,
         12248,   514, 29889,   510, 29914,  7312, 29914,  2987,   504, 29899,
         29906, 29900, 29900, 29947, 29914, 29886,  6751, 29899,  1272, 29899,
          4645, 29899,  2975, 29889,  6307,   607,  3430,   472,  2599,  3132,
         29899,  2975,  1350,   572,  1218,   411,  6385,   322, 10888, 18891,
         29889,   306,  1106,   472,   920,   304,  1303,   263,  1856,  2669,
           411,  8286,   322,   565,   366,  5142,   278,  4559,   366, 29915,
           645,  1074,   920,   304,  3638,   848,  3132, 29899,  2975,   304,
           263,  1856,  2669, 29889,    13,  6246,   445,  4863,  4320,   373,
           278, 12738, 29889,  6006,  4700,  1122,   884,   367,   310,   671,
           448,  1732,   597,  1636, 29889,  4692, 29889,  1212, 29914, 19668,
         29914,  6538, 29899, 29894,  7958, 29914,  9641, 29899, 29947, 29906,
         29889,  6307, 29889,   739, 29915, 29879,   373,   920,   304, 10985,
          1856,  5786,   363,  2471,  2669, 27108, 29889,    13,    13],
        [    1,  7255,  1082, 11266, 29883,   441,   275,  1772, 29885,   423,
           338,  6942,   411,  7282, 10551,   800,   297, 26823,  1539, 19388,
          1608,   322,  5864,  1518,   355, 17252,   313, 17896,   467,   512,
         12814,  3273,  1840, 17517,   310, 14710,  7492,  3144,  1682,   542,
           441,  1417,  4841,   338,   451,  6942,   411, 11664,   382, 29923,
         29889,   910,  6559,   674,  4153,  7252,  1274,  1082,   322,  3273,
          1840,  3144,  1682,   542,   441,  1417,   333, 17517,   304,  8161,
           565,   298,   555,  7177,  2779,   373, 26823,  1539, 19388,  1608,
           322,  5864,  1518,   355, 17252, 16317,   666,   630,   411, 14385,
           310,   671, 29889,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 499, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6562],
         ...,
         [ -4.1484,  -4.4453,  16.3750,  ...,  -2.4238,  -1.4834,  -2.7129],
         [ -5.5430,  -2.6641,  10.9766,  ...,  -5.2461,  -4.0195,  -2.4707],
         [ -9.5938,  -9.1797,   3.0625,  ...,  -6.7109,  -5.6250,  -5.1289]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.0898,  -5.3164,   3.4395,  ...,  -2.1270,  -2.2383,   0.2141],
         [ -8.3672,  -9.0625,   1.4609,  ...,  -4.1562,  -5.1016,  -4.8516],
         ...,
         [ -9.6641,   3.5879,   3.7969,  ...,  -3.5195,  -5.3945,  -2.3477],
         [ -9.6484,   3.6172,   3.7910,  ...,  -3.5117,  -5.3906,  -2.3574],
         [ -9.6562,   3.4258,   3.7949,  ...,  -3.5410,  -5.4453,  -2.4414]]],
       device='cuda:0')
torch.Size([2, 499, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         [29902],
         [ 5618],
         [ 2037],
         [  263],
         [  278],
         [29899],
         [29892],
         [29892],
         [   13],
         [29902],
         [  505],
         [ 9873],
         [  445],
         [ 4274],
         [  373],
         [ 1497],
         [  920],
         [  304],
         [  372],
         [29899],
         [ 2506],
         [  338],
         [10318],
         [ 7490],
         [ 1379],
         [29889],
         [  920],
         [  304],
         [  372],
         [  304],
         [23773],
         [29889],
         [  278],
         [ 4383],
         [29889],
         [  372],
         [  297],
         [ 1342],
         [29892],
         [  366],
         [ 1404],
         [11803],
         [29894],
         [ 4769],
         [  263],
         [ 1234],
         [29889],
         [ 9342],
         [29889],
         [   13],
         [   13],
         [  471],
         [  565],
         [  372],
         [ 1033],
         [ 1371],
         [  592],
         [ 1781],
         [  470],
         [  920],
         [  304],
         [ 2334],
         [  445],
         [  263],
         [ 1728],
         [   13],
         [   13],
         [ 2099],
         [  393],
         [ 2305],
         [29901],
         [   13],
         [29905],
         [29896],
         [  263],
         [  716],
         [ 3170],
         [  393],
         [  674],
         [  278],
         [ 1353],
         [  322],
         [  322],
         [ 3639],
         [  649],
         [29879],
         [  278],
         [ 1347],
         [ 1347],
         [29889],
         [   13],
         [  263],
         [10318],
         [  393],
         [  278],
         [ 2154],
         [29901],
         [ 6422],
         [  952],
         [29886],
         [ 7445],
         [29958],
         [   13],
         [   13],
         [ 1246],
         [  278],
         [ 2793],
         [  995],
         [   13],
         [  278],
         [ 1813],
         [29889],
         [  278],
         [  697],
         [  697],
         [29889],
         [   13],
         [ 6246],
         [  306],
         [  306],
         [  565],
         [  445],
         [ 4274],
         [ 1298],
         [ 1016],
         [  694],
         [29889],
         [ 1363],
         [ 1016],
         [29915],
         [  278],
         [ 1347],
         [ 1347],
         [  304],
         [  541],
         [  920],
         [  338],
         [  367],
         [  367],
         [  278],
         [  491],
         [11839],
         [ 8282],
         [29889],
         [   13],
         [   13],
         [ 4856],
         [ 1371],
         [  272],
         [ 1298],
         [ 4856],
         [ 2180],
         [ 1298],
         [  592],
         [  263],
         [ 9673],
         [ 9673],
         [ 3525],
         [  304],
         [  517],
         [29908],
         [  373],
         [  306],
         [29973],
         [   13],
         [  366],
         [29889],
         [   13],
         [   13],
         [22550],
         [29901],
         [   13],
         [   13],
         [29902],
         [29892],
         [  306],
         [29915],
         [  393],
         [23773],
         [  338],
         [10318],
         [23684],
         [29889],
         [  372],
         [ 5517],
         [  372],
         [29915],
         [  263],
         [29889],
         [ 8286],
         [  580],
         [ 2767],
         [ 5191],
         [  278],
         [ 1933],
         [29889],
         [  607],
         [  278],
         [29889],
         [ 6006],
         [18891],
         [29889],
         [  278],
         [14998],
         [29889],
         [ 4716],
         [ 1624],
         [ 1135],
         [12738],
         [29889],
         [ 6006],
         [ 2563],
         [ 2911],
         [  467],
         [  607],
         [  338],
         [  694],
         [ 3287],
         [ 4280],
         [ 2767],
         [11747],
         [  467],
         [   13],
         [   13],
         [  449],
         [  297],
         [29892],
         [  366],
         [29915],
         [12604],
         [  304],
         [   13],
         [  871],
         [  775],
         [  526],
         [  373],
         [ 1510],
         [  372],
         [  599],
         [29889],
         [   13],
         [   13],
         [  635],
         [ 4663],
         [ 4663],
         [ 1347],
         [  366],
         [  338],
         [  263],
         [  263],
         [14355],
         [29898],
         [ 1482],
         [29892],
         [   13],
         [  596],
         [ 4701],
         [29889],
         [  278],
         [29889],
         [ 6006],
         [13348],
         [29889],
         [  322],
         [  366],
         [  306],
         [  723],
         [29881],
         [  671],
         [  263],
         [ 4663],
         [ 1347],
         [ 4746],
         [  572],
         [29892],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [29902],
         [  306],
         [ 1369],
         [  278],
         [ 2969],
         [ 7490],
         [29892],
         [29915],
         [  366],
         [ 1303],
         [  263],
         [ 1106],
         [  310],
         [  445],
         [ 4274],
         [29901],
         [ 5456],
         [  263],
         [ 1732],
         [  597],
         [ 1636],
         [29889],
         [ 4692],
         [  265],
         [29899],
         [12248],
         [  514],
         [29889],
         [  510],
         [29914],
         [29906],
         [29914],
         [29906],
         [  504],
         [29899],
         [29906],
         [29900],
         [29900],
         [29929],
         [29914],
         [ 4692],
         [ 5281],
         [29899],
         [ 4692],
         [ 8357],
         [ 1379],
         [29899],
         [ 6307],
         [   13],
         [   13],
         [29915],
         [  472],
         [  278],
         [  304],
         [ 5994],
         [  895],
         [  278],
         [23684],
         [ 1379],
         [  322],
         [  920],
         [  338],
         [  367],
         [  304],
         [  777],
         [ 8031],
         [  330],
         [29889],
         [  366],
         [ 5149],
         [29889],
         [   13],
         [   13],
         [29915],
         [ 4368],
         [  263],
         [ 1400],
         [  373],
         [ 1732],
         [  597],
         [ 1636],
         [29889],
         [ 4025],
         [  265],
         [29899],
         [12248],
         [  514],
         [29889],
         [  510],
         [29914],
         [ 7312],
         [29914],
         [ 2987],
         [  504],
         [29899],
         [29906],
         [29900],
         [29900],
         [29947],
         [29914],
         [ 4692],
         [ 6751],
         [29899],
         [ 2541],
         [29899],
         [ 2541],
         [29899],
         [ 2975],
         [29889],
         [ 6307],
         [  448],
         [ 3697],
         [  472],
         [  920],
         [  282],
         [ 2625],
         [ 2975],
         [  282],
         [  572],
         [ 1218],
         [  411],
         [10318],
         [  322],
         [12738],
         [18891],
         [29889],
         [   13],
         [29915],
         [  472],
         [  920],
         [  304],
         [  437],
         [  278],
         [  282],
         [ 2669],
         [  322],
         [ 6385],
         [  322],
         [  920],
         [  366],
         [ 1106],
         [  278],
         [ 2752],
         [  366],
         [  508],
         [  645],
         [ 1074],
         [  920],
         [  304],
         [  437],
         [  278],
         [ 1250],
         [29899],
         [ 2975],
         [  322],
         [  278],
         [ 1856],
         [ 2669],
         [29889],
         [   13],
         [   13],
         [  306],
         [  338],
         [  338],
         [  448],
         [17368],
         [  341],
         [29889],
         [ 6006],
         [ 3268],
         [  338],
         [ 1371],
         [  367],
         [  310],
         [ 4066],
         [  448],
         [ 1732],
         [  597],
         [ 1636],
         [29889],
         [ 4692],
         [29889],
         [ 1212],
         [29914],
         [19668],
         [29914],
         [29894],
         [29914],
         [29894],
         [ 7958],
         [29914],
         [ 9641],
         [29899],
         [29896],
         [29945],
         [29889],
         [ 6307],
         [29889],
         [   13],
         [ 3697],
         [29879],
         [  263],
         [  278],
         [  304],
         [  671],
         [  278],
         [ 5786],
         [  411],
         [18891],
         [  292],
         [ 5717],
         [29889],
         [   13],
         [   13],
         [20001]],

        [[  917],
         [ 2124],
         [10057],
         [16808],
         [  441],
         [  275],
         [  324],
         [29885],
         [  423],
         [  297],
         [ 6942],
         [  411],
         [11664],
         [ 3036],
         [  800],
         [  297],
         [  278],
         [ 4603],
         [19388],
         [ 1608],
         [29889],
         [11664],
         [ 1518],
         [  355],
         [17252],
         [29889],
         [17896],
         [  467],
         [  450],
         [  445],
         [29892],
         [29899],
         [11266],
         [  310],
         [ 3144],
         [ 7492],
         [ 3144],
         [ 1682],
         [  542],
         [  441],
         [ 1417],
         [ 4841],
         [  313],
         [ 6942],
         [ 6942],
         [  411],
         [10551],
         [  382],
         [29923],
         [29889],
         [   13],
         [ 6559],
         [ 7405],
         [ 8161],
         [ 7252],
         [  278],
         [ 1082],
         [11266],
         [17168],
         [ 1840],
         [ 9545],
         [ 1682],
         [  542],
         [  441],
         [ 1417],
         [  333],
         [17517],
         [  373],
         [ 8161],
         [  565],
         [  278],
         [  555],
         [  650],
         [11525],
         [  373],
         [  382],
         [ 1539],
         [19388],
         [ 1608],
         [  322],
         [  382],
         [ 1518],
         [  355],
         [17252],
         [  526],
         [  666],
         [ 1078],
         [  411],
         [ 3273],
         [  310],
         [17517],
         [29889],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [    1],
         [30488],
         [30488],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 7228],
         [ 7228],
         [ 7228],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 7228],
         [ 7228],
         [ 7228],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 7228],
         [ 7228],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 7228],
         [ 7228],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 7228],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [   13],
         [    3],
         [    3],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [    3],
         [    3],
         [   13],
         [ 7228],
         [ 7228],
         [ 7228],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [ 7228],
         [ 7228],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 499, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,     2,   739,  ...,   910,  1670,   512],
         [   13, 29950, 29902,  ...,  2855,  1576,  8439],
         [20001, 29909, 22550,  ...,  3644,  2887, 26856]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 2124,   510, 18291,  ...,   339,   328,   300],
         [10057,   322,   590,  ...,   301,  2538,  4325],
         ...,
         [    3,    13,  7228,  ..., 30166, 29954,  1576],
         [    3,    13,  7228,  ..., 30166,  1576, 29954],
         [    3,    13,  7228,  ..., 30166,  1576, 29954]]], device='cuda:0')
Batch 32, 65.2% of total tokens
encoded shape: torch.Size([2, 333])
torch.Size([2, 333]) tensor([[    1, 22510, 29882,    13,    13, 29954,   403, 29882,  3861,  1122,
          2737,   304, 29901,    13, 22510, 29882,   897, 29882,    13, 22510,
         29882, 29899,  4099,  2567,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,  7803, 29899,  6360,  8078, 29879,   526,   674,  4720,   367,
           528,  5963,   287,   491,  1790,  3148,  1559,  4336, 29889,  1551,
          5490, 29871, 29947, 29892, 29871, 29906, 29900, 29896, 29953, 29892,
         15531, 29987, 29911,   674,  5040, 27032,  8078, 29879,   411,   967,
         15040,   561,  2873, 29892,   278,  5455, 16725,   304, 24323, 29903,
          1111,   459, 29889,  2193,  2794,   393,   278,   871,  5837,   304,
           679,   263,   716,  9008,   515, 15531, 29987, 29911,   674,   367,
           304,  5146,  2989,  8666,   470,  5146,   297,  2601,  1860,   411,
         15531, 29987, 29911,  8084, 29889, 15531, 29987, 29911,   947,  1827,
           393,  5381, 20330,   674,  1603,   367,  2221,   304,   679,   263,
          8078, 29889,    13,    13,  6816,   273,  8000, 29892,   454, 10327,
           322, 16558,   943,   505, 28453,   901,  3578,   373, 15531, 29987,
         29911, 30010, 29879,   701, 11506,  4337, 29889,   951, 12535, 15531,
         29987, 29911, 10701,  1510,   393, 25531,  1798, 18162, 29892,   607,
         10325, 11084, 27032,  8078, 29879,   304,   716, 20330,   541,  1603,
          2758,  5923,  8078, 20330,   304, 14955,   304,   263, 11684,   333,
          1891,  9008, 29892,  8078, 29879,   674,   367,  7123,   363,  1716,
           716,   322,  5923, 15531, 29987, 29911, 20330, 29889,   960,   366,
           864,   263,  1591, 29873, 29892,  7375, 17500, 29892, 19531,   519,
         29892,   470,  4685,   310, 28706,  4742,   515, 15531, 29987, 29911,
         29892,  2466, 29892,   263,   360,  1007, 29899, 26754,  3461,  4083,
           393,   366, 30010,   645,  1603,   367,  2221,   304,   679,  1906,
          9316,   373,   263,  8078, 29889,    13,    13, 21263, 29879,  1304,
           304,   367,   278,   982,   393,  5051,  1568,   599,  3148, 26677,
         20330, 18093,   263,   716,  9008, 29892,   541,   297,  7786,  2440,
         29892,   278, 19638,   414,   505,  1063,  8401,   304,  2601,   358,
         13900, 29889, 15531, 29987, 29911,  4687,   304,  4337,  3448,   515,
          8078, 29879,  8859,   445,  1629,   746,   372, 11084, 27032,   963,
           472,  4654, 29899, 22633,  3240,   737,   414,   763,  6407,  5373,
         29891, 29892,   541,  4720,   896, 30010,   645,  5040,  1641,  3625,
           472, 15531, 29987, 29911, 14422, 29892,  2086, 29889,   739, 30010,
         29879,   263,  4802,  5376,   363,   278,  3148, 26677, 13661,   393,
          6911,   304,  1510, 11233,   414,   278,  1565,  3438,   310,   263,
         15040,  6710, 29889]], device='cuda:0')
torch.Size([2, 333, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-12.3281, -10.5625,  -2.1172,  ...,  -7.1484,  -7.1055,  -8.7656],
         [ -8.7969,  -5.9766,   6.4609,  ...,  -2.1211,  -7.1680,  -3.0430],
         ...,
         [ -7.7617,   4.8125,   7.0703,  ...,  -1.2510,  -3.1191,  -0.5317],
         [ -7.6875,   4.7266,   7.0938,  ...,  -1.2002,  -3.0859,  -0.4487],
         [ -7.6523,   4.6680,   7.0820,  ...,  -1.1855,  -3.0723,  -0.4177]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-10.4453,  -9.0312,  -1.7002,  ...,  -9.1406,  -9.2266,  -6.6016],
         [ -6.7656,  -9.5703,   1.4365,  ...,  -5.6445,  -4.3594,  -3.4824],
         ...,
         [ -0.9873,  -5.1562,  11.7344,  ...,   2.1270,   1.1914,   0.0795],
         [ -3.3906,  -2.7578,  13.1875,  ...,  -1.7246,  -1.1953,  -3.3125],
         [ -9.3359, -11.1094,  13.8906,  ...,  -4.6094,  -5.8945,  -5.4883]]],
       device='cuda:0')
torch.Size([2, 333, 1]) tensor([[[  917],
         [ 1582],
         [23676],
         [29954],
         [29954],
         [  403],
         [29882],
         [  313],
         [  338],
         [ 2737],
         [  304],
         [29901],
         [   13],
         [   13],
         [29882],
         [29892],
         [29882],
         [29892],
         [   13],
         [29882],
         [  897],
         [29872],
         [  438],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [30488],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29899],
         [ 2230],
         [29899],
         [  363],
         [  363],
         [  263],
         [  367],
         [  367],
         [  263],
         [  295],
         [  287],
         [  491],
         [  278],
         [ 4655],
         [ 2106],
         [ 4336],
         [29892],
         [   13],
         [27822],
         [29871],
         [29896],
         [29892],
         [29871],
         [29906],
         [29900],
         [29896],
         [29929],
         [29892],
         [  360],
         [29987],
         [29911],
         [ 9326],
         [  694],
         [27032],
         [ 1023],
         [29879],
         [  363],
         [  967],
         [26677],
         [  561],
         [ 2873],
         [29889],
         [ 5034],
         [ 5001],
         [ 9326],
         [  304],
         [  315],
         [  317],
         [ 1111],
         [  459],
         [29889],
         [   13],
         [ 2794],
         [20330],
         [20330],
         [ 1559],
         [  982],
         [  304],
         [  679],
         [  263],
         [  716],
         [18483],
         [  515],
         [15531],
         [29987],
         [29911],
         [  674],
         [  367],
         [  304],
         [15649],
         [ 2989],
         [ 8666],
         [  470],
         [  304],
         [  363],
         [ 2601],
         [ 1860],
         [29889],
         [15531],
         [29987],
         [29911],
         [ 8084],
         [29889],
         [   13],
         [29987],
         [29911],
         [29915],
         [  451],
         [  393],
         [  372],
         [20330],
         [  674],
         [ 1603],
         [  367],
         [ 2221],
         [  304],
         [  679],
         [ 8078],
         [ 1023],
         [29889],
         [   13],
         [ 1299],
         [ 2277],
         [  273],
         [ 8000],
         [29892],
         [  323],
         [12535],
         [ 4368],
         [16558],
         [  943],
         [  505],
         [ 1063],
         [ 3578],
         [ 3578],
         [  373],
         [  278],
         [29987],
         [29911],
         [29915],
         [29879],
         [13900],
         [11506],
         [13449],
         [  304],
         [  450],
         [12535],
         [10701],
         [29987],
         [29911],
         [10701],
         [ 1510],
         [  393],
         [  278],
         [ 1798],
         [18162],
         [29892],
         [15531],
         [  338],
         [11084],
         [27032],
         [ 8078],
         [29879],
         [29892],
         [  716],
         [20330],
         [29892],
         [ 1603],
         [16688],
         [ 5923],
         [20330],
         [20330],
         [  304],
         [ 3013],
         [29892],
         [  716],
         [  716],
         [  333],
         [ 1891],
         [ 9008],
         [29892],
         [15531],
         [29879],
         [  674],
         [  367],
         [ 7695],
         [  472],
         [14332],
         [  716],
         [  322],
         [ 5923],
         [20330],
         [29987],
         [29911],
         [20330],
         [29889],
         [   13],
         [  366],
         [  864],
         [  263],
         [  716],
         [29873],
         [  470],
         [  366],
         [17500],
         [29892],
         [  470],
         [  519],
         [29892],
         [  470],
         [  916],
         [  310],
         [28706],
         [ 4742],
         [29892],
         [15531],
         [29987],
         [29911],
         [29892],
         [  366],
         [29892],
         [  366],
         [ 8078],
         [12750],
         [29899],
         [ 4561],
         [ 3461],
         [ 4083],
         [  366],
         [  366],
         [30010],
         [  645],
         [ 1603],
         [  367],
         [ 2221],
         [  304],
         [  679],
         [  263],
         [  373],
         [  373],
         [  263],
         [ 8078],
         [29889],
         [   13],
         [   13],
         [ 2277],
         [29879],
         [  526],
         [  304],
         [  367],
         [  278],
         [  871],
         [  304],
         [ 1556],
         [ 1568],
         [14332],
         [ 3148],
         [19638],
         [19638],
         [ 2355],
         [ 1009],
         [  716],
         [ 9008],
         [29889],
         [  541],
         [  393],
         [ 7786],
         [ 2440],
         [29892],
         [19638],
         [  534],
         [  414],
         [  505],
         [ 1063],
         [ 8401],
         [ 3448],
         [  263],
         [  358],
         [13900],
         [29889],
         [15531],
         [29987],
         [29911],
         [30010],
         [27032],
         [ 4337],
         [ 3448],
         [  515],
         [ 8078],
         [29879],
         [  297],
         [  445],
         [ 1629],
         [29892],
         [  372],
         [ 9129],
         [27032],
         [  963],
         [  304],
         [  967],
         [29899],
         [22633],
         [ 3240],
         [  737],
         [  414],
         [29889],
         [ 6407],
         [ 5373],
         [29891],
         [29889],
         [  322],
         [  372],
         [29892],
         [30010],
         [  645],
         [  367],
         [ 1641],
         [ 3625],
         [  472],
         [15531],
         [29987],
         [29911],
         [14422],
         [29892],
         [ 2086],
         [29889],
         [   13],
         [30010],
         [29879],
         [  451],
         [ 4337],
         [ 1735],
         [29892],
         [15531],
         [ 1559],
         [26677],
         [13661],
         [29892],
         [15531],
         [  304],
         [ 1207],
         [  393],
         [  414],
         [  393],
         [  982],
         [ 3438],
         [  310],
         [  263],
         [ 9008],
         [ 6710],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 333, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1582,   310, 29950,  ..., 14058,  4412,  8771],
         [23676,   431,   681,  ...,  6334,  2232, 18245],
         ...,
         [   13, 30166,  1576,  ...,  4013,    12,  6224],
         [   13, 30166,  1576,  ...,  4013,    12, 29924],
         [   13, 30166,  1576,  ...,    12,  4013, 29924]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29899,  2440,   310,  ...,  2305,  7378,   901],
         [ 2230, 22585,  6360,  ..., 12531, 29956,  1349],
         ...,
         [ 6710,  9008,   561,  ...,   470, 29886, 10426],
         [29889, 29892,   322,  ...,   975,   313,   746],
         [   13,     2,   739,  ...,  1205,  2866,  2973]]], device='cuda:0')
Batch 33, 65.6% of total tokens
encoded shape: torch.Size([2, 357])
torch.Size([2, 357]) tensor([[    1,   402,  4369, 13329,  5500,   567,   297,  1570,  3088,    13,
            13, 29896,   402,  4369, 13329,  5500,   567,   297,  1570,  3088,
            13,    13,  9882,   310, 29416,  3949,   567,   297,  1570,  3088,
           313, 29940, 29979, 29897,   363,   413,  4841,   322,   734,   575,
         29889, 10987,   278,  1900,   975, 11147, 29892, 20201,   616,   322,
          8709, 21694,  3949,   567,   363,   445, 11801,   297,   322,  2820,
           278,  6242,  7935, 29892, 22274,  7003, 29892,  1528, 10530, 29892,
          8713,   945,  1509, 29892,   322, 14950,   983, 10161,   310,  1570,
          3088, 29889,    13,    13, 20154, 25435,   756,  1063, 13138,  3122,
         10530, 29892, 13822,  2671, 29892,  2517, 29882, 23586, 29892, 29940,
           465,   585,   669,  2166,   600, 28387, 24060,   411,   278,  1436,
           342,  4266,  1017,  4242, 11104,   297,   278, 23526,  4038, 29889,
          2178,   310,  1749,  4242,   414,   526, 18443,   287,   304, 26371,
           749,  1009, 25078,   669, 12359,   434,  1009, 12561, 29879,   297,
           263,  2090,   669,  9109,  5177,   411,   263, 10712, 16370, 10257,
         13925, 29889,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13,  8136,  5445, 29918,  3560,   304,
          1993, 29918,  3560,    13,    13,  5618,   471,   278,  2769,  5742,
          4547,  3277,  1993, 29918,  3560,   322, 16460,  1218,  5445, 29918,
          3560,  1951,  1716,  2099,   278,  1021,  2655, 29889,  2113, 29915,
         29873,   445,  1735,   367,   263,   298,   513, 11115,   304,  1250,
          1328, 24521, 29973,    13,    13, 29909, 29901,    13,    13, 15156,
          1993, 29918,  3560,  2012,   310,  5445, 29918,  3560,   674,  6058,
          1207,   278,  5759, 12279, 29968,   443,  3389, 29876,   519,   297,
          9642,  6910,  1363,   297,   278,  5759, 12279, 29968,   278, 27170,
           310,  1993, 29918,  3560, 29915, 29879,   322,  5445, 29918,  3560,
         29915, 29879,   674,   367,  8611,   411,  1009,  6590, 28601,  7865,
         29892,   607,   338,  1021,   297,   445,  1206,   313, 20313,   526,
           448, 29896,   511,   577,  1021, 12279, 29968,   508,  1065,   373,
          9642,  6910,   310,  5669,  7481,   408,  1532, 29889,    13,  6246,
          1550, 22520,   278,   775,   565,   366,  4607,   304,  9642,  1873,
           313,  3259, 29871, 29955,   470,  2400, 29897,   769,   366,   674,
           679,   263, 14835,  1059,   313, 16076,  1993, 29918,  3560,   338,
           451,  3342,   297,  1873, 29871, 29955,   470,  2400,   467,    13,
            13, 29909, 29901,    13,    13,  8136, 28197,  4083, 29901,    13,
            13,  3738,  2208, 29918, 16320,  3919,   313,  1267,  2795,   341,
         14789, 29918, 16320,  3919,   297,  3450, 21597, 29871, 29947,   322,
          6133,   511,   607,  2794,   393,   278,  1776, 10753,   304,   367,
           408,  4802,   408,   967,  3847,   313, 12254,  7164, 29897,    13,
          5589, 29918,  3560, 29901,   450,  1776,   881,   367,   408,  4802,
           408,   967,  3847,   313, 12254,  7164,   467,    13,  4013,  4868,
           338, 18164,  6257,   515,  3450, 21597, 29871, 29947,   322,   338,
          8611,    13,  1609,  1993, 29918,  3560, 29889,    13,    13,  6295,
          2688,   526,   278,  1021,   408,  1009,  1819,   526,  1716,   448,
         29896, 29889,  1205,   565,   366, 15982,  1048,   278,  1250,  1328,
         24521, 29892,   366,   508,   748,  1244, 29901, 18870,  3166,  1873,
            13,  1366,  2367,   366,   263,  2253,  2969,   373,   746,   366,
           881,  1735,   599,   596,  5445, 29918,  3560,   304,  1993, 29918,
          3560, 29889,    13,   294,   310,  1286, 29892,   372,  2444, 29871,
         29945, 29900, 29995,   282,   572,   526,   773,  3450, 21597, 29871,
         29947,   470,  2038, 29889,  1105,   372, 29915, 29879,   701,   304,
           366,   304,  1735,   372, 29889,    13,    13]], device='cuda:0')
torch.Size([2, 357, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [ -7.7500,  -3.0762,   2.0801,  ...,  -4.1445,  -3.3457,  -3.9961],
         [ -8.8281,  -9.8047,  -0.4385,  ...,  -5.0234,  -6.0234,  -6.5078],
         ...,
         [ -8.7734,   3.0508,   3.8438,  ...,  -2.2441,  -4.3633,  -1.3936],
         [ -8.8047,   3.0020,   3.9141,  ...,  -2.2715,  -4.4297,  -1.4336],
         [ -8.8125,   2.9688,   3.9492,  ...,  -2.2891,  -4.4688,  -1.4541]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-10.8672, -10.6562,  -2.9961,  ...,  -6.8203, -10.1016,  -6.8672],
         [-13.6250, -13.5391,  -1.5010,  ...,  -7.1484,  -8.3359,  -5.6484],
         ...,
         [ -3.3477,  -5.8203,  16.4844,  ...,  -3.2520,  -0.6797,  -2.8125],
         [ -1.9541,   1.1602,  16.6562,  ...,  -2.1367,   0.0879,  -0.3462],
         [-10.4453, -10.2500,   5.7266,  ...,  -6.8477,  -5.1914,  -5.1875]]],
       device='cuda:0')
torch.Size([2, 357, 1]) tensor([[[  917],
         [  798],
         [29901],
         [ 5500],
         [  567],
         [   13],
         [  278],
         [ 3088],
         [   13],
         [29954],
         [29954],
         [29889],
         [ 4369],
         [13329],
         [ 5500],
         [  567],
         [  297],
         [ 1570],
         [ 3088],
         [   13],
         [29907],
         [ 4373],
         [  310],
         [ 1570],
         [11801],
         [  567],
         [  297],
         [ 1570],
         [ 3088],
         [  313],
         [29940],
         [29979],
         [29897],
         [  363],
         [  413],
         [ 4841],
         [  322],
         [  734],
         [  575],
         [29889],
         [10987],
         [  278],
         [ 1900],
         [  975],
         [11147],
         [29892],
         [20201],
         [  616],
         [  322],
         [ 8709],
         [21694],
         [ 3949],
         [  567],
         [  363],
         [  445],
         [11801],
         [  297],
         [  322],
         [ 2820],
         [  278],
         [ 1570],
         [ 7935],
         [29892],
         [ 1570],
         [ 7003],
         [29892],
         [ 1528],
         [10530],
         [29892],
         [ 8713],
         [  945],
         [ 1509],
         [29892],
         [16197],
         [ 1570],
         [  983],
         [10161],
         [  310],
         [ 1570],
         [ 3088],
         [29889],
         [   13],
         [ 4373],
         [ 4373],
         [25435],
         [  402],
         [ 1063],
         [13138],
         [  278],
         [10530],
         [ 5127],
         [23526],
         [ 2671],
         [29892],
         [  322],
         [29882],
         [23586],
         [29892],
         [  322],
         [29979],
         [  585],
         [29892],
         [ 2166],
         [  600],
         [28387],
         [ 5127],
         [  411],
         [  278],
         [ 1900],
         [  342],
         [  297],
         [ 1891],
         [14717],
         [11104],
         [  363],
         [  278],
         [ 3367],
         [29907],
         [  363],
         [   13],
         [  310],
         [ 1749],
         [ 3949],
         [11104],
         [  526],
         [ 7180],
         [  287],
         [  304],
         [ 2693],
         [  749],
         [ 1009],
         [25078],
         [  297],
         [ 5969],
         [  434],
         [ 1009],
         [20017],
         [29879],
         [29889],
         [  263],
         [ 2090],
         [29892],
         [ 9109],
         [ 5177],
         [29889],
         [ 1749],
         [13925],
         [16370],
         [13925],
         [13925],
         [29889],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [   13],
         [30488],
         [30488],
         [   13],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29901],
         [ 1724],
         [29902],
         [ 5618],
         [ 7448],
         [  261],
         [  262],
         [   13],
         [ 1993],
         [29918],
         [ 3560],
         [   13],
         [   13],
         [29902],
         [  338],
         [  278],
         [ 2769],
         [  363],
         [  278],
         [ 3277],
         [ 5445],
         [29918],
         [ 3560],
         [  297],
         [ 2020],
         [ 1218],
         [ 5445],
         [29918],
         [ 3560],
         [29973],
         [ 5669],
         [  310],
         [  278],
         [ 1021],
         [ 2655],
         [29973],
         [   13],
         [29915],
         [29873],
         [  372],
         [ 4556],
         [ 4556],
         [16051],
         [16679],
         [  465],
         [11115],
         [  363],
         [  278],
         [ 1328],
         [24521],
         [29973],
         [   13],
         [   13],
         [22550],
         [29901],
         [   13],
         [   13],
         [ 1576],
         [ 1993],
         [29918],
         [ 3560],
         [  338],
         [  310],
         [ 5445],
         [29918],
         [ 3560],
         [  338],
         [ 1207],
         [ 2867],
         [  596],
         [  623],
         [ 5912],
         [29968],
         [ 7200],
         [23712],
         [29876],
         [  519],
         [  373],
         [ 9642],
         [ 6910],
         [  310],
         [  278],
         [ 9642],
         [ 9642],
         [12279],
         [29968],
         [29892],
         [ 5912],
         [  310],
         [ 5445],
         [29918],
         [ 3560],
         [  338],
         [29879],
         [  674],
         [ 5445],
         [29918],
         [ 3560],
         [29915],
         [29879],
         [  526],
         [  367],
         [ 8611],
         [  491],
         [  278],
         [ 7126],
         [ 1819],
         [ 1819],
         [29889],
         [  607],
         [  338],
         [29871],
         [  297],
         [ 1716],
         [ 1206],
         [29889],
         [ 5589],
         [  526],
         [29871],
         [29896],
         [  467],
         [  577],
         [  278],
         [12279],
         [29968],
         [  674],
         [  367],
         [  297],
         [ 1716],
         [ 6910],
         [29889],
         [ 5669],
         [29889],
         [29889],
         [ 1532],
         [29889],
         [   13],
         [   13],
         [  565],
         [  773],
         [  278],
         [12279],
         [29892],
         [  366],
         [  671],
         [  304],
         [ 1993],
         [ 1873],
         [  310],
         [ 8787],
         [  529],
         [29896],
         [  470],
         [ 5224],
         [29897],
         [  310],
         [  366],
         [  674],
         [  679],
         [  385],
         [ 9177],
         [ 1059],
         [29889],
         [18103],
         [ 1993],
         [29918],
         [ 3560],
         [  338],
         [  451],
         [ 6969],
         [  297],
         [ 9642],
         [29871],
         [29955],
         [  470],
         [ 2400],
         [  467],
         [   13],
         [   13],
         [20001],
         [ 1595],
         [   13],
         [   13],
         [ 1576],
         [ 5445],
         [29901],
         [29901],
         [   13],
         [   13],
         [29905],
         [ 2208],
         [29918],
         [16320],
         [ 3919],
         [29901],
         [  311],
         [ 2795],
         [  304],
         [14789],
         [29918],
         [16320],
         [ 3919],
         [  297],
         [ 3450],
         [ 3233],
         [29871],
         [29955],
         [29897],
         [ 6133],
         [29897],
         [   13],
         [  338],
         [  304],
         [  278],
         [ 1776],
         [  674],
         [  304],
         [  367],
         [  408],
         [ 4802],
         [  408],
         [ 1950],
         [ 3847],
         [29889],
         [ 1552],
         [ 7164],
         [  322],
         [   13],
         [   13],
         [29918],
         [ 3560],
         [  338],
         [   13],
         [ 1776],
         [10753],
         [  367],
         [  408],
         [ 4802],
         [  408],
         [  967],
         [ 3847],
         [  313],
         [12254],
         [ 7164],
         [  467],
         [   13],
         [ 4352],
         [  338],
         [  338],
         [18164],
         [29889],
         [  411],
         [ 3450],
         [21597],
         [29871],
         [29947],
         [29889],
         [  881],
         [ 8611],
         [  491],
         [ 1609],
         [  341],
         [29918],
         [ 3560],
         [29889],
         [   13],
         [   13],
         [20001],
         [29892],
         [  526],
         [  451],
         [ 1021],
         [ 2655],
         [ 2215],
         [ 2983],
         [  526],
         [ 1021],
         [  448],
         [29896],
         [29889],
         [   13],
         [  278],
         [  366],
         [  526],
         [ 1048],
         [  278],
         [ 1250],
         [ 1328],
         [24521],
         [  769],
         [  769],
         [  508],
         [  671],
         [  411],
         [29901],
         [   13],
         [  262],
         [29879],
         [24521],
         [   13],
         [  674],
         [  366],
         [  278],
         [ 1051],
         [ 2969],
         [ 1048],
         [  920],
         [  304],
         [  508],
         [  671],
         [  596],
         [  596],
         [  775],
         [29918],
         [ 3560],
         [  304],
         [ 1993],
         [29918],
         [ 3560],
         [29889],
         [   13],
         [   13],
         [  639],
         [ 1286],
         [29892],
         [  278],
         [  338],
         [  393],
         [29955],
         [29889],
         [29995],
         [  310],
         [  572],
         [  526],
         [  773],
         [ 5445],
         [ 3233],
         [29871],
         [29947],
         [  322],
         [ 2038],
         [29889],
         [   13],
         [  366],
         [  338],
         [29879],
         [ 9109],
         [  304],
         [  366],
         [  304],
         [11097],
         [  372],
         [  470],
         [   13],
         [   13],
         [20001]]], device='cuda:0')
torch.Size([2, 357, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  798,   586,  4369,  ..., 29924,  1581,  1117],
         [29901,   315,   338,  ...,  5977,   297,  3236],
         ...,
         [   13,  1576, 30143,  ..., 29909, 29943,     3],
         [   13,  1576, 30143,  ..., 29909,     3, 29943],
         [   13,  1576, 30143,  ..., 29954, 29909, 29943]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13,     2,  1205,  ...,   541,   313,   887],
         [   13,     2, 29902,  ..., 29950,  1124,   392],
         [20001, 29909, 22550,  ...,  4435, 29905, 29933]]], device='cuda:0')
Batch 34, 66.1% of total tokens
encoded shape: torch.Size([2, 3016])
torch.Size([2, 3016]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,  4918, 11322,  ...,   297,  1884, 29889]], device='cuda:0')
torch.Size([2, 3016, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6562],
         ...,
         [-11.4297,   5.0352,   2.4336,  ...,  -6.5000,  -7.5312,  -4.3320],
         [-10.9922,   4.3828,   2.4336,  ...,  -6.3828,  -7.1289,  -4.1875],
         [-10.3047,   4.0625,   2.3789,  ...,  -6.0742,  -6.5391,  -3.9043]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.6992,  -7.0781,  -0.5420,  ...,  -3.3730,  -6.0469,  -3.8125],
         [-11.7969,  -8.1094,   2.3789,  ...,  -2.4727,  -5.5156,  -6.2695],
         ...,
         [ -3.2520,  -6.2969,   7.7461,  ...,   1.9170,  -7.9727,  -2.0762],
         [ -0.6675,   0.1641,  14.8750,  ...,   0.6870,  -0.8218,   1.1826],
         [ -7.9219,  -9.4062,  11.7031,  ...,   0.3489,  -3.8730,   0.5015]]],
       device='cuda:0')
torch.Size([2, 3016, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [29871],
         [29871],
         [29871]],

        [[  917],
         [  287],
         [29871],
         ...,
         [ 1884],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 3016, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [29871,    13,    12,  ...,   268,   448, 29915],
         [29871,    13,    12,  ...,   268,   448, 29915],
         [29871,    12,    13,  ...,   268,  6319,   418]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  287, 29879,   491,  ...,  1867,   292,  5105],
         [29871, 29889, 29896,  ..., 29946, 29941, 29955],
         ...,
         [ 1884,  3800, 29899,  ..., 16273,   833,  9917],
         [29889, 29892,  5575,  ...,   411, 19423,   470],
         [   13,     2,  3575,  ...,  9823,   350,  2266]]], device='cuda:0')
Batch 35, 69.3% of total tokens
encoded shape: torch.Size([2, 404])
torch.Size([2, 404]) tensor([[    1,   498,  1295,  3250, 29892,  5846, 29871, 29906, 29906, 29892,
         29871, 29906, 29900, 29896, 29953,    13,    13, 12283, 29899, 29943,
          6092,   272,   333,   630,  3917,  2722,   360,  2572, 29873,   293,
           360, 29366,   297,   304,   720, 20228,    13,    13,  1349,  1295,
          3250, 29892,  5846, 29871, 29896, 29945, 29892, 29871, 29906, 29900,
         29896, 29953,    13,    13, 29928,   296,  2879, 29098, 23716,  2538,
         16719,    13,    13, 29933,  5658,  1556, 12042,  2879,  5821,   304,
          7539,   278,  4094,   310,   322,   451,   278, 25287,   310,  4482,
         17869, 23035, 29892,    13,   262, 23716, 29892, 27718, 14703,  1528,
          4835,   526,   278,   748, 29899,   517, 14502,  2984,   363,   901,
          1135, 29871, 29946, 29945, 29892, 29900, 29900, 29900,  2305,   411,
         12042,   284,  4828,   515, 29871, 29906, 29900, 29896, 29900,   304,
         29871, 29906, 29900, 29896, 29945, 29889,    13,    13,  1576,  2106,
         30010, 29879,  3436,   983,   333,  1824,   313,  1552,  8818, 10472,
           414, 29897, 18691,   701,   278,  4434,   363, 29871, 29946, 29896,
         10151,   310,  1438,  4251,   813,  8886, 29871, 29896, 29929, 29892,
         29900, 29900, 29900,  1998,  1169, 29889,  2180,   385,  6588,   310,
           395, 29955, 29946, 29929,   639,  6493, 29892,   393, 30010, 29879,
          3755,   263, 19875,   310,   970, 17208,  2675,   304,  7539,  1554,
           393,  1033,   367,  5557,   287,   472,   263, 12042,   391, 30010,
         29879,  8034,   363,  1048,   263,  4654,   310,   278,  3438, 29889,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2],
        [    1,  8502,  1784,   916, 28007, 29892,   591,   671, 21046,   322,
          3787, 21046,   373,   596,  6601, 29889,  4525, 21046,   526,  1304,
           304, 11157,  1749,  4700,   322,  3867,   901,  7333,  3368,  5786,
           304,   366, 29892,  1716,   373,   278,  4700,   322,  1549,   916,
          5745, 29889,  1152,  4340,  2472, 29892,  3113,  1074,  1749, 17278,
           347, 25219, 29889,    13,    13, 19960,   785, 10428,   373,  5702,
           411,  4485, 29879,   669,  1706, 22687, 25453,   399,  4350, 18744,
            13,    13, 30166,  1576,  8799,  1934,   310,  6162,  2132,   271,
          6963,  7542,   537,   304, 29380, 13332,   362,   322,   995,   304,
          5381,   267,   297,   599, 10161,   310, 14338,   322, 16049, 19863,
         10643,   322,  5941,   292, 16650,   583, 29889,   512,  9589,   651,
           411,  6162,  2132,   271, 29892,  4116,   332,  9202,   476,  8055,
          1090,   517,   554,   263,  1346, 29956,  2235,   278, 22787, 30024,
          9076,   310,   278,  6931,   472,  4485, 29879,   669,  1706, 22687,
           322, 29892,  4208, 29892,   896, 15659, 28602,  1907,   304,   337,
         29899, 10599,   261,   385,  5923,  2874,   310,   278, 25453,   399,
          4350, 18744, 29889,    13,    13, 29933,   824,   538,  1913,   359,
         29892, 14645, 29949,  6162,  2132,   271, 15057, 15538, 29892, 18568,
         29901,  1346, 12636,   332,  9202,   476,  8055,  4944,   263, 15075,
           475,   519,  8671,   304,   263, 19863,  9687,  3800,  1650,   363,
           278, 24205,   310,   714, 29899,   974, 29899,  1256,  9687,  9316,
         29889,  8680,  1203,  3145,   892,   304,  5957,   263,  1650,   304,
          5129,   510, 10222, 23622,  1735, 29892, 10032, 19863, 29892,   671,
         15075,   475,   519, 10650, 17279,   322,   304,  2304,   278,  5381,
         30010, 29879, 11314,   936,  3534,   292, 30010, 29889,  4116,   332,
          9202,   476,  8055, 20115,   263,  1650,   393, 13461,   287,  4485,
         29879,   669,  1706, 22687,  8402,   319, 11780,   322, 20601,   297,
           385, 12463,  5518, 20376,   310, 29871, 29896, 29906, 29929,   260,
         24729,  3178,    13,    13, 30015,  1576, 17279,  1304,   892, 29871,
         29896, 29900, 29900, 29995,  1162, 29891,   695,   519,   322,   263,
         29871, 29896, 29945, 29995, 20376,   304,   278,  2159,   310,   278,
          9687,  3800, 11664,   301,  3818,  5445,   491, 29871, 29896, 29900,
         29900, 13667, 27668,   278,  8608, 22004,  3661,  2158,   491, 29871,
         29945, 29900, 15543,  6162,  2132,   271,   338, 15319,   287,   304,
           505,   385, 11314,  1711,  5129, 12692, 30010,  4870,  6751, 18096,
          1058,   338, 19781, 24233,  1230, 29892,   322,  1058,   508,  1371,
           502, 12021,  4485, 29879,   669,  1706, 22687,  8402,   319,  1203,
          3145,   411, 16716, 29892,   322,  2441,   537,  3178,   512, 29871,
         29906, 29900, 29896, 29896, 29892,  6162,  2132,   271,   471, 15074,
           263,   544,  5286,  2738,   315, 14098,  7526,   491,  4485, 29879,
           669,  1706, 22687, 29889]], device='cuda:0')
torch.Size([2, 404, 32000]) tensor([[[-12.8047,  -7.3125,  -0.4812,  ...,  -6.7695,  -8.0078,  -7.4883],
         [ -9.7422, -10.1719,   0.8706,  ...,  -4.6133,  -4.5312,  -5.2344],
         [ -3.0781,   0.3499,   8.1172,  ...,   1.0693,  -1.6982,   0.8730],
         ...,
         [ -8.2812,   2.8164,   4.0781,  ...,  -2.2480,  -4.1211,  -0.5688],
         [ -8.2656,   2.8223,   4.1641,  ...,  -2.2617,  -4.1523,  -0.6191],
         [ -8.2422,   2.8359,   4.1914,  ...,  -2.2676,  -4.1641,  -0.6450]],

        [[-12.8047,  -7.3125,  -0.4812,  ...,  -6.7695,  -8.0078,  -7.4883],
         [-13.8906, -13.8281,  -3.9062,  ...,  -9.3203, -10.1250,  -9.4766],
         [ -9.1172,  -6.2031,  -1.5762,  ...,  -5.3125,  -7.7227,  -6.3750],
         ...,
         [ -1.6973,  -2.7559,   8.5234,  ...,   2.5000,   2.2051,   3.4941],
         [ -3.1055,   1.2148,  11.1797,  ...,  -2.1758,  -1.7852,  -1.5312],
         [ -7.1602,  -4.8359,  11.8984,  ...,  -2.8418,  -4.4844,  -3.9980]]],
       device='cuda:0')
torch.Size([2, 404, 1]) tensor([[[  917],
         [ 1295],
         [ 3250],
         [29892],
         [29871],
         [29871],
         [29896],
         [29900],
         [29892],
         [29871],
         [29906],
         [29900],
         [29896],
         [29953],
         [29871],
         [ 1576],
         [29961],
         [29899],
         [29888],
         [ 2463],
         [ 2361],
         [  680],
         [  630],
         [13062],
         [ 2722],
         [   13],
         [13703],
         [19574],
         [ 1711],
         [  368],
         [17678],
         [  297],
         [20354],
         [  720],
         [20228],
         [   13],
         [   13],
         [29966],
         [ 1295],
         [ 3250],
         [29892],
         [ 5846],
         [29871],
         [29906],
         [29945],
         [29892],
         [29871],
         [29906],
         [29900],
         [29896],
         [29953],
         [   13],
         [   13],
         [29943],
         [13703],
         [ 2879],
         [  526],
         [  304],
         [20986],
         [16719],
         [   13],
         [   13],
         [ 1349],
         [  453],
         [  310],
         [12042],
         [ 2879],
         [  526],
         [  304],
         [ 1207],
         [  278],
         [25828],
         [11421],
         [ 1009],
         [  278],
         [  278],
         [ 2305],
         [  310],
         [ 1009],
         [17869],
         [ 2305],
         [29889],
         [  278],
         [   13],
         [23716],
         [29892],
         [  278],
         [14703],
         [  360],
         [ 4835],
         [  526],
         [ 1641],
         [  871],
         [  304],
         [  517],
         [ 2058],
         [  363],
         [  363],
         [12042],
         [ 1135],
         [29871],
         [29896],
         [29900],
         [29892],
         [29900],
         [29900],
         [29900],
         [ 4344],
         [ 1269],
         [12042],
         [  284],
         [ 4828],
         [ 1269],
         [29871],
         [29906],
         [29900],
         [29896],
         [29900],
         [  304],
         [29871],
         [29906],
         [29900],
         [29896],
         [29946],
         [29889],
         [   13],
         [   13],
         [ 1349],
         [23716],
         [30010],
         [29879],
         [12042],
         [  983],
         [  333],
         [ 1824],
         [29892],
         [29909],
         [23716],
         [29886],
         [  414],
         [29897],
         [12530],
         [  701],
         [  278],
         [ 4434],
         [  363],
         [  395],
         [29929],
         [29900],
         [29892],
         [  310],
         [ 1906],
         [11176],
         [29892],
         [  901],
         [  395],
         [29896],
         [29947],
         [29892],
         [29900],
         [29900],
         [29900],
         [  813],
         [ 1169],
         [29889],
         [   13],
         [  385],
         [ 6588],
         [ 3438],
         [  395],
         [29896],
         [29900],
         [29900],
         [  639],
         [ 6493],
         [29892],
         [  393],
         [30010],
         [29879],
         [  395],
         [  263],
         [12042],
         [  310],
         [ 1735],
         [ 6909],
         [29889],
         [  304],
         [ 7539],
         [12042],
         [  393],
         [ 1033],
         [  505],
         [ 5557],
         [  287],
         [29889],
         [  263],
         [15958],
         [  391],
         [30010],
         [29879],
         [ 8034],
         [29889],
         [  263],
         [  395],
         [ 4654],
         [  310],
         [  393],
         [ 3438],
         [29889],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [   13],
         [    1],
         [30488],
         [30488],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [ 1784],
         [  916],
         [ 2563],
         [29892],
         [ 7821],
         [  671],
         [21046],
         [  304],
         [  916],
         [  848],
         [  373],
         [  596],
         [ 6601],
         [29889],
         [   13],
         [21046],
         [  526],
         [ 1304],
         [  304],
         [11157],
         [  596],
         [ 4700],
         [  322],
         [  596],
         [  366],
         [ 7333],
         [ 1891],
         [ 5786],
         [  304],
         [  366],
         [29892],
         [ 1716],
         [  373],
         [  445],
         [ 4700],
         [  322],
         [ 1549],
         [  916],
         [ 5745],
         [29889],
         [   13],
         [  901],
         [ 2472],
         [ 1048],
         [ 3113],
         [ 1074],
         [ 1749],
         [17278],
         [  347],
         [25219],
         [29889],
         [   13],
         [ 1576],
         [ 2277],
         [   13],
         [ 4223],
         [  304],
         [17026],
         [  363],
         [  278],
         [ 1704],
         [  669],
         [ 1706],
         [22687],
         [   13],
         [   13],
         [ 4350],
         [   13],
         [ 6751],
         [   13],
         [21298],
         [   13],
         [10261],
         [  362],
         [  472],
         [  278],
         [15702],
         [  271],
         [  505],
         [  366],
         [  537],
         [  304],
         [  278],
         [18066],
         [  362],
         [  322],
         [ 1072],
         [  304],
         [  596],
         [  267],
         [29889],
         [  278],
         [  409],
         [  310],
         [29380],
         [  322],
         [16049],
         [29380],
         [10643],
         [16650],
         [ 1162],
         [ 5864],
         [16650],
         [  583],
         [29889],
         [   13],
         [  445],
         [  651],
         [  411],
         [ 1749],
         [ 2132],
         [  271],
         [29892],
         [  591],
         [  442],
         [ 9202],
         [  476],
         [ 8055],
         [  756],
         [  517],
         [  554],
         [  263],
         [ 2060],
         [ 7341],
         [ 4350],
         [  278],
         [  323],
         [30024],
         [15058],
         [  310],
         [  278],
         [  341],
         [  472],
         [  278],
         [29879],
         [  669],
         [ 1706],
         [22687],
         [30010],
         [15659],
         [  297],
         [29892],
         [  591],
         [15659],
         [  263],
         [ 1907],
         [  304],
         [10032],
         [29899],
         [13892],
         [  261],
         [  278],
         [ 5923],
         [19863],
         [  304],
         [  278],
         [ 4870],
         [  399],
         [ 4350],
         [18744],
         [29889],
         [   13],
         [   13],
         [ 2277],
         [ 1463],
         [  538],
         [  438],
         [  359],
         [29892],
         [ 2315],
         [29949],
         [  310],
         [ 2132],
         [  271],
         [29892],
         [15538],
         [19806],
         [ 1497],
         [29901],
         [ 1346],
         [ 4806],
         [  332],
         [ 9202],
         [  476],
         [ 8055],
         [  338],
         [  263],
         [ 1650],
         [  475],
         [  519],
         [ 1650],
         [  304],
         [  278],
         [13807],
         [ 4870],
         [ 4870],
         [  393],
         [  393],
         [ 4485],
         [ 4485],
         [  310],
         [ 9687],
         [29899],
         [  974],
         [29899],
         [ 1256],
         [ 9687],
         [ 9316],
         [29889],
         [  450],
         [ 3815],
         [ 3145],
         [  892],
         [  304],
         [10032],
         [  263],
         [ 1650],
         [  393],
         [  278],
         [ 1181],
         [ 1050],
         [ 9687],
         [ 1735],
         [30010],
         [10032],
         [19863],
         [  322],
         [  322],
         [ 3109],
         [  475],
         [  519],
         [17279],
         [17279],
         [  322],
         [10032],
         [11157],
         [  278],
         [19308],
         [  297],
         [29879],
         [ 9063],
         [  936],
         [  322],
         [  292],
         [ 8898],
         [29889],
         [   13],
         [  332],
         [ 9202],
         [  476],
         [ 8055],
         [30010],
         [  263],
         [ 1650],
         [  393],
         [ 1539],
         [  287],
         [ 1749],
         [29879],
         [  669],
         [ 1706],
         [22687],
         [30010],
         [  319],
         [22525],
         [  322],
         [  278],
         [  297],
         [  263],
         [16710],
         [20376],
         [14238],
         [  310],
         [29871],
         [29896],
         [29900],
         [29995],
         [  260],
         [24729],
         [  310],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 4116],
         [ 1304],
         [  297],
         [29871],
         [29896],
         [29900],
         [29900],
         [29995],
         [ 1162],
         [29891],
         [  695],
         [  519],
         [  322],
         [  278],
         [20376],
         [29896],
         [29900],
         [29995],
         [20376],
         [  297],
         [  278],
         [22004],
         [  310],
         [  278],
         [ 4870],
         [19863],
         [  471],
         [  278],
         [ 3818],
         [13284],
         [  886],
         [29871],
         [29896],
         [29900],
         [15543],
         [15543],
         [27668],
         [  278],
         [ 1353],
         [  362],
         [ 3661],
         [ 2158],
         [  491],
         [29871],
         [29896],
         [29900],
         [15543],
         [  450],
         [ 2132],
         [  271],
         [30010],
         [15319],
         [  287],
         [  304],
         [  505],
         [ 1063],
         [15130],
         [  936],
         [ 6047],
         [ 7341],
         [30010],
         [ 1650],
         [ 6751],
         [ 1650],
         [  297],
         [  338],
         [ 2221],
         [19355],
         [ 1230],
         [  322],
         [  322],
         [  591],
         [  338],
         [12021],
         [  502],
         [  304],
         [ 1749],
         [29879],
         [  669],
         [ 1706],
         [22687],
         [30010],
         [  319],
         [ 3178],
         [ 3145],
         [ 3178],
         [  263],
         [ 3178],
         [19201],
         [  472],
         [  537],
         [ 3178],
         [   13],
         [ 6124],
         [29906],
         [29900],
         [29900],
         [29900],
         [29892],
         [ 4485],
         [ 2132],
         [  271],
         [  322],
         [15074],
         [  278],
         [ 8078],
         [ 5286],
         [ 2738],
         [10470],
         [14098],
         [ 9862],
         [  363],
         [  278],
         [29879],
         [  669],
         [ 1706],
         [22687],
         [  363],
         [   13]]], device='cuda:0')
torch.Size([2, 404, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1295,   681,  1774,  ...,   798,  5062,  1794],
         [ 3250, 16700, 29871,  ...,  1609, 29901, 26319],
         ...,
         [   13, 29966,  4345,  ...,  8999, 29912, 30143],
         [   13, 29966,  4345,  ...,  8999, 29912, 30143],
         [   13, 29966,  4345,  ...,  8999, 29912, 30143]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 1784,  1556,   263,  ...,   916,   306,   372],
         [  916,   310,  2305,  ...,  2712, 10916,  4123],
         ...,
         [22687,  3977, 25594,  ...,  2108, 21043,   759],
         [  363, 29889,   297,  ...,  5936,   472,   304],
         [   13,   450,   910,  ...,  4485, 30166,   739]]], device='cuda:0')
Batch 36, 69.9% of total tokens
encoded shape: torch.Size([2, 457])
torch.Size([2, 457]) tensor([[    1, 22746, 23378,  7418,   310,   278,   525,   561, 25715,   542,
           276,   271,   457,   528,  4774,   280,  2396,   306, 29889,   319,
          6976,  2948,   304,   278,  6139,   310,  1374, 25715,   542,   276,
           271,   457,  5802,   297,   278,  7303, 29881,   907,   271,   457,
         19015,   559, 29899,  1299, 29925, 29914,  3035, 29925,  1301,  2029,
           559, 29899,  2251,   333,  1230,  1374, 25715,   706, 18411,   337,
          7387,   297,  5192,  1380,  2878,   898,  2849, 29889,    13,  2831,
           278,   937,   931, 29892,   263,  6976,  2948,   471,  1304,   304,
          8453,  5192,  1380,  2878,   898,  9315,  4613, 12232,   297,   278,
         18350,   411, 27884, 29892,  6781,   322,  9609, 29878,   541,  1728,
         11033, 29925, 29889,  2538, 29886,  8491,  1380,  2878,   898,  2849,
           892,  5545,   408,   263,  2211, 29899,  9700,  1788, 29892,  3704,
           313, 29896, 29897, 19100,   333,  1230,  1374, 25715,   706, 18411,
           337,  7387,   607,  3867, 13714, 27884, 26702,   297,   278,  1380,
          2878,   898,  9315,  4636, 29936,   313, 29906, 29897,   594,   264,
           457, 22699,   327,   680,  1301,  2029,   559, 29892,   607,  8128,
         14523,  6782,   310,  4636, 27884,   363,  5377,   907,   271,   457,
         19015,   559, 29899, 19303,  2957, 11033, 29925,   746,  1716, 25148,
          1078,   526, 21699,  3216,   304,  1301,  2029,   559,   322,   313,
         29941, 29897,   907,   271,   457, 19015,   559, 29892,  6257,  1438,
           337,  7387,   746,  5039,   630,   491,   278, 25148,  1078,   515,
         18350, 29889,   450,  2702,  4682,   310,   445,  1788,   338,   263,
          3802, 23203,   537,   310,   907,   271,   457, 19015,   559,   322,
          1301,  2029,   559, 13206, 21337, 29889,   910,  2582,   297,  1880,
          6976,   310,  1513, 26229,   310,  1301,  2029,   559,   491,   907,
           271,   457, 19015,   559, 29899,   672,  2347, 11033, 29925,  1728,
           967, 24993,   964,   278, 18350, 29889,   512,  2507, 29892,   278,
          5039,   630,  1301,  2029,   559,   411,   278,  1021,  1880,  6976,
          4153,  8128,   907,   271,   457, 19015,   559,   411,  4636, 29899,
           672,  2347, 27884, 29889,   450, 17246,  3637,   293,  4280,   267,
           310,   907,   271,   457, 19015,   559,   411, 27884,   515,  4636,
          4208,   411,  1906,  8429,   515, 25148,  1078,   515, 18350,  3867,
          1880, 26229,   310,   907,   271,   457, 19015,   559,  7303, 29881,
           304,  1301,  2029,   559, 26229, 29889,   450,  5545,  2070, 11614,
           892, 21050,   964,   263, 19475,  1904, 29889,   450,  1904,  5119,
          7168,  2354,  1027,   352,  1078,   278, 17986,   848,   491, 10968,
           375, 29892,   399, 29889, 29923, 29889,   322,   317, 10327, 29892,
           478, 29889, 29909, 29889,  5135, 29896, 29929, 29947, 29906, 29897,
          2595, 29889, 21184, 14969, 29889,  3457,  3021,   952, 29889, 29871,
         29906, 29896, 29929, 29892, 29871, 29896, 29953, 29955, 29899, 29896,
         29955, 29947,   511,  1058,  7405,   630,   445,  1788,   297,   599,
          1072,   326,   575,   310,   740,   292, 29889,   450,  2582,  4368,
           278,  8900, 19015,  7492,   322, 14563,   397,  8739, 27931,  1907,
           297,   278,  6030,   310,  2281,   332,   635, 29899,  9917,   907,
           271,   457, 19015,   559,   408,   263,  1513, 17004,   310,   967,
         19932, 23638,   304,  1301,  2029,   559, 29889],
        [    1,   660, 29901,    13,    13, 12542,   278, 13451,   310,  1023,
          3168,  6943,   385,  8380,   995,    13,    13,  4806,   892,  2183,
           278,  1023,  3168,   395, 29888, 29918, 29896, 29898, 29916, 29897,
           353,   891, 29916, 25183,   322,   395, 29888, 29918, 29906, 29898,
         29916, 29897,   353,   921, 29985, 29906, 29899, 29906, 29938,   310,
           607,   591,  4312,   304,  1284,   278,  7101,   310, 29889,  1619,
          1650,   445,  2215,   338, 29901,    13,    13, 17245, 29892,   306,
          1016, 29915, 29873,  1073,   607, 13451,   306,   505,   304,   671,
           363,   590, 10160, 29889,  1932,   306,   715, 15048,   278,  3983,
           373,   590,  3983,   293,  3408,  1061,   278,  1023, 13451,   892,
         15727, 29906, 29938,   322,   395, 29906,  1628,   541,   306,  1016,
         29915, 29873,  1073,   920,   306,  1033, 10075,  1284,   963,  1728,
         29889,    13, 10773,  1371,   338,  7556, 29889,    13,    13, 29909,
         29901,    13,    13,  3492,   505,  2307,  1476,   278, 13451, 29889,
           887,   505,  3971, 29901,    13,    13,  6730,  1206, 29892,   395,
         29916, 29905,   479, 29871, 29900, 21063,    13,  3997, 29916, 29985,
         29906, 29899, 29916, 29899, 29906, 29922, 29900, 29905, 21304, 29905,
           463, 29912, 11436, 29913, 29916, 29922, 29906,  1966, 29916, 10457,
         29896, 29905,   355, 29912, 11436,  9458,    13,  6246,   445,   937,
          1206,  6858,   395, 29916, 29905,   479, 29871, 29900, 29938,   313,
          4149,  1023,  3454,  2038,   511,   577,   278,   871,  2854,  1650,
           338,   395, 29916, 29922, 29906,  1504,    13, 11863,  1206, 29892,
           395, 29916, 29905,   280, 29871, 29900, 21063,    13,  3997, 29916,
         29985, 29906, 29974, 29916, 29899, 29906, 29922, 29900, 29905, 21304,
         29905,   463, 29912, 11436, 29913, 29916, 29922, 29896,  1966, 29916,
         10457, 29906, 29905,   355, 29912, 11436,  9458,    13,  6246,   445,
          1473,  1206,  6858,   395, 29916, 29905,   280, 29871, 29900, 29938,
           313,  4149,  1023,  3454,  2038,   511,   577,   278,   871,  2854,
          1650,   338,   395, 29916, 10457, 29906,  1504,    13,    13,  8439,
           748,   596,  1023, 13451, 29889,    13,    13,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 457, 32000]) tensor([[[-12.8125,  -7.3203,  -0.4802,  ...,  -6.7695,  -8.0156,  -7.4883],
         [ -9.0625,  -7.5352,  -0.7744,  ...,  -4.1797,  -4.7891,  -4.1680],
         [ -6.0234,  -6.7266,   3.3574,  ...,  -5.0234,  -6.4141,  -4.1875],
         ...,
         [ -1.3906,  -0.7222,   9.1250,  ...,   3.6973,   0.3098,   1.6240],
         [ -5.0938,  -5.9961,   9.2656,  ...,  -3.2129,  -3.2617,  -4.4062],
         [ -6.1016,  -7.0078,  17.1875,  ...,  -1.5918,  -0.8135,  -1.9580]],

        [[-12.8125,  -7.3203,  -0.4802,  ...,  -6.7695,  -8.0156,  -7.4883],
         [-10.8672, -10.6562,  -3.0000,  ...,  -6.8242, -10.0938,  -6.8633],
         [-13.6250, -13.5469,  -1.5039,  ...,  -7.1484,  -8.3281,  -5.6562],
         ...,
         [-10.6250,   0.1110,   1.5605,  ...,  -3.2598,  -5.6602,  -2.5840],
         [-10.5469,   0.2382,   1.7002,  ...,  -3.1660,  -5.5547,  -2.4883],
         [-10.4688,   0.3916,   1.8174,  ...,  -3.0859,  -5.4531,  -2.3965]]],
       device='cuda:0')
torch.Size([2, 457, 1]) tensor([[[  917],
         [  398],
         [ 7418],
         [  310],
         [  278],
         [ 2779],
         [29879],
         [  327],
         [  403],
         [  276],
         [  271],
         [  457],
         [29915],
         [ 4774],
         [  280],
         [29915],
         [  263],
         [29889],
         [ 1963],
         [10230],
         [ 1904],
         [   13],
         [  278],
         [ 7418],
         [  310],
         [  278],
         [25715],
         [  542],
         [  276],
         [  271],
         [  457],
         [ 8608],
         [  322],
         [18109],
         [ 2301],
         [29881],
         [ 2301],
         [  271],
         [  457],
         [29899],
         [  559],
         [29899],
         [  561],
         [29925],
         [ 1788],
         [ 3035],
         [29925],
         [ 1788],
         [ 2029],
         [  559],
         [ 1788],
         [  561],
         [  333],
         [ 1230],
         [ 1374],
         [25715],
         [  706],
         [18411],
         [ 1788],
         [ 7387],
         [29889],
         [ 2301],
         [ 2301],
         [ 2878],
         [  898],
         [ 2849],
         [29889],
         [   13],
         [ 1576],
         [  278],
         [  937],
         [  931],
         [29892],
         [  263],
         [ 4323],
         [ 2948],
         [  338],
         [ 1304],
         [  304],
         [ 8453],
         [  278],
         [ 1380],
         [ 2878],
         [  898],
         [ 9315],
         [ 1374],
         [12232],
         [29889],
         [  278],
         [10122],
         [29899],
         [29871],
         [  322],
         [11033],
         [29925],
         [11033],
         [29878],
         [29889],
         [ 1728],
         [11033],
         [29925],
         [29889],
         [  450],
         [29886],
         [12232],
         [ 1380],
         [ 2878],
         [  898],
         [ 2849],
         [  892],
         [ 5528],
         [  408],
         [  263],
         [ 1788],
         [29899],
         [  510],
         [ 1788],
         [19849],
         [19849],
         [  278],
         [29875],
         [29897],
         [  278],
         [  333],
         [ 1230],
         [ 1374],
         [25715],
         [  706],
         [18411],
         [29892],
         [ 7387],
         [29892],
         [  526],
         [27884],
         [ 5864],
         [29892],
         [29892],
         [  278],
         [18350],
         [ 2878],
         [  898],
         [ 9315],
         [ 4636],
         [29892],
         [  313],
         [29906],
         [29897],
         [  278],
         [  264],
         [  457],
         [ 3367],
         [  327],
         [  680],
         [ 1301],
         [ 2029],
         [  559],
         [  607],
         [  607],
         [ 1301],
         [  263],
         [  310],
         [  310],
         [11033],
         [29899],
         [  322],
         [  274],
         [27884],
         [  271],
         [  457],
         [ 1374],
         [  559],
         [29899],
         [ 1299],
         [ 2957],
         [11033],
         [29925],
         [29936],
         [  278],
         [27884],
         [ 1078],
         [  526],
         [ 2198],
         [ 2198],
         [  304],
         [  278],
         [ 2029],
         [  559],
         [29936],
         [  313],
         [29941],
         [29897],
         [  907],
         [  271],
         [  457],
         [19015],
         [  559],
         [29892],
         [  607],
         [  515],
         [  337],
         [ 7387],
         [29889],
         [11033],
         [  630],
         [  491],
         [ 9609],
         [ 1374],
         [ 1078],
         [29889],
         [  278],
         [29889],
         [  450],
         [ 6976],
         [  537],
         [  310],
         [  278],
         [ 2948],
         [  338],
         [  393],
         [13331],
         [23638],
         [  537],
         [  310],
         [  278],
         [  271],
         [  457],
         [19015],
         [  559],
         [  322],
         [  594],
         [ 2029],
         [  559],
         [  304],
         [21337],
         [  297],
         [  450],
         [23203],
         [  297],
         [  263],
         [ 6976],
         [  310],
         [16991],
         [ 6782],
         [  310],
         [  907],
         [ 2029],
         [  559],
         [  491],
         [  907],
         [  271],
         [  457],
         [19015],
         [  559],
         [29889],
         [ 9917],
         [ 2347],
         [11033],
         [29925],
         [29889],
         [27884],
         [14523],
         [  482],
         [  278],
         [18350],
         [29889],
         [  450],
         [  445],
         [29892],
         [  445],
         [ 6976],
         [  630],
         [ 1301],
         [ 2029],
         [  559],
         [ 8128],
         [ 3216],
         [ 3216],
         [ 6976],
         [ 6976],
         [ 1301],
         [ 1301],
         [14523],
         [  271],
         [  457],
         [19015],
         [  559],
         [  411],
         [11033],
         [27884],
         [ 9917],
         [ 2347],
         [27884],
         [29889],
         [  450],
         [ 6976],
         [ 3637],
         [  293],
         [ 6354],
         [  267],
         [  310],
         [  907],
         [  271],
         [  457],
         [19015],
         [  559],
         [  322],
         [11033],
         [  322],
         [  278],
         [  322],
         [  411],
         [11033],
         [  310],
         [  411],
         [ 5377],
         [ 1078],
         [  297],
         [18350],
         [  526],
         [  263],
         [ 6976],
         [  310],
         [19100],
         [  271],
         [  457],
         [19015],
         [  559],
         [29889],
         [29881],
         [  411],
         [  278],
         [ 2029],
         [  559],
         [29889],
         [29889],
         [  450],
         [ 6976],
         [ 6976],
         [11614],
         [  892],
         [12833],
         [  297],
         [  263],
         [ 1788],
         [ 1904],
         [  607],
         [  450],
         [ 1904],
         [  471],
         [ 7168],
         [ 2354],
         [ 5439],
         [ 7964],
         [ 1078],
         [  278],
         [17986],
         [  848],
         [  373],
         [20766],
         [ 1100],
         [  634],
         [  634],
         [29889],
         [  341],
         [29889],
         [  322],
         [  379],
         [ 2202],
         [29892],
         [  478],
         [29889],
         [29909],
         [29889],
         [  313],
         [29896],
         [29929],
         [29955],
         [29900],
         [29897],
         [  435],
         [29889],
         [21184],
         [14969],
         [29889],
         [ 3457],
         [ 3021],
         [  952],
         [29889],
         [29871],
         [29906],
         [29896],
         [29929],
         [29892],
         [29871],
         [29896],
         [29899],
         [29896],
         [29899],
         [29896],
         [29955],
         [29946],
         [  467],
         [  322],
         [12399],
         [  630],
         [  278],
         [ 1788],
         [  297],
         [  278],
         [ 1950],
         [ 1355],
         [  575],
         [  310],
         [  278],
         [  292],
         [29889],
         [  450],
         [ 1904],
         [  310],
         [  393],
         [ 1494],
         [ 1374],
         [ 7492],
         [ 6030],
         [24378],
         [  397],
         [ 8739],
         [ 4426],
         [ 1907],
         [  297],
         [  278],
         [ 1788],
         [  310],
         [  278],
         [ 3631],
         [  635],
         [ 2788],
         [29764],
         [  907],
         [  271],
         [  457],
         [19015],
         [  559],
         [29899],
         [  263],
         [ 1121],
         [17004],
         [  310],
         [  278],
         [ 3802],
         [15477],
         [  304],
         [  278],
         [ 2029],
         [  559],
         [29889],
         [   13]],

        [[  917],
         [29901],
         [ 1724],
         [29902],
         [ 5618],
         [  278],
         [ 1353],
         [  310],
         [  278],
         [18942],
         [  395],
         [  278],
         [10362],
         [  995],
         [29889],
         [   13],
         [28956],
         [  505],
         [ 2183],
         [  278],
         [ 1494],
         [ 3168],
         [29901],
         [29888],
         [29898],
         [29896],
         [29898],
         [29916],
         [29897],
         [  353],
         [  320],
         [29916],
         [29989],
         [  322],
         [  395],
         [29888],
         [29918],
         [29906],
         [29898],
         [29916],
         [29897],
         [  353],
         [  891],
         [29985],
         [29906],
         [ 1504],
         [29896],
         [29916],
         [  322],
         [  278],
         [  591],
         [  526],
         [  304],
         [ 1284],
         [  278],
         [13451],
         [ 4038],
         [  278],
         [   13],
         [12251],
         [  471],
         [ 2215],
         [  338],
         [29901],
         [   13],
         [   13],
         [29938],
         [29892],
         [  306],
         [  626],
         [29915],
         [29873],
         [ 1073],
         [  920],
         [13451],
         [  304],
         [  881],
         [  304],
         [  671],
         [  363],
         [  278],
         [ 7101],
         [29889],
         [  306],
         [  306],
         [  671],
         [15048],
         [  278],
         [ 3168],
         [  310],
         [ 2726],
         [ 3408],
         [  292],
         [ 3408],
         [ 1061],
         [29892],
         [13451],
         [ 3168],
         [  306],
         [  395],
         [29906],
         [29938],
         [  322],
         [  395],
         [29906],
         [ 1504],
         [  541],
         [  306],
         [ 1016],
         [29915],
         [29873],
         [ 1073],
         [  565],
         [  304],
         [  508],
         [  505],
         [  679],
         [  278],
         [29889],
         [  773],
         [   13],
         [   13],
         [ 1371],
         [  723],
         [ 7556],
         [29889],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [ 1576],
         [  508],
         [  304],
         [ 1476],
         [  278],
         [13451],
         [  310],
         [   13],
         [  508],
         [  304],
         [  278],
         [   13],
         [   13],
         [ 3997],
         [29892],
         [29901],
         [  395],
         [29916],
         [  320],
         [  479],
         [29871],
         [29900],
         [29938],
         [   13],
         [   13],
         [29905],
         [29985],
         [29906],
         [29899],
         [29906],
         [29905],
         [29906],
         [29905],
         [29900],
         [29905],
         [21304],
         [  921],
         [ 3676],
         [29912],
         [11436],
         [29913],
         [29916],
         [29922],
         [29906],
         [ 1966],
         [29916],
         [10457],
         [29906],
         [29905],
         [  355],
         [29912],
         [11436],
         [ 9458],
         [   13],
         [   13],
         [  366],
         [  338],
         [ 1206],
         [  338],
         [  395],
         [29916],
         [29905],
         [  479],
         [29871],
         [29900],
         [ 1628],
         [  322],
         [ 4716],
         [  278],
         [ 4251],
         [ 2038],
         [  467],
         [  577],
         [  278],
         [13451],
         [ 1650],
         [ 1650],
         [  338],
         [  395],
         [29916],
         [29922],
         [29906],
         [ 1504],
         [   13],
         [   13],
         [ 1206],
         [29892],
         [  395],
         [29916],
         [29905],
         [  280],
         [29871],
         [29900],
         [21063],
         [   13],
         [ 3997],
         [29916],
         [29985],
         [29906],
         [29899],
         [29916],
         [29899],
         [29906],
         [29922],
         [29900],
         [29905],
         [21304],
         [29905],
         [  463],
         [29912],
         [11436],
         [29913],
         [29916],
         [10457],
         [29906],
         [ 1966],
         [29916],
         [10457],
         [29906],
         [29905],
         [  355],
         [29912],
         [11436],
         [ 9458],
         [   13],
         [ 6246],
         [  445],
         [ 1473],
         [ 1206],
         [ 6858],
         [  395],
         [29916],
         [29905],
         [  280],
         [29871],
         [29900],
         [29938],
         [  313],
         [ 4149],
         [ 1023],
         [ 3454],
         [ 2038],
         [  511],
         [  577],
         [  278],
         [  871],
         [ 2854],
         [ 1650],
         [  338],
         [  395],
         [29916],
         [10457],
         [29906],
         [ 1504],
         [   13],
         [   13],
         [20001],
         [ 1079],
         [  596],
         [13451],
         [13451],
         [29889],
         [   13],
         [   13],
         [20001],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [29873],
         [29873],
         [    1],
         [30488],
         [30488],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [  338],
         [  338],
         [  338],
         [  338],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [ 1516],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 457, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  398, 23378,  9215,  ...,  7018,  1417,  1598],
         [ 7418, 24352,   322,  ..., 24809, 10550,   390],
         ...,
         [  559,   403,  1061,  ...,  1008,  1288,  1230],
         [29889,   322, 29892,  ...,   411,  6354, 13206],
         [   13,   450,     2,  ...,  4525,  6549,  2688]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13, 29966, 29871,  ...,  4345, 29924, 30004],
         [   13, 29966, 29871,  ...,  4345, 29924, 30004],
         [   13, 29966, 29871,  ...,  4345, 29924,  8999]]], device='cuda:0')
Batch 37, 70.6% of total tokens
encoded shape: torch.Size([2, 262])
torch.Size([2, 262]) tensor([[    1,   323,   562,  1467,   326,   375,   297,  9241,   424,  7601,
          3813,   661,   681,   452,   561,  1336,   493, 29891,   489, 29874,
          3461,   310, 29871, 29941,  4251, 29889,    13,  1762,  6559,   278,
          6366,  4135,   322, 15332,   310,   260,   562,  1467,   326,   375,
           297,  7601,  3813,   661,   681,   452,   561,  1336,   493, 29891,
         29889,  1334,  8453, 29871, 29941, 22069,   411,  7601,  3813,   661,
           681,   452,   561,  1336,   493, 29891,  1058,   892,  2845,  9241,
           424,   304,   470,  1033,   451, 20341,   403, 16864,  3398,   411,
           470,  1728,   274,  3637,   327,  2251,   293, 19518, 29889,  2688,
           892, 14914,   411,   260,   562,  1467,   326,   375, 29871, 29900,
         29889, 29906,   286, 29887, 29914,  9415, 29914,  3250,   363, 29871,
         29953,  7378, 29889,   450,  3248,   482,   310,   260,   562,  1467,
           326,   375,   471, 10365,   287,   304,  3013,   263,  3353, 10416,
           260,   562,  1467,   326,   375,  3233,   310, 29871, 29945, 29899,
         29896, 29900,  8736, 29914,   828, 29889,  3118, 16500,   750,  4359,
          4866,  8796, 21711,   310, 26823, 26607,  1550,   278,   916, 29871,
         29906,   750,   472,  3203, 29871, 29945, 29900, 29995, 20376,   297,
         26823, 26607, 29889, 14409,   262, 26607, 11664,  1449,   297, 29871,
         29906,   310,   278, 22069,  1156,   260,   562,  1467,   326,   375,
           471, 11084, 29892,   541,   297,  9561,   310,   963, 26823, 26607,
          4133,   304,   278,   758,  2484,   271,   358,  3233, 29871, 29953,
          7378,  1156,   260,   562,  1467,   326,   375,   471, 11084, 29889,
          1334, 17668,   393,   260,   562,  1467,   326,   375,  1122,   505,
           263,   878,   342,  6366,  4135,   297,   278, 14502,   310,  9241,
           424,  3813,   661,   681,   452,   561,  1336,   493, 29891, 29889,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1, 19054,  4834,  7078,    13,    13, 29949, 14494,  4834,  7078,
           313, 12703, 29871, 29906, 29900, 29892, 29871, 29896, 29929, 29900,
         29941,   785,  5306, 29871, 29906, 29900, 29892, 29871, 29896, 29929,
         29947, 29906, 29897,   471,   263, 16833,   310,   278,  2315,  4233,
          9245,   322, 17719,   310,  3086,  5282,  1947,   310,   278, 26260,
         29889,    13, 29933,  1398,   297,   315, 10910,  8088,   273, 29892,
         18151,   382, 26575, 29892,  4834,  7078,   427, 24476,   472,   278,
          3087,  8699,   316,  2803,   661,   322,  2678,   472, 12783,  9992,
           316,   360,   406,  1859, 29889,   940,   471, 20186,   304,   278,
         12325,   457,  2261,   297, 29871, 29896, 29929, 29906, 29955,   322,
           471, 18018,  1652,  8122,   297,  4223,   322, 10432, 29889,   940,
          2678,  6153,   304,  3303,  3900, 29892,   988,   540,  6423,   373,
          5306, 29871, 29906, 29900, 29892, 29871, 29896, 29929, 29947, 29906,
         29892, 26552, 29871, 29955, 29929, 29889,    13,    13, 13393,   884,
            13,  8498,   442,   358,   310,  3086,  5282,  1947,    13,  1293,
           310, 11680,   262,  1691,   310,   278, 26260,    13,    13,  1123,
         10662,    13,    13, 15738,  7078, 29915, 29879, 17093,    13,    13,
         10900, 29901, 29896, 29929, 29900, 29941, 12060, 29879,    13, 10900,
         29901, 29896, 29929, 29947, 29906,  4892, 29879,    13, 10900, 29901,
         28459,  4314,   310,  3086,  5282,  1947,   310,   278, 26260,    13,
         10900, 29901,  3434,   666,  1789,  6577,  2710,    13, 10900, 29901,
          3434,   666,  1789,  4307, 29891,   414,    13, 10900, 29901,  7967,
          1397,   601,   316,  3087,  8699,   316,  2803,   661,   394,  1227,
         29875,    13, 10900, 29901, 11574,   537,   310, 21377,  4335,   294,
           394,  1227, 29875,    13, 10900, 29901, 15666,  1991,   515,   315,
         10910,  8088,   273,    13, 10900, 29901,  2182,   381,  1789, 23303,
         28966,  5144]], device='cuda:0')
torch.Size([2, 262, 32000]) tensor([[[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [ -9.9375,  -9.6562,  -0.2874,  ...,  -5.4375,  -7.7227,  -5.9844],
         [ -9.5234, -10.0312,  -1.4082,  ...,  -4.3555,  -4.2734,  -4.0625],
         ...,
         [ -6.9336,  20.6562,  10.0078,  ...,  -0.2028,  -3.1289,  -0.2074],
         [ -7.1094,  17.0469,   8.8047,  ...,  -0.5981,  -3.3574,  -0.5923],
         [ -7.5547,  10.3984,   4.3281,  ...,  -1.9424,  -4.1914,  -1.8037]],

        [[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [-11.1484,  -9.0469,  -0.2275,  ...,  -7.1523,  -8.8516,  -5.1562],
         [-10.7969, -11.0312,   3.1777,  ...,  -7.6680,  -6.4570,  -4.9766],
         ...,
         [ -5.6172,  -8.0391,  15.1016,  ...,  -2.4922,  -5.4492,  -5.2383],
         [ -4.9414,  -2.4414,  16.1719,  ...,  -2.2578,  -2.8887,  -7.1836],
         [  1.5977,   2.6855,  21.3125,  ...,  -1.6777,  -0.2634,  -0.4089]]],
       device='cuda:0')
torch.Size([2, 262, 1]) tensor([[[  917],
         [ 5086],
         [  277],
         [  326],
         [  375],
         [  338],
         [  278],
         [  424],
         [  452],
         [ 5700],
         [  661],
         [  681],
         [  452],
         [  561],
         [ 1336],
         [  493],
         [29891],
         [   13],
         [29874],
         [ 1206],
         [  310],
         [ 1023],
         [29906],
         [ 4251],
         [29889],
         [   13],
         [29924],
         [14707],
         [  278],
         [ 2779],
         [ 4135],
         [  310],
         [15332],
         [  310],
         [  260],
         [  562],
         [ 1467],
         [  326],
         [  375],
         [  297],
         [ 9241],
         [ 3813],
         [  661],
         [  681],
         [  452],
         [  561],
         [ 1336],
         [  493],
         [29891],
         [  313],
         [   13],
         [ 3240],
         [29871],
         [29941],
         [ 4251],
         [  411],
         [ 7601],
         [ 3813],
         [  661],
         [  681],
         [  452],
         [  561],
         [ 1336],
         [  493],
         [29891],
         [ 1058],
         [  892],
         [ 9241],
         [ 9241],
         [  424],
         [  304],
         [  470],
         [  938],
         [  451],
         [20341],
         [  403],
         [28557],
         [ 3398],
         [29220],
         [  470],
         [ 1728],
         [ 5094],
         [ 3637],
         [  327],
         [ 2251],
         [  293],
         [19518],
         [29889],
         [ 2178],
         [  892],
         [14914],
         [  411],
         [  260],
         [  562],
         [ 1467],
         [  326],
         [  375],
         [29889],
         [29900],
         [29889],
         [29896],
         [29945],
         [29887],
         [29914],
         [ 9415],
         [29914],
         [ 3250],
         [29889],
         [29871],
         [29896],
         [ 7378],
         [29889],
         [  450],
         [  724],
         [  482],
         [  471],
         [  260],
         [  562],
         [ 1467],
         [  326],
         [  375],
         [  471],
         [10365],
         [  287],
         [ 5034],
         [ 7344],
         [  278],
         [  534],
         [10416],
         [  534],
         [  562],
         [ 1467],
         [  326],
         [  375],
         [ 3233],
         [  310],
         [29871],
         [29945],
         [29899],
         [29896],
         [29900],
         [ 8736],
         [29914],
         [  828],
         [29889],
         [  450],
         [16500],
         [  750],
         [  263],
         [ 4866],
         [ 1083],
         [21711],
         [  310],
         [26823],
         [26607],
         [  322],
         [  278],
         [  916],
         [29871],
         [29906],
         [22069],
         [  263],
         [ 3203],
         [29871],
         [29945],
         [29900],
         [29995],
         [20376],
         [  297],
         [26823],
         [26607],
         [29889],
         [  450],
         [  262],
         [26607],
         [  471],
         [  297],
         [  297],
         [29871],
         [29906],
         [22069],
         [  278],
         [29871],
         [ 1156],
         [  766],
         [  562],
         [ 1467],
         [  326],
         [  375],
         [  471],
         [  766],
         [29889],
         [  541],
         [  278],
         [  278],
         [16500],
         [  963],
         [  471],
         [26607],
         [  471],
         [  304],
         [  278],
         [  758],
         [ 2484],
         [  271],
         [  358],
         [ 3233],
         [29889],
         [29953],
         [ 7378],
         [ 1156],
         [  260],
         [  562],
         [ 1467],
         [  326],
         [  375],
         [  471],
         [11084],
         [29889],
         [  450],
         [17668],
         [  393],
         [  260],
         [  562],
         [ 1467],
         [  326],
         [  375],
         [  338],
         [  367],
         [  263],
         [ 6297],
         [  342],
         [ 6297],
         [ 4135],
         [  297],
         [ 7601],
         [14502],
         [  310],
         [ 7601],
         [  424],
         [ 7601],
         [  661],
         [  681],
         [  452],
         [  561],
         [ 1336],
         [  493],
         [29891],
         [29889],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [29873],
         [29873],
         [   13]],

        [[  917],
         [29899],
         [ 9093],
         [   13],
         [ 1576],
         [ 2277],
         [14494],
         [ 4834],
         [ 7078],
         [  313],
         [29896],
         [29871],
         [29896],
         [29945],
         [29892],
         [29871],
         [29896],
         [29929],
         [29896],
         [29945],
         [  785],
         [ 5490],
         [29871],
         [29896],
         [29953],
         [29892],
         [29871],
         [29896],
         [29929],
         [29947],
         [29946],
         [29897],
         [  471],
         [  263],
         [24777],
         [  310],
         [  278],
         [22569],
         [  277],
         [16208],
         [  310],
         [  263],
         [  310],
         [17181],
         [ 5282],
         [ 1947],
         [  310],
         [  278],
         [26260],
         [29889],
         [   13],
         [   13],
         [ 1398],
         [  297],
         [ 2315],
         [  774],
         [ 8088],
         [  273],
         [29892],
         [18151],
         [  382],
         [26575],
         [29892],
         [ 4834],
         [ 7078],
         [  471],
         [24476],
         [  472],
         [  278],
         [ 3014],
         [  350],
         [  316],
         [ 2803],
         [  661],
         [ 6346],
         [  278],
         [  472],
         [  278],
         [ 9992],
         [21981],
         [  360],
         [  406],
         [ 1859],
         [29889],
         [  940],
         [  471],
         [20186],
         [  304],
         [  278],
         [ 2594],
         [  457],
         [ 2261],
         [  297],
         [29871],
         [29896],
         [29929],
         [29906],
         [29955],
         [29889],
         [ 3897],
         [10658],
         [20186],
         [ 8122],
         [  297],
         [ 4223],
         [  322],
         [10432],
         [29889],
         [   13],
         [  471],
         [ 3897],
         [  304],
         [ 2315],
         [ 3900],
         [  304],
         [  988],
         [  540],
         [12399],
         [  297],
         [ 5306],
         [29871],
         [29906],
         [29900],
         [29892],
         [29871],
         [29896],
         [29929],
         [29947],
         [29906],
         [29889],
         [  472],
         [29871],
         [29955],
         [29929],
         [29889],
         [   13],
         [   13],
         [ 2277],
         [  884],
         [29901],
         [   13],
         [  442],
         [  358],
         [  310],
         [ 3086],
         [ 5282],
         [ 1947],
         [  313],
         [   13],
         [  310],
         [10213],
         [10157],
         [ 1691],
         [  310],
         [  278],
         [26260],
         [   13],
         [   13],
         [ 2277],
         [10662],
         [   13],
         [   13],
         [ 2277],
         [ 7078],
         [29892],
         [29879],
         [ 4768],
         [   13],
         [   13],
         [  991],
         [29901],
         [29896],
         [29929],
         [29900],
         [29941],
         [12060],
         [29879],
         [   13],
         [10900],
         [29901],
         [29896],
         [29929],
         [29947],
         [29906],
         [ 4892],
         [29879],
         [   13],
         [10900],
         [29901],
         [15666],
         [ 4314],
         [  310],
         [ 3086],
         [ 5282],
         [ 1947],
         [  310],
         [  278],
         [26260],
         [   13],
         [10900],
         [29901],
         [15666],
         [  666],
         [ 1789],
         [ 4307],
         [ 2710],
         [   13],
         [10900],
         [29901],
         [ 3434],
         [  666],
         [ 1789],
         [ 4307],
         [29891],
         [  414],
         [   13],
         [10900],
         [29901],
         [ 3434],
         [ 1397],
         [  601],
         [  316],
         [ 3087],
         [ 8699],
         [  316],
         [ 2803],
         [  661],
         [  394],
         [ 1227],
         [29875],
         [   13],
         [10900],
         [29901],
         [29923],
         [  537],
         [  310],
         [21377],
         [ 4335],
         [  294],
         [  394],
         [ 1227],
         [29875],
         [   13],
         [10900],
         [29901],
         [29923],
         [ 1991],
         [  515],
         [  315],
         [10910],
         [ 8088],
         [  273],
         [   13],
         [10900],
         [29901],
         [15666],
         [29874],
         [ 1789],
         [11680],
         [11680],
         [ 5144],
         [   13]]], device='cuda:0')
torch.Size([2, 262, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 5086,  1041,  2235,  ...,  1955,  4590,   860],
         [  277,   359,  2127,  ...,   305, 29880,   542],
         ...,
         [29873,     1, 29879,  ..., 29912, 29908,    12],
         [29873,    13,     1,  ..., 29912,   856, 29908],
         [   13, 29873, 29903,  ...,    12, 29915, 29907]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29899,   349,  4624,  ..., 10418,   897, 29915],
         [ 9093,   514,   292,  ...,  5259, 29901,  2911],
         ...,
         [11680, 28966,    13,  ...,   394, 11050,  7668],
         [ 5144, 11050,  7035,  ...,  4509, 29885,   341],
         [   13,     2, 10900,  ...,   313, 17943, 27514]]], device='cuda:0')
Batch 38, 71.2% of total tokens
encoded shape: torch.Size([2, 82])
torch.Size([2, 82]) tensor([[    1, 28728, 29892,  3979, 29871, 29906, 29892, 29871, 29906, 29900,
         29900, 29955,    13,    13, 29902,  1348,  1438, 21635,  3081,   287,
         17661, 26068,   526,   925,   278, 28539,   342, 29899,   372,  2794,
           366,  1033, 10200,   403,   596,  3699,   763,   445,  7623,  1550,
           451,  4459, 27719,  1048,   599,   278,  3081,   366, 29915, 29881,
           671,   669,   451,   505,   304,  5146,   393, 12176, 11118, 29991,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,   476,  3365,  1212,   578, 29894,  7912,    13,    13, 29968,
          3365,  1212,   578, 29894,  7912,  3861,   338,   263, 17692,  1887,
           537,   313, 29874,   413, 29882,  3406, 29897,   297,   306,   845,
         19977,   388,  7912,  7457, 29892, 29677, 29895,   441,   520,   273,
         29892, 12710, 29889,   450,  4665,   471, 29871, 29929, 29947,   408,
           310, 29871, 29906, 29900, 29896, 29900, 29889,  1670,   526, 29871,
         29906, 19756, 29889,    13,    13,  1123, 10662, 29871,    13,    13,
         10900, 29901, 29934,  3631,  1887,  1907,   297, 29677, 29895,   441,
           520,   273]], device='cuda:0')
torch.Size([2, 82, 32000]) tensor([[[-12.8281,  -7.3867,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-11.9766,  -8.0547,  -0.6475,  ...,  -6.1953,  -9.0156,  -6.6953],
         [ -3.6641,  -0.2507,   7.9727,  ...,  -0.7651,  -1.0957,  -0.7788],
         ...,
         [-11.0312,  -4.8633,   0.1049,  ...,  -4.8047,  -6.2578,  -1.9180],
         [-11.1406,  -4.9961,   0.2489,  ...,  -4.7891,  -6.2305,  -1.9824],
         [-11.2266,  -5.0625,   0.4419,  ...,  -4.8008,  -6.1992,  -2.0840]],

        [[-12.8281,  -7.3867,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -9.2578, -10.0703,  -0.4602,  ...,  -7.2305,  -6.2422,  -5.5117],
         [ -9.2969, -13.6875,  -2.3711,  ...,  -8.1172,  -5.7148,  -5.3008],
         ...,
         [ -6.1328,  -7.5742,  10.7188,  ...,  -1.9883,  -3.7734,  -2.6348],
         [ -6.9297,  -7.9727,  13.6953,  ...,  -0.8423,  -3.0684,  -4.8359],
         [ -1.0176,  -0.7021,  22.4375,  ...,  -2.2109,  -2.4531,  -1.2852]]],
       device='cuda:0')
torch.Size([2, 82, 1]) tensor([[[  917],
         [29892],
         [29871],
         [29871],
         [29896],
         [29906],
         [29871],
         [29906],
         [29900],
         [29896],
         [29955],
         [29892],
         [ 1576],
         [ 1576],
         [29915],
         [  306],
         [  526],
         [ 7243],
         [  287],
         [18647],
         [26068],
         [  526],
         [  263],
         [  278],
         [ 2655],
         [  342],
         [ 2655],
         [23261],
         [29915],
         [  366],
         [  508],
         [ 1925],
         [  403],
         [  596],
         [ 3699],
         [  363],
         [  445],
         [  599],
         [29892],
         [  366],
         [ 2534],
         [27719],
         [ 1048],
         [  278],
         [  278],
         [12646],
         [  366],
         [29915],
         [  276],
         [  367],
         [29889],
         [  278],
         [  505],
         [  304],
         [15982],
         [  363],
         [ 4805],
         [12646],
         [  472],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [   13],
         [30488],
         [30488],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [ 4841],
         [ 1212],
         [  578],
         [29894],
         [29892],
         [29892],
         [29968],
         [29968],
         [ 3365],
         [ 1212],
         [  578],
         [29894],
         [ 7912],
         [  313],
         [ 1752],
         [  278],
         [17692],
         [ 1887],
         [  537],
         [  313],
         [29874],
         [  413],
         [29882],
         [ 3406],
         [29897],
         [  297],
         [  476],
         [ 5590],
         [ 9089],
         [  388],
         [ 7912],
         [ 7457],
         [29892],
         [ 3684],
         [29895],
         [  441],
         [  520],
         [  273],
         [29892],
         [12710],
         [29889],
         [  450],
         [ 4665],
         [  471],
         [29871],
         [29896],
         [  408],
         [  408],
         [  310],
         [29871],
         [29906],
         [29900],
         [29896],
         [29900],
         [29889],
         [ 1670],
         [  526],
         [29871],
         [29906],
         [19756],
         [29889],
         [   13],
         [   13],
         [ 2277],
         [10662],
         [   13],
         [   13],
         [   13],
         [ 2277],
         [29901],
         [29968],
         [ 3631],
         [ 1887],
         [ 1907],
         [  297],
         [  306],
         [29895],
         [  441],
         [  520],
         [  273],
         [    2]]], device='cuda:0')
torch.Size([2, 82, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29892, 29871, 11554,  ..., 30010, 22853, 29901],
         [29871,  5533,  3979,  ...,  5468,  3786,  6339],
         ...,
         [   13, 29937,  2277,  ..., 29902, 29871,   797],
         [   13, 29937,  2277,  ..., 29902,   797, 29871],
         [   13, 29937,  2277,  ..., 29902,   797, 29871]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 4841,   860,  1508,  ...,   355, 29899, 29923],
         [ 1212,   655, 29884,  ...,  1171, 29890, 19254],
         ...,
         [  520, 14411,  3718,  ...,   579,  4374,   303],
         [  273,   550,  1715,  ..., 12190,    13,   392],
         [    2,    13, 29968,  ...,   476,  9986,  5262]]], device='cuda:0')
Batch 39, 71.3% of total tokens
encoded shape: torch.Size([2, 2001])
torch.Size([2, 2001]) tensor([[    1, 14305,   627,  ...,     2,     2,     2],
        [    1, 28218, 29879,  ..., 29923, 10214,  1199]], device='cuda:0')
torch.Size([2, 2001, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.2969,  -6.4453,   0.2512,  ...,  -3.1641,  -5.8750,  -4.3203],
         [-13.2109,  -9.8594,  -4.1523,  ...,  -7.3945, -10.5469, -11.0938],
         ...,
         [ -9.5156,   1.5977,   2.4180,  ...,  -3.8887,  -5.3672,  -3.8105],
         [ -9.6016,   1.6221,   2.4766,  ...,  -3.8848,  -5.3477,  -3.7676],
         [ -9.6797,   1.6611,   2.5254,  ...,  -3.8906,  -5.3555,  -3.7578]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.5078,  -6.0781,   1.0059,  ...,  -3.0723,  -7.0352,  -3.8652],
         [-13.6250, -12.4141,  -3.4355,  ...,  -7.7109, -10.3594,  -7.4414],
         ...,
         [  3.8164,   4.1445,   3.1152,  ...,   6.8984,   2.7930,   5.8867],
         [  7.9180,   9.5625,   1.2559,  ...,   8.8359,   7.1172,   8.2266],
         [ -8.1953,  -8.2578,  12.9297,  ...,  -6.8281,  -7.1719,  -8.6328]]],
       device='cuda:0')
torch.Size([2, 2001, 1]) tensor([[[  917],
         [  627],
         [  310],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [  284],
         [29871],
         ...,
         [10214],
         [ 1199],
         [   13]]], device='cuda:0')
torch.Size([2, 2001, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  627,  5795,  4019,  ...,   520,  1466, 15664],
         [  310, 29879,  4587,  ..., 29901, 29871,   512],
         ...,
         [    3, 29949,    13,  ..., 29909, 29903, 29924],
         [    3, 29949,    13,  ..., 29909, 29903, 29924],
         [    3, 29949,    13,  ..., 30166, 29903, 29924]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  284, 29879,   310,  ...,   635,  4408,   363],
         [29871,   310,   322,  ...,   393,   363,   505],
         ...,
         [10214,   386,  2806,  ...,   700, 11530, 29886],
         [ 1199,   293,   936,  ...,   267,   391,   638],
         [   13,   297, 25700,  ..., 21561, 10298, 24147]]], device='cuda:0')
Batch 40, 73.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   462,   795,  ..., 29934,   542,   314]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6562],
         ...,
         [-11.0078,   5.7578,   1.0234,  ...,  -5.0703,  -6.6523,  -4.4102],
         [-11.0156,   5.7578,   0.9805,  ...,  -5.1289,  -6.6719,  -4.4180],
         [-10.9609,   5.8711,   0.9512,  ...,  -5.1406,  -6.6055,  -4.4141]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.0977,   1.3623,   6.2305,  ...,   0.5659,   1.6436,   3.4629],
         [ -9.6172,  -6.8359,  -0.1367,  ...,  -4.2344,  -4.6406,  -3.5371],
         ...,
         [  1.6104,   2.9453,   4.0742,  ...,   6.6875,   1.3770,   4.4492],
         [ -6.2969,  -5.9766,   7.0156,  ...,   0.3242,  -0.5361,  -2.6406],
         [-11.0859, -15.1641,   8.6562,  ...,  -4.9609,  -5.0039,  -4.9141]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [    1],
         [    1],
         [    1]],

        [[  917],
         [  462],
         [  529],
         ...,
         [ 2209],
         [  314],
         [ 2207]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [    1,    13, 29871,  ..., 29909, 29911, 29933],
         [    1,    13, 29871,  ..., 29909,     3, 29911],
         [    1,    13, 29871,  ..., 29909, 29911, 29902]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  462,  1678,  4706,  ..., 29871,   795,   632],
         [  529,    13,  6319,  ..., 29896,   849,   450],
         ...,
         [ 2209,   542, 18219,  ..., 15693,  4950,   293],
         [  314, 29885, 10178,  ...,   370,   398, 11108],
         [ 2207,   272,  2963,  ...,  4616, 21481,  1572]]], device='cuda:0')
Batch 41, 78.4% of total tokens
encoded shape: torch.Size([2, 933])
torch.Size([2, 933]) tensor([[    1,  1724,   341,  ...,  8745,  2984, 29889],
        [    1,   450,   671,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 933, 32000]) tensor([[[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-12.6016,  -9.4531,  -2.6074,  ...,  -7.0430,  -9.5156,  -9.2422],
         [ -9.0469,  -5.9844,  -0.5327,  ...,  -4.1641,  -5.4648,  -7.2500],
         ...,
         [-11.5469, -16.0312,   2.9141,  ...,  -6.9375,  -8.4922,  -5.6562],
         [ -2.4824,  -4.8164,  14.5859,  ...,  -2.3594,  -2.4141,  -2.1934],
         [ -1.4883,  -4.9492,  17.0781,  ...,   1.0713,  -2.3340,  -0.3135]],

        [[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-13.5156, -11.7344,  -6.9766,  ...,  -9.1484, -10.2500,  -8.5781],
         [ -5.4766,  -1.4395,   5.6914,  ...,  -1.5156,  -2.4707,  -1.4561],
         ...,
         [ -7.5469,   3.3105,   3.1797,  ...,  -2.6816,  -4.1406,  -2.3301],
         [ -7.4883,   3.2852,   3.1836,  ...,  -2.6465,  -4.1094,  -2.3242],
         [ -7.3555,   3.5859,   3.2559,  ...,  -2.5742,  -4.0430,  -2.2383]]],
       device='cuda:0')
torch.Size([2, 933, 1]) tensor([[[  917],
         [  338],
         [ 6926],
         ...,
         [ 2669],
         [29889],
         [   13]],

        [[  917],
         [29871],
         [  310],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 933, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  338,   526, 30010,  ...,   304,  4683,   263],
         [ 6926,   523,  4992,  ...,   391,  5086, 13415],
         ...,
         [ 2669,  1650,  1824,  ...,  3234, 27032,  6851],
         [29889, 29991,   988,  ...,   470,   363, 29901],
         [   13,     2,  1334,  ..., 29871,  2973,  8680]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  310,   322,  1206,  ..., 29899,   338,   297],
         ...,
         [    3,    13, 30166,  ..., 30212, 29902,   197],
         [    3, 30166,    13,  ..., 30212, 29902,   197],
         [    3, 30166,    13,  ..., 30212, 29902,   197]]], device='cuda:0')
Batch 42, 79.5% of total tokens
encoded shape: torch.Size([2, 2094])
torch.Size([2, 2094]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 29871, 29896,  ...,  1985,  6455, 29889]], device='cuda:0')
torch.Size([2, 2094, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6562],
         ...,
         [-11.0156,   3.4512,   1.6279,  ...,  -5.5977,  -6.7031,  -3.8457],
         [-11.0234,   3.4531,   1.6123,  ...,  -5.5898,  -6.6992,  -3.8438],
         [-11.0234,   3.5000,   1.6084,  ...,  -5.5820,  -6.6992,  -3.8633]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.0156,  -3.6582,   0.7739,  ...,  -4.5352,  -6.8125,  -4.2930],
         ...,
         [ -4.9258,  -2.4121,   5.7930,  ...,  -6.6602,   0.1792,  -3.6133],
         [ -4.2031,  -3.7070,   7.6172,  ...,  -2.7441,   0.0886,   0.0743],
         [ -1.7725,  -4.8086,   9.0000,  ...,  -2.6660,   0.2561,  -2.5000]]],
       device='cuda:0')
torch.Size([2, 2094, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29896],
         [29889],
         ...,
         [ 6455],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 2094, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13, 29871,  7228,  ...,   268,  4345, 29949],
         [   13, 29871,  7228,  ...,  4345,   268,     1],
         [   13, 29871,  7228,  ...,  4345,     1,   268]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [29889, 29900, 29929,  ..., 29946, 29941, 29953],
         ...,
         [ 6455,  1342,  1222,  ..., 29455,  7309, 29899],
         [29889, 29892,   322,  ...,   310,  1728,   313],
         [   13,   450,   512,  ...,  1152,  8512, 17044]]], device='cuda:0')
Batch 43, 81.9% of total tokens
encoded shape: torch.Size([2, 306])
torch.Size([2, 306]) tensor([[    1, 16972,   373,   278,   938,   336,   854,   681,  1374,  2817,
           562,   554, 10157,  1199,   297, 27127,   277,   322,   297, 13901,
           307, 26823,  9956,   310,  1023,   716,  4497,  1372,   310,   604,
          1541,   456, 11078,   262, 29901,   604,  1541,   456, 11078,   262,
          4439,   517, 29890,   291,   403,   322,   604,  1541,   456, 11078,
           262,   285, 24540,   403, 29889,    13,  4819,  2817,   562,   554,
         10157,  1199,   297, 27127,  1169,  1494,   938,   336,   854,   681,
         17517,   322,   297, 13901,   307, 26823,  9956,   892, 12399,   363,
          1023,   716,  4497,  1372,   310,   604,  1541,   456, 11078,   262,
           313,   708,   386,   456, 11078,   262,  4439,   517, 29890,   291,
           403,   322,   604,  1541,   456, 11078,   262,   285, 24540,   403,
           467,  1816,   398,   604,  1541,   456, 11078,   262, 11174,  1494,
           938,   336,   854,   681, 20859,   892,  5439,   491,  1023, 29078,
           358,  1904,   413, 10157,  1199, 29892,   322,  1819,   363,   278,
          4978,  7977,   310,   278,  6555, 29078,   358, 29892,   278, 23603,
          8096,   284, 29078,   358,   322, 12463,  4978,  7977,   892, 12833,
         29889,   450, 29007,  3381,  4203, 29899, 29880,  3145,   310,   604,
          1541,   456, 11078,  1144,   297,   724,   398,   892, 29871, 29947,
         29941,  1375, 29892, 29871, 29896, 29953, 29947,  1375, 29892,   322,
         29871, 29896, 29900, 29941,  1375,   363,   604,  1541,   456, 11078,
           262,  4439,   517, 29890,   291,   403, 29892,   604,  1541,   456,
         11078,   262,   285, 24540,   403, 29892,   322,   604,  1541,   456,
         11078,   262,   425,   312,   711,   291,   403,   313,  5679,  3918,
           511,  8307, 29889,   450,   604,  1541,   456, 11078,   262,  4497,
          1372,   892, 10712,   313, 29883, 29889, 29871, 29929, 29900,   639,
          1644, 29897, 26823,  3216, 29892,   541,   278,  9956,   471,  1476,
           304,   367, 18764,  1821, 29889,   360,  8349,  2063,   297,   278,
          1374,  2817,   562,   554,   262,  7492,  4128,  1156, 17517,   310,
          7126,  3248,   267,   310,   278,  4497,  1372, 29892, 12266,  1950,
         19262,   297,  1801,   983,  2478,   310,  1422,  4497,  1372, 29889,
             2,     2,     2,     2,     2,     2],
        [    1,  6438,  6152, 29871, 29896, 29889, 29955, 29901, 18129,  2911,
          7437,   355,    13,    13,  4591,  6438,  6152,  5653, 29875,    13,
            13,  1123,  4924,   408,   310, 29871, 29900, 29953, 29901, 29945,
         29955, 29892, 29871, 29945,  3979, 29871, 29906, 29900, 29896, 29900,
           491,  7906,  1362, 29898, 29911,  2235,   891, 17737, 29879,  5033,
         20399,  1813,   411,   525, 29924,  2112,  2911,  1250, 29899,   355,
         11524,   385, 13304,  1546,   478, 29947,   763,  9608,   322, 18129,
          2911,   435,  7230, 29889,   910, 13304, 12080,   297,  6438,  6152,
           322, 10703,   350, 24301,  5067, 29889,   910, 13304,   881,  5191,
          6629,  8696,  6152, 30098,  1495,    13,    13,  5618,   338,   278,
          8286,  2677,   297,   278,  3030,   310,  6438,  6152, 11258, 29973,
          6028,   366,  8453,  5302,  4249,   350, 24301,  3618, 29973,    13,
            13,  3057,   315,  2129,    13,    13,  1252,   572, 12418,   310,
           777,  1855,  3186, 21846,   393,  5930,   746, 13490,   263,  1856,
          2280, 29889,  4525, 21846,  8453,   297, 29899,  5014,  8744,   310,
           278,  3974,  6152, 29899,  5509,  1549,   263,   350, 24301, 13304,
         29889,   450,  6996,  6964,   338,   408,  4477, 29901,    13,    13,
         18654,  6152,  3740,   313,  4081,   349,  3870, 29897, 10309,   350,
         24301, 10309,   383,  9851, 10309,   435,  7230,    13,    13, 11921,
           338,  6438,  6152, 29889, 11862,   914,   297,   445,  6964, 29973,
            13,    13, 17918,    13,    13, 17918,   304,   278,  4714, 29889,
            13,    13,  2577, 15228, 29879,    13,    13,  2577,  1051,   310,
           599,  3625,  3030, 29879,   297,   278,  6631,  4714, 29889,    13,
            13,  6843,  8634, 13223,    13,    13,  2577,  1051,   310,   599,
         14835, 10340,   363,  2183,  3030, 29889,    13,    13,  2577,  7562,
            13,    13,  2577,  2752,   775,   313,  3881, 29897,   363,  2183,
         14835,  5190, 29889,    13,    13,  2697, 28301,  3149,    13,    13,
          2697,   263,  2867,  3149,   297,  2183, 14835,  5190, 29889,    13,
            13, 11921,   278,  1051,   310, 14835, 10340,   338,  6087, 29973,
            13,    13,  5618,   338,   278,  1741, 29914, 14035,   393,  6511,
           304,  6314,   599, 14835, 10340, 29973]], device='cuda:0')
torch.Size([2, 306, 32000]) tensor([[[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [-12.2422,  -5.7734,  -1.0078,  ...,  -7.9570,  -9.8672,  -8.1250],
         [ -9.1953,  -9.9375,   2.0078,  ...,  -2.6465,  -6.0820,  -5.7734],
         ...,
         [ -3.2676,  33.0000,   6.0742,  ...,   0.1371,  -1.3594,  -0.3069],
         [ -4.7812,  31.4531,   6.8828,  ...,  -0.4475,  -2.2324,  -0.7461],
         [ -6.0312,  29.5625,   7.8281,  ...,  -0.8735,  -2.9316,  -1.0215]],

        [[-12.8281,  -7.3867,  -0.4646,  ...,  -6.7773,  -8.0078,  -7.5000],
         [-10.7500, -13.5234,  -0.9526,  ...,  -8.4219,  -6.2695,  -7.5430],
         [-13.4375, -13.2656,  -3.9160,  ...,  -8.5625, -11.1484,  -7.1602],
         ...,
         [ -3.0801,  -1.9990,  10.7656,  ...,   0.4766,  -1.1133,  -1.5283],
         [ -5.9297,  -4.7344,   5.3984,  ...,  -1.3887,  -1.3887,  -2.1992],
         [  1.4277,  -2.6211,  14.0312,  ...,   1.4395,   0.7261,   0.3838]]],
       device='cuda:0')
torch.Size([2, 306, 1]) tensor([[[  917],
         [  297],
         [  278],
         [ 2779],
         [  945],
         [29899],
         [  681],
         [17517],
         [ 2817],
         [  562],
         [  554],
         [10157],
         [ 1199],
         [  310],
         [  364],
         [ 1169],
         [  310],
         [11203],
         [  767],
         [  307],
         [ 1539],
         [ 9956],
         [  310],
         [  278],
         [  716],
         [ 3677],
         [  293],
         [  310],
         [29871],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [   13],
         [  604],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [11314],
         [  403],
         [  344],
         [ 2363],
         [  403],
         [  322],
         [  604],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [ 1886],
         [24540],
         [  403],
         [   13],
         [   13],
         [29909],
         [ 2817],
         [  562],
         [  554],
         [10157],
         [ 1199],
         [  310],
         [27127],
         [  277],
         [  310],
         [  938],
         [  336],
         [  854],
         [  681],
         [17517],
         [  310],
         [26823],
         [13901],
         [  307],
         [26823],
         [ 9956],
         [  310],
         [12399],
         [  363],
         [ 1023],
         [  716],
         [ 4497],
         [ 1372],
         [  310],
         [  604],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [29901],
         [  708],
         [  386],
         [  456],
         [11078],
         [  262],
         [ 4439],
         [  517],
         [29890],
         [  291],
         [  403],
         [  322],
         [  604],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [  285],
         [24540],
         [  403],
         [  467],
         [  450],
         [  398],
         [14953],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [14953],
         [  892],
         [  938],
         [  336],
         [  854],
         [  681],
         [17517],
         [  310],
         [ 6133],
         [  491],
         [  263],
         [29899],
         [  358],
         [ 4733],
         [29889],
         [10157],
         [ 1199],
         [29889],
         [  411],
         [  278],
         [  310],
         [  278],
         [ 7977],
         [ 7977],
         [  322],
         [  278],
         [ 6555],
         [29078],
         [  358],
         [  313],
         [  278],
         [ 7977],
         [ 8096],
         [  284],
         [29078],
         [  358],
         [ 7977],
         [  278],
         [ 2821],
         [ 7977],
         [  892],
         [12833],
         [29889],
         [  450],
         [26823],
         [ 3381],
         [ 4203],
         [29899],
         [19264],
         [ 3145],
         [  310],
         [  278],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [  892],
         [  278],
         [  398],
         [  892],
         [29871],
         [29896],
         [29889],
         [  322],
         [  363],
         [29871],
         [29896],
         [29900],
         [29900],
         [ 1375],
         [  322],
         [29871],
         [29871],
         [29896],
         [29906],
         [29900],
         [ 1375],
         [  363],
         [  604],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [ 4439],
         [  517],
         [29890],
         [  291],
         [  403],
         [29892],
         [  604],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [  285],
         [24540],
         [  403],
         [  322],
         [  322],
         [  604],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [29892],
         [  312],
         [  711],
         [  291],
         [  403],
         [29892],
         [ 1552],
         [  752],
         [  511],
         [ 8307],
         [29889],
         [  450],
         [26823],
         [ 1541],
         [  456],
         [11078],
         [  262],
         [ 4439],
         [ 1372],
         [  892],
         [ 1476],
         [ 3216],
         [29958],
         [  398],
         [29871],
         [29929],
         [29929],
         [10997],
         [ 1644],
         [29897],
         [ 3216],
         [ 3216],
         [  297],
         [  322],
         [  278],
         [ 9956],
         [  471],
         [  451],
         [  304],
         [  367],
         [ 1661],
         [ 1821],
         [29889],
         [  450],
         [ 8349],
         [ 2063],
         [  297],
         [  278],
         [26823],
         [ 2817],
         [  562],
         [  554],
         [10157],
         [ 7492],
         [ 4128],
         [  310],
         [  938],
         [  310],
         [  278],
         [ 3248],
         [  267],
         [  310],
         [  278],
         [  604],
         [ 1372],
         [  892],
         [  322],
         [  393],
         [12651],
         [  297],
         [  278],
         [  983],
         [ 2478],
         [  310],
         [  278],
         [  604],
         [ 1372],
         [  310],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1]],

        [[  917],
         [ 1003],
         [29871],
         [29896],
         [29889],
         [29945],
         [29889],
         [  319],
         [ 2911],
         [30010],
         [29879],
         [29892],
         [18654],
         [18654],
         [  278],
         [ 6152],
         [29871],
         [29875],
         [   13],
         [   13],
         [18654],
         [ 4924],
         [  408],
         [  310],
         [29871],
         [29896],
         [29929],
         [29901],
         [29900],
         [29929],
         [29892],
         [29871],
         [29906],
         [ 2610],
         [29871],
         [29906],
         [29900],
         [29900],
         [29900],
         [  491],
         [  435],
         [ 1362],
         [  313],
         [ 6152],
         [ 2235],
         [  891],
         [17737],
         [29879],
         [29897],
         [ 4373],
         [ 1813],
         [  411],
         [  525],
         [18654],
         [ 2112],
         [ 2911],
         [ 7437],
         [ 1975],
         [  355],
         [  338],
         [  278],
         [ 7463],
         [ 1546],
         [  278],
         [29947],
         [  322],
         [ 8286],
         [  322],
         [  278],
         [ 2911],
         [29915],
         [ 1799],
         [29889],
         [  739],
         [13304],
         [  338],
         [  297],
         [  278],
         [ 6152],
         [29871],
         [  338],
         [  278],
         [ 2324],
         [  313],
         [29889],
         [  739],
         [ 5067],
         [  338],
         [  367],
         [  278],
         [  856],
         [ 6152],
         [29899],
         [ 1495],
         [   13],
         [   13],
         [29924],
         [  338],
         [18129],
         [18129],
         [16171],
         [29973],
         [ 6438],
         [18129],
         [ 6143],
         [ 6438],
         [ 6152],
         [29973],
         [29973],
         [   13],
         [  366],
         [ 5649],
         [  278],
         [ 1546],
         [  278],
         [24301],
         [29892],
         [29973],
         [   13],
         [   13],
         [29924],
         [  292],
         [ 2129],
         [   13],
         [   13],
         [29930],
         [ 6021],
         [  487],
         [   13],
         [  278],
         [  310],
         [29899],
         [  671],
         [   13],
         [  508],
         [  297],
         [  773],
         [  263],
         [ 1856],
         [ 2280],
         [29889],
         [   13],
         [  526],
         [  526],
         [  278],
         [ 9493],
         [19488],
         [12084],
         [  310],
         [ 6438],
         [ 6438],
         [ 6152],
         [29889],
         [ 1315],
         [29889],
         [  278],
         [ 1856],
         [24301],
         [29889],
         [29889],
         [   13],
         [21846],
         [ 2969],
         [  338],
         [  393],
         [ 4477],
         [29901],
         [   13],
         [   13],
         [29896],
         [ 6152],
         [  338],
         [  338],
         [18654],
         [29879],
         [ 3870],
         [29897],
         [   13],
         [ 6438],
         [24301],
         [ 2087],
         [ 6438],
         [ 5688],
         [10309],
         [ 7649],
         [ 7230],
         [   13],
         [   13],
         [ 1576],
         [29901],
         [  278],
         [ 6152],
         [ 3740],
         [ 1315],
         [  914],
         [29889],
         [  278],
         [11258],
         [29973],
         [   13],
         [   13],
         [18654],
         [  292],
         [   13],
         [17918],
         [  304],
         [  263],
         [ 6438],
         [  322],
         [   13],
         [   13],
         [ 4205],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 2577],
         [ 3030],
         [  310],
         [ 3030],
         [ 3030],
         [ 3030],
         [29879],
         [29889],
         [  278],
         [ 4714],
         [ 4714],
         [29889],
         [   13],
         [   13],
         [ 2577],
         [  598],
         [   13],
         [   13],
         [   13],
         [ 2577],
         [14835],
         [  310],
         [  599],
         [ 3625],
         [10340],
         [  297],
         [  278],
         [ 3030],
         [29889],
         [   13],
         [   13],
         [ 2577],
         [ 7562],
         [   13],
         [   13],
         [ 2577],
         [ 2752],
         [  363],
         [  363],
         [ 7020],
         [29897],
         [  363],
         [ 2183],
         [14835],
         [ 5190],
         [29889],
         [   13],
         [   13],
         [ 2577],
         [28301],
         [ 3149],
         [   13],
         [   13],
         [ 2697],
         [ 2867],
         [ 2867],
         [ 3149],
         [  297],
         [  278],
         [ 2752],
         [ 5190],
         [29889],
         [   13],
         [   13],
         [ 2577],
         [  338],
         [ 2867],
         [  310],
         [ 2867],
         [10340],
         [ 5304],
         [ 6087],
         [29973],
         [   13],
         [   13],
         [ 2577],
         [  338],
         [  278],
         [ 2752],
         [  393],
         [14035],
         [  393],
         [  338],
         [  304],
         [  679],
         [  278],
         [14835],
         [10340],
         [29973],
         [   13]]], device='cuda:0')
torch.Size([2, 306, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  297,   310,   373,  ...,   322,   526,  4368],
         [  278,   263,   777,  ...,   341,   317,   405],
         ...,
         [    1, 29873, 29879,  ..., 29908, 29881, 29915],
         [    1, 29873, 29879,  ..., 29915, 29908,   856],
         [    1, 29873, 29879,  ...,   645,   856, 29908]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 1003, 13129,   279,  ..., 14795, 29899,  2817],
         [29871,   338,   365,  ...,   363,   756,   448],
         ...,
         [10340,  5190,   443,  ...,  2525,  3030, 29914],
         [29973,   363,   297,  ...,   393,   310,   472],
         [   13,   313,  1317,  ...,  5618,  5328,  3624]]], device='cuda:0')
Batch 44, 82.5% of total tokens
encoded shape: torch.Size([2, 511])
torch.Size([2, 511]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,  1005,  6324,  ...,   278,  5434, 29889]], device='cuda:0')
torch.Size([2, 511, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.8672, -10.6562,  -3.0020,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5391,  -1.5020,  ...,  -7.1484,  -8.3359,  -5.6523],
         ...,
         [ -8.4062,   3.8691,   5.2344,  ...,  -2.9258,  -4.5742,  -0.7622],
         [ -8.5391,   3.7012,   5.4141,  ...,  -3.0137,  -4.7266,  -0.9375],
         [ -8.5156,   3.5059,   5.5586,  ...,  -3.0273,  -4.7812,  -1.0869]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5312,  -5.6797,  -0.1543,  ...,  -5.2188,  -5.5859,  -6.0547],
         [ -9.8906, -12.8438,   0.7651,  ...,  -6.6328,  -8.8438,  -6.3594],
         ...,
         [ -4.7773,  -7.7852,   6.5742,  ...,  -0.6455,   0.5737,  -0.7446],
         [ -0.8018,   0.3254,  15.0312,  ...,  -1.1133,  -0.7021,  -1.5020],
         [ -3.1406,  -5.6289,  18.0469,  ...,  -0.0861,  -1.1416,  -1.8662]]],
       device='cuda:0')
torch.Size([2, 511, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29901],
         [  407],
         ...,
         [ 5434],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 511, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13, 29966,    12,  ...,  1576, 29949,  1678],
         [   13, 29966,    12,  ...,  4345, 29949,  1678],
         [   13, 29966,     3,  ...,  4345,  6224,  1678]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29901,   476,   360,  ...,   390,   365,   350],
         [  407,  9759, 17344,  ...,  1131, 18800,   495],
         ...,
         [ 5434, 24899,  4444,  ...,   478, 18070,  1206],
         [29889, 29892,   322,  ...,    13,   411,   773],
         [   13,     2, 14187,  ...,   512,  8725,   341]]], device='cuda:0')
Batch 45, 83.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  1346, 29933,  ...,   322,   916,  7875],
        [    1, 13329,  1818,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.8750,  -7.4531,   1.0586,  ...,  -3.0820,  -3.9707,  -2.0684],
         [ -8.7656, -10.1797,  -1.2490,  ...,  -2.7910,  -7.1133,  -6.1406],
         ...,
         [ -7.8320, -12.0625,   1.8193,  ...,  -4.1758,  -5.4023,  -6.8711],
         [ -7.4609,  -6.3711,   3.1426,  ...,  -5.2617,  -5.4414,  -5.7109],
         [ -4.3672,  -4.2383,   7.8398,  ...,  -2.7891,  -2.4492,  -3.3184]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.1719, -10.3281,  -0.7686,  ...,  -6.3711,  -6.6758,  -5.7148],
         [ -5.6953,  -4.2617,   5.7617,  ...,  -1.4258,  -1.1475,  -1.2314],
         ...,
         [ -6.8008,   7.2500,   4.1328,  ...,  -2.6426,  -4.3086,  -1.9521],
         [ -6.8047,   7.8242,   4.3438,  ...,  -2.6152,  -4.3984,  -1.8379],
         [ -6.7422,   8.4219,   4.4648,  ...,  -2.5781,  -4.4727,  -1.7080]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[ 917],
         [1576],
         [5658],
         ...,
         [1487],
         [3942],
         [ 297]],

        [[ 917],
         [ 338],
         [ 367],
         ...,
         [   1],
         [   1],
         [   1]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1576, 29902,  4806,  ...,  4013, 29924, 29950],
         [ 5658, 19036,  1032,  ...,   768, 10798,  1463],
         ...,
         [ 1487,   916,  4595,  ...,   278,  3196,   777],
         [ 3942, 14576,  7875,  ..., 18012, 18085,  1532],
         [  297,   322, 29889,  ...,   373,   304, 10534]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  338, 29871,   297,  ...,  7259,  4523, 29915],
         [  367, 29899,   505,  ...,   451,  6963,   538],
         ...,
         [    1,    13,     3,  ..., 30166, 29909, 29954],
         [    1,    13,     3,  ..., 29954, 30166, 29943],
         [    1,    13, 29903,  ..., 29909, 30166, 30191]]], device='cuda:0')
Batch 46, 88.3% of total tokens
encoded shape: torch.Size([2, 1189])
torch.Size([2, 1189]) tensor([[    1,   450,  3863,  ...,   996, 26461,    13],
        [    1,  1858,   403,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1189, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [-13.5078, -11.7266,  -6.9727,  ...,  -9.1484, -10.2422,  -8.5703],
         [ -8.6797,  -6.6562,   1.6006,  ...,  -3.0020,  -5.3906,  -4.5820],
         ...,
         [ -8.2031,  -7.7109,   4.4883,  ...,  -5.1367,  -5.2578,  -4.6055],
         [ -8.1250,  -8.9297,   6.4844,  ...,  -3.5020,  -4.9688,  -3.3047],
         [ -6.7266,  -5.3047,   3.9180,  ...,   1.2910,  -2.3789,  -1.5049]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [ -5.3359,  -1.0078,   3.2871,  ...,  -0.5527,  -0.3779,   0.7256],
         [-13.1797, -13.5547,  -3.9785,  ...,  -6.3672, -11.1016,  -9.2578],
         ...,
         [ -8.1172,   3.4102,   3.1367,  ...,  -2.8789,  -4.3203,  -2.6230],
         [ -7.9336,   3.2227,   3.0000,  ...,  -2.8418,  -4.2695,  -2.6406],
         [ -7.8359,   3.0312,   2.9004,  ...,  -2.8340,  -4.2539,  -2.6719]]],
       device='cuda:0')
torch.Size([2, 1189, 1]) tensor([[[  917],
         [29871],
         [  943],
         ...,
         [29999],
         [29999],
         [ 1576]],

        [[  917],
         [ 9450],
         [29871],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1189, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   937,  1494,  ...,   341,   349,  1900],
         [  943,   519,   310,  ...,  2826,   674,   601],
         ...,
         [29999, 29899, 29979,  ...,  4056, 17599, 25675],
         [29999, 24625,   796,  ..., 29956,   574, 29990],
         [ 1576, 29909, 29930,  ..., 29896,  4013,  4806]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 9450,   550,  6288,  ...,   688,  6478,   403],
         [29871,  1026,   585,  ..., 29899, 29901, 29892],
         ...,
         [    3,    13, 29949,  ..., 29902, 30212, 29909],
         [    3,    13, 29949,  ..., 29902, 30212,  9137],
         [    3,    13,    12,  ..., 30212, 29902,  9137]]], device='cuda:0')
Batch 47, 89.7% of total tokens
encoded shape: torch.Size([2, 3580])
torch.Size([2, 3580]) tensor([[    1,  2379, 29884,  ...,     2,     2,     2],
        [    1, 23146,  1944,  ...,   278,  7021,  7765]], device='cuda:0')
torch.Size([2, 3580, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.0625,  -9.3203,  -1.1035,  ...,  -4.0586,  -4.6211,  -3.7891],
         [-11.5703, -13.7344,  -1.5547,  ...,  -8.0859,  -6.8555,  -6.0781],
         ...,
         [-10.6016,   3.6816,   1.6914,  ...,  -5.1758,  -6.5742,  -5.3086],
         [-10.5000,   3.6309,   1.7500,  ...,  -5.0859,  -6.4453,  -5.2070],
         [-10.3281,   3.5273,   1.7578,  ...,  -5.0273,  -6.3594,  -5.1328]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7891, -14.5781,  -1.9004,  ...,  -8.9844,  -8.3047,  -9.0000],
         [-13.6094, -14.8984,  -0.2717,  ...,  -6.2227, -10.4922,  -8.7266],
         ...,
         [ -6.2930,  -7.7109,   4.9570,  ...,  -2.1016,  -5.2461,  -2.6270],
         [ -4.3164,  -5.4180,   7.1328,  ...,  -2.6797,  -1.5469,  -1.9434],
         [ -0.3438,   3.0762,  19.2500,  ...,  -3.4336,  -2.6758,  -2.2344]]],
       device='cuda:0')
torch.Size([2, 3580, 1]) tensor([[[  917],
         [ 5861],
         [ 2361],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [29877],
         [29892],
         ...,
         [ 7021],
         [ 7765],
         [   13]]], device='cuda:0')
torch.Size([2, 3580, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 5861,   523,   271,  ...,   420,  1280,   473],
         [ 2361,   272,   446,  ...,   478,  1383,  3819],
         ...,
         [    3, 29949,    13,  ..., 29911, 29924,    12],
         [    3, 29949,    13,  ..., 29911, 29924,    12],
         [    3, 29949,    13,  ...,    12, 29911, 29924]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29877,  1005,  6639,  ...,  9516, 29915,   350],
         [29892,   310,   313,  ..., 29915,   448, 30010],
         ...,
         [ 7021,  7765,  3082,  ...,  4831, 28218, 10637],
         [ 7765, 27348,  1879,  ..., 12601,  8907, 28218],
         [   13,   313,     2,  ..., 29943, 29896,   363]]], device='cuda:0')
Batch 48, 93.6% of total tokens
encoded shape: torch.Size([2, 661])
torch.Size([2, 661]) tensor([[    1,   660, 29901,  ...,  1961,    13,    13],
        [    1,  1317,   324,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 661, 32000]) tensor([[[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-10.8672, -10.6484,  -2.9961,  ...,  -6.8203, -10.0938,  -6.8672],
         [-13.6250, -13.5312,  -1.5088,  ...,  -7.1523,  -8.3359,  -5.6523],
         ...,
         [  0.2607,  -0.2822,  16.0312,  ...,  -3.2734,   0.0190,  -1.4863],
         [ -6.6016,  -5.1445,  11.5469,  ...,  -6.3516,  -4.5508,  -3.0684],
         [ -9.0625, -10.1406,   5.0859,  ...,  -6.2852,  -5.2227,  -3.0254]],

        [[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-13.8438, -15.2188,  -4.2812,  ...,  -6.0586,  -8.1250,  -7.8477],
         [ -9.0078,  -6.8672,  -0.6694,  ...,  -5.8438,  -6.5977,  -6.8359],
         ...,
         [ -9.2891,   1.7783,   3.5801,  ...,  -2.4141,  -4.5859,  -2.2031],
         [ -9.2891,   1.8018,   3.6230,  ...,  -2.3750,  -4.5391,  -2.1348],
         [ -9.2734,   1.8535,   3.6758,  ...,  -2.3438,  -4.5000,  -2.0840]]],
       device='cuda:0')
torch.Size([2, 661, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         ...,
         [29889],
         [   13],
         [20001]],

        [[  917],
         [  727],
         [  630],
         ...,
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 661, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [29889,    13,   322,  ...,   869,   297,     2],
         [   13,   392,     2,  ..., 29905,   272,  3644],
         [20001, 22550, 29905,  ...,  2248,  3492,  3644]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  727,   372,   278,  ...,  3575,  1670,   450],
         [  630,  1218,   311,  ...,  4097,  1314,  1490],
         ...,
         [   13, 30166,  1576,  ..., 29903,  8999,  4345],
         [   13,  1576, 30166,  ..., 29903,  8999,  4345],
         [   13,  1576, 30166,  ..., 29903,  4345,  8999]]], device='cuda:0')
Batch 49, 94.7% of total tokens
encoded shape: torch.Size([2, 339])
torch.Size([2, 339]) tensor([[    1,   660, 29901,    13,    13,  1123,  2055,  2760,  5449,  1535,
           363,  4969,   383,  7168,   341,   326,   860,   292,  3371,  4542,
          2363,    13,    13,  3624,   727,   263,  1426,  2909,   393,  3743,
           278,  2362,  1199,   363,  4969,   383,  7168,   341,   326,   860,
           292,  3371,  4542,  2363, 29973,  8512,   727,   338,   263,  3287,
           310, 23533, 29899, 27828,   287, 12845,   373,   445, 29892,   306,
          2609,  1284,  1426, 12733,   373,  1094,   842,  1588, 18499,   393,
          5649,   297,   376, 24595,  3838, 29908,   920,   304,  1653,   383,
          7168,   341,   326,   860,   292,  3371,  4542,  2363, 29889,    13,
            13, 29909, 29901,    13,    13,  6572,  4349,  1781,  8252,   338,
           297,  9234,   267,   261,   315,  4519, 29301,  8695,   363,   315,
          4519,  3233,  4786, 29889, 13730, 29871, 29941,   322, 29871, 29945,
         29892,   472,  3203,   515, 29871, 29906, 29900, 29900, 29929, 29892,
           565,   306,  6456,  1492, 29889,  2823,   884, 19089,   388,   390,
         29889, 29903, 29889, 24352,   310,  4231,   273,  1455,  5974, 10488,
           313, 29956, 15168, 10488,   297,  1019, 29890,  3097,   322, 27098,
           467,   849, 29871, 29906, 29900, 29896, 29900, 29889, 29871,   448,
          1781,  1342,   411,  5314,   297,   390, 29889,    13,    13,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1, 28771,  3631,  7117,   310, 21762, 29899, 29872,  8192, 29885,
           324, 18853,   363,   967,  3104,  7268,  1218,  2779,   373,  8348,
           262,  2904,   305, 26496, 29899, 19910,  1133, 26808,   290,   375,
         16637,  2908,  1943,   297,   286,   625, 29889,    13,  3571, 29899,
         29923,  8192, 29885,   324, 29892,   263,  3999,   339,  1524,  2238,
          3398, 27231,  5391, 23968,   515,  2180,  1461,  2904,  2631, 28905,
         29874, 18178,   466,  4125, 29892,  3104,  7268,  1078,   278, 26808,
           290,   375, 16637, 23473,  2779,   310,  8348,   262,  2904,   305,
         26496,   313,  5091,  1451,   467,   450,  3104,  7268,  1218,  2779,
           338,  7621,   297,   652,   370,  7492,  2301,  7799,  1135,   297,
          4226,  6743, 29889,  1763, 12439,   278,  2281,  3631,  7117,   310,
         21762, 29899, 29872,  8192, 29885,   324, 17737, 17068,   304,   445,
          3158, 29892,   591,  4392,  1312,   278,  3104,  7268,  1218,  2779,
           310, 15141, 14710,   267,  1891,   260,   814, 29875,   653, 27231,
         29882,  3775,  4475,   304, 21762, 29899, 29872,  8192, 29885,   324,
           297, 12216,   264,   293,   302,  7143, 29899, 15321,   561,  1431,
         29885,  2301,  2841, 10223,   800,   310,  4226,   322, 25169, 29916,
           273, 29899,  6051,   370,  7492,   286,   625, 29889, 10173,  7268,
          1218,  9545,   892, 10371,  1573,   491,  5094, 15126, 20970,  2904,
           333,  1600, 25748,   541,   451,   491,  5094, 15126, 20970,   273,
           650,   470,  5094, 15126, 20970,   273,   324, 25748, 29889,   450,
           752,   618, 29871, 29906, 17722, 29941, 29899, 29882, 11279,  3594,
         29899, 29941, 29899, 29885,   621,  2904,  4187,  2904, 29897,  8798,
           417, 20970,  2904,   333,  1600, 10371,  1573,   263,  3104,  7268,
          1218,  2779, 29892,   541, 29871, 29941, 17722, 29941, 29899, 29882,
         11279,  3594, 29899, 29941, 29899, 29885,   621,  2904,  4187,  2904,
         29897,  8798,   417, 20970,  2904,   333,  1600,  1258,   451, 29889,
          4525,  2582, 12266,   393,  1716,   278, 10122,   310,   385,   429,
         29877, 29899, 29885,   621,  2904,  1600, 10959,   304,   263,  5094,
         15126, 20970,  1662,  9228,   322,   278,  5418,  1546,   278,   429,
         29877, 29899, 29885,   621,  2904,  1600,   322,   278, 17546,  3594,
          2318,   297, 21762, 29899, 29872,  8192, 29885,   324,   526,  9701,
           297,   278,  3104,  7268,  1218,  2779,   373,  2166,  1451, 29899,
         19910,  1133, 26808,   290,   375, 16637,  2908,  1943, 29889]],
       device='cuda:0')
torch.Size([2, 339, 32000]) tensor([[[-1.2828e+01, -7.3945e+00, -4.6899e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5000e+00],
         [-1.0867e+01, -1.0656e+01, -2.9961e+00,  ..., -6.8203e+00,
          -1.0102e+01, -6.8672e+00],
         [-1.3625e+01, -1.3539e+01, -1.5010e+00,  ..., -7.1484e+00,
          -8.3359e+00, -5.6484e+00],
         ...,
         [-8.0156e+00,  3.1719e+00,  3.9531e+00,  ..., -1.9023e+00,
          -3.6504e+00, -1.1375e-02],
         [-7.9805e+00,  3.2441e+00,  4.0664e+00,  ..., -1.8711e+00,
          -3.6172e+00,  3.6896e-02],
         [-8.0000e+00,  3.2520e+00,  4.1758e+00,  ..., -1.9004e+00,
          -3.6797e+00, -1.4839e-02]],

        [[-1.2828e+01, -7.3945e+00, -4.6899e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5000e+00],
         [-1.1406e+01, -9.0781e+00, -1.9336e+00,  ..., -6.6289e+00,
          -7.7188e+00, -5.5117e+00],
         [-5.8008e+00, -8.5156e+00,  1.7012e+00,  ..., -5.3242e+00,
          -7.5039e+00, -4.1328e+00],
         ...,
         [-7.0068e-01,  1.0010e+00,  1.2734e+01,  ...,  7.9639e-01,
          -9.9170e-01,  1.4709e-01],
         [-2.2324e+00,  3.7207e-01,  1.3578e+01,  ..., -2.5312e+00,
          -1.5342e+00, -2.3105e+00],
         [-5.2773e+00, -6.7930e+00,  1.6656e+01,  ..., -1.6602e+00,
          -3.6621e+00, -1.9111e+00]]], device='cuda:0')
torch.Size([2, 339, 1]) tensor([[[  917],
         [29901],
         [ 1724],
         [29902],
         [ 5618],
         [  571],
         [ 2760],
         [  491],
         [ 1535],
         [   13],
         [  278],
         [  263],
         [ 2506],
         [  616],
         [ 2631],
         [  860],
         [  292],
         [   13],
         [ 4542],
         [ 2363],
         [   13],
         [   13],
         [ 2277],
         [  727],
         [  738],
         [ 1051],
         [ 2909],
         [  470],
         [18469],
         [  263],
         [19475],
         [ 1199],
         [  310],
         [ 4969],
         [  383],
         [ 7168],
         [  341],
         [  326],
         [  860],
         [  292],
         [ 3371],
         [ 4542],
         [ 2363],
         [29973],
         [   13],
         [  306],
         [  526],
         [  263],
         [ 3287],
         [  310],
         [12845],
         [29899],
         [27828],
         [  287],
         [12845],
         [  373],
         [  278],
         [11261],
         [  306],
         [  626],
         [ 1284],
         [  263],
         [12733],
         [  393],
         [  445],
         [  842],
         [  838],
         [18499],
         [24134],
         [ 4612],
         [  278],
         [ 9493],
         [24595],
         [ 4223],
         [29908],
         [  920],
         [  304],
         [ 1653],
         [  383],
         [ 7168],
         [  341],
         [  326],
         [  860],
         [  292],
         [ 3371],
         [ 4542],
         [ 2363],
         [29889],
         [   13],
         [   13],
         [22550],
         [29901],
         [   13],
         [   13],
         [29902],
         [ 4349],
         [ 1568],
         [ 1234],
         [  310],
         [  297],
         [  278],
         [  442],
         [  261],
         [29915],
         [ 4519],
         [21597],
         [16886],
         [29889],
         [21597],
         [ 4519],
         [21597],
         [29871],
         [29889],
         [   13],
         [  491],
         [29896],
         [  322],
         [29871],
         [29946],
         [29889],
         [  306],
         [ 3203],
         [29889],
         [  825],
         [29906],
         [29900],
         [29896],
         [29929],
         [12203],
         [  505],
         [  306],
         [ 6456],
         [ 5149],
         [29889],
         [   13],
         [  884],
         [  278],
         [  388],
         [29915],
         [ 3873],
         [  313],
         [29889],
         [  313],
         [  310],
         [ 4231],
         [  273],
         [ 1455],
         [ 3630],
         [10488],
         [29892],
         [29906],
         [15168],
         [29892],
         [  297],
         [ 4231],
         [29890],
         [ 3097],
         [  322],
         [27098],
         [29897],
         [   13],
         [   13],
         [29906],
         [29900],
         [29900],
         [29900],
         [29889],
         [   13],
         [   13],
         [  445],
         [ 3143],
         [  310],
         [  390],
         [  310],
         [  390],
         [29889],
         [   13],
         [   13],
         [20001],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [   13],
         [30488],
         [30488],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [29937],
         [29937],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [ 3631],
         [  322],
         [  310],
         [  278],
         [29899],
         [  433],
         [  566],
         [29885],
         [  324],
         [  322],
         [17182],
         [  967],
         [ 3677],
         [  296],
         [  362],
         [ 2779],
         [  373],
         [  278],
         [16976],
         [ 2904],
         [  305],
         [26496],
         [29899],
         [19910],
         [ 1133],
         [26808],
         [  290],
         [  375],
         [16637],
         [ 2908],
         [ 1943],
         [29889],
         [  364],
         [  625],
         [29889],
         [   13],
         [ 1576],
         [29899],
         [29923],
         [ 8192],
         [29885],
         [  324],
         [  338],
         [  263],
         [ 3999],
         [  339],
         [ 1524],
         [29886],
         [ 3398],
         [23968],
         [ 5391],
         [23968],
         [  515],
         [  278],
         [ 1461],
         [ 2904],
         [ 2631],
         [28905],
         [29874],
         [29892],
         [  466],
         [  608],
         [29892],
         [  756],
         [ 7268],
         [ 1078],
         [ 8348],
         [26808],
         [  290],
         [  375],
         [16637],
         [23473],
         [ 2779],
         [  310],
         [ 8348],
         [  262],
         [ 2904],
         [  305],
         [26496],
         [  297],
         [29903],
         [  617],
         [29897],
         [  450],
         [ 2198],
         [ 7268],
         [ 1218],
         [ 2779],
         [  310],
         [  451],
         [  297],
         [  286],
         [  370],
         [ 7492],
         [  286],
         [ 7799],
         [ 1135],
         [  297],
         [ 4226],
         [ 2301],
         [29889],
         [  450],
         [  560],
         [  278],
         [ 2281],
         [ 3631],
         [ 7117],
         [  310],
         [21762],
         [29899],
         [29872],
         [ 8192],
         [29885],
         [  324],
         [14040],
         [17068],
         [  304],
         [  278],
         [ 3104],
         [29892],
         [  591],
         [14710],
         [ 1312],
         [  278],
         [ 9545],
         [ 7268],
         [ 1218],
         [ 2779],
         [  310],
         [21762],
         [14710],
         [  267],
         [ 1891],
         [21762],
         [  300],
         [29875],
         [  653],
         [27231],
         [29882],
         [ 3775],
         [  322],
         [  304],
         [21762],
         [29899],
         [29872],
         [ 8192],
         [29885],
         [  324],
         [29889],
         [  286],
         [  264],
         [  293],
         [  302],
         [ 7143],
         [29899],
         [15321],
         [  561],
         [ 1431],
         [29885],
         [10223],
         [ 2841],
         [10223],
         [  800],
         [  310],
         [  286],
         [  322],
         [  652],
         [29916],
         [  273],
         [29899],
         [ 6051],
         [  370],
         [ 7492],
         [  286],
         [  625],
         [29889],
         [  450],
         [ 7268],
         [  362],
         [ 9545],
         [  892],
         [ 8900],
         [ 1573],
         [  491],
         [29871],
         [15126],
         [20970],
         [ 2904],
         [29892],
         [ 1600],
         [29892],
         [  310],
         [  451],
         [  491],
         [  278],
         [15126],
         [20970],
         [ 2904],
         [  324],
         [25748],
         [ 5094],
         [15126],
         [20970],
         [  273],
         [  324],
         [25748],
         [29889],
         [  450],
         [ 3104],
         [ 3885],
         [29871],
         [29896],
         [29892],
         [29906],
         [29899],
         [ 8798],
         [11279],
         [ 3594],
         [ 8798],
         [29946],
         [29899],
         [29885],
         [  621],
         [ 2904],
         [ 4187],
         [ 2904],
         [ 6817],
         [ 8798],
         [  417],
         [20970],
         [ 2904],
         [  333],
         [ 1600],
         [29899],
         [ 1573],
         [  278],
         [ 3104],
         [ 7268],
         [ 1218],
         [ 2779],
         [  297],
         [  607],
         [  278],
         [29906],
         [29899],
         [29941],
         [29899],
         [29882],
         [11279],
         [ 3594],
         [29899],
         [29941],
         [29899],
         [29885],
         [  621],
         [ 2904],
         [ 4187],
         [ 2904],
         [29897],
         [ 8798],
         [  417],
         [20970],
         [ 2904],
         [  333],
         [ 1600],
         [ 1258],
         [  451],
         [29889],
         [  450],
         [ 2582],
         [ 4368],
         [  393],
         [  278],
         [  278],
         [17546],
         [  310],
         [  263],
         [27231],
         [  542],
         [29899],
         [29885],
         [  621],
         [ 2904],
         [ 2318],
         [ 2318],
         [  304],
         [  278],
         [29871],
         [15126],
         [20970],
         [ 2904],
         [ 9228],
         [  322],
         [  278],
         [10122],
         [ 1546],
         [  278],
         [  286],
         [29877],
         [29899],
         [29885],
         [  621],
         [ 2904],
         [ 1600],
         [  322],
         [  278],
         [ 5094],
         [29916],
         [ 2318],
         [  526],
         [  278],
         [29899],
         [29872],
         [ 8192],
         [29885],
         [  324],
         [  526],
         [ 4100],
         [  297],
         [  278],
         [ 3104],
         [ 7268],
         [ 1218],
         [ 2779],
         [29889],
         [ 2166],
         [ 1451],
         [29899],
         [19910],
         [ 1133],
         [26808],
         [  290],
         [  375],
         [16637],
         [ 2908],
         [ 1943],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 339, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29901, 29889, 29987,  ...,   669,  3120, 29899],
         [ 1724,  1128,   306,  ...,  1619,  1932,  4683],
         ...,
         [   13, 29966, 29871,  ..., 29912,  1678,  1576],
         [   13, 29966, 29871,  ..., 29912,  1678,  1576],
         [   13, 29966, 29871,  ..., 29912,  1678,  1576]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 3631,  2955,  1973,  ..., 29879, 29877, 29884],
         [  322, 22557,  7418,  ...,  3457, 29892, 21184],
         ...,
         [ 1943, 29889,   482,  ...,   472,   310,   373],
         [29889,   297, 29892,  ..., 29936,   472, 14030],
         [   13,     2,   450,  ...,   313, 12808,  1334]]], device='cuda:0')
Batch 50, 95.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 27576,    13,  ...,  3148, 20282, 29953],
        [    1,   632,  3303,  ..., 29892, 29871, 29906]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-1.2250e+01, -5.8711e+00,  2.6779e-02,  ..., -7.5742e+00,
          -9.0000e+00, -7.3203e+00],
         [-1.1281e+01, -7.0234e+00,  2.4902e+00,  ..., -5.0156e+00,
          -6.4375e+00, -3.5586e+00],
         ...,
         [-1.0967e+00,  2.3867e+00,  8.0625e+00,  ...,  1.2900e+00,
           2.5117e+00,  2.9023e+00],
         [-4.9961e+00, -2.6191e+00,  5.6367e+00,  ..., -5.2783e-01,
          -2.6406e+00, -8.6084e-01],
         [-3.1299e-01,  3.4336e+00,  8.2734e+00,  ...,  1.0628e-04,
          -2.0039e+00,  4.5654e-01]],

        [[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-9.3281e+00, -5.7227e+00,  2.4219e-01,  ..., -3.7656e+00,
          -6.6758e+00, -4.5781e+00],
         [-1.1727e+01, -8.0703e+00, -3.6719e-01,  ..., -6.8594e+00,
          -6.6211e+00, -7.5430e+00],
         ...,
         [-1.0410e+00, -6.0742e-01,  7.4648e+00,  ..., -7.9541e-01,
           3.3320e+00, -1.7590e-01],
         [-4.0742e+00, -4.9375e+00,  6.1172e+00,  ..., -8.3887e-01,
          -2.0957e+00, -1.9688e+00],
         [-5.5312e+00, -6.5156e+00,  5.9453e+00,  ..., -3.9746e+00,
          -3.5059e+00, -4.2109e+00]]], device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [  304],
         [ 1576],
         ...,
         [29938],
         [29896],
         [29889]],

        [[  917],
         [  529],
         [ 3900],
         ...,
         [29871],
         [29906],
         [29900]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  304, 29901,   491,  ...,   450,   448, 29889],
         [ 1576,    13,   797,  ..., 29924, 29931,  2887],
         ...,
         [29938, 29928,   395,  ..., 17208,  4535,  1504],
         [29896, 29906, 29945,  ..., 29955, 29947, 29871],
         [29889, 29900,   363,  ...,   639,   297, 29945]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  529,    13,  1533,  ...,   722,   313,   565],
         [ 3900, 12626, 18269,  ..., 29918,  5922, 29871],
         ...,
         [29871,  1939,   269,  ...,  4770,   418, 13159],
         [29906, 29896, 29929,  ..., 29953, 29945, 29900],
         [29900, 29929, 29947,  ..., 29946, 29941, 29945]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 661])
torch.Size([2, 661]) tensor([[    1, 20626, 21867,  ...,     2,     2,     2],
        [    1, 25422, 11001,  ..., 21850,  7993, 10769]], device='cuda:0')
torch.Size([2, 661, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -7.1953,  -8.5469,  -7.1797,  ...,  -3.0293,  -3.0605,  -2.9395],
         [-10.1562, -12.7734,  -8.0234,  ...,  -5.3477,  -8.6562,  -7.9688],
         ...,
         [ -3.9473,   4.6719,  -1.3379,  ...,  -0.4175,   1.0645,  -0.1310],
         [ -3.9082,   4.3242,  -1.3721,  ...,  -0.3989,   1.0469,  -0.1873],
         [ -3.9980,   4.0664,  -1.4219,  ...,  -0.4336,   0.9717,  -0.2671]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -9.4219, -13.4922,  -4.3867,  ...,  -5.5586,  -4.7227,  -7.6055],
         [ -5.4727,   3.2715,  -0.6665,  ...,  -1.8828,   1.1211,  -0.1166],
         ...,
         [ -1.8457,  -1.4043,   1.8105,  ...,   0.0829,   2.9766,   0.8105],
         [ -1.2666,  -1.3330,   0.7051,  ...,   0.4390,   1.6475,  -0.7393],
         [ -1.6699,  -0.3274,  10.6719,  ...,  -1.8115,   0.5469,  -2.3809]]],
       device='cuda:0')
torch.Size([2, 661, 1]) tensor([[[29892],
         [  311],
         [25348],
         ...,
         [    1],
         [    1],
         [23196]],

        [[29892],
         [  435],
         [ 2774],
         ...,
         [ 7993],
         [10769],
         [   13]]], device='cuda:0')
torch.Size([2, 661, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  311, 21867, 28253,  ..., 29881,   485, 29878],
         [25348,  9358,   286,  ...,   423,  4603,  1301],
         ...,
         [    1, 23196, 26077,  ...,  8629, 18627, 31779],
         [    1, 23196, 26077,  ..., 18627,  8629, 14332],
         [23196,     1, 26077,  ..., 18627, 14332,  8629]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  435, 11447,   319,  ...,   365,   322,   399],
         [ 2774,   275,   575,  ...,   790,  1144,   708],
         ...,
         [ 7993,  5165, 29254,  ..., 15477, 26077, 23196],
         [10769, 18195, 23196,  ..., 13454, 18627, 17492],
         [   13,     2, 17943,  ...,  6733,   310, 30131]]], device='cuda:0')
Batch 1, 1.1% of total tokens
encoded shape: torch.Size([2, 544])
torch.Size([2, 544]) tensor([[    1, 25857,   315,  ...,     2,     2,     2],
        [    1,   313, 29896,  ...,  4340, 19356, 29889]], device='cuda:0')
torch.Size([2, 544, 32000]) tensor([[[ -8.0312,  -1.1484,  -0.5361,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -8.6406, -14.3125,  -5.5234,  ...,  -4.4023,  -7.5703,  -3.5078],
         [ -6.7617,  -8.4453,  -0.9272,  ...,  -4.8672,  -5.2422,  -5.7812],
         ...,
         [ -9.4844,   1.8271,   1.4297,  ...,  -5.6797,  -6.0742,  -3.9141],
         [ -9.1172,   1.9697,   1.4814,  ...,  -5.5156,  -5.8984,  -3.7383],
         [-11.0781,   0.7847,   0.9741,  ...,  -6.3867,  -6.8516,  -4.7734]],

        [[ -8.0312,  -1.1484,  -0.5361,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -9.2578, -13.0938,  -3.5566,  ...,  -3.5820,  -4.6992,  -3.5605],
         [ -9.3672, -10.3359,   0.3665,  ...,  -5.8906,  -8.0234,  -7.4883],
         ...,
         [ -3.9961,  -1.6787,   1.3691,  ...,  -3.3047,  -3.9023,  -2.8125],
         [ -3.9512,  -2.6445,   5.0859,  ...,  -2.5078,  -0.2844,  -2.6738],
         [ -5.1758,  -5.2734,   3.4316,  ...,  -0.6777,   0.0234,  -4.5547]]],
       device='cuda:0')
torch.Size([2, 544, 1]) tensor([[[29892],
         [  652],
         [ 2696],
         ...,
         [  450],
         [  450],
         [  450]],

        [[29892],
         [24735],
         [29929],
         ...,
         [30488],
         [  304],
         [   13]]], device='cuda:0')
torch.Size([2, 544, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  652, 12201,  5169,  ...,  5977,  6813, 10914],
         [ 2696, 27273,  1336,  ...,  1450,   616,   943],
         ...,
         [  450,    13, 29871,  ...,   306,   319,   278],
         [  450,    13, 29871,  ...,   306,   315,   448],
         [  450, 29871,    13,  ...,   315,   317,   399]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [24735, 29896, 29906,  ..., 29883, 30121, 29941],
         [29929, 29897, 29947,  ...,   310, 29955, 29953],
         ...,
         [30488, 30879, 29889,  ...,   313, 29899,   856],
         [  304, 29889,   491,  ...,   472,  2745,  1090],
         [   13,   450,  2398,  ...,  4525,   319,   501]]], device='cuda:0')
Batch 2, 1.9% of total tokens
encoded shape: torch.Size([2, 87])
torch.Size([2, 87]) tensor([[    1,   341,  9998,  4702,   333,   713, 13249, 29879,   448, 13548,
          3082, 11243,   537, 13249,   338,   385,  1722, 29899,   355,  5220,
         11039,   630,   297, 23812, 18041, 29889,   450, 13249, 29915, 29879,
         13258,   358, 12091,   338,  7483,  5108,   362, 29892, 17005,   297,
          3148,   360,  3028,  1503, 29889,   450, 13249,  2437,  9197, 19434,
           297,   263,  2011, 25648, 13548,  3082,  1592,   537,   409,  2764,
          1907, 29889,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2],
        [    1,   826,  4515,   264, 29892,   530,  2353,  3462,  4885, 29898,
         19203,   266,  6656, 29892,   450,  3014,   310,  2292,  1885, 29892,
         29871, 29906, 29900, 29896, 29900, 29899, 29900, 29946, 29899, 29896,
         29946, 29897,    13,    13,  1576,  2198,  6559, 18365,   304, 23033,
          4863,  3748,   788,  2463,  4249, 27990, 16157, 29879, 26552, 29871,
         29896, 29953, 29899, 29946, 29900,  2440, 29889, 13987,  3748,   788,
          2463,   756,   451,  3447,  1063,   770,  2164,   408,   263,   766,
          2098,   297,   278,   360, 17061,   470,   306,  6530,  6757, 29892,
           322,   967, 10379,   338,  2553,   630,  2023]], device='cuda:0')
torch.Size([2, 87, 32000]) tensor([[[ -8.0312,  -1.1104,  -0.5269,  ...,  -4.1836,  -5.6641,  -4.5781],
         [ -8.7812,  -6.9023,  -2.6348,  ...,  -6.4180,  -4.3125,  -7.3203],
         [-12.9766, -14.1875,  -9.5000,  ...,  -5.8203,  -8.9766,  -9.0938],
         ...,
         [-13.0000,  -7.4141,  -0.9873,  ...,  -4.6367,  -5.4922,  -4.1055],
         [ -6.7734,  -2.0312,  -0.1821,  ...,  -4.0820,  -4.3008,  -2.7734],
         [ -6.1055,  -1.9170,   0.1074,  ...,  -3.9395,  -4.2188,  -2.7227]],

        [[ -8.0312,  -1.1104,  -0.5269,  ...,  -4.1836,  -5.6641,  -4.5781],
         [ -7.5586,  -4.5391,  -2.5410,  ...,  -2.4824,  -4.3594,  -1.9014],
         [-10.9219, -12.3906,  -7.8203,  ...,  -8.4375,  -5.6211,  -9.4453],
         ...,
         [ -2.9492,  -0.9482,   4.4258,  ...,   1.2275,  -0.1758,   2.4102],
         [ -5.9531,  -6.3867,   6.2031,  ...,  -0.8818,  -3.1016,  -4.1875],
         [ -1.0322,   2.2539,   4.8867,  ...,   1.3721,   2.0273,  -0.7163]]],
       device='cuda:0')
torch.Size([2, 87, 1]) tensor([[[29892],
         [ 5086],
         [29965],
         [29883],
         [  713],
         [18285],
         [29879],
         [  448],
         [ 4702],
         [ 6813],
         [ 7089],
         [  537],
         [13249],
         [ 4134],
         [  385],
         [ 1722],
         [29899],
         [  355],
         [ 5220],
         [11039],
         [  630],
         [  297],
         [  278],
         [18041],
         [29889],
         [  739],
         [13249],
         [29915],
         [30488],
         [30488],
         [30488],
         [30488],
         [  338],
         [  304],
         [ 5108],
         [  362],
         [29889],
         [  411],
         [  297],
         [ 3148],
         [17208],
         [26810],
         [ 1503],
         [29889],
         [  450],
         [13249],
         [ 1074],
         [ 9197],
         [  297],
         [  297],
         [  278],
         [30488],
         [30488],
         [  310],
         [ 3082],
         [10961],
         [ 1907],
         [  409],
         [ 2764],
         [ 1907],
         [29889],
         [  450],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [29871]],

        [[29892],
         [ 4881],
         [ 1609],
         [29892],
         [  435],
         [ 2028],
         [29889],
         [29889],
         [29892],
         [29896],
         [29879],
         [ 6656],
         [  847],
         [29871],
         [27990],
         [  310],
         [ 2292],
         [27279],
         [29897],
         [29871],
         [29906],
         [30488],
         [29896],
         [29900],
         [29897],
         [29900],
         [29945],
         [29899],
         [29906],
         [29945],
         [29897],
         [   13],
         [ 1576],
         [ 1576],
         [12242],
         [30488],
         [ 7405],
         [  304],
         [23033],
         [  278],
         [ 3748],
         [30488],
         [30488],
         [  297],
         [  263],
         [30488],
         [30488],
         [29889],
         [29871],
         [29896],
         [29947],
         [29899],
         [29953],
         [29900],
         [ 2440],
         [29889],
         [  450],
         [ 3748],
         [  313],
         [ 2463],
         [  338],
         [ 1063],
         [ 1063],
         [ 1063],
         [ 7405],
         [30488],
         [  408],
         [  263],
         [19119],
         [30488],
         [  297],
         [  278],
         [ 4623],
         [29889],
         [29899],
         [  306],
         [30488],
         [29892],
         [29892],
         [  541],
         [  278],
         [  758],
         [  338],
         [ 1603],
         [  630],
         [29889],
         [25145]]], device='cuda:0')
torch.Size([2, 87, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5086, 13415, 29902,  ...,  4992,  2190,  1541],
         [29965, 12002,   512,  ..., 29943,   338, 29899],
         ...,
         [ 1576, 29902, 29909,  ..., 11184, 29924, 29911],
         [29871, 29892, 29896,  ...,  1576, 29908,   450],
         [29871, 29892, 29899,  ..., 29909, 29908,   450]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 4881,   618,  5060,  ...,  2168, 15081,  1847],
         [ 1609, 29882, 29874,  ..., 29892, 29881, 29875],
         ...,
         [  630, 17219,   271,  ...,  2371,  1230,  2219],
         [29889,  4249,   297,  ...,  1716,  1546,  2836],
         [25145, 24366,  2664,  ...,  1303, 23795,   966]]], device='cuda:0')
Batch 3, 2.0% of total tokens
encoded shape: torch.Size([2, 835])
torch.Size([2, 835]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29889,    13,    13]], device='cuda:0')
torch.Size([2, 835, 32000]) tensor([[[ -8.0312,  -1.2578,  -0.5435,  ...,  -4.2266,  -5.7031,  -4.6328],
         [-10.7031, -11.7891,  -5.2344,  ...,  -6.0820,  -9.1328,  -6.8594],
         [-11.5078, -12.3672,  -3.2422,  ...,  -4.9961,  -5.4570,  -3.9492],
         ...,
         [ -1.9492,   5.2500,  -1.7998,  ...,   0.5371,   0.9839,   1.0186],
         [ -1.8623,   5.1367,  -1.7900,  ...,   0.6021,   1.0439,   1.0498],
         [ -1.8115,   5.0273,  -1.7939,  ...,   0.6362,   1.0791,   1.0615]],

        [[ -8.0312,  -1.2578,  -0.5435,  ...,  -4.2266,  -5.7031,  -4.6328],
         [-10.7031, -11.7891,  -5.2344,  ...,  -6.0820,  -9.1328,  -6.8594],
         [-11.5078, -12.3672,  -3.2422,  ...,  -4.9961,  -5.4570,  -3.9492],
         ...,
         [ -2.3086,  -4.7969,   8.5625,  ...,  -0.5620,  -0.5708,  -0.8535],
         [ -4.2461,  -3.2871,   9.0234,  ...,  -3.6309,  -2.0566,  -1.5615],
         [ -6.8594,  -8.8203,   2.0781,  ...,  -3.3496,  -1.8496,  -1.6855]]],
       device='cuda:0')
torch.Size([2, 835, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [14262],
         [14262],
         [14262]],

        [[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [29909]]], device='cuda:0')
torch.Size([2, 835, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,   306,  1128,  ...,  1932,  1317,   450],
         ...,
         [14262,  7228, 26077,  ..., 31779, 26502, 25528],
         [14262, 26077,  7228,  ..., 31779, 26502, 25528],
         [14262, 26077,  7228,  ..., 31779, 26502, 25528]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,   306,  1128,  ...,  1932,  1317,   450],
         ...,
         [   13, 29871,   960,  ...,   306,  1205, 13466],
         [   13, 29909,  3644,  ...,  6246, 29902, 17351],
         [29909, 22550, 20001,  ..., 12378,  3492,  6103]]], device='cuda:0')
Batch 4, 3.2% of total tokens
encoded shape: torch.Size([2, 1044])
torch.Size([2, 1044]) tensor([[    1, 21710,  9665,  ...,     2,     2,     2],
        [    1, 12391,  3052,  ...,   297, 27689, 29889]], device='cuda:0')
torch.Size([2, 1044, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -6.3750,  -4.7422,  -3.9922,  ...,  -3.4824,  -2.5742,  -3.3164],
         [ -9.6719, -10.1562,  -1.6318,  ...,  -7.9297,  -3.8789,  -7.5508],
         ...,
         [ -4.5898,  12.9453,   0.0282,  ...,  -1.4775,  -0.4207,  -1.1504],
         [ -4.7891,  13.1250,   0.1211,  ...,  -1.6543,  -0.5806,  -1.2998],
         [ -5.0938,  13.1016,   0.4988,  ...,  -1.9316,  -0.8853,  -1.5371]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -9.0625, -10.2578,  -3.2734,  ...,  -4.5859,  -5.7227,  -4.5000],
         [ -8.5625,  -7.7344,  -0.4421,  ...,  -3.2090,  -2.0195,  -4.8945],
         ...,
         [ -6.3516,  -4.3242,   3.9180,  ...,  -4.0000,  -4.7188,  -1.5020],
         [ -5.2695,  -1.7910,   9.1016,  ...,  -3.5645,  -1.6826,  -3.6055],
         [ -0.3550,   1.3203,  15.5703,  ...,   0.7988,  -1.1816,  -1.7090]]],
       device='cuda:0')
torch.Size([2, 1044, 1]) tensor([[[29892],
         [  335],
         [  348],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [ 3052],
         [ 1790],
         ...,
         [  445],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 1044, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  335,  1765,  2496,  ...,  3761, 12533,   404],
         [  348,   686,   574,  ...,   554,  3660,   870],
         ...,
         [    1,  7228, 29900,  ..., 29879,   891, 29929],
         [    1,  7228, 29900,  ...,  4345, 29929,   891],
         [    1,  7228, 29900,  ..., 29929, 29892, 29889]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 3052,  3458, 20692,  ...,  1049, 29893,  6091],
         [ 1790,   263,   385,  ...,  1749,  1438,   738],
         ...,
         [  445,   278,   263,  ...,  1749,  1438,   322],
         [29889,   393, 29892,  ...,   411,   297,  5733],
         [   13,     2,  1126,  ...,  3600, 18989,  3118]]], device='cuda:0')
Batch 5, 4.3% of total tokens
encoded shape: torch.Size([2, 668])
torch.Size([2, 668]) tensor([[    1,  7363,   983,  ...,     2,     2,     2],
        [    1, 10050,   262,  ...,   310, 23844, 29889]], device='cuda:0')
torch.Size([2, 668, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -9.0000,  -9.6641,  -4.2227,  ...,  -4.4570,  -4.7930,  -2.9570],
         [ -9.2031,  -8.6719,  -1.9932,  ...,  -2.1875,  -5.5703,  -6.7344],
         ...,
         [ -5.8086,   7.0430,  -0.6626,  ...,  -2.0234,  -1.4189,  -0.8677],
         [ -5.4648,   7.3164,  -0.7456,  ...,  -1.7754,  -1.1572,  -0.6494],
         [ -5.3555,   7.2188,  -0.6289,  ...,  -1.7871,  -1.0986,  -0.6743]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -9.1016, -15.9531,  -4.8438,  ...,  -4.1797,  -6.9414,  -6.1953],
         [-11.0859, -14.1797,  -4.1133,  ...,  -6.2383,  -7.3555,  -7.1953],
         ...,
         [ -4.9531,  -2.7051,   7.0586,  ...,  -2.3223,   0.3108,  -5.3438],
         [ -4.1680,  -1.7109,   8.8906,  ...,  -2.9531,  -0.5776,  -6.7305],
         [ -4.0977,  -6.5156,  13.7109,  ...,  -0.5327,  -1.6641,  -3.5215]]],
       device='cuda:0')
torch.Size([2, 668, 1]) tensor([[[29892],
         [ 1460],
         [  566],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [29899],
         [ 4428],
         ...,
         [23844],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 668, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1460, 18184, 18745,  ...,   488,  2671,   978],
         [  566,   533,   412,  ...,  3135, 30010,  9321],
         ...,
         [    1,  7228,   891,  ..., 31234,  4345, 17210],
         [    1,  7228,    10,  ..., 10888,  4345, 30322],
         [    1,  7228,    10,  ..., 10888, 17210, 30322]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29899,   771, 10660,  ...,  1403,   621,   420],
         [ 4428,   509, 20795,  ..., 10147,   794,   571],
         ...,
         [23844,   610,   472,  ...,  1661,   278, 10393],
         [29889, 29892,   297,  ...,  1363,   411,   472],
         [   13, 14187, 29871,  ...,   739,  8725,   349]]], device='cuda:0')
Batch 6, 5.1% of total tokens
encoded shape: torch.Size([2, 623])
torch.Size([2, 623]) tensor([[    1, 20583, 13342,  ..., 28990,  1889, 29889],
        [    1,   910,   338,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 623, 32000]) tensor([[[ -8.0312,  -1.1094,  -0.5273,  ...,  -4.1836,  -5.6641,  -4.5781],
         [ -8.5078,  -8.2969,  -8.7031,  ...,  -5.6172,  -7.6875,  -2.6465],
         [-11.7188, -12.7344,  -3.6152,  ...,  -5.9727,  -8.2109,  -7.9336],
         ...,
         [ -5.8047,  -7.1914,   8.8750,  ...,  -3.3691,  -1.0342,  -5.0234],
         [ -5.1680,  -5.8359,   9.7656,  ...,  -2.9766,  -0.6416,  -5.4531],
         [ -5.7891,  -6.9844,   9.7891,  ...,   0.9463,  -0.4531,  -2.1387]],

        [[ -8.0312,  -1.1094,  -0.5273,  ...,  -4.1836,  -5.6641,  -4.5781],
         [-13.1641, -11.2188,  -6.7930,  ...,  -8.4766,  -8.0312,  -9.4766],
         [-10.3750, -11.9375,  -2.4805,  ...,  -4.9141,  -4.5898,  -6.7383],
         ...,
         [ -1.5322,   3.7344,  -1.5391,  ...,   0.6167,   1.4961,   0.8506],
         [ -1.5225,   3.7480,  -1.5234,  ...,   0.6113,   1.5029,   0.8447],
         [ -1.6133,   3.8203,  -1.5176,  ...,   0.5508,   1.4551,   0.7969]]],
       device='cuda:0')
torch.Size([2, 623, 1]) tensor([[[29892],
         [ 3381],
         [  363],
         ...,
         [ 1889],
         [29889],
         [   13]],

        [[29892],
         [  338],
         [  263],
         ...,
         [14262],
         [14262],
         [14262]]], device='cuda:0')
torch.Size([2, 623, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 3381,  2002,  1030,  ..., 29875,  7925,   328],
         [  363,   304, 21099,  ...,   310,  1904,  2729],
         ...,
         [ 1889, 10174,   322,  ...,  7408,   297,  8576],
         [29889,   363,   297,  ...,  1156,   310,   304],
         [   13, 14187,   450,  ...,   512,   313,  1019]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  338,  6251,  4723,  ...,  1400,  1629,  4700],
         [  263,   278,   385,  ...,  1749,   920,   596],
         ...,
         [14262, 23196, 26077,  ..., 31779, 24708, 26502],
         [14262, 23196, 26077,  ..., 31779, 24708, 26502],
         [14262, 26077, 23196,  ..., 31779, 24708, 26502]]], device='cuda:0')
Batch 7, 6.0% of total tokens
encoded shape: torch.Size([2, 2612])
torch.Size([2, 2612]) tensor([[    1,  9899, 15168,  ...,     2,     2,     2],
        [    1,   910,   297,  ...,  2057, 14282, 29889]], device='cuda:0')
torch.Size([2, 2612, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.8125, -13.7344,  -7.1406,  ...,  -3.4648,  -1.3506,  -4.6953],
         [-13.5234, -13.4922,  -1.9785,  ...,  -8.9141, -10.7266,  -9.0859],
         ...,
         [ -7.3281,   9.7031,  -0.1093,  ...,  -3.5781,  -5.9414,  -3.0449],
         [ -7.3242,   9.6094,  -0.1366,  ...,  -3.5918,  -5.9258,  -3.0625],
         [ -7.3594,   9.6406,  -0.0643,  ...,  -3.6055,  -5.9375,  -3.0703]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-13.1641, -11.2188,  -6.8008,  ...,  -8.4766,  -8.0312,  -9.4766],
         [-11.4531, -11.9297,  -5.2891,  ...,  -8.5234,  -7.0078,  -8.7109],
         ...,
         [ -5.5586,  -7.1016,   0.1317,  ...,  -2.2793,  -0.3796,  -1.2910],
         [ -3.0176,  -4.0977,   0.2111,  ...,  -0.4817,   0.4583,  -2.4609],
         [ -0.4868,  -0.0884,   4.0234,  ...,   1.5674,   0.5117,  -1.6611]]],
       device='cuda:0')
torch.Size([2, 2612, 1]) tensor([[[29892],
         [ 1609],
         [29892],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [  338],
         [ 7316],
         ...,
         [14282],
         [ 6757],
         [ 1670]]], device='cuda:0')
torch.Size([2, 2612, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1609,  2546,   481,  ...,  1646,   262, 29875],
         [29892,   338,   313,  ..., 18117, 29901, 29899],
         ...,
         [    1, 29889, 29892,  ...,   229, 29879, 29871],
         [    1, 29889, 29892,  ..., 29879, 29871,   229],
         [    1, 29889, 29892,  ..., 29879, 29871,   229]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  338,  6251,  4723,  ...,  1400,  1629,  4700],
         [ 7316, 29899,  4548,  ...,   263, 13901,   385],
         ...,
         [14282,  9753,  8450,  ..., 29892, 26755, 18550],
         [ 6757,   607, 14002,  ...,  1316,   393, 16706],
         [ 1670, 10506,   450,  ...,   512, 13001, 12808]]], device='cuda:0')
Batch 8, 9.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 19578,  1672,  ...,   330,  1505, 29883]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7812,  -5.2188,  ...,  -6.0781,  -9.1250,  -6.8477],
         [-11.5312, -12.3906,  -3.2480,  ...,  -5.0195,  -5.4805,  -3.9707],
         ...,
         [ -0.5430,   5.3125,  12.9531,  ...,   2.2363,  -1.2656,   2.1387],
         [ -0.7002,   5.4180,  12.9688,  ...,   2.1035,  -1.4600,   2.0645],
         [ -0.7085,   5.5977,  12.9297,  ...,   2.1230,  -1.5303,   2.1055]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.0156, -10.8750,  -2.8145,  ...,  -6.5898,  -8.4453,  -8.7656],
         [-10.2656, -10.9141,   1.9355,  ...,  -6.6094,  -9.0312,  -6.8203],
         ...,
         [ -3.9375,  -3.2695,   0.0833,  ...,  -1.1416,   1.4004,  -0.8682],
         [ -4.6719,  -3.3887,   1.5771,  ...,  -1.0918,   1.9600,  -0.8169],
         [ -2.7539,  -3.0234,   1.2324,  ...,  -0.7578,   1.4648,   0.6211]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [   13]],

        [[29892],
         [ 1672],
         [14849],
         ...,
         [ 1505],
         [29883],
         [ 1505]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13, 29871, 29906,  ..., 29900, 29898, 29912],
         [   13, 29871, 29906,  ..., 29937, 29898, 29889],
         [   13, 29871, 29906,  ..., 29900, 29898, 29889]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1672,  1430,  7833,  ..., 22789,   435, 29965],
         [14849, 29901,  1806,  ...,   891, 29871,   448],
         ...,
         [ 1505, 29883, 26788,  ...,  4141,   312,   351],
         [29883, 29887,  1505,  ..., 26854,   312,   351],
         [ 1505, 27354, 26788,  ...,   312,  5138,  4141]]], device='cuda:0')
Batch 9, 13.3% of total tokens
encoded shape: torch.Size([2, 394])
torch.Size([2, 394]) tensor([[    1, 21220,  1880,  2756, 13593,  9956,   322,   316,  5105,   362,
           310,  1880,  9027,   619,  7323,  4859,  1144,   491, 23968,  9358,
           389,   295,   616,  9101,   310,  5199,  2319,   938,   342,   457,
         29889,    13,  1576, 14881,   310,  1880,  9027,   619,  7323,  4859,
          1144,   313, 29950, 19558, 29897,   411, 23968,  9358,   389,   295,
           616,  9101,   310,  5199,  2319,   938,   342,   457,   313,  5893,
         22502,  2167, 29897,   471, 12399, 29889, 29871, 29896, 29906, 29945,
         29902, 29899, 29950, 19558, 29941,   313, 21518,   537,   353, 29871,
         29896, 29892, 29896, 29906, 29945,   304, 29871, 29896, 29892, 29896,
         29906, 29953,   330, 29914,  4912, 29941, 29897, 10371,   277,   263,
          1880, 29899,  3470, 13593,   313, 29968, 29881,   353, 29871, 29947,
         29889, 29941,  1060, 29871, 29896, 29900,  6278, 29947,   467,   350,
          3317,   353, 29871, 29947, 29947, 29953,  8736, 29914, 29885, 29887,
          3038, 26823,   511,   269,  1337,   519,   322, 18764,  1821,  9956,
           304, 23968,  3896, 22502,  2167, 29889,   512,   278, 10122,   310,
         19163,   443, 29880, 24025, 18435, 29931, 29941, 29892,   278,  3038,
          7101, 29899,  9917, 29871, 29896, 29906, 29945, 29902, 29899, 29950,
         19558, 29941,   526,  5492,   964,   278, 18350,  1661,   311,  5105,
           287, 29889,  6479,   271,   358,   310,  9101,   411, 11504,   559,
           947,   451,  6602, 29871, 29896, 29906, 29945, 29902, 29899, 29950,
         19558, 29941,  9956, 29889,   450,  9956,   338, 21302,   411,  7463,
          2133,   322,   316,  5105,   362,   310, 29871, 29896, 29906, 29945,
         29902, 29899, 29950, 19558, 29941, 29889,   678,  5095, 29877,   339,
           457,   297,  6335,  1169,   278,   316,  5105,   362,   322, 16415,
         29871, 29896, 29906, 29945, 29902, 29899, 29950, 19558, 29941,   318,
           415,  1296, 29889,   319,  2211,  8771, 19163,   310, 18435, 29931,
         29941,   322, 18435, 29931, 29906,   297,  6335,  1169,   278,  9956,
           322,   316,  5105,   362,   310, 29871, 29896, 29906, 29945, 29902,
         29899, 29950, 19558, 29941,   491, 29871, 29953, 29900, 13667, 13452,
           263, 29871, 29906, 29900, 29899,  8771, 19163,   310,  4482,  9027,
           619,  7323,  4859,  1144,   313, 10249, 29931,   511,   871,   491,
         29871, 29906, 29900, 15543, 18435, 29931, 29941,   313, 29906, 29900,
           304, 29871, 29896, 29892, 29900, 29900, 29900,  9200,  1393, 29879,
         29914, 29885, 29931, 29897, 20436,   352,  1078,   278, 14710,  6656,
           310, 16864,  3775,   322,   297,  6335,  1169, 16864,   324,   707,
           261, 14710,  6656,   297,  3896, 22502,  2167, 29889,   450,  7625,
          2582,  1207,   372,  1950,   304,  5251,   393,  9358,   389,   295,
           616,  9101,   310,   278,  2319,   938,   342,   457,  1122,  5221,
           403,   297,   278,  6635, 19388,  1608,   310, 18435, 29931,   297,
          5199,  2894,  1608, 29889],
        [    1,  1019, 29879, 29901, 23994, 29871, 29941, 29896, 29953, 26413,
          1196,   408,  1532, 29892,   322, 23994, 19932, 29892,  2444,   304,
           505,  1880,  4972,    13,    13, 13696, 29901,   591, 29915,   645,
           505,   304,  1074,   920,   263,   715,  6288,  4175,  8640,   701,
         29892,   577,  2215,   577,  1781,    13,    13,  4013,  4175, 29892,
           470,   697,  3063, 13557,   304,   372,  2996,   373,   590,  1828,
           327,   272, 29889,   306, 29915,   345,   750,   372,   373,   363,
           263,  1629,   411,   694,  5626,   322,  2444,   304,   505,  2107,
          4972,   322,  1781, 21166, 29889,   306,   925, 20848,   445,   408,
           263, 16920,   322,   577,  2215,   372, 29915, 29879,  1985,  2107,
         29889,   739, 29915, 29879,  7575,   304,   367,  2221,   304,  1074,
          3099, 12624,   297,   278,  4175, 29889,   450,  4175,  4315,  2444,
          7575,   322,  2319,   304,  4380,   738,  2411,   332,  1907, 29889,
           306,   508,  1827,   393,   590, 17042,  6729,  1559, 29890,   750,
          1407,  2217,  2553,   374,   297,   372,  1156,   445,   697,  1629,
          3785, 29889,   739,  2444,   304,   367,   263,  2289,  1781,  4175,
         29889,    13,    13,  6843,   300,   654, 11028,  3842,   338,   263,
          5001,   310,  7136, 10992, 23090,   322,   319,  8050, 23644, 15736,
         29879,  1058,   526, 16955,   304, 20794,   278,  1900,  1950, 17394,
          3262,  7271,   304,  1432,   364,  1241,   393,  1998,  1169,  1749,
         14422, 29889,  2860,   599, 29892,  1334, 29915,   345,  1063,   528,
         17347, 10992,  1270,   695,  2879,  1009, 10992, 23090,  1081, 29885,
          1691, 29892, 10992, 23090, 28015,  1691, 29892, 15482,  1960, 29892,
          1045,  1862,   322,   916, 10992, 23090,  2130,  3842,   363,   975,
         29871, 29945, 29900,  2440, 29889,   887,  1016, 29915, 29873, 13958,
          2820,   393,  1472,   297,   738,  5381,  1728,  5622,  2562,   310,
           596, 20330,   322,  6480,   411,   278,  3064, 29889,  1105,  9311,
           393,   591,   674, 12021,   322,   565,   591,   885,  3973,   701,
         29892,   591,   674,  1207,   372,  1492,   856,  1334, 11640, 29991,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 394, 32000]) tensor([[[ -8.0469,  -1.2461,  -0.5518,  ...,  -4.2305,  -5.7109,  -4.6406],
         [ -9.9531,  -9.1641,  -5.2656,  ...,  -7.7891,  -6.4492,  -6.5039],
         [ -9.9531, -15.0000,  -1.8916,  ...,  -4.6406,  -4.4648,  -8.1328],
         ...,
         [ -4.2148,  -6.8086,   5.1953,  ...,  -1.5293,  -1.5127,  -2.4785],
         [ -3.2051,  -2.3887,  10.5859,  ...,  -2.4219,  -2.0996,  -4.5938],
         [ -4.7305,  -8.4766,  15.1172,  ...,  -1.4316,  -1.9980,  -3.8008]],

        [[ -8.0469,  -1.2461,  -0.5518,  ...,  -4.2305,  -5.7109,  -4.6406],
         [ -4.4961,  -3.2832,  -1.3770,  ...,  -3.5957,  -2.8965,  -3.8633],
         [ -9.2109,  -8.3203,  -4.6484,  ...,  -2.4023,  -6.7969,  -2.2520],
         ...,
         [ -3.2793,  -1.2891,   1.0596,  ...,  -3.0801,  -3.7402,  -2.4863],
         [ -3.2832,  -1.2930,   1.0645,  ...,  -3.0820,  -3.7422,  -2.4883],
         [ -3.3086,  -1.2959,   1.0723,  ...,  -3.0957,  -3.7500,  -2.5000]]],
       device='cuda:0')
torch.Size([2, 394, 1]) tensor([[[29892],
         [17015],
         [29899],
         [13593],
         [ 9956],
         [11840],
         [ 1831],
         [ 5105],
         [  362],
         [  310],
         [  278],
         [13206],
         [  619],
         [ 7323],
         [ 4859],
         [  262],
         [  491],
         [ 4185],
         [ 7548],
         [  389],
         [  295],
         [  616],
         [ 9101],
         [  515],
         [  278],
         [ 8104],
         [  938],
         [  342],
         [  457],
         [29889],
         [  435],
         [29903],
         [ 9956],
         [  310],
         [ 1880],
         [ 9027],
         [  619],
         [ 7323],
         [ 4859],
         [ 1144],
         [  313],
         [29950],
         [19558],
         [29897],
         [  411],
         [23968],
         [ 9358],
         [  389],
         [  295],
         [  616],
         [ 9101],
         [  310],
         [  278],
         [ 2319],
         [  938],
         [  342],
         [  457],
         [  471],
         [ 5425],
         [22502],
         [ 2167],
         [29897],
         [  471],
         [12399],
         [  491],
         [  450],
         [29896],
         [29906],
         [29945],
         [29902],
         [29899],
         [ 1643],
         [19558],
         [  471],
         [29906],
         [29950],
         [  537],
         [29871],
         [29871],
         [29896],
         [29889],
         [29900],
         [29945],
         [29900],
         [  330],
         [29871],
         [29896],
         [29892],
         [29896],
         [29945],
         [29955],
         [  330],
         [29914],
         [  828],
         [29941],
         [29897],
         [  471],
         [ 1573],
         [  263],
         [ 1880],
         [ 2756],
         [ 3470],
         [13593],
         [ 9956],
         [29968],
         [29874],
         [  353],
         [29871],
         [29900],
         [29889],
         [29945],
         [  921],
         [29871],
         [29896],
         [29900],
         [ 6278],
         [29896],
         [29897],
         [  341],
         [  618],
         [  353],
         [29871],
         [29896],
         [29889],
         [29889],
         [  285],
         [29914],
         [29885],
         [29887],
         [26823],
         [26823],
         [29897],
         [  269],
         [ 1337],
         [  519],
         [14881],
         [18764],
         [ 1821],
         [14881],
         [  304],
         [ 3896],
         [ 3896],
         [22502],
         [ 2167],
         [29889],
         [  450],
         [12814],
         [18070],
         [  310],
         [29871],
         [  443],
         [29880],
         [24025],
         [18435],
         [29931],
         [29892],
         [29892],
         [  278],
         [ 2702],
         [ 1070],
         [  337],
         [ 9917],
         [ 7155],
         [29896],
         [29906],
         [29945],
         [29902],
         [29899],
         [29950],
         [19558],
         [29941],
         [  471],
         [19328],
         [  964],
         [  278],
         [18350],
         [29889],
         [29899],
         [ 5105],
         [  287],
         [29889],
         [  450],
         [  271],
         [  358],
         [  310],
         [ 3896],
         [  411],
         [29871],
         [  559],
         [29892],
         [  451],
         [10551],
         [  278],
         [29896],
         [29906],
         [29945],
         [29902],
         [29899],
         [29950],
         [19558],
         [29941],
         [ 9956],
         [29889],
         [  450],
         [ 3038],
         [  310],
         [  451],
         [  491],
         [  263],
         [ 2133],
         [  310],
         [  316],
         [30488],
         [  362],
         [  310],
         [  278],
         [29896],
         [29906],
         [29945],
         [29902],
         [29899],
         [29950],
         [19558],
         [29941],
         [29889],
         [  450],
         [  324],
         [29877],
         [  339],
         [  313],
         [29892],
         [ 6335],
         [ 1169],
         [  278],
         [ 3038],
         [30488],
         [  362],
         [  310],
         [  278],
         [  278],
         [29896],
         [29906],
         [29945],
         [29902],
         [29899],
         [29950],
         [19558],
         [29941],
         [ 9956],
         [  415],
         [ 1296],
         [29889],
         [  450],
         [ 2788],
         [29899],
         [ 7910],
         [  310],
         [  443],
         [29931],
         [29941],
         [  297],
         [29871],
         [29931],
         [29906],
         [  313],
         [ 6335],
         [ 1169],
         [  278],
         [ 9956],
         [  310],
         [  316],
         [ 5105],
         [  362],
         [  310],
         [29871],
         [29896],
         [29906],
         [29945],
         [29902],
         [29899],
         [29950],
         [19558],
         [29941],
         [29889],
         [ 3896],
         [29945],
         [29900],
         [29995],
         [13452],
         [  263],
         [29871],
         [29896],
         [29900],
         [29899],
         [ 8771],
         [19163],
         [  310],
         [18435],
         [ 9027],
         [  619],
         [ 7323],
         [ 4859],
         [ 1144],
         [  313],
         [10249],
         [29931],
         [29897],
         [ 1407],
         [22039],
         [29871],
         [29906],
         [29900],
         [15543],
         [  450],
         [29931],
         [29941],
         [  322],
         [29896],
         [29900],
         [29900],
         [29871],
         [29896],
         [29900],
         [29900],
         [29900],
         [29900],
         [ 8736],
         [ 1393],
         [29879],
         [29914],
         [  828],
         [29931],
         [29897],
         [  297],
         [ 5987],
         [30488],
         [  278],
         [11039],
         [  267],
         [  310],
         [21104],
         [ 3398],
         [  322],
         [16864],
         [ 6335],
         [ 1169],
         [  278],
         [  324],
         [  429],
         [  261],
         [ 2450],
         [  267],
         [  297],
         [ 3896],
         [29899],
         [ 2167],
         [29889],
         [  450],
         [ 2582],
         [ 2582],
         [12266],
         [  372],
         [ 1950],
         [  304],
         [ 4368],
         [  393],
         [ 3896],
         [30488],
         [30488],
         [  616],
         [ 9101],
         [  310],
         [  278],
         [ 2319],
         [  938],
         [  342],
         [  457],
         [  526],
         [  367],
         [    1],
         [  297],
         [  278],
         [ 1072],
         [  354],
         [ 1608],
         [  310],
         [18435],
         [29931],
         [29941],
         [  278],
         [  715],
         [ 1608],
         [29889],
         [   13]],

        [[29892],
         [ 1188],
         [12645],
         [  376],
         [ 2107],
         [29906],
         [29900],
         [29900],
         [  380],
         [ 3454],
         [29892],
         [ 1532],
         [  408],
         [ 3430],
         [  278],
         [  278],
         [  368],
         [  694],
         [  304],
         [  367],
         [  263],
         [11029],
         [ 6554],
         [29902],
         [13696],
         [29901],
         [ 8666],
         [  750],
         [30488],
         [ 1074],
         [  304],
         [ 1074],
         [  920],
         [  372],
         [30488],
         [30488],
         [28221],
         [30488],
         [  701],
         [  975],
         [  541],
         [ 2215],
         [29892],
         [ 1781],
         [   13],
         [   13],
         [ 1123],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  272],
         [29889],
         [  739],
         [29915],
         [  345],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [30488],
         [ 5626],
         [29889],
         [30488],
         [  304],
         [ 4972],
         [30488],
         [30488],
         [29889],
         [30488],
         [30488],
         [29889],
         [  306],
         [29915],
         [ 6398],
         [30488],
         [30488],
         [30488],
         [30488],
         [  363],
         [30488],
         [30488],
         [30488],
         [30488],
         [29879],
         [30488],
         [31147],
         [29889],
         [   13],
         [29915],
         [29879],
         [30488],
         [30488],
         [  505],
         [30488],
         [  304],
         [30488],
         [30488],
         [30488],
         [  297],
         [30488],
         [30488],
         [29889],
         [   13],
         [  871],
         [30488],
         [30488],
         [  304],
         [  322],
         [  380],
         [30488],
         [  592],
         [  278],
         [  270],
         [30488],
         [ 1907],
         [29889],
         [  306],
         [29915],
         [29915],
         [  393],
         [  306],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  304],
         [  374],
         [  297],
         [30488],
         [29889],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [  306],
         [29915],
         [  304],
         [  367],
         [  263],
         [30488],
         [  297],
         [30488],
         [29889],
         [  306],
         [   13],
         [21298],
         [  598],
         [30488],
         [30488],
         [29871],
         [  383],
         [30488],
         [30488],
         [  306],
         [30488],
         [30488],
         [30488],
         [29892],
         [  319],
         [29889],
         [29914],
         [30488],
         [29879],
         [30488],
         [29892],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 3262],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 1241],
         [29889],
         [ 1998],
         [29889],
         [ 1749],
         [30488],
         [  470],
         [ 1334],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  856],
         [30488],
         [30488],
         [30488],
         [ 5633],
         [30488],
         [25145],
         [30488],
         [  330],
         [30488],
         [29892],
         [ 1691],
         [  322],
         [  322],
         [30488],
         [  322],
         [  322],
         [30488],
         [29892],
         [  330],
         [ 2130],
         [30488],
         [ 2130],
         [30488],
         [30488],
         [30488],
         [29871],
         [29906],
         [29900],
         [ 2440],
         [29889],
         [ 1334],
         [30488],
         [29915],
         [29873],
         [30488],
         [ 2820],
         [  363],
         [ 1472],
         [30488],
         [  263],
         [  376],
         [30488],
         [13797],
         [  263],
         [  310],
         [  596],
         [20330],
         [29889],
         [13797],
         [30488],
         [  278],
         [ 3064],
         [29889],
         [ 1334],
         [ 3692],
         [  502],
         [  591],
         [29915],
         [ 2337],
         [29889],
         [29892],
         [  366],
         [ 1016],
         [ 3973],
         [  701],
         [29892],
         [  591],
         [29915],
         [ 1207],
         [  372],
         [ 1492],
         [29889],
         [19145],
         [30488],
         [29889],
         [   13],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 2277],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [29902],
         [29902],
         [29902],
         [ 1576],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29892],
         [29892],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29892],
         [29892],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29892],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 394, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [17015,   537,  2472,  ..., 11814, 15247,  4902],
         [29899,  3762,  1994,  ..., 10868,  3081,  6210],
         ...,
         [ 1608, 12903,  1788,  ...,   322, 29889, 11634],
         [29889,   322, 29892,  ...,  7226,  1549,  3025],
         [   13,   450,     2,  ...,  2688, 14187,   319]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1188,  5489, 21494,  ..., 29879,  5770,   546],
         [12645,   322,   546,  ...,   459,   643,  4125],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 29889]]], device='cuda:0')
Batch 10, 14.0% of total tokens
encoded shape: torch.Size([2, 573])
torch.Size([2, 573]) tensor([[    1,   319, 12700,  ..., 12919, 25811, 29889],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 573, 32000]) tensor([[[ -8.0312,  -1.1064,  -0.5293,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.2891,  -9.5703,  -6.6484,  ...,  -7.2969,  -8.5703,  -9.8516],
         [ -9.2031, -15.5234,  -7.8359,  ...,  -5.3008,  -5.6172,  -8.0781],
         ...,
         [ -5.4219,  -9.1406,   6.0859,  ...,  -4.2148,  -2.9629,  -3.5977],
         [ -3.8770,  -6.7852,  10.2031,  ...,  -0.9487,  -2.5098,  -4.1172],
         [ -8.6328, -11.2188,  10.2891,  ...,  -3.1641,  -3.7383,  -5.1562]],

        [[ -8.0312,  -1.1064,  -0.5293,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7812,  -5.2148,  ...,  -6.0781,  -9.1250,  -6.8477],
         [-11.5156, -12.3750,  -3.2422,  ...,  -5.0078,  -5.4688,  -3.9551],
         ...,
         [ -3.8438,   4.4492,  -1.8936,  ...,  -1.2490,  -0.4595,  -0.4465],
         [ -4.1914,   4.4062,  -1.9404,  ...,  -1.4883,  -0.6987,  -0.6592],
         [ -4.6992,   4.3125,  -2.0039,  ...,  -1.8398,  -1.0547,  -0.9883]]],
       device='cuda:0')
torch.Size([2, 573, 1]) tensor([[[29892],
         [  716],
         [29899],
         ...,
         [25811],
         [29889],
         [   13]],

        [[29892],
         [14873],
         [ 1724],
         ...,
         [ 7228],
         [ 7228],
         [ 7228]]], device='cuda:0')
torch.Size([2, 573, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  716,  2846, 16886,  ...,  8456,  1783,   558],
         [29899,  3901,  7418,  ..., 24135, 29888,  1904],
         ...,
         [25811,   451, 20458,  ...,   316,  4845, 28305],
         [29889, 29892,   297,  ...,   322,   408,   313],
         [   13,  2398,  4121,  ...,   512,   910,   319]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,   306,  1128,  ...,  1932,  1317,   450],
         ...,
         [ 7228,     1, 26077,  ..., 26502, 25528, 14332],
         [ 7228,     1, 26077,  ..., 26502, 25528, 14332],
         [ 7228,     1,  4345,  ...,    10, 14332, 26502]]], device='cuda:0')
Batch 11, 14.9% of total tokens
encoded shape: torch.Size([2, 417])
torch.Size([2, 417]) tensor([[    1,   887, 29915,   645,  1284,   263,  1051,   310, 24518, 18403,
         29879, 29889, 16297,   373,   278,  2988,   304,  1074,   599,   278,
         24518,  1722, 12955, 21467,   297,   393,  4038, 29889,  1334,  1018,
           304,  2767,   278, 24518,  1722,  3699, 20410,  4700,  2748,   263,
          4723, 29892,  5491,   491, 24211,  7250, 29889,    13,    13, 29906,
         29953, 29900, 29896, 28093,  3156,   390,  5525,  4942, 24518, 29892,
           323, 29990,   448, 29871, 29955, 29947, 29955, 29941, 29945,   448,
           395, 29941, 29892, 29929, 29929, 29945, 29892, 29900, 29900, 29900,
            13,    13, 24259,   267,  1152,   317,   744,   297, 24518,    13,
            13, 29909,   504,   262, 15089,   267,  1152,   317,   744, 29889,
         14439,  4956, 21051,  2502,   636,  8778,   310, 11399, 29892,  3942,
         29892,  4955,   669,  5360, 29991,   910, 10067, 15931, 10545, 20603,
         14439,   471,   429,  7680,   277,   873,  4240,   297,   263,   409,
         13347,  4444,  4249,   301,  1878,   322,   544,   391,   457,  2982,
          1557, 21430, 29892, 27032,  4866,  5999,  4135, 29889,  1174,  2212,
         29891,  4094,  2780,  6575,  7224,   373,  2246,   310,   278, 29871,
         29945, 29900, 30057, 30181, 30536, 19372, 29892,   394, 29888,   690,
          1111,   270,  2827,   472,   697,   310,  1784,   938,  6490,   714,
         17433,  6055, 29889, 28224,  5597,  4595,  8471, 10161, 29892,  1518,
           550,   573,  6575, 18901, 29892,  1539, 12906,  5794, 19949, 17161,
           575,   411,   263,   521, 21475,  1302,   459, 29889,   910, 15585,
         21031,   338, 12520,   297,   278,   544,  5286,  2738, 29892,   330,
           630, 18403,   310, 12245,   265, 15594, 29889,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13, 29938,   535,   976,  1972,  1059,
          9254,   411,  5048,    13,    13,  5618,   306, 29915, 29885,  1811,
           304,   437,   338,   679,   590,  3472, 29914,  1961,   775,   304,
          2479,   848,   515,   590,  9254,   297,   263,  1591, 29889, 29871,
            13,  3112,  4511, 29879,   925,  1284,   304,   278,  2566, 29892,
           541,   306,  1348,   306, 29915, 29885,  2805,   385,  1059,   472,
         29901,   395,  2914, 29873,  6080,   535,   976,  1972,   703,  6404,
         17440,  1170, 29892,   476,  6090, 29892, 14450, 29879, 29892,   399,
          1144, 29892, 25133,  3895,   323, 29911,  9075,  1496, 29871,   363,
           372,  2337,  3697,   393,   775,   408,  1426,   373,   278, 24499,
           746,   306,  6222,   372, 29889,  3115,   297,   278,  6131,   372,
          3697,  1269,   310,   278,  1948,  3519,   322,  1009,  2286, 29871,
          1834,   297,  6564,   363,   738,  1371, 29991,    13,  3399, 29901,
            13,  1124,   597, 16179,  2109, 29889,   510, 29914, 29926, 29896,
          3352,  1314, 29945, 29891,    13,  5379,  3860, 24499, 29901,    13,
          1124,   597, 16179,  3377, 29889,  1111, 29914, 29906, 29886, 29920,
         29939,  2890, 29876, 29893, 29889,  2732,    13,    13, 29909, 29901,
            13,    13, 29908,  3112,   338,   263,   869,  1420,   934, 29892,
           306,   674,  1423,   373,  3989, 29945, 29918,  5453,   785, 29871,
         29103,  1552,  8431, 29933, 29871, 29906,   286,  1144,  8020, 29908,
            13,    13, 29889,  1420,   934, 17752,   674,   451,  6088,  5048,
          1513,  3145, 29889,    13, 29909,   869,  1961,  6081,   338,  3734,
           304,   437,   445, 29892,  2298,  3907,  1854,   263,  1856,  2974,
           322,  5048,   526,  5130,   322,  6284, 13252, 29889,    13,  3644,
           373,   263,  1887,  4933, 29892,   366,   674,   817,   304,  2130,
           372,   763,  1732,   597,  7640, 29914,  1445, 29889,  1961,   322,
           451,   934,   597, 29914,  1445, 29889,  1961,    13,  3492,   508,
          3138, 29892, 18690, 13380,   304,  7539,   869,  1420,  2066,   408,
          5048,  1549,   869, 21294,   565,   393,   338,   596, 24583, 29889,
            13,  2528,  1542,  2280, 29914, 29916, 29899,  1124, 29881, 29899,
          1961,   869,  1420,    13,    13,  3644,   366,   871,  3814,   373,
          3704,   278,  5048,   373,   697,  1813, 29892,   372,   338,  2253,
           304,  6230,   445,   982, 29901,    13, 29966, 10547,   596,  3488,
         29889,  1420, 29958,    13,  2528,  1542,  2280, 29914, 29916, 29899,
          1124, 29881, 29899,  1961,   869,  1420,    13,   829, 10547, 29958,
            13,    13,  3644,   366,   526,  2734,  5048,   408,  8446, 29902,
            13,  2528,  4598,  2280, 29914, 29916, 29899,  1124, 29881, 29899,
          1961,   869,  1420,    13,    13,  3644,   373,  2921, 29928, 25644,
            13,  5856,   718,  5379, 11135, 29902,    13,  2528,  1542,  2280,
         29914, 29916, 29899,  1124, 29881, 29899,  1961,   869,  1961,   869,
          1420,    13,  2528,  4598,   921, 29899,  1124, 29881, 29899,  1961,
         29945,   869,  1961,   869,  1420,    13,    13]], device='cuda:0')
torch.Size([2, 417, 32000]) tensor([[[ -8.0391,  -1.2373,  -0.5518,  ...,  -4.2266,  -5.6992,  -4.6328],
         [ -9.4453, -10.4609,  -0.2123,  ...,  -3.4707,  -7.5820,  -3.8262],
         [ -3.2266,  -1.3271,   1.0723,  ...,  -3.0625,  -3.7344,  -2.4629],
         ...,
         [ -0.9370,   4.0703,  -0.3572,  ...,   0.9985,   2.0117,   1.2480],
         [ -0.9634,   4.0742,  -0.4341,  ...,   0.9873,   1.9805,   1.2363],
         [ -0.9619,   4.0391,  -0.5254,  ...,   1.0000,   1.9658,   1.2412]],

        [[ -8.0391,  -1.2373,  -0.5518,  ...,  -4.2266,  -5.6992,  -4.6328],
         [-10.6953, -11.7812,  -5.2227,  ...,  -6.0820,  -9.1250,  -6.8516],
         [-11.5234, -12.3906,  -3.2500,  ...,  -5.0117,  -5.4727,  -3.9609],
         ...,
         [  1.0840,   2.8594,   9.0312,  ...,  -0.7744,   2.8223,  -0.0243],
         [ -2.8223,  -0.9189,   6.5938,  ...,  -2.2246,  -0.7324,  -0.5093],
         [ -7.5547, -11.4375,   2.9395,  ...,  -3.6797,  -3.5664,  -1.0352]]],
       device='cuda:0')
torch.Size([2, 417, 1]) tensor([[[29892],
         [  526],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 1670],
         [  373],
         [  278],
         [30488],
         [30488],
         [  856],
         [  825],
         [30488],
         [30488],
         [30488],
         [30488],
         [  297],
         [23196],
         [30488],
         [30488],
         [29889],
         [  887],
         [  884],
         [  304],
         [ 3013],
         [  278],
         [30488],
         [30488],
         [ 3699],
         [29915],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 3250],
         [  541],
         [  373],
         [30488],
         [ 7250],
         [29889],
         [  960],
         [ 3644],
         [ 3644],
         [29900],
         [29900],
         [29900],
         [  399],
         [30488],
         [ 4942],
         [30488],
         [22850],
         [24518],
         [29892],
         [10319],
         [29889],
         [29871],
         [ 4673],
         [29955],
         [29947],
         [29955],
         [29941],
         [30488],
         [   13],
         [ 4673],
         [29945],
         [29929],
         [29929],
         [29929],
         [29945],
         [29892],
         [29900],
         [29900],
         [29900],
         [   13],
         [29906],
         [29906],
         [  267],
         [29889],
         [30488],
         [  317],
         [  297],
         [24518],
         [ 2448],
         [   13],
         [29909],
         [30488],
         [30488],
         [29892],
         [  267],
         [  363],
         [  317],
         [  744],
         [   13],
         [24518],
         [25145],
         [30488],
         [30488],
         [  338],
         [24518],
         [  363],
         [29871],
         [29892],
         [10618],
         [  322],
         [  322],
         [29892],
         [  278],
         [29889],
         [  910],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29892],
         [ 4240],
         [30488],
         [30488],
         [  856],
         [ 8688],
         [  297],
         [29871],
         [30488],
         [30488],
         [30488],
         [  373],
         [30488],
         [30488],
         [30488],
         [  301],
         [30488],
         [  457],
         [30488],
         [ 1557],
         [30488],
         [29889],
         [  411],
         [  263],
         [29871],
         [ 4135],
         [  322],
         [  910],
         [29899],
         [29891],
         [29871],
         [30488],
         [30488],
         [29899],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29941],
         [29900],
         [29900],
         [30488],
         [29871],
         [30488],
         [29892],
         [  470],
         [29595],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [30488],
         [  310],
         [  278],
         [30488],
         [30488],
         [29892],
         [30488],
         [  282],
         [29892],
         [  910],
         [29875],
         [  263],
         [30488],
         [  297],
         [  411],
         [11595],
         [30488],
         [  573],
         [30488],
         [30488],
         [29892],
         [11595],
         [30488],
         [30488],
         [13173],
         [29892],
         [  856],
         [29892],
         [  263],
         [ 5812],
         [29889],
         [ 1302],
         [29899],
         [29892],
         [  450],
         [ 3271],
         [29871],
         [  338],
         [  263],
         [ 2507],
         [ 5198],
         [29871],
         [ 5286],
         [ 2738],
         [30488],
         [  330],
         [30488],
         [30488],
         [  310],
         [30488],
         [30488],
         [30488],
         [29889],
         [14439],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29871],
         [29871],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29902],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [ 1576],
         [29902],
         [  306],
         [29892],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [29871],
         [  450],
         [  450],
         [  450],
         [  450],
         [23196],
         [24366],
         [24366],
         [24366],
         [24366],
         [24366],
         [24366],
         [24366],
         [24366],
         [24366],
         [24366],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262]],

        [[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [29896],
         [  874],
         [19125],
         [  703],
         [ 2643],
         [ 1923],
         [17248],
         [29820],
         [   13],
         [29902],
         [  338],
         [29915],
         [30488],
         [ 2599],
         [  304],
         [  437],
         [  338],
         [  304],
         [  263],
         [  313],
         [29889],
         [ 4268],
         [  304],
         [30488],
         [  664],
         [  278],
         [  515],
         [  263],
         [ 2566],
         [ 2566],
         [30488],
         [30488],
         [29889],
         [  306],
         [  306],
         [   13],
         [30488],
         [29879],
         [29892],
         [ 2691],
         [  541],
         [  278],
         [ 2566],
         [  322],
         [  541],
         [  746],
         [  679],
         [30488],
         [29915],
         [29885],
         [29871],
         [  263],
         [29871],
         [  411],
         [  278],
         [   13],
         [  535],
         [  353],
         [  353],
         [  535],
         [  976],
         [ 1972],
         [ 1566],
         [ 6404],
         [  334],
         [29892],
         [29892],
         [ 3824],
         [30488],
         [29892],
         [  399],
         [29879],
         [29892],
         [  399],
         [29876],
         [ 3895],
         [ 4602],
         [ 3895],
         [10769],
         [ 1849],
         [29918],
         [ 5754],
         [   13],
         [   13],
         [  777],
         [30488],
         [30488],
         [  278],
         [  278],
         [  297],
         [  278],
         [29889],
         [  278],
         [ 1813],
         [29889],
         [30488],
         [30488],
         [  372],
         [29889],
         [29871],
         [29892],
         [  278],
         [ 2566],
         [  306],
         [29915],
         [  278],
         [ 1897],
         [  278],
         [ 4341],
         [ 9066],
         [  408],
         [  278],
         [30488],
         [30488],
         [   13],
         [  363],
         [ 6564],
         [  363],
         [  278],
         [29889],
         [29889],
         [   13],
         [   13],
         [29901],
         [   13],
         [   13],
         [29889],
         [16179],
         [ 2109],
         [29889],
         [  510],
         [29914],
         [ 1610],
         [29929],
         [29999],
         [29945],
         [29999],
         [29999],
         [   13],
         [   13],
         [ 3860],
         [  373],
         [29901],
         [ 1732],
         [ 1124],
         [  597],
         [16179],
         [ 2109],
         [29889],
         [25145],
         [24366],
         [29906],
         [29900],
         [29955],
         [29929],
         [29955],
         [29999],
         [29889],
         [29889],
         [ 2732],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [ 3492],
         [ 6404],
         [30488],
         [30488],
         [30488],
         [ 1961],
         [30488],
         [30488],
         [  451],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [17248],
         [30488],
         [30488],
         [29896],
         [  653],
         [29931],
         [29891],
         [ 2627],
         [ 6610],
         [29871],
         [ 1144],
         [29889],
         [ 3863],
         [   13],
         [   13],
         [29902],
         [ 1420],
         [  338],
         [29892],
         [30488],
         [30488],
         [30488],
         [  263],
         [29889],
         [ 3145],
         [29889],
         [  887],
         [   13],
         [  869],
         [ 1961],
         [30488],
         [30488],
         [ 3734],
         [29889],
         [30488],
         [29889],
         [29889],
         [  322],
         [30488],
         [ 1854],
         [30488],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [30488],
         [30488],
         [29889],
         [   13],
         [   13],
         [  869],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  313],
         [30488],
         [  445],
         [  313],
         [ 7640],
         [29914],
         [ 1445],
         [29889],
         [ 1961],
         [29889],
         [30488],
         [  869],
         [29889],
         [29914],
         [ 1445],
         [29889],
         [ 1420],
         [29889],
         [   13],
         [  508],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  263],
         [ 1420],
         [  408],
         [30488],
         [  869],
         [29892],
         [30488],
         [21294],
         [29889],
         [30488],
         [30488],
         [  825],
         [30488],
         [29889],
         [   13],
         [   13],
         [30488],
         [30488],
         [29914],
         [29916],
         [29899],
         [ 1124],
         [30488],
         [29899],
         [ 1961],
         [  869],
         [ 1420],
         [   13],
         [   13],
         [20001],
         [  366],
         [29915],
         [  864],
         [  373],
         [30488],
         [30488],
         [  869],
         [30488],
         [30488],
         [30488],
         [29892],
         [  313],
         [29915],
         [  263],
         [30488],
         [30488],
         [  263],
         [30488],
         [29889],
         [   13],
         [   13],
         [29874],
         [  313],
         [ 1445],
         [29889],
         [ 1420],
         [  313],
         [30488],
         [30488],
         [30488],
         [30488],
         [29914],
         [29916],
         [19838],
         [ 1124],
         [29881],
         [29899],
         [ 1961],
         [  869],
         [ 1420],
         [   13],
         [  829],
         [30488],
         [30488],
         [   13],
         [   13],
         [20001],
         [  366],
         [ 3814],
         [30488],
         [  263],
         [  373],
         [30488],
         [29902],
         [30488],
         [29966],
         [  263],
         [30488],
         [24366],
         [20006],
         [26077],
         [ 1124],
         [29881],
         [29899],
         [20006],
         [  869],
         [ 1420],
         [   13],
         [   13],
         [ 3644],
         [  366],
         [  263],
         [  360],
         [25644],
         [  470],
         [ 3492],
         [29889],
         [29943],
         [11135],
         [31514],
         [  718],
         [ 5856],
         [ 4598],
         [30488],
         [29914],
         [29916],
         [30488],
         [ 1124],
         [29881],
         [29899],
         [ 1961],
         [  869],
         [ 1420],
         [   13],
         [ 1420],
         [   13],
         [   13],
         [ 4598],
         [30488],
         [29899],
         [ 1124],
         [29881],
         [29899],
         [ 1961],
         [  869],
         [  869],
         [ 1420],
         [  869],
         [ 1420],
         [   13],
         [   13],
         [ 3644]]], device='cuda:0')
torch.Size([2, 417, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  526,   508,  1122,  ...,  1795,  1073,  4683],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         ...,
         [14262, 24366, 23196,  ..., 23795, 28044, 19838],
         [14262, 24366, 23196,  ..., 28044, 23795, 19838],
         [14262, 24366, 23196,  ..., 28044, 23795, 19838]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,   306,  1128,  ...,  1932,  1317,   450],
         ...,
         [   13,   869,     2,  ..., 20006,  7834,  2380],
         [   13, 29966, 20006,  ...,  1961, 29934, 23174],
         [ 3644, 20001, 22550,  ...,  1124,  4013, 13393]]], device='cuda:0')
Batch 12, 15.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   530,  7418,  ...,     2,     2,     2],
        [    1, 27576,    13,  ...,   278,  2462,  7536]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -4.4609,  -2.3145,   0.2177,  ...,  -1.0596,  -3.0098,  -1.0645],
         [ -7.8516,  -7.2617,   0.3472,  ...,  -2.1816,  -6.7930,  -2.9023],
         ...,
         [ -6.9531,   8.2188,   0.4739,  ...,  -3.3672,  -5.1016,  -2.6895],
         [ -7.1016,   8.3203,   0.5693,  ...,  -3.3945,  -5.1797,  -2.7480],
         [ -7.2070,   8.3906,   0.6382,  ...,  -3.4004,  -5.2344,  -2.7734]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.3750,  -5.6523,  -1.9277,  ...,  -6.6016,  -7.1641,  -6.8672],
         [ -9.2578,  -5.3594,  -2.7754,  ...,  -3.2754,  -3.5664,  -2.0449],
         ...,
         [ -3.5684,  -1.6533,   1.1445,  ...,  -3.1816,  -3.8633,  -2.5957],
         [ -1.8281,  -0.1316,   2.2734,  ...,   0.4707,   2.1465,  -0.5352],
         [ -4.0859,  -1.9395,   1.2656,  ...,  -3.4336,  -3.9023,  -2.6641]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [15566],
         [  310],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [  304],
         [ 1576],
         ...,
         [30488],
         [ 7536],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [15566, 14793,   603,  ...,  1541, 27576,  2786],
         [  310,   491,   373,  ...,   756,   363,   338],
         ...,
         [    1, 29896, 29900,  ..., 29892,   229, 29946],
         [    1, 29896, 29900,  ..., 29892,   229, 29946],
         [    1, 29896, 29900,  ..., 29892,   229, 29946]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  304, 29901,   310,  ...,   448,   891,   785],
         [ 1576, 29902, 30015,  ..., 29931, 29933, 25898],
         ...,
         [30488, 30879, 31147,  ..., 31488, 31256,   313],
         [ 7536,  1434,   310,  ...,  3517,   746,   925],
         [30488,   304, 30879,  ..., 30282, 29871,   349]]], device='cuda:0')
Batch 13, 19.9% of total tokens
encoded shape: torch.Size([2, 1739])
torch.Size([2, 1739]) tensor([[    1,   910,  2060,  ...,     2,     2,     2],
        [    1,  3645,   278,  ..., 13152,  1660, 29889]], device='cuda:0')
torch.Size([2, 1739, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-13.1641, -11.2188,  -6.8008,  ...,  -8.4766,  -8.0312,  -9.4766],
         [ -9.5547, -12.2109,  -4.6758,  ...,  -4.2227,  -5.9688,  -4.2305],
         ...,
         [-10.8281,   2.9453,  -2.7559,  ...,  -8.1953,  -6.6953,  -6.8164],
         [-10.8750,   3.0918,  -2.7227,  ...,  -8.1797,  -6.7773,  -6.8086],
         [-10.9141,   3.0508,  -2.6562,  ...,  -8.2109,  -6.8359,  -6.8320]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.7969,  -9.2266,  -4.1211,  ...,  -5.5273,  -5.9453,  -5.9609],
         [-11.9531, -12.0625,  -6.2461,  ...,  -7.3789,  -8.8203,  -6.5156],
         ...,
         [ -4.6484,   5.4609,   2.2207,  ...,  -0.8755,  -2.3320,  -2.2383],
         [ -2.6289,  -2.2090,   7.7539,  ...,   0.4722,   0.3855,  -0.3184],
         [ -8.0547,  -6.3594,   9.4141,  ...,  -1.6631,  -2.2383,  -1.5820]]],
       device='cuda:0')
torch.Size([2, 1739, 1]) tensor([[[29892],
         [  338],
         [  338],
         ...,
         [29900],
         [29900],
         [29900]],

        [[29892],
         [  278],
         [ 3256],
         ...,
         [29900],
         [29889],
         [ 3834]]], device='cuda:0')
torch.Size([2, 1739, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  338,  6251,  4723,  ...,  1400,  1629,  4700],
         [  338,   471,   263,  ...,  7405, 11624, 29892],
         ...,
         [29900,  7228, 29929,  ..., 29946,   197, 29955],
         [29900,  7228, 29929,  ..., 29946, 29955, 29945],
         [29900,  7228, 29929,  ..., 29955, 29945, 29947]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  278, 29871,   263,  ..., 29901,   967,   385],
         [ 3256, 28320,   907,  ...,  6763,  4148,  1407],
         ...,
         [29900, 29903,   306,  ..., 29968,   319,  1966],
         [29889, 29892,  5300,  ...,   313, 12317,  7495],
         [ 3834,  5373,  2672,  ...,   512,   910,   450]]], device='cuda:0')
Batch 14, 22.1% of total tokens
encoded shape: torch.Size([2, 258])
torch.Size([2, 258]) tensor([[    1,   660, 29901,    13,    13,  8136,   304,  6459,   746,   366,
           526, 13587,  1623,   263,  2826,    13,    13, 29902,   817,   304,
           367,  2221,   304,  2649,   746,   278,  1404,   338, 13587,   263,
          2826,  1623,   322,   746,   278,  1404, 16869,   748, 29889,   910,
           338,  1422,   515,   373, 11676,   322,   373,  8208, 11676, 29889,
         29871,  1128,   723,   474,   748,  1048,  2599,  1554,   763,   445,
         29973,   259,    13,  2831,  1342,   306,  3965,   263,  2826,   393,
          8665,   263, 17168,  8328, 14030, 27358,  5333,   775, 29897,    13,
           361, 11025,  3624,  3629,   292, 24104,    13, 29912,    13,  5904,
          8328,  1369,   890,   849,   392,  3013,  2675,    13, 29913,    13,
          2870, 17168,  8328,  5040,   890,    13,   458,   272,   373,  6507,
           470,  1554,    13, 29913,    13,    13, 29909, 29901,    13,    13,
         14959,   964,   278,  1551, 15852,  3962,   372,   756,  7142,   291,
         13634,   363,  9943,   313,  2139, 29897,   322,  5020,   313, 14096,
          1125,    13,  1493, 29889,   842,  2951, 15852,  3962, 29898,  1482,
          1551, 15852,  3962,   580,   426,    13,  1678,   732,  4640,    13,
          1678,   970,  7223,   373, 15852, 29898,  1043,   325, 29892,  7142,
           291,  2624,  1741, 29897,   426,    13,  4706,  4607, 29898,  3696,
         29889,   657,  4276,  3101,   426,    13,  4706,  1206,  7142,   291,
          2624, 29889, 24705, 29918,  3970, 16048, 29901,    13,  9651,   849,
          7370,    13,  9651,  2867, 29936,    13,  4706,  1206,  7142,   291,
          2624, 29889, 24705, 29918,  4897, 29901,    13,  9651,   849,  2796,
            13,  9651,  2867, 29936,    13,  4706,   500,    13,  4706,   736,
          2089, 29936,    13,  1678,   500,    13,  3680,    13,    13,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2],
        [    1,  9511,  1547,  4127,   310,  1023, 29899, 18448,  2030,   365,
           962,  1056, 11248,   302,  2075,  6322,   304,   777,  8024,  6597,
         29879, 29889,    13,  1576,   286,  3028, 22142,   562, 23670,  3104,
          3819,   310, 29871, 29896, 29955, 20537,   713, 18577, 23892,   491,
           278,  1597, 29894, 26191,   630,  7618,   311,  4094,   313,  4462,
         29907, 29956, 29897,  1158,   471, 19030,   373,  1023, 29899, 18448,
          2030,   365,   962,  1056, 11248,   302,  2075,  6322, 19387,  1558,
         29889, 22853,  6597, 29879,   892,   451,  6136,   541,  6597, 29879,
           310,  7392,   273,  3246,   263,   387,  3637,   423,  1113, 29892,
          3164,  1141,   423, 21672,  1458, 29892, 10211,  5872,   423,  2959,
         17894,  2236, 29892,   315,   790,  1160,   295,   359,   286,  1682,
          1617,   532, 29892,  5953, 22826,  9200,  4287, 29886,   398, 29892,
           476,   335, 18556,   263,  1341, 12679, 29892,  6461, 11836,   274,
          2152,   333, 28963, 29892,  4815,   423,  3711,   407, 28634,  3857,
         29892,  2043, 17125,   398,  2485, 10222,   398, 29892, 21286,   542,
           287,   276,   433, 21062,   816, 25675, 29892, 26700,  2841, 29874,
          3405, 28963,   322,  5356,   332,   333, 11989,  1472,   666,   287,
           348,  1810,   532,   892,   286,  3028, 22142,   562, 23670, 29889,
          1670,   338,  7037,   363,  1009,  5434,   671,   297,   278, 23387,
          2761,   310,   365,   962,  1056, 11248,   302,  2075,  6322, 29892,
           408,  1532,   408,   916,  5807,  2234, 29889, 15533,  2877,   848,
           363,   454,   386,   284, 26702,  1819,   363,   599,  6597, 29879,
           892,  3483,   952,   287,   491,   671,   310,  2070,   277, 13852,
         29889,   450,  7568,   322,  5224, 25947, 29884,  1455, 13071,   310,
           278,   365, 29907, 29945, 29900,   313, 29925,   353, 29871, 29900,
         29889, 29900, 29945, 29897,   892,   884, 10087, 29889]],
       device='cuda:0')
torch.Size([2, 258, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [-10.6953, -11.7812,  -5.2227,  ...,  -6.0820,  -9.1250,  -6.8516],
         [-11.5078, -12.3750,  -3.2422,  ...,  -5.0000,  -5.4648,  -3.9512],
         ...,
         [ -3.2910,   4.8047,   7.8516,  ...,  -1.6367,  -0.1179,   1.6211],
         [ -4.8398,   3.4238,   7.8203,  ...,  -1.8057,  -1.2871,   2.1836],
         [ -6.9414,   1.1279,   6.4805,  ...,  -2.4746,  -2.8398,   1.4746]],

        [[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -9.0547, -10.2812,  -3.3672,  ...,  -2.5293,  -3.4492,  -4.8281],
         [ -4.5820,  -4.1016,   4.2031,  ...,   2.1211,  -1.5684,   0.5400],
         ...,
         [ -6.2070,  -6.3906,   3.8848,  ...,  -3.6387,  -3.1035,   1.0693],
         [ -3.0410,  -3.3184,   9.7578,  ...,  -1.1055,  -1.1807,  -1.5156],
         [ -7.4883,  -8.6094,  12.9062,  ...,  -1.6572,  -5.7188,  -1.8506]]],
       device='cuda:0')
torch.Size([2, 258, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [ 7448],
         [10012],
         [  278],
         [  278],
         [  526],
         [  297],
         [  278],
         [  278],
         [ 2826],
         [  363],
         [   13],
         [29902],
         [  626],
         [  304],
         [ 6459],
         [ 2221],
         [30488],
         [ 6459],
         [30488],
         [  263],
         [  376],
         [  313],
         [13587],
         [ 1623],
         [ 2826],
         [ 1623],
         [29889],
         [  451],
         [  896],
         [30488],
         [  338],
         [  748],
         [  310],
         [  306],
         [30488],
         [30488],
         [30488],
         [  278],
         [30488],
         [30488],
         [  373],
         [29889],
         [30488],
         [29889],
         [  306],
         [  306],
         [30488],
         [  306],
         [  437],
         [ 1048],
         [ 2599],
         [  445],
         [  763],
         [  445],
         [29973],
         [   13],
         [  306],
         [   13],
         [  263],
         [29892],
         [30488],
         [  278],
         [ 2826],
         [  322],
         [  306],
         [  263],
         [30488],
         [30488],
         [  322],
         [20404],
         [30488],
         [  775],
         [29892],
         [   13],
         [   13],
         [29898],
         [  338],
         [24104],
         [30488],
         [24104],
         [30488],
         [29912],
         [   13],
         [ 1678],
         [30488],
         [29889],
         [   13],
         [   13],
         [ 2962],
         [30488],
         [  372],
         [ 2745],
         [29913],
         [   13],
         [ 2870],
         [  565],
         [30488],
         [29889],
         [  890],
         [   13],
         [   13],
         [  392],
         [ 1554],
         [  278],
         [  310],
         [  373],
         [  763],
         [   13],
         [   13],
         [   13],
         [22550],
         [29901],
         [   13],
         [   13],
         [ 3492],
         [30488],
         [  278],
         [ 1551],
         [30488],
         [30488],
         [29889],
         [29915],
         [  263],
         [30488],
         [30488],
         [  393],
         [  366],
         [29892],
         [13120],
         [  511],
         [  322],
         [30488],
         [  313],
         [14096],
         [29897],
         [   13],
         [   13],
         [29889],
         [  842],
         [30488],
         [15852],
         [29898],
         [29898],
         [ 1482],
         [ 1551],
         [15852],
         [ 3962],
         [  580],
         [  426],
         [   13],
         [ 1678],
         [  732],
         [ 4640],
         [   13],
         [ 1678],
         [  970],
         [30488],
         [30488],
         [15852],
         [ 2624],
         [ 1043],
         [  325],
         [29892],
         [ 7142],
         [29871],
         [ 2624],
         [30488],
         [30488],
         [  426],
         [   13],
         [ 4706],
         [  565],
         [  313],
         [ 3696],
         [29889],
         [  657],
         [ 4276],
         [ 3101],
         [  426],
         [   13],
         [ 9651],
         [ 1206],
         [ 7142],
         [  291],
         [ 2624],
         [29889],
         [24705],
         [29918],
         [ 3970],
         [16048],
         [29901],
         [   13],
         [ 9651],
         [ 4522],
         [  437],
         [  278],
         [ 9651],
         [ 2867],
         [29936],
         [   13],
         [ 4706],
         [ 1206],
         [ 7142],
         [  291],
         [ 2624],
         [29889],
         [24705],
         [29918],
         [ 4897],
         [29901],
         [   13],
         [ 9651],
         [  849],
         [22303],
         [   13],
         [ 9651],
         [ 2867],
         [29936],
         [24366],
         [ 4706],
         [  500],
         [   13],
         [ 4706],
         [  736],
         [ 1565],
         [29936],
         [   13],
         [ 1678],
         [  500],
         [   13],
         [ 3680],
         [   13],
         [   13],
         [20001],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29896],
         [   13],
         [   13],
         [   13]],

        [[29892],
         [ 1103],
         [ 4127],
         [  310],
         [  278],
         [29899],
         [12531],
         [29899],
         [ 2545],
         [29889],
         [  424],
         [11248],
         [  380],
         [29889],
         [ 6322],
         [ 5807],
         [14586],
         [10849],
         [ 6597],
         [29879],
         [  322],
         [26360],
         [ 1576],
         [ 2858],
         [ 3028],
         [22142],
         [  365],
         [23670],
         [ 6354],
         [ 3819],
         [  310],
         [  777],
         [29896],
         [29900],
         [ 8024],
         [  713],
         [ 8024],
         [  471],
         [  411],
         [ 1105],
         [ 1105],
         [  339],
         [26191],
         [  630],
         [  899],
         [  311],
         [15721],
         [  899],
         [23129],
         [29907],
         [29956],
         [29897],
         [ 1158],
         [  471],
         [ 7405],
         [ 2750],
         [ 1023],
         [29899],
         [18448],
         [ 2030],
         [  365],
         [  962],
         [ 1056],
         [11248],
         [  302],
         [ 2075],
         [ 6322],
         [29889],
         [  375],
         [  313],
         [  450],
         [14953],
         [29879],
         [  892],
         [ 1476],
         [  304],
         [  472],
         [  278],
         [29879],
         [  310],
         [ 3037],
         [  273],
         [ 3246],
         [  263],
         [11125],
         [  398],
         [19783],
         [ 1113],
         [29892],
         [ 3037],
         [29871],
         [  423],
         [  317],
         [30488],
         [29892],
         [ 3037],
         [ 5872],
         [  423],
         [  302],
         [17894],
         [ 2236],
         [29892],
         [ 3037],
         [29889],
         [30488],
         [  295],
         [  359],
         [  610],
         [19838],
         [ 1617],
         [  532],
         [  322],
         [  322],
         [  275],
         [ 9200],
         [ 4287],
         [29886],
         [  398],
         [  322],
         [19734],
         [30488],
         [30488],
         [ 6308],
         [ 1341],
         [12679],
         [29892],
         [ 4815],
         [30488],
         [  302],
         [30488],
         [11729],
         [28963],
         [  322],
         [ 4815],
         [  262],
         [31147],
         [30488],
         [28634],
         [ 2236],
         [29892],
         [13675],
         [30488],
         [14149],
         [  274],
         [29874],
         [  398],
         [  322],
         [13675],
         [  273],
         [29876],
         [  276],
         [24366],
         [31147],
         [  816],
         [30879],
         [  322],
         [13675],
         [ 2841],
         [29874],
         [  270],
         [28963],
         [  322],
         [29175],
         [30488],
         [  333],
         [11989],
         [  365],
         [30488],
         [ 7486],
         [18627],
         [ 1810],
         [  532],
         [  892],
         [ 6136],
         [ 3028],
         [22142],
         [  293],
         [23670],
         [  472],
         [  450],
         [  471],
         [  694],
         [  363],
         [  278],
         [  671],
         [16035],
         [  297],
         [  278],
         [ 2761],
         [ 2761],
         [  310],
         [ 5807],
         [  962],
         [ 1056],
         [11248],
         [23093],
         [ 2075],
         [ 6322],
         [  297],
         [  278],
         [ 1532],
         [  408],
         [  916],
         [ 5807],
         [ 2234],
         [  322],
         [   13],
         [ 2877],
         [  310],
         [  892],
         [  278],
         [ 5309],
         [  284],
         [14953],
         [  313],
         [  313],
         [ 1269],
         [  278],
         [29879],
         [  892],
         [25890],
         [  952],
         [    1],
         [  773],
         [  263],
         [  310],
         [  263],
         [30488],
         [  322],
         [  322],
         [  450],
         [ 2582],
         [29871],
         [ 5224],
         [  454],
         [29884],
         [ 1455],
         [13071],
         [  310],
         [  278],
         [ 2070],
         [29907],
         [29945],
         [29900],
         [ 1819],
         [22795],
         [ 2239],
         [29871],
         [29900],
         [29889],
         [29900],
         [29945],
         [29897],
         [  363],
         [29871],
         [12833],
         [29889],
         [  450]]], device='cuda:0')
torch.Size([2, 258, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13,  1576, 29902,  ..., 29950,   797, 11184],
         [   13,  1576,  2277,  ..., 29896, 29909,   797],
         [   13, 29937,  2277,  ..., 29930, 29896, 29958]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1103, 29886, 14167,  ...,   812,   347, 14081],
         [ 4127,  1821,   747,  ...,   573, 13876,   519],
         ...,
         [12833, 10087, 15899,  ..., 10723, 19030,   715],
         [29889,   363,   322,  ...,   304,  3983,   408],
         [  450,    13,     2,  ...,  6213,   319,  4525]]], device='cuda:0')
Batch 15, 22.6% of total tokens
encoded shape: torch.Size([2, 2038])
torch.Size([2, 2038]) tensor([[    1,  5293,   596,  ...,     2,     2,     2],
        [    1,   319,  1353,  ...,  5761,   423, 29889]], device='cuda:0')
torch.Size([2, 2038, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-13.1641, -12.6719,  -8.1797,  ...,  -9.7188, -12.1562, -11.4688],
         [ -7.4453,  -8.4609,  -0.4541,  ...,  -3.0273,  -4.2656,  -4.2539],
         ...,
         [ -9.8672,   8.0078,  -3.2832,  ...,  -6.1719,  -4.5234,  -5.3281],
         [-10.0859,   7.6172,  -3.4590,  ...,  -6.2266,  -4.5586,  -5.5117],
         [-10.1641,   7.6133,  -3.5996,  ...,  -6.1250,  -4.4297,  -5.5273]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.2891,  -9.5703,  -6.6523,  ...,  -7.2969,  -8.5625,  -9.8438],
         [ -8.0625,  -7.7344,  -0.2362,  ...,  -3.0234,  -2.9414,  -2.2988],
         ...,
         [  3.0195,   0.7822,   2.1855,  ...,   3.9551,   5.7773,   3.4980],
         [ -6.3984,  -8.1172,   5.7852,  ...,  -0.7192,  -1.0840,  -4.3320],
         [ -7.5312,  -7.8047,  10.3906,  ...,  -0.7754,   0.4409,  -0.7075]]],
       device='cuda:0')
torch.Size([2, 2038, 1]) tensor([[[29892],
         [  278],
         [ 1914],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [  716],
         [  310],
         ...,
         [  423],
         [29889],
         [  512]]], device='cuda:0')
torch.Size([2, 2038, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  278,   263,  1749,  ...,   319,   848, 29871],
         [ 1914, 10426, 15040,  ...,  7314, 10656,  3271],
         ...,
         [    1,  7228, 29871,  ...,  4345, 29889, 29906],
         [    1,  7228, 29871,  ...,   448, 29906, 29896],
         [    1,  7228, 29871,  ...,   448, 29896, 29906]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  716,  2846, 16886,  ...,  8456,  1783,   558],
         [  310,   393,   287,  ...,   304,   297,   363],
         ...,
         [  423,   616,  1974,  ...,   293,   583, 21425],
         [29889, 29892,   297,  ...,  9101,  5312,   607],
         [  512,   450,   910,  ...,  6811,   739,  4525]]], device='cuda:0')
Batch 16, 25.0% of total tokens
encoded shape: torch.Size([2, 280])
torch.Size([2, 280]) tensor([[    1, 26132,  4750,  4947,  1147,  5521,   515,  2246,   438, 29899,
          1915, 11422,    13,    13, 29949,   280,  4750,  2355,  1790,  4802,
          5733,  9063,   358,   373, 15050,  4515,  3250,   746,  3037,   433,
          1582,  1283,  6270,  8372,  7733, 12537,  4846,   278, 12936,  1379,
           670,  1734, 29889,    13,  1576, 29871, 29953, 29899,  6661, 29899,
         29946, 29892, 29871, 29941, 29900, 29945, 29899, 29886,   618,   261,
           338,   278,  2106, 30010, 29879,  2246, 27289, 29892,  5545,   491,
          1784,   278,  2246,  8372,   297,   278,  4234, 29889,    13, 29911,
         11017, 29892,   263, 29871, 29946, 29899,  8508, 29892, 12784, 26132,
          4750,   975,  4797,  8064, 26911, 29889,   450,  1147,  5521, 16229,
         26132,  4750,   304,  1939, 29889, 29871, 29896, 29900,   297,   278,
         21505,  1338,  3815,  1162,  9216,   292,  7115,   886, 29889,  3600,
          3815, 29885,  1078, 29892,  9377, 19870,  8373,   497, 20349,   322,
         15332, 11546,  2741, 19512, 29892,   505,  2307, 19355,   304,   278,
         12936,  1379, 29889,    13, 29949,   280,  4750,   338,   884,   263,
          2186,   391,   363,   678,  1191,   414, 30010,   822,  6270,  1095,
          5826, 14045,  5013, 10327, 29892,   263, 29871, 29946, 29899,  8508,
         27289,  1058,  1497, 15050,  4515,  3250,   540,   674,  6755,  1546,
         26132,  4750, 29892, 13813,  4306,   322, 19444, 13353,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,  6850,  3040,   317,  1430,  3040,   349,  3289,  1660, 29903,
          1346, 28577,   612,  1955, 29968,  4810,  3580,  1525, 29950,  1430,
          5425, 12064,  2672, 19094,  8098, 28962,  1254, 12665,   319,  1783,
         30024,    13,    13,  2792, 27623,  2259,   319, 29889,   897,  7675,
          3476,  1111,  9326,   393,   670, 11118,   313, 29903, 29906, 29941,
         29896, 29946, 29897,  4502,   278,  1570,  3088,  4306, 18148,  9826,
         29892,  5306, 29871, 29896, 29906, 29892, 29871, 29906, 29900, 29896,
         29941, 29889,    13,    13,  6638,   304,  2472,   338, 27131,   304,
          4969,   385,  5177, 13417,   455,   345,   304,  6509,   322, 24233,
           362, 29889,  7634,   445, 13332,   362, 29892,   278,  1570,  3088,
          4306,  9538,   723,   367,  4148,  1891,   304, 14821,   278, 20590,
           310, 27758, 21218,   322,   916,  2472,  7788,   363,  2106,   946,
         15942, 29892,  3489,  6757, 29892,   322,   916,  5874,   284, 16212,
         29889,    13,    13, 30015, 20761,  8068,  1570,  3088,   414,   526,
           773,  1009,  1887,  9562,   304,  5925,  5703,   358, 28602,  1907,
           322,  5110,   716, 25078, 29889,   910, 11118,   723,  2758,  9562,
           304,  5224,  1009,   975,   354,   538, 29892, 16116,  1009,  7788,
         29892,   322,  5957,  2373, 12628,   901,   363,  3109,  3995,  1497,
         27623,   897,  7675,  3476,  1111, 29889,    13,    13,  4373,  3088,
          4306, 30010, 29879, 29871, 29946, 29892, 29900, 29900, 29900,  9562,
         18864, 14746,   310, 17208,   263,  1629,   373, 10596,  5832,  7395,
         21218,   515,  2024,  9691,   943, 29889, 13361,  5281,   278,  4306,
          9538,   304, 20590,  1438, 21696,  1980,   373,  2306,  3131,   310,
          5221,  1218, 16212, 29892,   674,  2758,   278,  4306,   304,  4017,
          5224, 26094,   322,  7621,  2130, 29889,    13,    13, 30015,  2059,
          1136, 17211,  1218, 10596,  5832, 29892,  8818, 10472,   414,  1033,
         16289, 14746,   310, 17208,   297,  4048,   886,   297,   925,   263,
          2846,  2440,  3995, 22834, 27623,   897,  7675,  3476,  1111, 29889]],
       device='cuda:0')
torch.Size([2, 280, 32000]) tensor([[[-8.0234e+00, -1.1396e+00, -5.4004e-01,  ..., -4.1914e+00,
          -5.6680e+00, -4.5898e+00],
         [-3.3945e+00, -4.3047e+00, -3.0391e+00,  ..., -9.3457e-01,
           2.1074e+00, -2.3672e+00],
         [-7.0859e+00, -6.9336e+00, -3.0391e+00,  ..., -2.8555e+00,
          -3.2949e+00, -5.1641e+00],
         ...,
         [-3.2227e+00, -1.3174e+00,  1.0430e+00,  ..., -3.0488e+00,
          -3.7441e+00, -2.4570e+00],
         [-3.2344e+00, -1.3291e+00,  1.0498e+00,  ..., -3.0566e+00,
          -3.7480e+00, -2.4648e+00],
         [-3.2383e+00, -1.3389e+00,  1.0576e+00,  ..., -3.0605e+00,
          -3.7480e+00, -2.4668e+00]],

        [[-8.0234e+00, -1.1396e+00, -5.4004e-01,  ..., -4.1914e+00,
          -5.6680e+00, -4.5898e+00],
         [-9.4062e+00, -1.1094e+01, -3.1348e+00,  ..., -7.7266e+00,
          -8.7422e+00, -8.6406e+00],
         [-8.9609e+00, -7.4805e+00, -9.9902e-01,  ..., -4.1562e+00,
          -8.1250e+00, -5.5000e+00],
         ...,
         [-1.2852e+00,  8.3542e-03,  8.4473e-01,  ...,  2.7832e+00,
          -5.1025e-01, -3.8135e-01],
         [-2.2344e+00, -7.2266e-01,  9.8672e+00,  ..., -6.0205e-01,
           7.2217e-01, -2.0273e+00],
         [-1.7373e+00,  3.1787e-01,  1.5711e+01,  ...,  6.3818e-01,
          -8.1787e-01, -2.0020e+00]]], device='cuda:0')
torch.Size([2, 280, 1]) tensor([[[29892],
         [ 2039],
         [ 5733],
         [ 9063],
         [ 5521],
         [ 9063],
         [29871],
         [29899],
         [29931],
         [ 1915],
         [11422],
         [  297],
         [29949],
         [29949],
         [  280],
         [ 4750],
         [  756],
         [  263],
         [ 1147],
         [ 1147],
         [ 1147],
         [  358],
         [  373],
         [  498],
         [ 4515],
         [30488],
         [ 4646],
         [30488],
         [30488],
         [30488],
         [  313],
         [30488],
         [22002],
         [30488],
         [30488],
         [ 9326],
         [  670],
         [12936],
         [29879],
         [  670],
         [30488],
         [29889],
         [   13],
         [29911],
         [29871],
         [29953],
         [29899],
         [ 6661],
         [29899],
         [29945],
         [29892],
         [29871],
         [29941],
         [29900],
         [29945],
         [29899],
         [29886],
         [30488],
         [12537],
         [  338],
         [  263],
         [29871],
         [30010],
         [29879],
         [ 1939],
         [30488],
         [  297],
         [ 5034],
         [  263],
         [30488],
         [  304],
         [ 1900],
         [ 4847],
         [  297],
         [30488],
         [30488],
         [  322],
         [  940],
         [ 3868],
         [11017],
         [  338],
         [ 1058],
         [30879],
         [29946],
         [30488],
         [ 8508],
         [30488],
         [  338],
         [26132],
         [ 4750],
         [  975],
         [  319],
         [30488],
         [30488],
         [29892],
         [  940],
         [12936],
         [30488],
         [30488],
         [  278],
         [ 4750],
         [30010],
         [ 1939],
         [29889],
         [29871],
         [29896],
         [29900],
         [  297],
         [  278],
         [29871],
         [30488],
         [29889],
         [30488],
         [30488],
         [  292],
         [30488],
         [  886],
         [29889],
         [   13],
         [30488],
         [25046],
         [ 1078],
         [29892],
         [ 2734],
         [19870],
         [30488],
         [30488],
         [30488],
         [  322],
         [ 1196],
         [30488],
         [30488],
         [30488],
         [29892],
         [  526],
         [  884],
         [19355],
         [  304],
         [26132],
         [12936],
         [ 1379],
         [29889],
         [   13],
         [29911],
         [  280],
         [ 4750],
         [11182],
         [  884],
         [ 2805],
         [ 2186],
         [  391],
         [  363],
         [ 2734],
         [30488],
         [30488],
         [30488],
         [29871],
         [30488],
         [22002],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [ 1058],
         [29871],
         [29946],
         [29899],
         [ 8508],
         [27289],
         [  515],
         [  338],
         [  540],
         [ 4515],
         [30488],
         [  540],
         [30010],
         [30488],
         [30488],
         [26132],
         [ 4750],
         [  322],
         [  319],
         [29892],
         [  322],
         [  315],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29902],
         [29902],
         [29902],
         [ 1576],
         [29871],
         [29871],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29892],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [18627],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [ 3040],
         [13780],
         [ 1430],
         [ 1299],
         [29901],
         [ 3289],
         [ 1660],
         [29903],
         [  350],
         [29933],
         [  612],
         [ 1955],
         [30488],
         [ 6850],
         [30488],
         [30488],
         [29950],
         [30879],
         [ 5425],
         [  856],
         [24492],
         [30488],
         [ 8098],
         [17067],
         [ 1254],
         [12665],
         [ 8079],
         [30488],
         [ 8079],
         [   13],
         [29903],
         [ 1576],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [  313],
         [30488],
         [29892],
         [30488],
         [30488],
         [29903],
         [29889],
         [30488],
         [29929],
         [29929],
         [29909],
         [  304],
         [  297],
         [ 1570],
         [ 3088],
         [ 4306],
         [29871],
         [  373],
         [  491],
         [  607],
         [29871],
         [29906],
         [29929],
         [  386],
         [29871],
         [29906],
         [29900],
         [29896],
         [30488],
         [29889],
         [  450],
         [ 1576],
         [ 1576],
         [30488],
         [30488],
         [29892],
         [  263],
         [  304],
         [  278],
         [  263],
         [ 1722],
         [  988],
         [  455],
         [30488],
         [  304],
         [  278],
         [29892],
         [29892],
         [30488],
         [29889],
         [  450],
         [  278],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [29892],
         [30488],
         [30488],
         [  304],
         [ 1653],
         [30488],
         [30488],
         [29892],
         [30488],
         [30488],
         [30488],
         [30488],
         [27758],
         [29889],
         [  363],
         [30488],
         [30488],
         [30488],
         [  322],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  560],
         [  284],
         [  322],
         [29889],
         [  910],
         [   13],
         [ 1576],
         [ 4013],
         [  322],
         [30488],
         [30488],
         [  414],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 2130],
         [30488],
         [30488],
         [30488],
         [ 1907],
         [29892],
         [30488],
         [30488],
         [30488],
         [29889],
         [  910],
         [30488],
         [29892],
         [ 2758],
         [ 9562],
         [30488],
         [ 3867],
         [30488],
         [30488],
         [30488],
         [29874],
         [30488],
         [  322],
         [ 1009],
         [30488],
         [29892],
         [  322],
         [  297],
         [  263],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1497],
         [27623],
         [  897],
         [30488],
         [30488],
         [ 1111],
         [29889],
         [ 1346],
         [   13],
         [ 1576],
         [ 3088],
         [ 4306],
         [29892],
         [30488],
         [29871],
         [25145],
         [29906],
         [30488],
         [29900],
         [29900],
         [29899],
         [30488],
         [30488],
         [  310],
         [17208],
         [30488],
         [30488],
         [30488],
         [  278],
         [30488],
         [  322],
         [30488],
         [29889],
         [  263],
         [29892],
         [30488],
         [29889],
         [  910],
         [30488],
         [  278],
         [ 1570],
         [  304],
         [29892],
         [14821],
         [  322],
         [ 7788],
         [30488],
         [30488],
         [30488],
         [ 3131],
         [  310],
         [ 9562],
         [30488],
         [ 9562],
         [30488],
         [ 9562],
         [ 2758],
         [ 9562],
         [ 9562],
         [ 9538],
         [  454],
         [  278],
         [30488],
         [  322],
         [  304],
         [30488],
         [  304],
         [   13],
         [   13],
         [ 1576],
         [ 4013],
         [14372],
         [30488],
         [30879],
         [10596],
         [30488],
         [29892],
         [ 9562],
         [30488],
         [  414],
         [29892],
         [ 4078],
         [ 7282],
         [  310],
         [17208],
         [  297],
         [ 4048],
         [30488],
         [ 3995],
         [  278],
         [  263],
         [30488],
         [30488],
         [ 3995],
         [ 1497],
         [27623],
         [  897],
         [ 7675],
         [ 3476],
         [ 1111],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 280, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 2039, 26584,  3214,  ...,   402, 10234,  4750],
         [ 5733,  8914,  7186,  ..., 12616, 24909,  4947],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 3040,  1718,  1299,  ..., 29902,  9468, 29965],
         [13780,  8079,   383,  ...,  1744,   315,   399],
         ...,
         [ 1111,  1113, 20587,  ...,  3476, 25145, 15126],
         [29889,  1058, 29892,  ...,     2,   636,  5069],
         [   13,  1346,     2,  ...,   940,  1570, 26622]]], device='cuda:0')
Batch 17, 25.5% of total tokens
encoded shape: torch.Size([2, 1643])
torch.Size([2, 1643]) tensor([[    1,   315,   524,  ...,     2,     2,     2],
        [    1,   450, 19937,  ...,  6136, 29889,    13]], device='cuda:0')
torch.Size([2, 1643, 32000]) tensor([[[-8.0000e+00, -1.0967e+00, -5.2686e-01,  ..., -4.1719e+00,
          -5.6445e+00, -4.5625e+00],
         [-8.3984e+00, -8.4141e+00,  1.8335e-01,  ..., -4.5078e+00,
          -3.9414e+00, -6.4688e+00],
         [-3.5039e+00, -1.0078e+01, -3.3340e+00,  ...,  4.1962e-02,
           1.2334e+00, -2.1055e+00],
         ...,
         [-3.8848e+00,  7.8438e+00, -1.7627e+00,  ..., -5.5420e-01,
           4.8853e-01, -1.3046e-02],
         [-4.0000e+00,  7.9375e+00, -1.7471e+00,  ..., -6.4453e-01,
           4.1479e-01, -5.6915e-02],
         [-4.2070e+00,  8.1172e+00, -1.7549e+00,  ..., -7.9053e-01,
           2.8467e-01, -1.4368e-01]],

        [[-8.0000e+00, -1.0967e+00, -5.2686e-01,  ..., -4.1719e+00,
          -5.6445e+00, -4.5625e+00],
         [-1.1812e+01, -1.0727e+01, -8.4219e+00,  ..., -8.2422e+00,
          -8.7500e+00, -7.5703e+00],
         [-9.1797e+00, -1.5156e+01, -2.0840e+00,  ..., -2.6230e+00,
          -1.1182e+00, -4.4023e+00],
         ...,
         [-2.3853e-01,  2.9175e-01,  1.6396e+00,  ...,  1.5547e+00,
           3.1133e+00,  8.7891e-01],
         [-6.2561e-02,  1.1836e+00,  1.9980e+00,  ...,  1.8447e+00,
           3.1719e+00,  1.5889e+00],
         [ 2.6953e-01,  2.2324e+00,  3.9785e+00,  ...,  2.0374e-01,
           3.0137e+00, -1.5625e-01]]], device='cuda:0')
torch.Size([2, 1643, 1]) tensor([[[29892],
         [ 6146],
         [  294],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [29871],
         [29899],
         ...,
         [23196],
         [19838],
         [19838]]], device='cuda:0')
torch.Size([2, 1643, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 6146, 14404,  1915,  ...,  4641,  1038, 14044],
         [  294,   336, 29875,  ...,  9864,   284,   279],
         ...,
         [    1,  7228, 14262,  ..., 28906,    10,  8132],
         [    1,  7228, 14262,  ..., 28906,    10, 29900],
         [    1,  7228, 14262,  ...,  8132, 26077,    10]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,  1570,   937,  ...,   349,   319,   390],
         [29899, 29871,  7243,  ...,   325,   478,  6434],
         ...,
         [23196, 26077, 21490,  ..., 27406, 14262, 20189],
         [19838, 18627, 23196,  ..., 26077, 23795, 24366],
         [19838, 18627, 25145,  ..., 14262, 21209, 23795]]], device='cuda:0')
Batch 18, 27.7% of total tokens
encoded shape: torch.Size([2, 511])
torch.Size([2, 511]) tensor([[    1, 24596,  1169,  ...,     2,     2,     2],
        [    1,   319,   558,  ...,   445, 12618, 29889]], device='cuda:0')
torch.Size([2, 511, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6641,  -4.5781],
         [-10.4141,  -8.1406,  -4.6992,  ...,  -3.2812,  -6.5312,  -3.1172],
         [-11.3828,  -9.4219,  -2.4277,  ...,  -5.6367,  -8.3594,  -6.5664],
         ...,
         [ -0.6655,   5.4453,  -1.5723,  ...,   1.3770,   1.9971,   1.4395],
         [ -2.3418,   6.1523,  -1.8926,  ...,   0.3792,   0.8765,   0.6592],
         [ -5.4219,   5.0977,  -2.2266,  ...,  -1.4492,  -1.1387,  -0.9082]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6641,  -4.5781],
         [-11.2891,  -9.5703,  -6.6523,  ...,  -7.2969,  -8.5625,  -9.8438],
         [-10.5391, -13.7422,  -7.5820,  ...,  -4.1797,  -4.7695,  -6.8516],
         ...,
         [ -9.7500,  -8.7031,   1.8730,  ...,  -4.9219,  -4.9688,  -2.4336],
         [ -3.3242,  -2.7949,   8.9453,  ...,  -2.4121,  -0.0585,   0.6411],
         [ -5.8164,  -6.9023,  10.1250,  ...,  -0.1283,  -2.5586,  -1.8730]]],
       device='cuda:0')
torch.Size([2, 511, 1]) tensor([[[29892],
         [  277],
         [29901],
         ...,
         [14262],
         [    1],
         [    1]],

        [[29892],
         [  716],
         [29871],
         ...,
         [12618],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 511, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  277, 17259,  1821,  ..., 29877,   663,  2105],
         [29901,   322,   363,  ...,   526,   310, 29914],
         ...,
         [14262, 26077, 23196,  ..., 25145, 31779,  6610],
         [    1, 14262,  7228,  ..., 18627, 31440, 31779],
         [    1,  7228, 17687,  ..., 31440,  4345, 26077]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  716,  2846, 16886,  ...,  8456,  1783,   558],
         [29871, 29906,   293,  ...,  3324,   265,  8395],
         ...,
         [12618,  2472,  3268,  ...,  4274,  5518,   470],
         [29889, 29914,   470,  ...,   297,   363,  2472],
         [   13,  3529,   306,  ...,   910,  3374,  2648]]], device='cuda:0')
Batch 19, 28.3% of total tokens
encoded shape: torch.Size([2, 292])
torch.Size([2, 292]) tensor([[    1, 16866,   333, 14650,   310,  2994,   484,   284,   379, 11279,
           567,   297,   263,   922, 23000,  9969,   424,  1058, 24328,  2347,
          4671,   356,  7413,   261,   363,  4059,  3663,   573,  4918,   261,
          1611,  4649,   262,   459,   493, 29891,   310,  6097,  1337,   537,
         29889,    13, 29909,  5188,  1535, 24354,  1058,   471, 13457,  1891,
           411,   278, 24876, 19263,   310,   409,   567,   275,   471, 14914,
           411,   652,   356,  1869,   261,  6731,  6235,   351,  2785,   363,
           946,  3663,   573, 13446,  3240,   262,   459,   493, 29891,   310,
          5188,  1337,   537, 29889,   360,  2593,  1509,  1034,   484,   284,
           321,   312, 26252,   322,  1034,   484,   284, 17546,   567,  8906,
           297,   278,  1492, 10977, 29892,   322,  7498,   561,  2603,   322,
          1034,   484,   284, 17546,   567,  8906,   373,   278,  2175, 10977,
           373,  1400,  3372,  1230,  2462, 29871, 29896, 29906, 29889,   450,
         16500,  6423,  1363,   310,  5881, 29875,   586,  6151,  1070, 24382,
           322,  9736,   397,  8739,   832,  3097, 29889,   922,   567,   275,
          1122,   367,   263, 17737,   329,   706,  7329,   304,   278, 24899,
           936,  2858,  1547,  4127,   310,   278, 16500,   363,   278,  1400,
          3372,  1230,  1034,   484,   284,  9545,   310,   278,  1869,   261,
         29889,   910,  6434,   756,   451,  1063,  9251,  8967,   297,   278,
         12845, 29889,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1, 29124,   936,  2050,   800,   297, 10695,  8491,  4768,  5996,
         18470,   515,  1970, 18642, 20710,  1883,  4338, 29901,   899,   794,
          2779,   322, 10430,  2779, 29889,    13, 29943,  6092,  2361, 29883,
           663,  9200, 21785,   293,  6382,   292,   313, 29943, 10403, 29897,
           338,   697,   310,   278,  5172,   342, 15678,   322,  1556, 13988,
         13698,   304,  6559,  3038,  1070, 14188,   297,   263,  8471,  2323,
          3038, 29889,   383, 10403,   756,  1063, 17644,  1304,   304, 11819,
           278, 25406,   322, 18652,  3620,   310,  1784,  4100,   938,   945,
           514,  1070,  4473, 21709,  1316,   408,  9243, 29906, 29974, 29892,
           379, 29974,   322,   274, 19297, 29889,   512,   278,  3236,   310,
          1749,  6559,   310,  3038,  1070, 20890,   411,  1970, 18642,   885,
          9450, 20501,  2361, 29883,   663,  9200,  1557,  2270, 29892,   591,
         17809,  1023,  8974,   310, 24238, 29879,   607,  1122,  4050, 17986,
         13917,  8340, 29889,  3824, 29892,   278,  4094,  2793,   310,   278,
           360,  4345, 29949,  1304,  1033,  6602,   278, 19201,   310,  8363,
           310,   278, 20501,  2361, 29883,   663, 27717,   964,  9101,   322,
           884,  2367, 14451,   304,   805,   332,  2738, 20501,  2361, 29883,
           663,   805,  1862, 29889,  6440,   368, 29892, 13229,   805,   609,
         23584, 10430, 29899, 18980, 21519,   800,   310,   350,  4741,  9207,
         20501,  2361, 29883,   663,   322,  3038,  1070,   282,  7273,   800,
           892, 10478,   297,  9101,   607,  1795,   367,  3984,  1639,  1457,
          9446,   408,  5613, 18178,  1541, 13076,  6030, 29889,  4525,   892,
          2678,  4318,   304,   367, 24238, 29879,   564,  5921,   515,  3620,
           297,  2143,  1461,   573, 16285,   310,   278,  5198,  4455, 17182,
          2861,   304,  2319,  1652,  5313, 29884,   800,   297, 10430, 29892,
           607,   297,  2507, 11981,   304,  4036,   528, 17741,   310,   278,
         12789,   284, 10694,  4589,   650,  5794, 10419,   408,  7182, 21519,
           800, 29889, 16564,   373,  1438, 13917, 29892,  3058,  6907,   800,
           363,   278,  2761,   322, 29007,  3381,   310,  2089,  4558,   526,
          9132, 29889]], device='cuda:0')
torch.Size([2, 292, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -9.5234, -12.3203,  -7.2930,  ...,  -4.0352,  -4.1367,  -6.4766],
         [ -6.3906,  -8.0859,  -4.8906,  ...,  -3.6758,  -5.5391,  -6.5156],
         ...,
         [ -3.2734,  -1.3066,   1.0576,  ...,  -3.0723,  -3.7402,  -2.4824],
         [ -3.2656,  -1.3203,   1.0654,  ...,  -3.0703,  -3.7402,  -2.4766],
         [ -3.2695,  -1.3477,   1.0752,  ...,  -3.0762,  -3.7480,  -2.4785]],

        [[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -8.7031,  -6.0703,  -7.4258,  ...,  -1.7305,  -1.3340,  -2.7207],
         [ -5.3711,  -5.5039,  -4.5625,  ...,  -5.7539,  -2.2207,  -5.3789],
         ...,
         [ -6.2148, -10.5547,   3.7891,  ...,  -1.9287,  -1.0664,   0.8438],
         [ -4.1211,  -5.8594,  12.0469,  ...,  -2.4023,  -0.2581,  -3.1543],
         [ -7.0156,  -7.9961,  12.8203,  ...,  -1.2266,  -0.2722,  -3.3027]]],
       device='cuda:0')
torch.Size([2, 292, 1]) tensor([[[29892],
         [  333],
         [ 6438],
         [  310],
         [  263],
         [  265],
         [  284],
         [ 2448],
         [11279],
         [ 7467],
         [12206],
         [  263],
         [ 4121],
         [ 9359],
         [ 4121],
         [  424],
         [  411],
         [24328],
         [ 2347],
         [  263],
         [21780],
         [ 7413],
         [  261],
         [19040],
         [ 4649],
         [ 3663],
         [  573],
         [ 6479],
         [  261],
         [ 1611],
         [ 8713],
         [  979],
         [  459],
         [  493],
         [29891],
         [  310],
         [ 6097],
         [ 1337],
         [  537],
         [   13],
         [  435],
         [29925],
         [29871],
         [ 1535],
         [28056],
         [  411],
         [ 8906],
         [ 6345],
         [ 1891],
         [  363],
         [22261],
         [24876],
         [19263],
         [  310],
         [13446],
         [  567],
         [  275],
         [ 8906],
         [14914],
         [  411],
         [ 1869],
         [  356],
         [ 1869],
         [  261],
         [ 6731],
         [ 6235],
         [  351],
         [ 2785],
         [  363],
         [  946],
         [ 3663],
         [  573],
         [13446],
         [ 3240],
         [  262],
         [  459],
         [30488],
         [29891],
         [  310],
         [ 5188],
         [ 1337],
         [  537],
         [  313],
         [  450],
         [  309],
         [ 1509],
         [ 1034],
         [  484],
         [  284],
         [ 1226],
         [  312],
         [29874],
         [ 8906],
         [ 1034],
         [  484],
         [  284],
         [17546],
         [  567],
         [ 8906],
         [ 2629],
         [  278],
         [16500],
         [10977],
         [ 2629],
         [  322],
         [  278],
         [  561],
         [  856],
         [ 8906],
         [ 1034],
         [  484],
         [  284],
         [ 1226],
         [  567],
         [ 8906],
         [  297],
         [  278],
         [ 2175],
         [10977],
         [29889],
         [  278],
         [ 3372],
         [ 1230],
         [ 2462],
         [29871],
         [29896],
         [29900],
         [29889],
         [  450],
         [16500],
         [  471],
         [  373],
         [  310],
         [ 4613],
         [13544],
         [  586],
         [ 6151],
         [30488],
         [24382],
         [  373],
         [ 2473],
         [30488],
         [  309],
         [  832],
         [ 3097],
         [29889],
         [  450],
         [ 9359],
         [  275],
         [  322],
         [  367],
         [  263],
         [12045],
         [17068],
         [  706],
         [ 7329],
         [  304],
         [  278],
         [ 5849],
         [  936],
         [ 5849],
         [ 1547],
         [ 4127],
         [  310],
         [14338],
         [ 1034],
         [  304],
         [  278],
         [ 5849],
         [ 3372],
         [ 1230],
         [ 5849],
         [  484],
         [  284],
         [  752],
         [29889],
         [ 1869],
         [ 1869],
         [  261],
         [ 6731],
         [   13],
         [ 1206],
         [  881],
         [  451],
         [ 1063],
         [ 8967],
         [ 8967],
         [29889],
         [  278],
         [12845],
         [29889],
         [   13],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [29892],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [   13],
         [ 1516],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [  936],
         [16886],
         [  800],
         [  363],
         [  278],
         [ 8491],
         [  322],
         [ 5996],
         [11916],
         [  515],
         [  278],
         [ 1312],
         [ 9200],
         [ 1883],
         [ 4338],
         [ 4558],
         [  263],
         [  794],
         [29879],
         [  373],
         [ 7182],
         [ 4771],
         [   13],
         [   13],
         [29999],
         [  996],
         [ 2361],
         [29883],
         [30488],
         [ 9200],
         [ 1557],
         [  267],
         [ 6382],
         [  292],
         [  310],
         [29943],
         [30488],
         [29897],
         [  338],
         [  263],
         [  310],
         [  278],
         [ 1556],
         [29899],
         [14338],
         [13698],
         [ 1556],
         [ 4100],
         [ 8492],
         [  297],
         [23033],
         [  278],
         [29899],
         [30488],
         [29889],
         [30488],
         [30488],
         [30488],
         [ 3038],
         [29889],
         [  450],
         [10403],
         [  338],
         [ 1063],
         [17644],
         [ 1304],
         [  297],
         [ 6559],
         [  278],
         [19753],
         [30488],
         [30488],
         [30879],
         [  310],
         [ 4768],
         [ 4768],
         [ 3038],
         [30488],
         [30488],
         [ 1070],
         [ 4959],
         [30879],
         [29892],
         [  408],
         [15835],
         [29906],
         [29974],
         [29892],
         [  274],
         [30488],
         [29892],
         [  390],
         [30488],
         [29889],
         [ 2398],
         [  445],
         [  383],
         [  310],
         [  383],
         [ 5925],
         [29892],
         [  278],
         [30488],
         [30488],
         [  304],
         [  383],
         [30488],
         [  383],
         [30488],
         [30488],
         [30488],
         [29883],
         [  663],
         [20710],
         [30488],
         [ 2270],
         [29892],
         [  591],
         [  505],
         [  393],
         [ 4655],
         [  310],
         [24238],
         [29879],
         [  393],
         [  526],
         [ 6602],
         [  278],
         [  383],
         [  443],
         [29889],
         [ 3118],
         [29892],
         [  278],
         [  383],
         [30488],
         [  297],
         [  278],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  367],
         [  278],
         [20501],
         [  310],
         [  278],
         [30488],
         [  263],
         [30488],
         [30488],
         [ 1760],
         [  663],
         [  270],
         [  964],
         [  278],
         [29889],
         [30488],
         [  278],
         [14451],
         [  304],
         [  263],
         [30488],
         [ 2738],
         [29892],
         [ 2361],
         [29883],
         [30488],
         [18470],
         [30488],
         [29889],
         [ 6440],
         [29892],
         [29892],
         [  278],
         [30488],
         [30488],
         [30488],
         [20501],
         [30488],
         [18980],
         [ 3620],
         [30488],
         [  310],
         [20501],
         [30488],
         [30488],
         [30488],
         [30488],
         [29883],
         [30488],
         [  892],
         [  274],
         [29899],
         [  274],
         [30488],
         [30488],
         [  892],
         [ 8900],
         [  297],
         [  278],
         [  297],
         [  892],
         [  367],
         [ 2861],
         [29899],
         [29899],
         [ 9446],
         [  408],
         [ 4768],
         [  313],
         [30488],
         [13076],
         [14188],
         [29889],
         [ 4525],
         [24238],
         [ 1476],
         [ 1476],
         [  304],
         [  367],
         [24238],
         [29879],
         [ 8581],
         [ 5921],
         [  515],
         [  278],
         [  297],
         [  360],
         [30488],
         [  573],
         [29899],
         [  310],
         [  278],
         [  360],
         [30488],
         [30488],
         [30488],
         [  304],
         [30488],
         [30488],
         [30488],
         [30488],
         [  800],
         [  297],
         [30488],
         [29889],
         [  322],
         [  297],
         [30488],
         [29892],
         [  304],
         [ 3620],
         [30488],
         [30488],
         [  297],
         [  278],
         [ 1970],
         [30488],
         [10694],
         [29889],
         [30488],
         [ 5794],
         [29889],
         [  292],
         [ 3038],
         [  292],
         [  800],
         [29889],
         [ 4525],
         [  373],
         [ 1438],
         [13917],
         [29892],
         [  591],
         [15031],
         [  800],
         [  526],
         [  278],
         [  383],
         [  310],
         [29914],
         [30488],
         [  310],
         [ 1438],
         [29899],
         [  526],
         [ 1754],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 292, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  333, 17834,  2350,  ..., 11222,  2879,  1557],
         [ 6438,  3061,   830,  ..., 13291,  3620,   390],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  936,   625,  1711,  ...,   895, 29381,   293],
         [16886,   322, 10754,  ...,   405, 25562,  2472],
         ...,
         [ 1754,  2183,  7972,  ..., 15648,   714,   883],
         [29889,   297,  1244,  ...,   607,  2400,   408],
         [   13,     2,  4525,  ...,   313,   910, 14187]]], device='cuda:0')
Batch 20, 28.8% of total tokens
encoded shape: torch.Size([2, 641])
torch.Size([2, 641]) tensor([[    1,   660, 29901,  ..., 29889,    13,    13],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 641, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [-10.6953, -11.7734,  -5.2188,  ...,  -6.0781,  -9.1250,  -6.8516],
         [-11.5234, -12.3828,  -3.2539,  ...,  -5.0117,  -5.4688,  -3.9629],
         ...,
         [ -6.7305,  -9.9531,   9.9922,  ...,  -2.0078,  -2.5957,  -3.1289],
         [ -6.5117,  -5.1992,  10.2812,  ...,  -3.4805,  -4.5742,  -2.9980],
         [ -7.6211,  -9.4844,   5.4102,  ...,  -2.4453,  -2.8438,  -1.8037]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [-10.6953, -11.7734,  -5.2188,  ...,  -6.0781,  -9.1250,  -6.8516],
         [-11.5234, -12.3828,  -3.2539,  ...,  -5.0117,  -5.4688,  -3.9629],
         ...,
         [ -3.9766,   9.0391,  -2.8730,  ...,  -1.0723,  -0.7441,   0.2727],
         [ -4.1289,   9.2422,  -2.8359,  ...,  -1.1631,  -0.8188,   0.2527],
         [ -4.3242,   9.4219,  -2.8984,  ...,  -1.3047,  -0.9448,   0.1893]]],
       device='cuda:0')
torch.Size([2, 641, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [22550]],

        [[29892],
         [14873],
         [ 1724],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 641, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13,   960,  1987,  ...,  1126,     2,  6975],
         [   13,  3644, 25559,  ...,     2,  2855, 14769],
         [22550, 20001,  3644,  ...,  3492,  6246, 29909]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [    1,  7228,  4345,  ..., 31440, 26502, 25528],
         [    1,  7228,  4345,  ..., 26502, 25528, 26077],
         [    1,  7228,  4345,  ..., 10888, 31440, 25528]]], device='cuda:0')
Batch 21, 29.6% of total tokens
encoded shape: torch.Size([2, 1053])
torch.Size([2, 1053]) tensor([[    1, 29871, 29896,  ...,    13,    13,    13],
        [    1,  6682,  8135,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1053, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -8.3984,   0.6177,  -1.6689,  ...,   2.6641,   0.4219,   0.0745],
         [-12.6641,  -7.2578,  -3.2578,  ...,  -6.5742,  -7.4023,  -6.8789],
         ...,
         [ -1.4482,  -1.8828,   6.0352,  ...,   0.0594,   1.1514,   0.0763],
         [ -2.7383,  -3.6387,   3.7129,  ...,  -1.1064,   0.4919,  -0.0562],
         [ -1.9062,  -2.6465,   1.9824,  ...,  -0.7104,   1.2637,   0.2795]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -8.8516, -10.4766,  -4.3008,  ...,  -0.1150,  -5.0000,  -7.1719],
         [ -5.9570,  -1.7686,   0.5566,  ...,  -2.5156,  -0.5903,  -1.9414],
         ...,
         [ -1.5156,   4.8789,   0.0815,  ...,   0.4565,   1.2852,   0.9175],
         [ -1.4756,   4.9766,   0.0819,  ...,   0.4766,   1.3203,   0.9370],
         [ -1.4590,   4.9336,   0.0211,  ...,   0.4885,   1.3545,   0.9331]]],
       device='cuda:0')
torch.Size([2, 1053, 1]) tensor([[[29892],
         [29896],
         [29900],
         ...,
         [   13],
         [23196],
         [23196]],

        [[29892],
         [  291],
         [ 4006],
         ...,
         [14262],
         [14262],
         [14262]]], device='cuda:0')
torch.Size([2, 1053, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29900, 29889, 29929,  ..., 29946, 29941, 29953],
         ...,
         [   13, 23196,     2,  ..., 12879,  1074, 24366],
         [23196,  3925,  2823,  ..., 25289, 26817, 27867],
         [23196, 18627, 25145,  ..., 11170, 28044,  6610]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  291,   402, 18527,  ...,  3439,   438,   322],
         [ 4006,   299,   275,  ...,   404, 29895,   264],
         ...,
         [14262,     1, 23196,  ..., 31779, 25145, 28044],
         [14262,     1, 23196,  ..., 31779, 25145, 28044],
         [14262,     1, 23196,  ..., 31779, 25145, 28044]]], device='cuda:0')
Batch 22, 31.2% of total tokens
encoded shape: torch.Size([2, 348])
torch.Size([2, 348]) tensor([[    1, 14589,  2679,  2165, 29892,  5493, 30066,   808,  5127,    13,
            13, 30157,  2679,  2165, 29871,   338,   263,  5720,   297,   278,
         19185,  6474,   310,   402, 13257,  5493, 30066,   808, 17326,  4238,
         22736, 29892,  2629,  5493, 30066,   808,  5127, 29892,  8622,   586,
           713,  4785,   440,  2631,  4034, 29892,   297,  9755, 29899, 25171,
         18898, 29889,    13,    13,  1123, 10662,    13,    13, 10900, 29901,
         29963,   453,  1179,   297,  5493, 30066,   808,  5127,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2],
        [    1, 21397,  1319,  1301, 24389,   362,   310, 20702, 24424, 29899,
         19910,  1133,   758,   280,  2679, 29747,   964, 20805,  3038, 29899,
          1753,   293,   993,   285, 26310,   286,   625, 29889,    13,  1576,
           454,  2679,   331,  3173, 20974,   491,   278, 20702, 15680,  1270,
           386, 29747, 24424,   322,   916,   454,  2679,   331,  6352,   293,
         24877,  2405,  6394,   505,  9251,   451,  1063,  1301, 24389,   519,
          2745, 11405,   470,  7378,  1156, 24424,   297,   542,  2785, 29889,
          7311, 21622,   272, 29899, 14940,  5198,  1540,  7208, 12903, 24379,
           297,  1716,  3805,  3665, 29875,   630,   322,   302,  1151,   286,
           625, 29892,   372,   756,   451,  1063,  1950,   304,  8161,   565,
           445,  1121,   338,  2861,   304,   337,  6929,   310,  9101,  2307,
          5198,   441,   284,  1891,   491, 24877,  2405,   375,   297, 20309,
         29892,   470,  9432, 29879,   385,  7846,   296, 29485,   297,   278,
           410, 29880,  9633,  1230, 13284,   322,   286,  2520,  6906,   310,
          1438,   376,  1457,   280,  2679,   331,   293, 29908,  9101, 29889,
          1763, 15544,  1438,  5626, 29892,   591,   505,  1301,   572,  9714,
         24424, 29899,   262,  3647,   287,   289,   650,  1766,   798,   964,
          9495, 27431,  6394,   393,   526,  5198,   348,  1189,  1711,  5198,
          1535,   322,  4550,   297,  5030,   519,   310,  2646,   615,   337,
          6929, 29889,  1334,  3461,  1244,   393,  2629,  3841,   310, 24424,
           297,   542,  2785, 29892,  1301, 24389,   519,  9101, 15390,   310,
         17135,   410, 11476,   297,  3058,   285, 26310, 18982,   508,   367,
         17809,   411,   445, 11043, 29889,  4525,  2582, 22222,   393,  9101,
           411,   278, 13284,   363, 20607,   454,  2679,   331,   293,   410,
         29880,  9633,   362, 29030,  1407,  4688,   297, 20702, 24424, 29899,
         19910,  1133, 17135, 29889,  2398, 29892,  9150,  1301, 24389,   362,
           471,  3595,   871,   297,  2531,   300,  1711,   385,   331,   293,
         23957, 10070,   313, 29956, 29916, 29914, 29956, 29894,   511,   607,
           526,   822,   293,   993,   297,   298,  4579, 12861,  2035,   293,
         20805,  9101, 29892,   322,   451,   297,  1009,  4226,   301,  5171,
         29885,  1078, 29889,  6549, 29892,   297, 15017,   411,  7786,   297,
         13901,   307, 13917, 29892,   445,   297,   325,  4243,   848, 14661,
           393,  4226,   298,  4579, 12861,  2035,   293,  9101, 29892,  7417,
           310,  5198,  1540,  7208, 12903, 29892,   508, 21301,   278,   286,
          2520,   424,   410, 11476,   310, 27615,  9101, 29889]],
       device='cuda:0')
torch.Size([2, 348, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.1875,  -7.6484,  -2.5664,  ...,  -5.8594,  -1.3857,  -4.4727],
         [ -8.5391, -10.7188,  -3.6914,  ...,  -4.1406,  -2.0176,  -6.2617],
         ...,
         [ -6.0273,   5.1367,  -0.7471,  ...,  -2.0020,  -2.1172,  -1.3105],
         [ -4.7188,   5.6211,  -1.0049,  ...,  -1.2588,  -1.3125,  -0.7715],
         [ -4.9688,   5.6055,  -1.0732,  ...,  -1.4180,  -1.5381,  -0.9790]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -9.7344, -11.0703,  -6.4062,  ...,  -4.3555,  -6.3906,  -7.0117],
         [ -5.9141,  -3.6855,  -4.1484,  ...,  -4.2891,  -4.1172,  -5.6211],
         ...,
         [ -6.4023,  -8.7578,   1.1445,  ...,  -4.3906,  -0.7783,  -1.4473],
         [ -5.2852,  -7.6523,   3.6113,  ...,  -2.9551,  -1.6250,  -2.1973],
         [ -4.1328,  -5.9102,  12.2656,  ...,  -1.3213,   0.5239,  -1.3350]]],
       device='cuda:0')
torch.Size([2, 348, 1]) tensor([[[29892],
         [ 6955],
         [11716],
         [29892],
         [18898],
         [26796],
         [  808],
         [17326],
         [29892],
         [29930],
         [30157],
         [ 2679],
         [ 2165],
         [  518],
         [  518],
         [  263],
         [ 5720],
         [  297],
         [  278],
         [19185],
         [ 6474],
         [  310],
         [  402],
         [13257],
         [30488],
         [  328],
         [  808],
         [17326],
         [ 4238],
         [22736],
         [29892],
         [ 2629],
         [ 5493],
         [  856],
         [  808],
         [ 5127],
         [29892],
         [ 8622],
         [  586],
         [  713],
         [ 4785],
         [  440],
         [ 2631],
         [ 4034],
         [29892],
         [  297],
         [ 9755],
         [29899],
         [25171],
         [18898],
         [29889],
         [  739],
         [   13],
         [ 2831],
         [15628],
         [  304],
         [   13],
         [ 7626],
         [29901],
         [30157],
         [  453],
         [ 1179],
         [  297],
         [ 8622],
         [30066],
         [  808],
         [ 5127],
         [10900],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29871],
         [29871],
         [29889],
         [30488],
         [30488],
         [30488],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [  450],
         [ 4345],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [    1],
         [    1],
         [    1],
         [    1],
         [ 7228],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [ 7228],
         [ 7228],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [ 7228],
         [ 7228],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [ 7228],
         [    1],
         [    1],
         [    1]],

        [[29892],
         [ 1319],
         [13285],
         [ 2187],
         [  362],
         [  310],
         [  263],
         [  368],
         [29899],
         [  690],
         [ 1133],
         [ 7167],
         [29899],
         [ 2679],
         [  331],
         [ 9101],
         [  454],
         [ 3038],
         [ 7329],
         [ 1753],
         [  293],
         [  993],
         [  286],
         [26310],
         [  286],
         [  625],
         [29889],
         [  435],
         [29903],
         [20702],
         [ 2679],
         [  331],
         [ 6352],
         [  393],
         [  491],
         [20702],
         [20702],
         [24424],
         [ 4125],
         [20009],
         [29747],
         [24424],
         [  313],
         [20702],
         [20702],
         [ 2679],
         [29747],
         [ 6352],
         [  293],
         [10636],
         [ 2405],
         [ 6394],
         [  526],
         [ 1063],
         [ 1063],
         [ 1063],
         [ 1301],
         [24389],
         [  519],
         [  964],
         [  278],
         [ 1156],
         [ 7378],
         [ 1156],
         [  297],
         [  297],
         [20309],
         [ 2785],
         [29889],
         [ 1334],
         [  310],
         [  272],
         [ 2101],
         [ 2344],
         [ 3677],
         [ 6997],
         [20890],
         [12903],
         [ 1122],
         [  363],
         [  278],
         [  278],
         [ 3665],
         [29875],
         [30488],
         [  322],
         [ 1661],
         [  381],
         [  286],
         [  625],
         [29892],
         [  591],
         [  471],
         [ 1063],
         [ 1063],
         [ 1950],
         [  304],
         [ 8161],
         [ 3692],
         [  278],
         [ 9055],
         [  338],
         [ 2861],
         [  304],
         [  278],
         [30488],
         [  310],
         [  278],
         [29892],
         [30488],
         [30488],
         [  284],
         [ 1891],
         [  491],
         [  278],
         [30488],
         [  284],
         [29889],
         [20309],
         [  470],
         [  470],
         [ 3692],
         [29879],
         [  263],
         [  297],
         [  296],
         [  297],
         [  310],
         [  278],
         [11509],
         [30488],
         [ 9633],
         [ 1230],
         [ 7037],
         [  310],
         [29914],
         [30488],
         [30488],
         [ 7037],
         [  278],
         [21622],
         [ 1457],
         [29899],
         [30488],
         [  331],
         [30488],
         [29908],
         [ 9101],
         [29889],
         [ 1334],
         [ 3211],
         [  445],
         [ 5626],
         [29892],
         [  591],
         [  505],
         [ 8906],
         [29899],
         [29889],
         [20702],
         [30488],
         [  262],
         [30488],
         [  287],
         [ 9101],
         [  650],
         [ 1766],
         [30488],
         [30488],
         [  302],
         [ 5312],
         [30488],
         [10225],
         [10225],
         [30488],
         [  348],
         [30879],
         [ 1711],
         [  322],
         [  275],
         [  322],
         [  297],
         [29892],
         [ 5030],
         [  519],
         [  310],
         [12560],
         [30488],
         [29899],
         [30488],
         [29889],
         [  450],
         [ 1476],
         [  393],
         [  393],
         [20702],
         [29871],
         [ 1156],
         [  297],
         [30488],
         [  542],
         [30488],
         [29892],
         [20702],
         [30488],
         [  519],
         [  454],
         [  508],
         [  310],
         [30488],
         [30488],
         [11476],
         [30488],
         [30488],
         [30488],
         [30488],
         [  286],
         [30488],
         [  367],
         [23968],
         [  297],
         [30488],
         [30488],
         [29889],
         [ 4525],
         [ 2582],
         [12266],
         [  393],
         [  278],
         [ 3041],
         [  278],
         [30488],
         [  304],
         [  454],
         [  410],
         [30488],
         [  331],
         [30488],
         [  297],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 2629],
         [ 4688],
         [  297],
         [  278],
         [30488],
         [  297],
         [19910],
         [30488],
         [15680],
         [  322],
         [   13],
         [29892],
         [  278],
         [ 1301],
         [30488],
         [  362],
         [  310],
         [  451],
         [  871],
         [  297],
         [  263],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  286],
         [29889],
         [29892],
         [29876],
         [30488],
         [30488],
         [30488],
         [30488],
         [  322],
         [  322],
         [14661],
         [  297],
         [30488],
         [  993],
         [  297],
         [ 1716],
         [30488],
         [30488],
         [30488],
         [  293],
         [20805],
         [ 9101],
         [29889],
         [  322],
         [  451],
         [  297],
         [  302],
         [30488],
         [30488],
         [30488],
         [29899],
         [  286],
         [  313],
         [ 4525],
         [29892],
         [  278],
         [12814],
         [  749],
         [  278],
         [30879],
         [13901],
         [  307],
         [11898],
         [29892],
         [  278],
         [  297],
         [  325],
         [ 4243],
         [  376],
         [14661],
         [  393],
         [  278],
         [20805],
         [29889],
         [30488],
         [30488],
         [  293],
         [20805],
         [  526],
         [  322],
         [  310],
         [ 1009],
         [ 1540],
         [ 7208],
         [29899],
         [29892],
         [ 1122],
         [ 4046],
         [  278],
         [  410],
         [30488],
         [  424],
         [  410],
         [30488],
         [  310],
         [20702],
         [ 9101],
         [  297],
         [   13]]], device='cuda:0')
torch.Size([2, 348, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 6955,   653,   370,  ...,  4858,  5693,   774],
         [11716,  2165,   340,  ...,   823, 29877, 29893],
         ...,
         [    1,  7228,  4345,  ...,  8132,    10,  2047],
         [    1,  7228,  4345,  ...,  8132, 26077,   891],
         [    1,  7228,  4345,  ...,  8132,   891, 26077]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1319,  3730, 13740,  ...,   363,   338, 15874],
         [13285,  2305,  5381,  ...,   349,   512, 14582],
         ...,
         [ 9101,   298,   758,  ..., 20805,  9736, 10416],
         [  297, 29889,   393,  ...,  1494,  3041,  4688],
         [   13,     2,  4525,  ...,  1954, 25485,  9788]]], device='cuda:0')
Batch 23, 31.6% of total tokens
encoded shape: torch.Size([2, 338])
torch.Size([2, 338]) tensor([[    1, 26475, 29879,   310, 21762, 29899,   355,  5676,   262,   373,
         25348, 14710,  6656,   297, 17294, 12786,   310,   758,   705,   273,
          1847,   364,  1446, 29889,    13,  4789,   296, 11898,   310,  3353,
         17294,   297,  7548,  2653,   567,   505,  4318,   263, 10902, 23806,
           297, 25348, 14710,  6656,  1494,   938,   945,   275,  1890,   313,
         29875, 29889, 29883,  1846, 17517,   310, 21762, 29899,   355,  5676,
           262,   313, 15349,   467,   910, 22522,  4392,  1475, 25348, 14710,
          6656,   297,   278,   274,   406,  1182,   284,  1034,  4776,   322,
           274,   406, 12562,   398,   304,  8161,  3692,   278,  2779,  3697,
         14014,  1831,  2068, 29889,  7803, 29899,   304, 10081, 29899,  3250,
         29899,  1025,   364,  1446,   892,  2183,   263,  2323, 16077, 20859,
           310, 20700, 29892,   322, 25348, 14710,  6656,   471,  1223, 11517,
         29871, 29896,   298,  2678, 29889,   512,   278,   274,   406,  1182,
           284,  1034,  4776, 29892,   263,  5120,   393,  1090,  1484,   267,
          4655, 29540,   310,  3038, 21666,   297,   278, 16800,   758, 29899,
           322,  1400, 29876,  2075, 23704, 29892, 20700, 16951,  9263,  1463,
         25348, 14710,  6656,   297, 29871, 29906, 29899,  3250, 29899,  1025,
           364,  1446, 29892,   322,   263, 23183,   297,  6335,   654,   471,
          7625,   491, 29871, 29946,  3841,   310,  5046, 29889,   512, 12814,
         29892,   278,   274,   406, 12562,   398, 29892,   263,  5120,   393,
         25088,   758, 24130, 10835,  1156, 12060, 29892, 10018,  3109,  4771,
         24858,   304, 20700,  2645,   278,  4688,  1400, 29876,  2075,  3841,
         29892,   322,   263, 23183,  2779,   471,   451,  1098,  7114,  2745,
         29871, 29896, 29900,  3841,   310,  5046, 29889,  5806,   472, 29871,
         29896, 29945,  3841,   310,  5046,   278,   297,  6335,   654,  4689,
           304, 22964,   728,   297,   278,  1034,  4776, 29892,   263, 23183,
          2779,   471,  1603,  3595,   297,   278,   274,   406, 12562,   398,
         29889,   405,   284,  2251,   650,  5557,   287,   278,  2933,   297,
          1716, 17294, 12786, 29892, 23941,   278, 27577,   310,  1015,   601,
           333,   337,  1547,   943, 29889,  4525,  2582, 12266,   393,   315,
          3059, 20700,   338, 13229,  2221,   304, 10551, 25348, 14710,  6656,
         10106,   278, 17294, 29892,   411,   278, 14176,  4771, 24858, 13920,
           292,   297,  1906, 12786,   411,  9939,  1380, 13574, 19257,   472,
           278,   931,   310, 14060,   545,   304, 20700, 29889],
        [    1,  1815,   306,  6232, 10426,  8986,  3957, 29973,    13,    13,
         29903,  3034,   386,  1112,   267,   505,   278,  2984,   304,  6232,
          8986,  3957,   411, 20810,  9224, 29889,  1317,   372,  1950,   304,
          6232,   263,  3957,   310, 10426,  8986,  1549, 22844,   577,   372,
           508,   367,  1304,   491,  2999,  9224,   373,   278, 17487, 29973,
           960,   372,   338,  1950, 29892,   607,  4964,  4495,   267,   437,
           306,   817,   304,  2601,   304,   367,  2221,   304,  2189,   372,
         29973,    13,    13,  6028,   306,  6232, 10426,  8986,  3957, 29973,
            13,    13,  8241,   310,  3236,   366,   508,  6232,   596, 10426,
          8986,  3957,  5948,   491,   773,   596, 14570, 18800,  7375, 17500,
         29889,  3387,  2507,   373,   278,  4607,   310,   596,  7375, 17500,
           607,   674,  1653,   385,  8986,  3957, 10640, 29889,  5901,  2305,
           508,   671,   278,  8986,  5948,   491,   773,  1009, 14570, 18800,
          3957, 29889,  3387,   748,   304,   596, 10426,  4444, 29892,   769,
          1831,   901,   769,  1831,   260,  1979,   292,   322,  2011,   519,
          7375, 17500,   322,  4607,   373,   596,  2011,   519, 14570, 18800,
          7375, 17500, 29889,   739,   338,  1407,  4780,   304,   437, 29889,
            13,    13, 29911,  5309, 29891, 29894,   338,   697,   310,   278,
          8236,  1650,  1326, 11376, 21653,  1422, 21420,   310, 11796,   414,
           322, 10343, 17968, 29889,  1334,   505,   263,  2898, 22899,  3815,
           310,  6351,  1338,   297,  1422, 10161,   393,   508,  3867,   366,
           411, 22688,  6851,   304,   263,  1999,   355,   310,   596,  4828,
         29889,  1334,   505,   263, 16955,   322, 24600,  3815,   310, 10257,
         23550,   411,  2473, 29899, 12531,  7271,   310,  3196,  2440, 29889,
          1094,   263,  1121, 29892,   591,  7738, 11029,  2793,   373,   263,
         12875,   310, 17800, 29889,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 338, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.9297,  -4.3203,  -2.2656,  ...,  -1.6221,  -4.6602,  -3.7871],
         [ -8.1328,  -4.5000,  -1.2529,  ...,  -2.2754,  -7.5898,  -4.3555],
         ...,
         [ -3.7207,  -7.0820,   5.5117,  ...,  -2.6777,   0.6099,   0.6982],
         [ -2.8496,  -4.4570,  10.8672,  ...,  -3.0625,  -2.1953,  -1.4941],
         [ -7.2891, -10.3594,  14.1094,  ...,  -2.5625,  -3.2891,  -3.0547]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.6562, -11.5859,  -7.4766,  ...,  -7.4141,  -7.0859,  -9.5781],
         [ -7.5156,  -8.6797,  -1.1709,  ...,  -1.5889,  -4.1719,  -2.5371],
         ...,
         [ -3.9609,  -0.9644,   0.9941,  ...,  -3.3691,  -3.6680,  -2.6816],
         [ -4.3594,  -0.6660,   0.8921,  ...,  -3.5312,  -3.5762,  -2.7832],
         [ -4.3125,  -0.6924,   0.9092,  ...,  -3.5137,  -3.5918,  -2.7754]]],
       device='cuda:0')
torch.Size([2, 338, 1]) tensor([[[29892],
         [  573],
         [  310],
         [  278],
         [29899],
         [25934],
         [ 5676],
         [  262],
         [  373],
         [  278],
         [14710],
         [ 6656],
         [  297],
         [ 4185],
         [21622],
         [  310],
         [  278],
         [ 5138],
         [  273],
         [ 1847],
         [  364],
         [ 1446],
         [29889],
         [ 5032],
         [29909],
         [  296],
         [11898],
         [  505],
         [  278],
         [17294],
         [ 8478],
         [ 2990],
         [  505],
         [  567],
         [  505],
         [ 4318],
         [  393],
         [10902],
         [ 7910],
         [  297],
         [25348],
         [14710],
         [ 6656],
         [  297],
         [17517],
         [  945],
         [  406],
         [ 1890],
         [17517],
         [29875],
         [29889],
         [29883],
         [ 1846],
         [17517],
         [  310],
         [21762],
         [29899],
         [  355],
         [ 5676],
         [  262],
         [  313],
         [15349],
         [29925],
         [  450],
         [23806],
         [  471],
         [ 1312],
         [  278],
         [14710],
         [ 6656],
         [  297],
         [  278],
         [ 7251],
         [  406],
         [ 1182],
         [  284],
         [ 1034],
         [ 4776],
         [29892],
         [ 7251],
         [  406],
         [12562],
         [  398],
         [  310],
         [ 8161],
         [ 3692],
         [  278],
         [23806],
         [  310],
         [14014],
         [ 2702],
         [ 2068],
         [29889],
         [  450],
         [ 6471],
         [18448],
         [ 2211],
         [29899],
         [ 3250],
         [29899],
         [ 1025],
         [  364],
         [ 1446],
         [  892],
         [11658],
         [  474],
         [ 2323],
         [  474],
         [20859],
         [  310],
         [20700],
         [  313],
         [  322],
         [25348],
         [14710],
         [ 6656],
         [  471],
         [ 1223],
         [11517],
         [  491],
         [29906],
         [29906],
         [ 2678],
         [  491],
         [  512],
         [  278],
         [  274],
         [  406],
         [ 1182],
         [  284],
         [ 1034],
         [ 4776],
         [29892],
         [25348],
         [ 7282],
         [29899],
         [  338],
         [ 1484],
         [  267],
         [17818],
         [ 5849],
         [  310],
         [ 3038],
         [ 1070],
         [ 2645],
         [  278],
         [ 1400],
         [ 1400],
         [  705],
         [  322],
         [ 1400],
         [29876],
         [ 2075],
         [ 3785],
         [29892],
         [20700],
         [16951],
         [12212],
         [ 1463],
         [25348],
         [14710],
         [ 6656],
         [29889],
         [  278],
         [29906],
         [29899],
         [  322],
         [29899],
         [ 1025],
         [  364],
         [30488],
         [29892],
         [  541],
         [  297],
         [  260],
         [23806],
         [ 6335],
         [30488],
         [  471],
         [ 8900],
         [  297],
         [29871],
         [29896],
         [ 3841],
         [  310],
         [ 5046],
         [29889],
         [  512],
         [  278],
         [29892],
         [  297],
         [  274],
         [30488],
         [12562],
         [  398],
         [29892],
         [  607],
         [ 5120],
         [  393],
         [ 1090],
         [ 1400],
         [30488],
         [30488],
         [ 1400],
         [12060],
         [29892],
         [10018],
         [  694],
         [ 4771],
         [24858],
         [  304],
         [20700],
         [29889],
         [  278],
         [  937],
         [ 1400],
         [29876],
         [ 2075],
         [ 3785],
         [29889],
         [  322],
         [  694],
         [ 7282],
         [  297],
         [  471],
         [  451],
         [ 8900],
         [ 7114],
         [ 2745],
         [29871],
         [29896],
         [29900],
         [ 3841],
         [  310],
         [ 5046],
         [29889],
         [  450],
         [  278],
         [29871],
         [29906],
         [29900],
         [ 3841],
         [  310],
         [ 5046],
         [29892],
         [  274],
         [ 6335],
         [30488],
         [  310],
         [  304],
         [ 4845],
         [  728],
         [29892],
         [  278],
         [  274],
         [30879],
         [29892],
         [  372],
         [ 7282],
         [ 2779],
         [  471],
         [ 1603],
         [ 8900],
         [  297],
         [  278],
         [  274],
         [  406],
         [12562],
         [  398],
         [29889],
         [ 4525],
         [30488],
         [30488],
         [29899],
         [29892],
         [  287],
         [  278],
         [  297],
         [  304],
         [  278],
         [12786],
         [12786],
         [29889],
         [23941],
         [  393],
         [ 5297],
         [  310],
         [ 1015],
         [29347],
         [  333],
         [  337],
         [ 1547],
         [  943],
         [29889],
         [  450],
         [ 2582],
         [ 4368],
         [  393],
         [20700],
         [30488],
         [12786],
         [  756],
         [  263],
         [  451],
         [30488],
         [  297],
         [25348],
         [14710],
         [ 6656],
         [  297],
         [  278],
         [  758],
         [29892],
         [  541],
         [  263],
         [  274],
         [ 4771],
         [24858],
         [13920],
         [  292],
         [  297],
         [  278],
         [12786],
         [  393],
         [  278],
         [19257],
         [30488],
         [  313],
         [29889],
         [  278],
         [  931],
         [  310],
         [17517],
         [  545],
         [29889],
         [  278],
         [29889],
         [   13]],

        [[29892],
         [  306],
         [  679],
         [  590],
         [  848],
         [  848],
         [  411],
         [   13],
         [ 6028],
         [29902],
         [  388],
         [  357],
         [  431],
         [  267],
         [  505],
         [  263],
         [11509],
         [  304],
         [ 6232],
         [10426],
         [ 3957],
         [  411],
         [  916],
         [ 9224],
         [29889],
         [  306],
         [  727],
         [ 1950],
         [  304],
         [ 6232],
         [10426],
         [10426],
         [ 1546],
         [  263],
         [ 8986],
         [ 3957],
         [12951],
         [29973],
         [  393],
         [  508],
         [  367],
         [ 1304],
         [  491],
         [  916],
         [ 9224],
         [21699],
         [  278],
         [ 1021],
         [29973],
         [   13],
         [ 4874],
         [  338],
         [ 1950],
         [29892],
         [  920],
         [10426],
         [ 4495],
         [  267],
         [  526],
         [  306],
         [  817],
         [  304],
         [  671],
         [  373],
         [ 6176],
         [ 2221],
         [30488],
         [  437],
         [  445],
         [29973],
         [   13],
         [   13],
         [22550],
         [30488],
         [ 6232],
         [10426],
         [ 8986],
         [ 3957],
         [29973],
         [   13],
         [   13],
         [29903],
         [29892],
         [29899],
         [  366],
         [  508],
         [ 6232],
         [  278],
         [10426],
         [ 8986],
         [ 3957],
         [  411],
         [29889],
         [  260],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [   13],
         [  748],
         [  373],
         [  596],
         [14570],
         [  310],
         [14570],
         [10426],
         [30488],
         [  322],
         [  338],
         [  367],
         [  263],
         [ 8986],
         [ 3957],
         [  363],
         [29889],
         [ 2567],
         [ 9224],
         [  508],
         [ 4511],
         [  445],
         [ 8986],
         [  491],
         [  491],
         [16791],
         [  596],
         [10426],
         [18800],
         [ 9224],
         [29889],
         [   13],
         [ 2507],
         [  304],
         [  278],
         [  376],
         [ 6055],
         [  322],
         [ 2507],
         [  304],
         [  278],
         [29892],
         [  399],
         [  260],
         [30488],
         [30488],
         [  322],
         [30488],
         [29889],
         [30488],
         [30488],
         [29889],
         [ 2507],
         [  373],
         [  278],
         [10426],
         [30488],
         [ 7375],
         [18800],
         [ 7375],
         [29889],
         [29889],
         [   13],
         [  674],
         [ 1407],
         [ 4780],
         [  304],
         [ 6232],
         [29889],
         [   13],
         [   13],
         [20001],
         [ 1979],
         [30488],
         [30488],
         [  666],
         [30488],
         [  310],
         [  278],
         [ 1900],
         [  322],
         [ 1326],
         [11376],
         [  363],
         [29871],
         [21420],
         [  310],
         [  306],
         [30488],
         [29892],
         [21600],
         [17968],
         [29889],
         [ 1334],
         [ 3867],
         [30488],
         [30488],
         [30488],
         [29892],
         [29889],
         [ 2902],
         [ 1338],
         [ 1058],
         [30488],
         [  409],
         [  310],
         [  508],
         [ 1371],
         [  366],
         [  411],
         [  278],
         [30488],
         [  304],
         [  596],
         [ 1353],
         [  355],
         [  310],
         [13315],
         [13315],
         [29889],
         [ 1334],
         [  505],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  310],
         [29871],
         [  322],
         [29889],
         [  263],
         [30488],
         [30488],
         [30488],
         [  297],
         [30488],
         [30488],
         [  297],
         [ 2688],
         [  263],
         [  760],
         [29892],
         [  591],
         [  505],
         [ 1880],
         [30488],
         [  393],
         [  263],
         [30488],
         [  310],
         [23820],
         [29889],
         [ 1334],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29902],
         [29902],
         [29902],
         [29902],
         [29902],
         [29902],
         [29902],
         [29902],
         [29902],
         [29902],
         [29892],
         [29892],
         [30488],
         [30488],
         [29889],
         [29892],
         [29892],
         [29892],
         [29892],
         [  306],
         [29892],
         [29892],
         [29892],
         [30488],
         [30488],
         [29889],
         [29892],
         [29892],
         [29892],
         [29889],
         [30488],
         [30488],
         [29889],
         [29892],
         [  306],
         [   13],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889]]], device='cuda:0')
torch.Size([2, 338, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  573,   310, 29879,  ...,   292, 29901,   322],
         [  310,  4587,   373,  ..., 29892, 29901,  1551],
         ...,
         [  278, 20700,   445,  ...,   263,  1095,   474],
         [29889, 29892, 14030,  ..., 29901,  2645, 17517],
         [   13,   450,     2,  ...,  6549, 12808,  2398]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  306,   366,  4428,  ..., 29915,  2265,   591],
         [  679,   671,  2125,  ...,   367,  2244, 15649],
         ...,
         [30488, 30879, 29889,  ...,   313, 29899, 30186],
         [29889, 29892, 29871,  ..., 30282,   856, 29914],
         [29889, 29892, 30488,  ..., 30282,   856, 29914]]], device='cuda:0')
Batch 24, 32.2% of total tokens
encoded shape: torch.Size([2, 352])
torch.Size([2, 352]) tensor([[    1, 20861,   347,  1102,   279,   261,    13,    13,  3853,  1328,
          1102,   279,   261,   313, 29967, 15623,   653, 29871, 29906, 29953,
         29892, 29871, 29896, 29929, 29900, 29906,   785,  2610, 29871, 29945,
         29892, 29871, 29896, 29929, 29947, 29929, 29897,   471,   263, 10257,
          5733,  4847,   515,  1763,   839, 29877, 29892, 15821, 29889,   940,
         14283,   322,  5318,   670, 12755,  5733,   472,   278,  3014,   310,
         24337,   360,   420,   322,  3014,   310, 25749,  4702,  1270, 29889,
          5806,   472, 24337,   360,   420, 29892,  1102,   279,   261,  8581,
           263,   364,  2027,  1546,   278, 12755, 29915, 29879,  6673, 29892,
         17852,  5322,   365, 29889,   438, 29915, 29928,  3409,   514,   322,
          8360,  1082,  8027,   484, 29889,   512, 29871, 29896, 29929, 29906,
         29945,   438, 29915, 29928,  3409,   514,  1518, 14356,  1102,   279,
           261,   515, 24337,   360,   420, 29892,   363,   376,  1030, 14520,
           310, 29822,  1642,   910,  5331,   304,   263, 10021,   491,  1102,
           279,   261, 29915, 29879, 21955,   272, 29892,  6682, 11389,   267,
         29892,   263,  8078,   272,   515,  4107,  5899, 29889,  8027,   484,
           769, 28705,   373,  1102,   279,   261, 29915, 29879,  2306,  3131,
           363,  7378,   304,   438, 29915, 29928,  3409,   514, 29889,  9788,
          1102,   279,   261,   471,  6068,   304,  1708,   363,   278, 29871,
         29896, 29929, 29906, 29945,  4259, 29889,    13,    13, 29903,  3090,
           261,   769,  5318,   297,   278,  3086,  8914,  5165,   411,   278,
         25749,  6518,  3341,   297, 29871, 29896, 29929, 29906, 29953, 29892,
           278, 10173,  1372,  4909,  1085, 29877,   787,   297, 29871, 29896,
         29929, 29906, 29955,   322,   278, 25749, 11902,   369,  1475,   297,
         29871, 29896, 29929, 29906, 29947, 29889,    13,    13,  1123, 10662,
            13,    13, 10900, 29901, 29896, 29929, 29900, 29906, 12060, 29879,
            13, 10900, 29901, 29896, 29929, 29947, 29929,  4892, 29879,    13,
         10900, 29901, 14689,  5733,  2734,  1250, 29879,    13, 10900, 29901,
          6362, 15164, 11810,   550,  5733, 10769,    13, 10900, 29901,  3664,
           276,   360,   420, 26650,   292, 12601,  5733, 10769,    13, 10900,
         29901,  6362, 15164,  6518,  3341, 10769,    13, 10900, 29901,  6362,
         15164, 11902,   369,  1475,   313, 29940, 10536, 29897, 10769,    13,
         10900, 29901, 29925,   327,  1372,  4909,  1085, 29877,   787, 10769,
            13, 10900, 29901, 13454,   414,   310,  3082,  5733,   515, 15821,
            13, 10900, 29901, 29903,  4011, 25719,   515,  1763,   839, 29877,
         29892, 15821],
        [    1,  1763, 14707,   278,  2779,   310,   438,   299,   550,   300,
          1617,   373,  8104,   293,   322,  8078,   488,  6354,   322, 16225,
           297,  4226, 17800,   322, 22069,   411,   306,  9851, 29889,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 352, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.4805,  -9.9219,  -6.2539,  ...,  -4.0547,  -0.8315,  -5.2344],
         [ -9.2266, -12.5703,  -6.2852,  ...,  -6.6641,  -3.5742,  -8.5703],
         ...,
         [ -1.0527,  -1.8525,   6.9023,  ...,  -1.3496,   1.0889,  -0.1035],
         [ -4.5703,  -2.4551,   2.0820,  ...,  -3.6172,  -4.2539,  -2.7148],
         [  0.2345,   1.0889,  16.0781,  ...,  -2.3535,   0.5259,  -1.5010]],

        [[     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         ...,
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan]]],
       device='cuda:0')
torch.Size([2, 352, 1]) tensor([[[29892],
         [  347],
         [ 7487],
         [29874],
         [ 8212],
         [29892],
         [29923],
         [20517],
         [ 1328],
         [ 1102],
         [  279],
         [  261],
         [  313],
         [ 4939],
         [ 1540],
         [  653],
         [29871],
         [29896],
         [29947],
         [29892],
         [29871],
         [29896],
         [30488],
         [29896],
         [29929],
         [  785],
         [ 4779],
         [29871],
         [29896],
         [29892],
         [29871],
         [29896],
         [29929],
         [29947],
         [29896],
         [29897],
         [  471],
         [  385],
         [12755],
         [ 3082],
         [ 4847],
         [  297],
         [30488],
         [30488],
         [29877],
         [29892],
         [15821],
         [29889],
         [  940],
         [ 5318],
         [30488],
         [ 5318],
         [ 5733],
         [12755],
         [ 5733],
         [  472],
         [  278],
         [  313],
         [  310],
         [  315],
         [  360],
         [  420],
         [29889],
         [  471],
         [  310],
         [ 1763],
         [ 4702],
         [30488],
         [29889],
         [  940],
         [ 1098],
         [24337],
         [  360],
         [  420],
         [29892],
         [ 1102],
         [30488],
         [  261],
         [  471],
         [  263],
         [ 4771],
         [ 2707],
         [ 1546],
         [ 8360],
         [ 3762],
         [30488],
         [30488],
         [ 6673],
         [29892],
         [30488],
         [30488],
         [  438],
         [30488],
         [  438],
         [30488],
         [30488],
         [30488],
         [30879],
         [  322],
         [ 8360],
         [30488],
         [ 8027],
         [30488],
         [29889],
         [ 1102],
         [29871],
         [29896],
         [29929],
         [29906],
         [29946],
         [29892],
         [29915],
         [29928],
         [ 3409],
         [  514],
         [  750],
         [14356],
         [ 1102],
         [30488],
         [  261],
         [  515],
         [24337],
         [  360],
         [  420],
         [  363],
         [  322],
         [16831],
         [  535],
         [30488],
         [  310],
         [29822],
         [  322],
         [ 1102],
         [  471],
         [  304],
         [  263],
         [ 4307],
         [  491],
         [  278],
         [30488],
         [  261],
         [30488],
         [29879],
         [ 3815],
         [30488],
         [29892],
         [  278],
         [30488],
         [29892],
         [29892],
         [  263],
         [30488],
         [  272],
         [  297],
         [31147],
         [18076],
         [29892],
         [11389],
         [30488],
         [  471],
         [  620],
         [  393],
         [ 2306],
         [30488],
         [  261],
         [29915],
         [29879],
         [ 2306],
         [30488],
         [  322],
         [  670],
         [29892],
         [  679],
         [29915],
         [29928],
         [ 3409],
         [  514],
         [29892],
         [ 6864],
         [29892],
         [29874],
         [  261],
         [  471],
         [ 6068],
         [  304],
         [  736],
         [  363],
         [24337],
         [12601],
         [29896],
         [29929],
         [29906],
         [29945],
         [26650],
         [29889],
         [  940],
         [   13],
         [29923],
         [ 3090],
         [  261],
         [ 5318],
         [ 5318],
         [10257],
         [  278],
         [ 3086],
         [  313],
         [ 5165],
         [  313],
         [  278],
         [  315],
         [30488],
         [30488],
         [  297],
         [29871],
         [29896],
         [29929],
         [29906],
         [29953],
         [  322],
         [  322],
         [10173],
         [30488],
         [30488],
         [ 1085],
         [30488],
         [  787],
         [  297],
         [29871],
         [29896],
         [29929],
         [29906],
         [29955],
         [29892],
         [  278],
         [ 7646],
         [30488],
         [30879],
         [ 1475],
         [  297],
         [29871],
         [29896],
         [29929],
         [29906],
         [29947],
         [29889],
         [  940],
         [   13],
         [ 2277],
         [ 4011],
         [29901],
         [   13],
         [29930],
         [29901],
         [ 3664],
         [29929],
         [29900],
         [29906],
         [30488],
         [29879],
         [17943],
         [10900],
         [29901],
         [29896],
         [29929],
         [29947],
         [29929],
         [ 4892],
         [29879],
         [   13],
         [10900],
         [29901],
         [ 3664],
         [29889],
         [ 1410],
         [ 1250],
         [29879],
         [   13],
         [10900],
         [29901],
         [ 3664],
         [15164],
         [ 6518],
         [30879],
         [  313],
         [10769],
         [   13],
         [10900],
         [29901],
         [ 3664],
         [  276],
         [  360],
         [  420],
         [26650],
         [  292],
         [12601],
         [ 5733],
         [10769],
         [   13],
         [10900],
         [29901],
         [ 3664],
         [15164],
         [ 6518],
         [ 3341],
         [10769],
         [   13],
         [10900],
         [29901],
         [29925],
         [15164],
         [11902],
         [  369],
         [ 1475],
         [10769],
         [20012],
         [10536],
         [ 3815],
         [10769],
         [   13],
         [10900],
         [29901],
         [29925],
         [  986],
         [30488],
         [ 4909],
         [ 1085],
         [29877],
         [  787],
         [10769],
         [   13],
         [10900],
         [29901],
         [11574],
         [  414],
         [18627],
         [29889],
         [ 5733],
         [30488],
         [15821],
         [   13],
         [10900],
         [29901],
         [11574],
         [ 4011],
         [25719],
         [  515],
         [ 1763],
         [  839],
         [29877],
         [29892],
         [29889],
         [   13]],

        [[    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0]]], device='cuda:0')
torch.Size([2, 352, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  347, 29891,  4885,  ..., 29874, 29875,  1144],
         [ 7487, 10920,  4367,  ...,   341,   379,   315],
         ...,
         [29892, 10900, 23196,  ..., 29949,  5653, 19379],
         [29889, 29871, 29892,  ...,    13, 30488,   315],
         [   13,     2, 10900,  ..., 12883,  1576, 14689]],

        [[    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         ...,
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9]]], device='cuda:0')
Batch 25, 32.6% of total tokens
encoded shape: torch.Size([2, 1777])
torch.Size([2, 1777]) tensor([[    1,   450,  4815,  ...,   263,  1550, 29889],
        [    1,  3834,   310,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1777, 32000]) tensor([[[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [-11.8125, -10.7266,  -8.4219,  ...,  -8.2422,  -8.7500,  -7.5703],
         [ -9.5781, -12.3047,  -7.7539,  ...,  -4.3555,  -5.5820,  -9.0625],
         ...,
         [ -0.9824,  -2.0996,   1.8555,  ...,  -2.5527,   1.4336,   0.2224],
         [ -1.2891,  -1.2354,   6.6797,  ...,  -0.7979,   0.3252,  -0.8594],
         [ -0.8994,   0.3655,  12.8125,  ...,   1.2344,  -1.5186,   0.0298]],

        [[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [-13.8203, -13.4688,  -6.6250,  ...,  -7.3477, -11.8516,  -7.7852],
         [ -8.8984,  -7.7656,  -1.7744,  ...,  -2.6016,  -3.2246,  -4.1680],
         ...,
         [ -7.5820,   5.0859,  -1.7539,  ...,  -4.3906,  -5.3203,  -3.7656],
         [ -7.4492,   6.2539,  -1.3623,  ...,  -4.2930,  -5.2539,  -3.6152],
         [ -7.4609,   7.0938,  -1.2598,  ...,  -4.2812,  -5.2539,  -3.5566]]],
       device='cuda:0')
torch.Size([2, 1777, 1]) tensor([[[29892],
         [29871],
         [26803],
         ...,
         [ 1472],
         [29889],
         [   13]],

        [[29892],
         [  310],
         [  278],
         ...,
         [29892],
         [29892],
         [    1]]], device='cuda:0')
torch.Size([2, 1777, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,  1570,   937,  ...,   349,   319,   390],
         [26803, 29879,   292,  ..., 16923,  4412,   472],
         ...,
         [ 1472,  1550,  1407,  ...,   658,  2846,  6534],
         [29889,  3447,   304,  ...,  1286, 29991,  3969],
         [   13,     2,   450,  ...,   887,  1126,  1094]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  310,  2305,  3062,  ..., 29871,  2712,  2440],
         [  278,   366,   590,  ...,   596,  8680,   445],
         ...,
         [29892,   313, 29896,  ...,   448, 29889,   450],
         [29892,     1, 29896,  ..., 29889,   448, 30010],
         [    1, 29892, 29879,  ..., 29889,   448, 29871]]], device='cuda:0')
Batch 26, 34.5% of total tokens
encoded shape: torch.Size([2, 1217])
torch.Size([2, 1217]) tensor([[    1, 11647,  1985,  ...,   284,  7881,   756],
        [    1,  1383, 29939,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1217, 32000]) tensor([[[ -8.0312,  -1.1064,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6016,  -9.0859,  -4.4805,  ...,  -7.5781,  -9.0078,  -7.5586],
         [ -7.8672,  -6.4766,   0.6973,  ...,  -3.3223,  -5.8477,  -6.3867],
         ...,
         [ -9.8438,  -8.1172,   4.5391,  ...,  -5.2617,  -6.8359,  -6.3867],
         [ -2.4941,  -3.6895,   5.9180,  ...,  -1.4346,   3.4473,  -2.2324],
         [ -3.9863,  -4.9258,   5.8359,  ...,  -1.1826,   3.0430,  -1.7266]],

        [[ -8.0312,  -1.1064,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.5859,  -6.8945,  -2.3789,  ...,  -1.2900,  -1.9082,  -2.0664],
         [ -4.9961,  -4.8828,  -3.3652,  ...,   0.4314,   0.1740,  -5.3477],
         ...,
         [-14.8125, -10.7969,  -2.1875,  ...,  -9.0625,  -7.9062,  -8.3984],
         [-14.5156, -10.4844,  -1.6191,  ...,  -8.8125,  -7.5781,  -8.2344],
         [-15.0625, -10.7266,  -2.0391,  ...,  -9.2031,  -8.0312,  -8.5625]]],
       device='cuda:0')
torch.Size([2, 1217, 1]) tensor([[[29892],
         [  526],
         [  297],
         ...,
         [  322],
         [  756],
         [ 1063]],

        [[29892],
         [  459],
         [15705],
         ...,
         [  338],
         [  338],
         [  338]]], device='cuda:0')
torch.Size([2, 1217, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  526,  1058,   310,  ..., 30010, 29892,  6686],
         [  297,   472,   373,  ...,   304,   515,   408],
         ...,
         [  322,  2305, 14938,  ...,  1339, 12786,  3817],
         [  756,   338,   447,  ..., 29892,   961, 29987],
         [ 1063,  4953,   289,  ...,   884,  2041,   451]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  459,  6986,   666,  ...,  4362, 23453,   935],
         [15705, 21278,   666,  ...,  3605,  5750, 30083],
         ...,
         [  338,   275, 29924,  ..., 29903,   341,   471],
         [  338,   275, 29924,  ..., 29903,   341,   471],
         [  338,   275, 29924,  ...,   341, 29871, 29903]]], device='cuda:0')
Batch 27, 36.9% of total tokens
encoded shape: torch.Size([2, 353])
torch.Size([2, 353]) tensor([[    1,   660, 29901,    13,    13, 17038, 15376,  1813,  8951,   541,
          2020, 29973,    13,    13, 29902,   505,   385, 11322,   988,   474,
          2254,   263,  1813,   964,   263,  1933,  2000,  3646, 29889,   739,
          1736,  1532,   541,   411,   263, 10029, 12327,  5414,  6494, 29889,
            13, 10401,   306,  3965,   263,  6283,  1544,   372,   298,  2247,
           278,  1857,  2793,   322,  2254,   278,   716,   697,   541,   769,
           372,   298,  2247,   278,   716,   697,   322,  1510,   372,  1449,
         29889,   512,  3974,  6152,   474,  1074,   393,   278,  2471,  3732,
          1023,  7274,   363,   278,  1813,   372, 29915, 29879,  1811,   304,
          2254, 29889,  1205,   474,  5107,  2274,  2020,   372, 15376,   372,
          8951, 29973,    13, 29950, 11175,   590,  5804, 29901,    13, 29938,
         17350,  6654,  2564,  3808, 29898,  2220, 29898, 29872,  2597,    13,
          4706,   321, 29889, 22489,   890,    13,    13,  4706, 17575, 21720,
          2564, 11458, 29898, 29900,   416,  4706,    13,  4706,  7552,  5182,
          2824,  1420,   877, 29966,  4563,   770,   543,  3051,  1013, 29931,
          3689,   856,   829,  4563, 29958,  2157,    13,    13,  4706,  8184,
           657, 29898,  1366, 29889, 12653, 29892,   740, 29898,  1272, 29897,
           426,    13,    13,  9651,  8585,  5182,  2564, 11458, 29898, 29900,
         29892,   740,  4923,    13, 18884,  8585,  1491, 29918,  6510,  2564,
         21675,  3744,   703, 11255,  1496,   418,    13, 18884, 17575, 21720,
          2564,  4294, 29898, 29900,   416,    13, 18884,  2427,  1366,   467,
          1420, 29898,  1272,   467,  4294, 29898, 29900,   416,    13,  9651,
          2604,    13,    13,  4706,  2604, 29871,    13,    13,  3680,    13,
            13, 25353, 21778, 29991,    13,    13, 29909, 29901,    13,    13,
          3421,  4140,   674,   367,   393,   366,  2355, 29871, 29906,  3161,
           411,   770,   376,  6654,  1642,    13, 15870,  6655,  1566, 17350,
          6654,  2564,  2848,   416,   304,  1423,   920,  1784, 21268,   593,
         29879,   366,  2355, 29889,    13,    13, 29909, 29901,    13,    13,
          4013,   338,   515,   590,  3440,   373,   278,  6418, 29901,    13,
          9984,  1854,   596,   775,   363,   278,  2828,   871, 15376,  6732,
          4741, 29889,    13,    13,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,   624, 14389, 29892,   380, 14389,   856,    13,    13,   855,
         14389, 29892,   380, 14389,   856, 29871,   338,   278,  1473,  3769,
           491,   278, 20922,  1798,   311,   273,  4696,   713,  2610,   336,
          1126, 15464, 29892,  5492,   297, 29871, 29906, 29900, 29900, 29929,
         29889,    13,    13, 17936, 18028,    13,    13, 29871,   376,   855,
         14389, 29892,   380, 14389, 30098, 29908,   313, 12703,   336,  1126,
         15464, 29897,    13, 29871,   376, 29911,   305, 29976,  3746,  1055,
          3719,  1572, 29908,   313, 29928,  2212, 29891,  1913,   912, 29897,
            13, 29871,   376,  2008, 29884, 29908,   313, 12703,   336,  1126,
         15464, 29897,    13, 29871,   376, 29967, 29884, 29976,  1056, 29908,
           313, 29968,  8245,  2261,   833,  1362, 29897,    13, 29871,   376,
         29968,   787,  5170, 29879,   423, 29908,   313, 12703,   336,  1126,
         15464, 29897,    13, 29871,   376, 29949, 29881, 18597,   285,  2335,
         29976,   700, 29908,   313,   368, 10817, 29901,  2610,   336,  1126,
         15464, 29892,  4696, 29901,  5163,   273,  6981,   436,   295, 29897,
            13, 29871,   376, 29940,  2350,  9865, 29976, 17367, 29908,   313,
         29968,   326,   838,  1960, 29897,    13, 29871,   376,  7185,  1559,
         29878, 21299, 29908,   313,   368, 10817, 29901,  2610,   336,  1126,
         15464,   847, 10629,   819,   349,   275,  3270, 29892,  4696, 29901,
          2610,   336,  1126, 15464,   847, 14227,  1099,  1146,   349,  1000,
          1943, 29897,    12,    13, 29871,   376, 22050,  5871,  1354, 30098,
         29908,   313, 29968,   326,   838,  1960, 29897,    13, 29871,   376,
         28581,  2386, 29892,  1757,  1099,   301, 11054, 29908,   313, 25120,
         26454,  6640, 16234, 29897,    13, 29871,   376, 18210,   485,   336,
         29908,   313, 29924,  2628,  3182,  3934,  9194,  1362, 29897,    13,
         29871,   376, 29911,   332,  8645,  1690,  4977, 29908,   313, 29940,
          1981, 27832, 29897,    13, 29871,   376, 29931,   331,  1182,  1715,
          4977, 29908,   313, 29933, 24120, 29897,    13,    13,  1123,  1441,
            13,  1576,  3769,  2113,   278, 29318,   589, 12406,  1102,   497,
           572,  8606, 29895,   768,   638,  3861,   297,   278,  2787,  6125,
          7663, 29889,    13,    13,  1123, 10662,    13,    13, 25865,  2988,
            13, 29961,   624, 14389, 29892,   380, 14389, 17361,   472,  2178,
         23596,    13,  4205, 29883,  5275,  4004,   373,  2610,   336,  1126,
         15464, 29915, 29879,  6221,  1856,  3268,    13,    13, 10900, 29901,
         29906, 29900, 29900, 29929, 20618,    13, 10900, 29901, 12703,   336,
          1126, 15464, 20618]], device='cuda:0')
torch.Size([2, 353, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7734,  -5.2109,  ...,  -6.0781,  -9.1250,  -6.8438],
         [-11.5234, -12.3750,  -3.2461,  ...,  -5.0117,  -5.4688,  -3.9570],
         ...,
         [ -1.0664,   4.2188,   6.2969,  ...,   2.7871,   3.3340,   4.5625],
         [ -0.2659,   5.0664,   6.6328,  ...,   3.0996,   3.7324,   4.7266],
         [ -0.6885,   5.0664,   6.6328,  ...,   2.8691,   3.5117,   4.5273]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.6250,  -6.2305,  -0.3928,  ...,  -3.3535,  -4.0117,  -2.5742],
         [ -7.6250, -14.1484,  -2.9512,  ...,  -4.6016,  -5.4453,  -5.5977],
         ...,
         [ -1.0186,  -2.1680,   1.6934,  ...,   1.0107,   2.9062,   1.6816],
         [ -4.2383,  -2.4512,   7.9414,  ...,   0.7695,   0.8745,  -2.3984],
         [ -1.5352,   0.5991,  13.5312,  ...,   0.3645,  -0.7397,  -1.5264]]],
       device='cuda:0')
torch.Size([2, 353, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [21600],
         [  263],
         [  411],
         [29889],
         [  306],
         [29973],
         [   13],
         [   13],
         [29902],
         [  505],
         [  263],
         [12738],
         [ 6143],
         [  306],
         [ 2254],
         [  263],
         [ 1813],
         [  411],
         [  263],
         [13008],
         [29889],
         [  376],
         [29889],
         [   13],
         [ 1736],
         [ 2691],
         [  541],
         [  746],
         [  263],
         [ 8515],
         [ 8515],
         [ 5414],
         [ 6494],
         [29889],
         [   13],
         [   13],
         [  474],
         [ 2828],
         [  278],
         [ 2826],
         [ 2944],
         [29892],
         [15376],
         [ 2247],
         [  278],
         [ 3646],
         [ 1813],
         [  322],
         [15376],
         [  278],
         [ 3646],
         [  697],
         [29889],
         [  372],
         [  372],
         [15376],
         [ 2247],
         [  278],
         [  716],
         [  697],
         [  322],
         [ 2254],
         [  278],
         [ 1449],
         [29889],
         [   13],
         [  278],
         [ 6152],
         [  306],
         [  508],
         [  393],
         [  278],
         [ 3646],
         [15376],
         [  263],
         [ 7274],
         [  304],
         [  278],
         [ 1021],
         [29889],
         [15376],
         [30488],
         [ 8363],
         [  304],
         [ 2254],
         [29889],
         [   13],
         [ 2020],
         [ 1016],
         [ 4377],
         [ 2020],
         [29889],
         [  947],
         [  278],
         [ 8951],
         [29889],
         [   13],
         [   13],
         [30488],
         [  278],
         [  775],
         [  775],
         [   13],
         [   13],
         [12839],
         [ 6654],
         [  263],
         [ 3808],
         [29898],
         [ 2220],
         [ 4923],
         [ 3696],
         [30488],
         [   13],
         [ 1678],
         [17575],
         [29889],
         [22489],
         [  890],
         [   13],
         [ 4706],
         [ 4706],
         [17575],
         [ 5182],
         [ 2564],
         [ 4268],
         [  890],
         [29896],
         [  416],
         [   13],
         [  849],
         [ 4706],
         [17575],
         [ 5182],
         [ 2824],
         [ 1359],
         [29898],
         [29966],
         [22000],
         [  770],
         [29889],
         [13234],
         [ 3254],
         [18717],
         [29889],
         [  856],
         [  829],
         [ 4563],
         [29958],
         [ 2157],
         [   13],
         [ 4706],
         [ 4706],
         [ 8184],
         [ 6538],
         [26237],
         [ 2427],
         [29889],
         [12653],
         [29892],
         [  740],
         [29898],
         [ 1272],
         [ 2597],
         [  426],
         [   13],
         [ 9651],
         [ 9651],
         [17575],
         [ 5182],
         [ 2564],
         [ 1420],
         [29898],
         [29900],
         [  416],
         [  740],
         [ 4923],
         [   13],
         [18884],
         [ 8585],
         [ 5182],
         [ 5182],
         [ 6654],
         [ 2564],
         [ 1420],
         [  797],
         [29898],
         [28544],
         [ 1496],
         [   13],
         [   13],
         [18884],
         [ 8585],
         [ 3051],
         [ 2564],
         [21675],
         [29898],
         [29900],
         [  416],
         [   13],
         [18884],
         [ 8585],
         [ 1366],
         [  467],
         [ 1420],
         [29898],
         [ 1272],
         [  416],
         [21675],
         [29898],
         [29900],
         [  416],
         [   13],
         [ 9651],
         [ 2604],
         [   13],
         [ 4706],
         [ 4706],
         [ 2604],
         [   13],
         [   13],
         [ 1678],
         [ 1678],
         [   13],
         [   13],
         [20001],
         [21778],
         [29889],
         [   13],
         [   13],
         [22550],
         [29916],
         [   13],
         [   13],
         [29902],
         [  313],
         [  338],
         [  367],
         [  393],
         [  366],
         [29915],
         [30488],
         [29906],
         [ 1422],
         [  411],
         [  278],
         [ 6283],
         [ 6654],
         [ 1642],
         [   13],
         [   13],
         [  304],
         [29898],
         [17350],
         [ 6654],
         [ 2564],
         [ 2848],
         [  416],
         [  322],
         [29871],
         [  565],
         [29889],
         [ 3161],
         [  575],
         [29879],
         [  366],
         [  505],
         [29889],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [29902],
         [30488],
         [  263],
         [  278],
         [ 7271],
         [  373],
         [  278],
         [ 1139],
         [29915],
         [   13],
         [   13],
         [ 1854],
         [  366],
         [ 4544],
         [  313],
         [ 8363],
         [11322],
         [ 1741],
         [ 9545],
         [  278],
         [ 4741],
         [29889],
         [   13],
         [   13],
         [29902],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 2277],
         [ 2277],
         [ 5215],
         [ 5215],
         [ 5215],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[29892],
         [29889],
         [  316],
         [  263],
         [14389],
         [29892],
         [   13],
         [ 1576],
         [29949],
         [14389],
         [29892],
         [  380],
         [14389],
         [  856],
         [  904],
         [29896],
         [  263],
         [ 9512],
         [ 8693],
         [  491],
         [  278],
         [16078],
         [ 1798],
         [  311],
         [  273],
         [15640],
         [  713],
         [  856],
         [30488],
         [  856],
         [29878],
         [29889],
         [ 5492],
         [  297],
         [29871],
         [29906],
         [30488],
         [29900],
         [29955],
         [29889],
         [  739],
         [   13],
         [ 2277],
         [29871],
         [   13],
         [   13],
         [ 2277],
         [29896],
         [29903],
         [14389],
         [29892],
         [  624],
         [14389],
         [17794],
         [29908],
         [  338],
         [ 1725],
         [30488],
         [ 1126],
         [15464],
         [29897],
         [  785],
         [29871],
         [  376],
         [29903],
         [29889],
         [30488],
         [29892],
         [29908],
         [  260],
         [30488],
         [29908],
         [  313],
         [ 2855],
         [30488],
         [30488],
         [21826],
         [30488],
         [29892],
         [   13],
         [29871],
         [  376],
         [29924],
         [29884],
         [30488],
         [  313],
         [12703],
         [30488],
         [ 1126],
         [15464],
         [29897],
         [   13],
         [29871],
         [  376],
         [29924],
         [29976],
         [30488],
         [29908],
         [30488],
         [  313],
         [12703],
         [30488],
         [30488],
         [30488],
         [29892],
         [29897],
         [   13],
         [29871],
         [  376],
         [29924],
         [30488],
         [30488],
         [30488],
         [30488],
         [29908],
         [  313],
         [12703],
         [30488],
         [ 1126],
         [15464],
         [29897],
         [   13],
         [29871],
         [  376],
         [29903],
         [30488],
         [30488],
         [29908],
         [30488],
         [29976],
         [29908],
         [29908],
         [  313],
         [12703],
         [10817],
         [  491],
         [ 1913],
         [29874],
         [ 1126],
         [15464],
         [29892],
         [ 4696],
         [29901],
         [  360],
         [30488],
         [30488],
         [30488],
         [30488],
         [29897],
         [   13],
         [29871],
         [  376],
         [29924],
         [ 2350],
         [  330],
         [29908],
         [29908],
         [29908],
         [  313],
         [12703],
         [29889],
         [30488],
         [30488],
         [29897],
         [   13],
         [29871],
         [  376],
         [29903],
         [29980],
         [ 1212],
         [  681],
         [29908],
         [  313],
         [12703],
         [10817],
         [29901],
         [ 2610],
         [  336],
         [ 1126],
         [15464],
         [29892],
         [ 4696],
         [30488],
         [30488],
         [30488],
         [14262],
         [29892],
         [ 4696],
         [29901],
         [10629],
         [  336],
         [ 1126],
         [15464],
         [29897],
         [10629],
         [30488],
         [29892],
         [30488],
         [29889],
         [30488],
         [  847],
         [   13],
         [29871],
         [29871],
         [  376],
         [29924],
         [30488],
         [29908],
         [  336],
         [29908],
         [  313],
         [12703],
         [30488],
         [29892],
         [29889],
         [29897],
         [   13],
         [29871],
         [  376],
         [29924],
         [ 1076],
         [30488],
         [ 3036],
         [ 1099],
         [29908],
         [30488],
         [29908],
         [  313],
         [29968],
         [ 1484],
         [30488],
         [30488],
         [29897],
         [   13],
         [29871],
         [  376],
         [29924],
         [ 8247],
         [  336],
         [  316],
         [  313],
         [12703],
         [  585],
         [30488],
         [30488],
         [  847],
         [30488],
         [29897],
         [   13],
         [29871],
         [  376],
         [29903],
         [  305],
         [  655],
         [  296],
         [ 1512],
         [29908],
         [  313],
         [12703],
         [29889],
         [  349],
         [29897],
         [   13],
         [29871],
         [  376],
         [29903],
         [ 3365],
         [ 1182],
         [ 1743],
         [29879],
         [29908],
         [  313],
         [12703],
         [30488],
         [ 3182],
         [   13],
         [29871],
         [ 2277],
         [ 1441],
         [   13],
         [   13],
         [30488],
         [  471],
         [  278],
         [29871],
         [29871],
         [  317],
         [ 1102],
         [30488],
         [29899],
         [30879],
         [20041],
         [  768],
         [  638],
         [  297],
         [  297],
         [  278],
         [ 7663],
         [ 6125],
         [ 7663],
         [29889],
         [   13],
         [   13],
         [ 2277],
         [10662],
         [   13],
         [   13],
         [ 2277],
         [ 2988],
         [   13],
         [   13],
         [ 1124],
         [14389],
         [29892],
         [  380],
         [14389],
         [  856],
         [  472],
         [24262],
         [21238],
         [29889],
         [29961],
         [30488],
         [12099],
         [  472],
         [  472],
         [  278],
         [  336],
         [ 1126],
         [15464],
         [29915],
         [30488],
         [  376],
         [ 4700],
         [ 3268],
         [   13],
         [   13],
         [ 2277],
         [29901],
         [29906],
         [29900],
         [29900],
         [29929],
         [30879],
         [17943],
         [10900],
         [29901],
         [14058],
         [  336],
         [ 1126],
         [15464],
         [20618],
         [    2]]], device='cuda:0')
torch.Size([2, 353, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13,    12,  2277,  ..., 29902,  5215,   797],
         [   13,    12,  2277,  ..., 29937,   797, 29896],
         [   13,    12,  2277,  ...,   797, 29937, 29896]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29889,   388, 23693,  ...,  2707,   860,   519],
         [  316,   437,  1146,  ..., 29901, 29892, 29871],
         ...,
         [15464,  3665, 27364,  ...,  5606,  5803,  7940],
         [20618,  2313,  6475,  ..., 12516, 25764,     2],
         [    2, 17943,    13,  ...,  7663,  1293,  5262]]], device='cuda:0')
Batch 28, 37.5% of total tokens
encoded shape: torch.Size([2, 3757])
torch.Size([2, 3757]) tensor([[    1,  7813,   873,  ...,     2,     2,     2],
        [    1, 29871, 29896,  ..., 29953, 11278, 29973]], device='cuda:0')
torch.Size([2, 3757, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -9.0078, -11.9375,  -5.5859,  ...,  -4.4883,  -2.9160,  -8.0625],
         [-11.9609, -13.0156,  -6.3320,  ...,  -9.2188,  -5.0586,  -9.6094],
         ...,
         [-12.6719,  -2.5664,   0.7290,  ...,  -8.3672,  -8.0000,  -8.8594],
         [-12.6484,  -1.9482,   1.0391,  ...,  -8.3125,  -7.9922,  -8.6953],
         [-12.6875,  -1.4375,   1.2314,  ...,  -8.2500,  -8.0234,  -8.5703]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.3984,   0.6221,  -1.6709,  ...,   2.6641,   0.4211,   0.0731],
         [-12.6719,  -7.2656,  -3.2578,  ...,  -6.5781,  -7.4023,  -6.8789],
         ...,
         [ -3.5234,  -2.2246,   7.7695,  ...,  -0.1387,  -1.3857,  -0.6704],
         [ -8.3672,  -8.2578,   2.6777,  ...,  -0.8452,  -2.3555,  -4.8320],
         [ -3.0547,  -4.6562,  15.3438,  ...,  -3.1504,  -1.1211,  -3.3672]]],
       device='cuda:0')
torch.Size([2, 3757, 1]) tensor([[[29892],
         [ 4006],
         [29024],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29892],
         [29896],
         [29900],
         ...,
         [13862],
         [29973],
         [   13]]], device='cuda:0')
torch.Size([2, 3757, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 4006, 16470, 18419,  ..., 29890,  1362,   368],
         [29024,  4815, 29892,  ...,  2443, 15183,   438],
         ...,
         [29871, 29900, 29896,  ..., 29955, 29879, 29892],
         [29871, 29900, 29896,  ..., 29955, 29879, 29892],
         [29871, 29900, 29896,  ..., 29955, 29879, 29892]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29900, 29889, 29929,  ..., 29946, 29941, 29953],
         ...,
         [13862, 11278,   319,  ...,   402, 26354, 20499],
         [29973,  1577,   313,  ..., 29974, 15243,   322],
         [   13,     2, 29871,  ...,   334, 29906, 29945]]], device='cuda:0')
Batch 29, 42.3% of total tokens
encoded shape: torch.Size([2, 173])
torch.Size([2, 173]) tensor([[    1, 29871, 29945, 29946, 29953,   383, 29889, 29906, 29881, 29871,
         29929, 29900, 29955,    13, 29911,  1992, 29894, 29889, 29909,   430,
           562, 16233,    13,  3782, 29889, 29871, 29955, 29945, 29899, 29896,
         29896, 29896, 29929,    13,  2525,  1573,  3900,  9245,   310,  2401,
         29872,  1338, 29892, 29008,   386, 12594,  3121,    13, 29896, 29914,
         29941, 29896, 29914, 29955, 29955,    13, 29903, 29889, 29928, 29889,
         29943,   433,  1696, 29871, 29945, 29946, 29946,   383, 29889, 29906,
         29881, 29871, 29955, 29945, 29906,    13,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1, 26475,   310,   263, 17937,   424,   540,  1008,   373,  1400,
         29899,  3372,  1230, 13752,   837,   423, 29901, 10230,   411,   263,
          9432,   573,  9654,   300, 29889,    13,  1349, 13163, 22069,   411,
          1400, 29899,  3372,  1230, 13752,   837,   423,  1494,  4655, 25300,
           708,   313,   386,   272,   562,   293, 29892,   633,  3129,   979,
         29892, 14219,   459, 29874,  7486, 29897,   892, 19591, 20459,   304,
          2845,  6136,  1370,  4056,   411,   263, 17937,   424,   540,  1008,
           313, 29945, 29900, 29900,   399, 29897,   470,  1209,   573,   337,
         29893,  2817,   292,   411,   263,  9432,   573,  9654,   300, 29889,
         22914,   284, 10430, 29892,  2099, 19309, 10430,   313,   271,  3023,
          7540,  3864, 11840,   511,  9126,   447,   331,   468,   417,  2109,
           269,  1337,   362,   322,   528,  2147,   292,   892, 17005,   363,
         29871, 29906,   298,  1400, 29899,  3372,  6703, 29889,  8512,  1400,
         29899,  3372,  1230, 12871, 11421,   411,   263, 17937,   424,   540,
          1008, 20601,   297,  8473,   337, 29893,  2817,   292, 29892,   727,
           892,   694, 12651,  1546,   278,  1023,  6471,   411,  3390,   304,
           447,   331,   468,   417,  2109,   269,  1337,   362,   322,   528,
          2147,   292, 29889]], device='cuda:0')
torch.Size([2, 173, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5298,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.3984,   0.6235,  -1.6699,  ...,   2.6621,   0.4165,   0.0728],
         [-12.0781,  -8.2422,  -4.7305,  ...,  -9.4297,  -8.8984,  -7.8789],
         ...,
         [ -3.2715,  -1.3105,   1.1240,  ...,  -3.0742,  -3.7520,  -2.4648],
         [ -3.2852,  -1.3467,   1.1260,  ...,  -3.0859,  -3.7617,  -2.4727],
         [ -3.2793,  -1.3730,   1.1230,  ...,  -3.0879,  -3.7617,  -2.4707]],

        [[ -8.0312,  -1.1074,  -0.5298,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.9414,  -4.3359,  -2.2852,  ...,  -1.6270,  -4.6758,  -3.7988],
         [ -6.7852, -10.3594,  -0.5708,  ...,  -0.4226,  -3.3945,  -2.9609],
         ...,
         [ -3.5293,  -3.9570,   6.0703,  ...,  -2.4258,   0.4258,  -4.2969],
         [ -7.0625,  -8.5625,   0.7495,  ...,  -4.6055,  -2.3828,  -8.1094],
         [ -6.5547,  -6.5703,  11.9766,  ...,  -2.4824,   0.4155,  -3.9004]]],
       device='cuda:0')
torch.Size([2, 173, 1]) tensor([[[29892],
         [29896],
         [29900],
         [29900],
         [29900],
         [29889],
         [ 9179],
         [29881],
         [29871],
         [29896],
         [29929],
         [29929],
         [  313],
         [29907],
         [  261],
         [  325],
         [29889],
         [ 3303],
         [21198],
         [ 4018],
         [  272],
         [   13],
         [29907],
         [29889],
         [29871],
         [29955],
         [29941],
         [29899],
         [29896],
         [29896],
         [29896],
         [29896],
         [29889],
         [ 2525],
         [ 1573],
         [ 3900],
         [ 9245],
         [  310],
         [ 2401],
         [30488],
         [ 1338],
         [29892],
         [  405],
         [  386],
         [12594],
         [ 3121],
         [29889],
         [ 1433],
         [29929],
         [29896],
         [29896],
         [29914],
         [29955],
         [29955],
         [ 3323],
         [ 4035],
         [29889],
         [  315],
         [29889],
         [ 8490],
         [  433],
         [29889],
         [  360],
         [29955],
         [29900],
         [29896],
         [  383],
         [29889],
         [ 9179],
         [29881],
         [29871],
         [29896],
         [29929],
         [29945],
         [29892],
         [ 1433],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [29871],
         [29871],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 8096],
         [ 8096],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [  573],
         [  278],
         [29871],
         [12122],
         [ 5864],
         [ 1218],
         [  373],
         [  278],
         [ 3372],
         [ 3372],
         [ 1230],
         [ 6788],
         [  837],
         [  423],
         [  297],
         [  263],
         [  310],
         [  263],
         [11826],
         [  573],
         [ 3041],
         [  300],
         [   13],
         [ 4957],
         [29909],
         [  837],
         [22069],
         [ 1090],
         [  633],
         [29899],
         [ 3372],
         [ 1230],
         [13752],
         [  837],
         [  423],
         [  892],
         [  633],
         [25300],
         [  708],
         [  892],
         [12676],
         [  852],
         [  562],
         [  327],
         [29892],
         [  633],
         [ 3129],
         [  979],
         [29892],
         [14219],
         [  459],
         [29874],
         [ 7486],
         [29892],
         [  892],
         [ 4036],
         [  304],
         [  304],
         [ 7150],
         [  263],
         [17937],
         [ 4056],
         [  411],
         [  263],
         [17937],
         [  424],
         [  540],
         [ 1008],
         [  470],
         [ 4782],
         [29900],
         [29900],
         [  399],
         [ 1131],
         [  470],
         [  304],
         [  573],
         [ 1370],
         [29893],
         [ 2817],
         [  292],
         [  411],
         [  263],
         [ 9432],
         [  573],
         [ 9654],
         [  300],
         [29889],
         [  450],
         [  284],
         [10430],
         [  471],
         [ 7136],
         [19309],
         [10430],
         [29892],
         [ 4345],
         [  278],
         [11840],
         [ 3864],
         [11840],
         [  511],
         [  322],
         [ 5881],
         [  331],
         [  397],
         [  417],
         [ 2109],
         [  288],
         [ 1337],
         [  362],
         [  313],
         [ 9505],
         [ 2147],
         [  292],
         [  892],
         [11819],
         [29889],
         [29871],
         [29906],
         [29946],
         [ 1156],
         [29899],
         [ 3372],
         [ 6703],
         [29889],
         [  450],
         [  278],
         [29899],
         [ 3372],
         [ 1230],
         [13752],
         [ 6410],
         [  471],
         [  278],
         [17937],
         [  424],
         [  540],
         [ 1008],
         [  471],
         [  297],
         [  263],
         [  337],
         [29893],
         [ 2817],
         [  292],
         [29892],
         [  727],
         [  471],
         [  694],
         [ 7282],
         [  297],
         [  278],
         [ 1023],
         [ 6471],
         [  297],
         [ 3390],
         [  304],
         [ 2099],
         [  331],
         [  468],
         [  417],
         [ 2109],
         [  269],
         [ 1337],
         [  362],
         [29892],
         [  528],
         [ 2147],
         [  292],
         [29889],
         [  450]]], device='cuda:0')
torch.Size([2, 173, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29900, 28706, 29906,  ...,   323,   386, 29946],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  573,   310, 29879,  ...,   292, 29901,   322],
         [  278,   263,   360,  ...,   315,  1422,   405],
         ...,
         [  292, 10868, 16897,  ..., 20890,   266, 19435],
         [29889, 29892, 10868,  ...,   472,   470, 29511],
         [  450,  2398,   512,  ...,   319,  1939,  4121]]], device='cuda:0')
Batch 30, 42.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,  8512,   372,  ...,   450,  1556,  3619]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7812,  -5.2188,  ...,  -6.0781,  -9.1250,  -6.8477],
         [-11.5312, -12.3906,  -3.2480,  ...,  -5.0195,  -5.4805,  -3.9707],
         ...,
         [ -0.0609,   5.7305,  12.9219,  ...,   2.7539,  -1.2656,   2.3164],
         [ -0.0509,   5.6992,  12.9688,  ...,   2.7109,  -1.2646,   2.2559],
         [  0.0929,   5.7188,  12.9922,  ...,   2.7930,  -1.1230,   2.3008]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.0156,  -9.7500,  -6.3867,  ...,  -5.5117,  -7.9336,  -8.3359],
         [ -7.6719, -11.3906,  -1.2871,  ...,  -5.2148,  -4.2695,  -5.7461],
         ...,
         [ -3.5293,  -1.6055,   1.1377,  ...,  -3.2012,  -3.9062,  -2.6074],
         [ -3.9688,  -1.8633,   1.3867,  ...,  -3.5098,  -3.9805,  -2.7910],
         [ -4.1797,  -2.0977,   1.2520,  ...,  -3.7383,  -4.3203,  -2.7852]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [   13]],

        [[29892],
         [  278],
         [  338],
         ...,
         [30488],
         [30879],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13, 29871, 29906,  ..., 29912,     2, 29918],
         [   13, 29871, 29906,  ...,     2, 29912, 29918],
         [   13, 29871, 29906,  ..., 29900, 29912, 29918]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  278,   372,   306,  ...,   263,   540,   896],
         [  338, 30010,   471,  ...,  2444, 10083,  9007],
         ...,
         [30488, 30879, 31147,  ..., 30555, 31256, 29871],
         [30879, 30488, 31147,  ..., 29871, 29892, 30186],
         [30488,   313,   285,  ..., 30879, 30282,   263]]], device='cuda:0')
Batch 31, 46.9% of total tokens
encoded shape: torch.Size([2, 755])
torch.Size([2, 755]) tensor([[    1,  2803,   357,  ...,  7226, 29896, 29962],
        [    1, 26475, 29879,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 755, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.8828,  -9.7891,  -2.9512,  ...,  -6.3008,  -6.8281,  -7.1211],
         [ -9.7500,  -9.2812,  -2.8398,  ...,  -2.9609,  -7.6523,  -5.7422],
         ...,
         [ -3.1367,  -5.4766,  -0.7822,  ...,   1.3838,   2.3730,   0.5093],
         [ -9.3516,  -7.1992,   2.7480,  ...,  -5.0117,  -5.0273,  -5.2266],
         [ -4.0430,  -4.2031,   9.3906,  ...,  -1.7363,  -2.0098,  -5.9062]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.9297,  -4.3203,  -2.2656,  ...,  -1.6221,  -4.6602,  -3.7871],
         [ -8.1328,  -4.5000,  -1.2529,  ...,  -2.2754,  -7.5898,  -4.3555],
         ...,
         [-14.3203,  -7.7812,  -5.9531,  ...,  -6.6484,  -7.2344,  -5.4922],
         [-14.6172,  -8.3438,  -6.7500,  ...,  -7.0547,  -7.6523,  -5.8008],
         [-14.8125,  -8.8828,  -7.4180,  ...,  -7.3906,  -8.0000,  -6.0312]]],
       device='cuda:0')
torch.Size([2, 755, 1]) tensor([[[29892],
         [30010],
         [  515],
         ...,
         [29896],
         [29962],
         [   13]],

        [[29892],
         [  573],
         [  310],
         ...,
         [  338],
         [  338],
         [  338]]], device='cuda:0')
torch.Size([2, 755, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [30010,   357,   592,  ...,  1259,   596, 10783],
         [  515,   304, 29901,  ...,   292,  1717, 29892],
         ...,
         [29896, 20273, 22752,  ..., 14930, 29945, 29906],
         [29962, 29900, 29929,  ..., 29955, 29945, 29947],
         [   13,   306,   450,  ...,   512,   887,   910]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  573,   310, 29879,  ...,   292, 29901,   322],
         [  310,  4587,   373,  ..., 29892, 29901,  1551],
         ...,
         [  338, 29902,  1576,  ..., 29956,  5618, 29909],
         [  338,  1576, 29902,  ...,   275,   797, 29924],
         [  338, 29892, 29899,  ..., 29956,   306,   275]]], device='cuda:0')
Batch 32, 48.4% of total tokens
encoded shape: torch.Size([2, 1639])
torch.Size([2, 1639]) tensor([[    1,   660, 29901,  ..., 29889,    13,    13],
        [    1, 25538, 18299,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1639, 32000]) tensor([[[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [-10.7031, -11.7891,  -5.2188,  ...,  -6.0820,  -9.1328,  -6.8516],
         [-11.5156, -12.3672,  -3.2422,  ...,  -5.0039,  -5.4648,  -3.9551],
         ...,
         [ -0.6787,   1.0000,  13.8359,  ...,   1.1729,   1.6797,  -3.0996],
         [ -1.8652,   1.1465,   8.0781,  ...,  -0.8672,  -0.6069,  -2.4980],
         [ -5.3828,  -5.1992,  -0.4978,  ...,  -0.8838,  -0.5205,  -1.4082]],

        [[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [-11.6172, -11.1484,  -5.4453,  ...,  -8.0703,  -8.3359,  -7.2773],
         [ -9.1797, -15.3828,  -3.7656,  ...,  -6.9023,  -3.4883,  -5.6289],
         ...,
         [ -7.3320,  10.2969,  -1.1719,  ...,  -4.1367,  -6.0195,  -3.1348],
         [ -7.3594,  10.3359,  -1.1387,  ...,  -4.1758,  -6.0586,  -3.1582],
         [ -7.4766,  10.4766,  -1.1133,  ...,  -4.2500,  -6.1953,  -3.2559]]],
       device='cuda:0')
torch.Size([2, 1639, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [22550]],

        [[29892],
         [21694],
         [  278],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 1639, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13,   779,     2,  ...,   450,   660,  1126],
         [   13, 16894, 29950,  ...,  6295,  1576, 10605],
         [22550, 20001,  4535,  ..., 29925, 29933,  7422]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [21694,  2191,   592,  ...,  1450,  3575,   304],
         [  278,   263, 26656,  ...,   350, 11131,   322],
         ...,
         [    1, 29892, 29899,  ..., 29915,   448, 29901],
         [    1, 29892, 29899,  ..., 29915, 29901,   448],
         [    1, 29871, 29899,  ..., 29915, 29901, 29896]]], device='cuda:0')
Batch 33, 50.2% of total tokens
encoded shape: torch.Size([2, 393])
torch.Size([2, 393]) tensor([[    1,   660, 29901,    13,    13,  5328,   304,   788,   263, 19995,
          8989,   393,   674,  1051, 16256, 15942,   515,   289,  1107,    13,
            13, 29902,  2996,  4822,   289,  1107,  5106,   322,   306,   723,
           763,   304,   671,   372,   297,   263,  1904,   393,   756,   263,
         16256, 15942,   353,  4733, 29889, 29620,  3073, 29889,  1128,   437,
           306,   671,   289,  1107,   297, 16145, 16256, 15942,   304,  1051,
           297,   278,  2038,  1746,  1024, 29973,    13,    13, 29909, 29901,
            13,    13,  3644,   366,   864,   304,   671,   350,  1107,   363,
           393,   366,   508,  1018,  1554,   763,   445, 29901,    13,  3166,
           289,  1107, 29889, 20326,  1053,  1051, 29918, 21962, 15942,    13,
         22484, 29934,  1430, 29907, 29979, 29918,  3210, 29949,  2965,  2890,
           353, 17288, 26095, 29892, 27550, 29897,   363, 27550,   297,  1051,
         29918, 21962, 15942,   580, 29962, 29871,    13, 29937,   421,  1859,
          1575, 29952,   756,   304,   367,   385,  4256,   519,   313, 29872,
         29889, 29887,  1696,   263,  1051,   470, 18761, 29897, 19849,    13,
         29937,  3528,   310,  4256,  1849,   310,  3721,  1023,  4452,   515,
           607,   937,   310,  1819,   338,    13, 29937,  6087,   297,  2566,
           322,   278,  1473,   338,   363,  8954, 29889,    13,  1990,  8125,
          1170, 29898,  9794, 29889,  3195,  1125,    13,  1678, 27550,   353,
          4733, 29889, 27890, 29898,    13,  4706,  4236, 29918,  2848, 29922,
         29941, 29892,  1870, 29922,  5574, 29892,  9654, 29922,  5574, 29892,
         19995, 29922, 22484, 29934,  1430, 29907, 29979, 29918,  3210, 29949,
          2965,  2890,    13,  1678,  1723,    13,  1678, 27550, 29918,  2541,
         29918,  4381,   353,  4733, 29889, 27890, 29898,    13,  4706,  4236,
         29918,  2848, 29922, 29941, 29892,  2322,  2433,  3308, 29928,   742,
         19995, 29922, 22484, 29934,  1430, 29907, 29979, 29918,  3210, 29949,
          2965,  2890,    13,  1678,  1723,  1678,    13,    13,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,   518, 11357,   292, 13436,   286,  4850,  5275, 29901,   697,
          1629,  1121,   363,   278,   838,  5547, 29899,  7083,   277,  1355,
          5120,  1822,    13, 13555,   697,  1629,   310,  7271,   411,  4315,
           292, 13436,   286,  4850,  5275, 29892,   278,  2582,   310,   445,
         11043,   313, 29876, 29922, 29929, 29953, 29946, 29900, 29897,   526,
          9401,   304,  4315, 29899,  9663,   286,  4850,  5275,   313, 29876,
         29922, 29906, 29946, 29900, 29871, 29941, 29955, 29953, 29897,   411,
          3765,  5183, 29889,   382,  4387,   362,   363,  1269, 11043,   310,
           278,  6554,   310,  1246, 29899,  1627, 29892,  6374,  2582,  1434,
           322,  1156,   664, 29899,   786,   491,   278,   937,  9591,   322,
          4978,  2729,   373,   278,   350, 29902, 29899, 29934,  3035, 29903,
         12965,   491,   278,   319, 11341, 29892,  6554,   310, 19595,   653,
          3148, 29892, 17809,   633,  8945,  1907,   313, 29885,  2357, 28667,
          8232, 29897,   322, 17809,   508, 22543, 29889,   450,  6554,   310,
          6374,   286,  4850,   468, 25402,   471, 16951,  6133,   363,   278,
         13436, 11043,   313, 29896, 29955, 29889, 29941, 29995, 23797, 29871,
         29896, 29945, 29889, 29896, 10997,  1363,   310,   278,   937,  9591,
           313, 29896, 29953, 29889, 29941, 29995, 23797, 29871, 29896, 29941,
         29889, 29929, 10997, 13452,   372,   471, 16951,  5224,  1156, 19595,
           653,   664, 29899,   786,   313, 29941, 29995, 23797, 29871, 29941,
         29889, 29955, 28003,   450,  6554,   310,   350, 29902, 29899, 29934,
          3035, 29903, 29871, 29900,   471, 16951,  6133,   411, 13436,  6382,
           292,  3805,   690, 12645,   310, 16500,  5046, 29889,   450,  6554,
           310,  3148,   471,  6133,   363,  1134, 29871, 29896,   322, 29871,
         29906,  2078, 19416,   472, 13436,  6382,   292,   313, 29946, 29953,
         29995, 23797, 29871, 29941, 29953, 13667,   282, 29966, 29900, 29889,
         29900, 29900, 29900, 29896, 29897,  1550,   278, 11837,   471,  1565,
           363,  6245,   261,  2078, 19416,   313, 29946, 29929, 29995, 23797,
         29871, 29945, 29946,  8874,   282, 29901, 29900, 29889, 29900, 29900,
         29900, 29945,   467,  5853,  9200, 28667,  8232,   892, 17809,   373,
         13436,  6382,   292,   313, 29906, 29946, 29889, 29946, 29995, 23797,
         29871, 29906, 29896, 29889, 29947, 10997,  1728, 10879,   373,   278,
          6554,   310, 13681,  3235,   322, 29688,   573,  1559, 16381, 18902,
         29889,   450,  6554,   310,   508, 22543, 17809,   411,  1716, 11043,
           892, 13557, 29889,   450, 11664,  1353,   310,  6374,  2582,   472,
           937,  5183,   322, 11664,  1353,   310,  3148,   363, 13436,   286,
          4850,  5275,  1122, 29279,   304,   263,  6509, 11672,   322, 23553,
           297, 17420,   411,  7536,  4392,   262,   800, 29889,  4525,  2582,
           881,  3133,  5794,   367, 11819,   287,   322,  9401,   304,  4797,
          4759,  1179, 29889]], device='cuda:0')
torch.Size([2, 393, 32000]) tensor([[[ -8.0469,  -1.2461,  -0.5518,  ...,  -4.2305,  -5.7109,  -4.6406],
         [-10.7031, -11.7891,  -5.2227,  ...,  -6.0781,  -9.1328,  -6.8516],
         [-11.5156, -12.3828,  -3.2617,  ...,  -5.0078,  -5.4648,  -3.9609],
         ...,
         [ -3.2168,  -1.3652,   1.0684,  ...,  -3.0586,  -3.7441,  -2.4570],
         [ -3.2227,  -1.3633,   1.0723,  ...,  -3.0605,  -3.7461,  -2.4590],
         [ -3.2266,  -1.3633,   1.0742,  ...,  -3.0625,  -3.7480,  -2.4629]],

        [[ -8.0469,  -1.2461,  -0.5518,  ...,  -4.2305,  -5.7109,  -4.6406],
         [ -6.3789,  -8.2500,   0.0609,  ...,  -0.7236,  -1.1514,  -0.9634],
         [ -6.2734,  -9.1484,  -2.6582,  ...,  -4.4258,  -4.5508,  -3.8828],
         ...,
         [ -3.3125,  -1.4854,   1.1416,  ...,  -3.1074,  -3.7676,  -2.5059],
         [ -3.3203,  -0.1577,   9.6797,  ...,   0.8335,  -0.8149,  -4.6250],
         [ -7.0000,  -7.4883,  11.5938,  ...,  -0.9214,  -2.4414,  -3.7793]]],
       device='cuda:0')
torch.Size([2, 393, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [ 1784],
         [  679],
         [  263],
         [  716],
         [ 1051],
         [  304],
         [  338],
         [  367],
         [  599],
         [15942],
         [  322],
         [  263],
         [ 8873],
         [29899],
         [   13],
         [29902],
         [  505],
         [ 4822],
         [  445],
         [ 1107],
         [  322],
         [  322],
         [  306],
         [  626],
         [  763],
         [  304],
         [  671],
         [  372],
         [  297],
         [  590],
         [  883],
         [  883],
         [  306],
         [  263],
         [27550],
         [15942],
         [ 1746],
         [  426],
         [29889],
         [29907],
         [ 3073],
         [29898],
         [   13],
         [  508],
         [  306],
         [  437],
         [  372],
         [ 1107],
         [  297],
         [  445],
         [16256],
         [15942],
         [  297],
         [19450],
         [16256],
         [  278],
         [19995],
         [ 5276],
         [29973],
         [29973],
         [   13],
         [   13],
         [22550],
         [29901],
         [   13],
         [   13],
         [28727],
         [  366],
         [  526],
         [  304],
         [  671],
         [  278],
         [ 1107],
         [  297],
         [ 5578],
         [29892],
         [  817],
         [  671],
         [  445],
         [  763],
         [  445],
         [29901],
         [   13],
         [   13],
         [ 9557],
         [ 1107],
         [29889],
         [ 3221],
         [ 1053],
         [27550],
         [29918],
         [21962],
         [15942],
         [   13],
         [21962],
         [29934],
         [ 1430],
         [ 8426],
         [29979],
         [29918],
         [ 3210],
         [29949],
         [ 2965],
         [30488],
         [  353],
         [ 1051],
         [29895],
         [30488],
         [30488],
         [30488],
         [  363],
         [27550],
         [  297],
         [ 1051],
         [29918],
         [21962],
         [29889],
         [30488],
         [29889],
         [   13],
         [  396],
         [ 1990],
         [  322],
         [26095],
         [30488],
         [29918],
         [  338],
         [30488],
         [30488],
         [  263],
         [29871],
         [30488],
         [  310],
         [ 1761],
         [29889],
         [29887],
         [29889],
         [30879],
         [30488],
         [30488],
         [30488],
         [29897],
         [  310],
         [  310],
         [29937],
         [29871],
         [  310],
         [29871],
         [30488],
         [  313],
         [ 5291],
         [29871],
         [ 3161],
         [ 1269],
         [  607],
         [  278],
         [ 2944],
         [   13],
         [   13],
         [  278],
         [29937],
         [  278],
         [  297],
         [  278],
         [ 1897],
         [29871],
         [ 1473],
         [  697],
         [  263],
         [  278],
         [  297],
         [   13],
         [ 1990],
         [ 1619],
         [29898],
         [30879],
         [ 9794],
         [29889],
         [ 3195],
         [30879],
         [   13],
         [ 1678],
         [27550],
         [  353],
         [ 4733],
         [29889],
         [27890],
         [29898],
         [ 1859],
         [ 4706],
         [19995],
         [30488],
         [ 2848],
         [29922],
         [29906],
         [29900],
         [   13],
         [30488],
         [ 5574],
         [29892],
         [19995],
         [30488],
         [ 5574],
         [29892],
         [19995],
         [29922],
         [22484],
         [30488],
         [ 1430],
         [29907],
         [29979],
         [29918],
         [ 3210],
         [29949],
         [ 2965],
         [ 2890],
         [29897],
         [ 1678],
         [ 1723],
         [   13],
         [   13],
         [  396],
         [29918],
         [18098],
         [29918],
         [18098],
         [  353],
         [ 4733],
         [29889],
         [27890],
         [29898],
         [   13],
         [ 4706],
         [ 4236],
         [29918],
         [ 2848],
         [29922],
         [29941],
         [29892],
         [ 1870],
         [29922],
         [ 3308],
         [29928],
         [  742],
         [ 1870],
         [29922],
         [22484],
         [29934],
         [ 1430],
         [29907],
         [29979],
         [29918],
         [ 3210],
         [29949],
         [ 2965],
         [ 2890],
         [   13],
         [ 1678],
         [ 1723],
         [   13],
         [   13],
         [   13],
         [20001],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   12],
         [   12],
         [   12],
         [   12],
         [   12],
         [ 1576],
         [ 1576],
         [29902],
         [29902],
         [ 1576],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29871],
         [29871],
         [29871],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [26336],
         [ 3267],
         [  310],
         [  275],
         [ 4850],
         [ 5275],
         [  297],
         [  263],
         [29899],
         [ 7271],
         [  310],
         [  263],
         [ 4665],
         [19954],
         [29899],
         [ 7083],
         [  277],
         [ 1355],
         [14311],
         [  313],
         [   13],
         [11357],
         [  263],
         [ 1629],
         [  310],
         [ 7271],
         [29892],
         [  278],
         [  292],
         [13436],
         [  286],
         [ 4850],
         [ 5275],
         [29892],
         [  278],
         [ 2582],
         [  526],
         [  278],
         [ 6559],
         [  526],
         [23149],
         [  353],
         [29896],
         [29900],
         [29900],
         [29897],
         [29897],
         [  526],
         [ 9132],
         [  411],
         [ 1906],
         [  292],
         [ 9663],
         [  286],
         [ 4850],
         [ 5275],
         [  313],
         [29876],
         [29922],
         [29896],
         [29900],
         [29892],
         [29900],
         [29900],
         [29900],
         [29900],
         [  467],
         [  297],
         [  263],
         [ 5183],
         [29889],
         [  450],
         [  523],
         [  362],
         [  310],
         [  278],
         [16500],
         [  338],
         [  278],
         [ 4771],
         [  310],
         [  633],
         [ 1250],
         [ 1627],
         [29879],
         [ 4768],
         [ 4768],
         [  322],
         [ 4768],
         [ 1156],
         [ 4768],
         [29899],
         [  786],
         [29892],
         [ 4768],
         [17937],
         [ 9591],
         [29892],
         [  278],
         [  310],
         [  373],
         [  278],
         [ 2186],
         [29902],
         [29899],
         [29934],
         [ 3035],
         [29903],
         [12965],
         [  526],
         [  278],
         [ 1473],
         [11341],
         [29899],
         [  526],
         [  310],
         [ 4768],
         [  653],
         [ 4392],
         [  322],
         [ 4768],
         [  508],
         [ 8945],
         [ 1907],
         [  322],
         [ 1785],
         [ 2520],
         [28667],
         [ 8232],
         [29892],
         [  322],
         [ 4768],
         [  508],
         [22543],
         [29889],
         [  450],
         [ 6554],
         [  310],
         [ 1246],
         [ 2582],
         [ 4850],
         [ 5275],
         [25402],
         [  471],
         [16951],
         [ 6133],
         [  363],
         [ 4315],
         [13436],
         [  286],
         [  313],
         [29896],
         [29896],
         [29889],
         [29906],
         [10997],
         [ 7186],
         [29871],
         [29896],
         [29906],
         [29889],
         [29906],
         [28003],
         [  322],
         [  310],
         [  278],
         [ 6133],
         [ 9591],
         [29915],
         [29896],
         [29906],
         [29889],
         [29906],
         [29995],
         [23797],
         [29871],
         [29896],
         [29946],
         [29889],
         [29929],
         [28003],
         [  322],
         [  278],
         [  471],
         [  451],
         [ 5224],
         [  363],
         [  664],
         [  653],
         [ 3148],
         [29899],
         [  786],
         [  313],
         [29896],
         [29889],
         [23797],
         [29871],
         [29946],
         [29889],
         [29929],
         [28003],
         [  450],
         [ 6554],
         [  310],
         [  633],
         [ 8193],
         [29899],
         [29934],
         [ 3035],
         [29903],
         [ 7663],
         [29941],
         [  966],
         [16951],
         [ 6133],
         [  363],
         [  278],
         [  286],
         [  292],
         [  313],
         [  690],
         [30488],
         [  310],
         [  278],
         [29915],
         [  313],
         [  450],
         [ 6554],
         [  310],
         [  633],
         [19595],
         [16951],
         [  411],
         [  278],
         [  319],
         [29896],
         [  313],
         [29871],
         [29906],
         [  966],
         [30488],
         [  313],
         [  278],
         [ 6382],
         [  292],
         [  313],
         [29896],
         [29889],
         [29889],
         [23797],
         [29871],
         [29941],
         [29929],
         [28003],
         [29871],
         [29966],
         [29900],
         [29889],
         [29900],
         [29900],
         [29896],
         [29896],
         [  467],
         [  322],
         [  372],
         [ 6554],
         [30488],
         [ 1565],
         [  363],
         [ 1134],
         [  261],
         [ 2078],
         [19416],
         [  313],
         [29941],
         [29900],
         [29995],
         [23797],
         [29871],
         [29945],
         [29906],
         [13667],
         [  282],
         [29966],
         [29871],
         [29889],
         [29900],
         [29900],
         [29900],
         [29896],
         [  467],
         [  450],
         [  508],
         [29899],
         [30488],
         [  892],
         [17809],
         [  411],
         [  278],
         [ 6382],
         [  292],
         [  313],
         [29896],
         [29889],
         [29995],
         [29945],
         [29995],
         [23797],
         [29871],
         [29906],
         [29900],
         [29889],
         [29906],
         [ 8874],
         [  322],
         [30488],
         [  373],
         [  278],
         [ 6554],
         [  310],
         [  508],
         [30488],
         [  313],
         [29688],
         [30488],
         [23900],
         [  262],
         [30488],
         [29889],
         [  450],
         [ 6554],
         [  310],
         [13681],
         [30488],
         [  471],
         [  313],
         [  278],
         [30488],
         [  313],
         [29871],
         [  313],
         [  450],
         [ 2582],
         [ 6554],
         [  310],
         [ 6374],
         [ 2582],
         [  411],
         [  278],
         [30488],
         [  313],
         [  278],
         [ 1353],
         [  310],
         [ 9200],
         [  297],
         [  278],
         [ 6382],
         [29889],
         [ 5275],
         [30488],
         [  367],
         [  304],
         [  278],
         [30488],
         [30488],
         [29889],
         [  263],
         [  297],
         [30488],
         [  278],
         [  278],
         [12298],
         [  262],
         [  800],
         [29889],
         [  450],
         [29871],
         [29892],
         [  367],
         [ 5794],
         [29889],
         [30488],
         [  287],
         [29889],
         [30488],
         [  304],
         [30488],
         [30488],
         [30488],
         [29889],
         [   13]]], device='cuda:0')
torch.Size([2, 393, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,   306,  1128,  ...,  1932,  1317,   450],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [26336, 12614, 30098,  ..., 29896, 29950, 29990],
         [ 3267,  1456,   292,  ..., 29903,  9888,   359],
         ...,
         [30488, 30879, 31147,  ..., 31256, 29889, 31575],
         [29889,   304,   297,  ...,   313,   310,   411],
         [   13,   450, 14187,  ..., 25678,   910,   319]]], device='cuda:0')
Batch 34, 50.9% of total tokens
encoded shape: torch.Size([2, 345])
torch.Size([2, 345]) tensor([[    1, 12842,   567, 29891, 25122,   313, 29896, 29929, 29906, 29900,
          2706, 29897,    13,    13, 29954, 29891,   567, 29891, 25122,   313,
         29954,  3504, 29901,   796,  2231,   348,   261,  2204,   329, 29897,
           338,   263, 29871, 29896, 29929, 29906, 29900,  5332, 17436,  2706,
         10624,   491,  8425, 13832, 19387,  1509,   322,   380, 23693,   365,
          3761,   897, 12065,  2034, 29892,  8965,   383,  4666,   322,  3739,
          6971,   264, 29889,   739,   338,  2729,   373, 18604,   350,   466,
           300, 29915, 29879,  1704,  1527,   322,   881,   451,   367,  9613,
           411,   278, 29871, 29896, 29929, 29896, 29947,  5332, 17436,  1704,
          1527, 29889,    13,    13, 15738,    13,   365,  3761,   897, 12065,
          2034, 29871,    13,  8965,   383,  4666, 29871,    13,  3739, 12444,
           272, 29871,    13,  5918, 14019,   663, 29871,    13, 22839,   341,
          6544,  1335,    13,    13,  1123, 10662,    13,    13, 29933,  2690,
          5275,    13,   350,  1698, 29892,  6971, 29899, 24083,   669,  9827,
         13287,   672, 29892,  7870, 29889,   450, 23924,   895,   315,   457,
          9527, 29889, 18791,   310,  5332, 27306, 29889,  9827, 29882,  5422,
         13730, 29892, 29871, 29906, 29900, 29900, 29929, 29889,    13,    13,
         25865,  2988,    13,    13, 10900, 29901, 29896, 29929, 29906, 29900,
         12298,    13, 10900, 29901, 29954,  3504, 12298,    13, 10900, 29901,
          3434,  1516,   310,   278,  1334, 20232,  8063,    13, 10900, 29901,
          3434,  1516, 10624,   491,  8425, 13832, 19387,  1509,    13, 10900,
         29901, 29954,  3504, 17436,  4682, 12298,    13, 10900, 29901,  3434,
          1516,  1048,  5917, 29875,  2305,    13, 10900, 29901, 29954,  3504,
          4628, 29899,   392, 29899, 10921, 12298,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13,  3624,   445,   263,  2854,  1207,
          1445, 29973,    13,    13, 29902,   505,   263,  1207,  1445,   304,
          2048,   590,   315,  1817,  1824, 29889,  2266,   338,   825,   306,
           864,   372,   304,   437, 29889,    13, 29896, 29889, 11190,  1667,
         29889,  8223, 29892,   322,  4583,  8096, 29889,  8223, 29892,   322,
          6633,   963,   964,   869, 29877, 29915, 29879,    13, 29906, 29889,
          6645,   278,  1023,   869, 29877, 29915, 29879,  4208,  8951, 29892,
           697,   964,   385, 16813,  2000,  4583,  8096, 29892,   278,   916,
           316,   455,  8096, 29889,    13,  1576,  2769,   306,   505,  1023,
          6704,  1849,   338,   393,   278,  1667, 29889,  8223, 12747,   607,
         16813,   366,   526,   773,   491,  8454,  1852, 29894, 29892,   322,
           769,   947,  4583,  8096,   470,   316,   455,  8096, 16205, 29889,
            13,  1576,  1207,  1445,   306,   505,  3971,   338,  1244, 29901,
          8561,  1445,   373,   349,  4350,  2109, 29889,   510,    13,  3624,
           445,   263,  2854, 29914, 16773,  1207,  1445, 29973,   306,   864,
           304,  1073,   565,   445,   674,   664,  1532,   322,   565,   727,
           526,   738,  2253,  5837,   304,   437,   445, 29889,    13,    13,
         29909, 29901,    13,    13,  8241, 29892,   393, 29915, 29879,  8959,
          2854, 29889, 29871,   960,   278,  1023,  6704,  1849,   526, 19781,
          9146,   304,   367, 13557, 29892,   366,   508,  4078,   777,   664,
           491,  3907,   697,   263,  3509,   470,  2898,  1544,   310,   278,
           916, 29892,  2012,   310, 22520,   278,  1021,   775,  8951, 29901,
            13,   455,  8096, 29901,  1667, 29889, 29877,  4583,  8096, 29889,
         29877,    13,  4706,  2427, 29954,  4174, 29897,  2427, 18823, 10749,
         29897,  1667, 29889, 29877,  4583,  8096, 29889, 29877,   448, 29877,
           395, 29992,    13,    13,   311,   455,  8096, 29901,  4583,  8096,
            13,  4706,   301, 29876,   448, 29888,   395, 29966,   395, 29992,
            13,    13,  9842,   393,   306, 29915,   345,  1304,   278, 18428,
          3651,   395, 29966,   322,   395, 29992,   304,  2737,   304,   278,
          2983,   310,   278,   937,   544,   406,  7680,   568,   322,   278,
          1024,   310,   278,  3646,  8307, 29889, 29871,  2688, 29915,   276,
           451, 18719,  5181,  1244, 29892,   541,   306,  1348,   896, 29915,
           276,  1781,  6944, 29892,  1951,   896,  2289,  2041,   297,  1361,
         29891,   746,   366,  1369, 22146,   901,  4280,  4766, 29899,  4352,
           292,  6865, 29889,    13,    13]], device='cuda:0')
torch.Size([2, 345, 32000]) tensor([[[-8.0312e+00, -1.1074e+00, -5.2881e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-8.3047e+00, -7.8711e+00, -2.0215e+00,  ..., -3.9609e+00,
          -2.7012e+00, -5.3984e+00],
         [-9.7969e+00, -1.1781e+01, -4.4727e+00,  ..., -4.5742e+00,
          -1.2041e+00, -4.2969e+00],
         ...,
         [-3.2031e+00, -1.3809e+00,  1.0576e+00,  ..., -3.0508e+00,
          -3.7441e+00, -2.4570e+00],
         [-3.1992e+00, -1.3770e+00,  1.0566e+00,  ..., -3.0508e+00,
          -3.7422e+00, -2.4551e+00],
         [-3.1992e+00, -1.3789e+00,  1.0566e+00,  ..., -3.0508e+00,
          -3.7422e+00, -2.4531e+00]],

        [[-8.0312e+00, -1.1074e+00, -5.2881e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-1.0695e+01, -1.1773e+01, -5.2109e+00,  ..., -6.0781e+00,
          -9.1250e+00, -6.8438e+00],
         [-1.1531e+01, -1.2383e+01, -3.2441e+00,  ..., -5.0117e+00,
          -5.4766e+00, -3.9609e+00],
         ...,
         [-9.6313e-02, -6.7932e-02,  1.6219e+01,  ..., -9.1113e-01,
           2.8345e-01, -1.3525e+00],
         [ 5.8203e-01,  2.8711e+00,  1.4219e+01,  ..., -2.3008e+00,
          -7.1289e-01, -1.2711e-02],
         [-7.7617e+00, -8.7422e+00,  1.9727e+00,  ..., -3.8926e+00,
          -3.3066e+00, -1.2812e+00]]], device='cuda:0')
torch.Size([2, 345, 1]) tensor([[[29892],
         [15663],
         [  583],
         [17429],
         [  491],
         [29896],
         [29929],
         [29955],
         [29900],
         [29897],
         [29897],
         [   13],
         [29954],
         [29954],
         [29891],
         [  567],
         [29891],
         [25122],
         [  338],
         [29954],
         [ 3504],
         [29901],
         [  796],
         [ 2231],
         [  348],
         [  261],
         [ 2204],
         [  329],
         [29897],
         [  338],
         [  263],
         [29871],
         [29896],
         [29929],
         [29906],
         [29900],
         [ 5332],
         [17436],
         [ 2706],
         [10624],
         [  491],
         [ 6158],
         [30488],
         [  265],
         [30488],
         [  322],
         [  380],
         [23693],
         [ 7137],
         [ 3761],
         [  316],
         [  624],
         [ 2034],
         [29892],
         [10686],
         [30879],
         [29889],
         [25145],
         [10686],
         [30879],
         [  538],
         [ 6610],
         [  739],
         [ 7017],
         [  385],
         [  373],
         [  278],
         [ 6439],
         [30879],
         [  300],
         [29915],
         [    1],
         [14495],
         [ 1527],
         [14495],
         [ 5680],
         [  451],
         [  367],
         [ 9613],
         [  411],
         [  278],
         [29871],
         [29896],
         [29929],
         [29906],
         [29945],
         [ 2706],
         [ 2706],
         [ 2706],
         [ 1527],
         [ 2706],
         [   13],
         [   13],
         [ 2277],
         [  292],
         [   13],
         [ 3761],
         [  897],
         [29899],
         [ 2034],
         [  408],
         [  408],
         [ 8965],
         [  383],
         [ 4666],
         [29871],
         [   13],
         [ 3739],
         [ 6971],
         [30488],
         [29871],
         [   13],
         [22839],
         [30488],
         [30488],
         [29871],
         [   13],
         [22839],
         [30488],
         [30488],
         [ 1335],
         [29871],
         [   13],
         [ 2277],
         [10662],
         [   13],
         [   13],
         [ 2277],
         [ 3738],
         [ 5275],
         [   13],
         [   13],
         [29889],
         [29892],
         [30488],
         [29899],
         [30488],
         [  669],
         [30488],
         [30488],
         [30488],
         [29892],
         [29911],
         [20336],
         [ 4623],
         [23924],
         [  895],
         [20189],
         [30879],
         [ 9527],
         [31017],
         [17138],
         [  310],
         [ 5332],
         [30488],
         [29889],
         [11438],
         [29882],
         [ 5422],
         [13730],
         [29892],
         [ 1570],
         [29906],
         [29900],
         [29900],
         [29929],
         [ 2210],
         [   13],
         [11769],
         [ 2277],
         [ 2988],
         [   13],
         [   13],
         [29930],
         [29901],
         [29896],
         [29929],
         [29906],
         [29900],
         [29879],
         [17943],
         [10900],
         [29901],
         [29954],
         [ 3504],
         [12298],
         [  310],
         [10900],
         [29901],
         [26729],
         [30488],
         [23196],
         [ 9556],
         [14262],
         [20232],
         [ 8063],
         [   13],
         [10900],
         [29901],
         [26729],
         [30488],
         [10322],
         [  491],
         [ 8425],
         [13832],
         [19387],
         [30488],
         [   13],
         [10900],
         [29901],
         [ 3434],
         [ 3504],
         [17436],
         [12298],
         [12298],
         [   13],
         [10900],
         [29901],
         [ 3434],
         [30488],
         [10322],
         [12842],
         [29875],
         [ 2305],
         [   13],
         [10900],
         [29901],
         [ 3434],
         [ 3504],
         [12298],
         [29899],
         [  392],
         [29899],
         [10921],
         [12298],
         [   13],
         [    1],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29902],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29892],
         [29892],
         [29892],
         [29892],
         [29889],
         [29892],
         [29892],
         [29892],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [  372],
         [  263],
         [ 2854],
         [  315],
         [ 1445],
         [29973],
         [   13],
         [   13],
         [29905],
         [  505],
         [  263],
         [ 1207],
         [ 1445],
         [  393],
         [ 6633],
         [  263],
         [ 2060],
         [ 1817],
         [ 2060],
         [29889],
         [  306],
         [  338],
         [  278],
         [  306],
         [  505],
         [  304],
         [  304],
         [  437],
         [29901],
         [   13],
         [   13],
         [29889],
         [ 3831],
         [  278],
         [29889],
         [ 8223],
         [  322],
         [  322],
         [ 6633],
         [ 8096],
         [  726],
         [ 8223],
         [29892],
         [  322],
         [ 4583],
         [  963],
         [  964],
         [  263],
         [29877],
         [ 2066],
         [29879],
         [29889],
         [29906],
         [29889],
         [ 6645],
         [  278],
         [  869],
         [  869],
         [29877],
         [29915],
         [30488],
         [ 4208],
         [  304],
         [  304],
         [ 2748],
         [30488],
         [  263],
         [16813],
         [29892],
         [  376],
         [29889],
         [29892],
         [  322],
         [29871],
         [  964],
         [30488],
         [ 8096],
         [29889],
         [   13],
         [29941],
         [ 1108],
         [  306],
         [30488],
         [29871],
         [ 6704],
         [30488],
         [  338],
         [30879],
         [  306],
         [ 4583],
         [30488],
         [ 8223],
         [  313],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [30488],
         [  263],
         [30488],
         [29961],
         [  322],
         [  306],
         [30488],
         [30488],
         [30488],
         [  470],
         [  316],
         [30488],
         [ 8096],
         [16205],
         [29889],
         [   13],
         [   13],
         [ 1207],
         [  306],
         [30488],
         [  505],
         [30488],
         [30488],
         [   13],
         [29901],
         [   13],
         [ 1445],
         [   13],
         [30488],
         [30488],
         [ 2109],
         [29889],
         [   13],
         [   13],
         [   13],
         [  445],
         [30488],
         [30488],
         [  315],
         [15728],
         [  313],
         [30488],
         [29973],
         [   13],
         [29915],
         [30488],
         [30488],
         [29889],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [30488],
         [30488],
         [29915],
         [31147],
         [31147],
         [ 5837],
         [29889],
         [  437],
         [29889],
         [29889],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [ 8241],
         [ 8241],
         [30488],
         [  445],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  739],
         [  306],
         [  306],
         [ 6704],
         [  869],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  313],
         [  263],
         [16813],
         [  376],
         [30488],
         [  263],
         [30488],
         [  310],
         [  278],
         [  916],
         [29889],
         [  322],
         [29889],
         [  313],
         [30488],
         [ 1023],
         [  315],
         [30488],
         [30488],
         [   13],
         [   13],
         [30488],
         [29901],
         [ 4583],
         [29889],
         [ 8223],
         [ 4583],
         [30488],
         [29889],
         [29877],
         [   13],
         [   12],
         [ 2427],
         [ 4174],
         [ 4862],
         [29897],
         [ 2427],
         [ 9207],
         [30488],
         [29897],
         [  448],
         [29889],
         [29877],
         [29889],
         [30488],
         [29889],
         [29877],
         [  448],
         [30488],
         [ 4583],
         [29992],
         [   13],
         [  311],
         [  311],
         [30488],
         [ 8096],
         [29901],
         [ 1667],
         [ 8096],
         [29889],
         [ 4706],
         [ 2427],
         [29876],
         [  448],
         [29879],
         [ 4583],
         [29966],
         [ 4583],
         [29992],
         [   13],
         [   13],
         [ 3396],
         [  393],
         [  278],
         [29915],
         [  345],
         [ 1304],
         [  263],
         [  376],
         [30488],
         [ 2427],
         [23196],
         [  322],
         [  395],
         [29992],
         [29889],
         [30488],
         [  304],
         [  278],
         [ 2752],
         [  310],
         [  278],
         [ 2752],
         [  322],
         [  406],
         [30488],
         [30488],
         [  322],
         [  278],
         [ 3646],
         [  310],
         [  278],
         [ 3646],
         [29892],
         [29889],
         [29871],
         [  910],
         [30488],
         [  276],
         [30488],
         [30879],
         [ 5181],
         [29892],
         [29892],
         [  541],
         [  306],
         [29915],
         [  372],
         [29915],
         [  276],
         [  263],
         [30488],
         [30488],
         [  322],
         [  896],
         [29915],
         [  437],
         [  297],
         [ 1361],
         [29891],
         [30488],
         [  263],
         [29915],
         [  304],
         [22525],
         [ 4280],
         [22525],
         [29899],
         [30488],
         [  292],
         [ 6865],
         [29889],
         [   13],
         [   13],
         [20001]]], device='cuda:0')
torch.Size([2, 345, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [15663,   484,   567,  ...,  1340,  6840,  5338],
         [  583, 29891,  3021,  ...,   962,  2480, 29882],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13, 29871,     2,  ...,  3115,   960,  2688],
         [   13, 29905, 17351,  ...,  3644,   797,  2831],
         [20001, 22550, 17351,  ..., 29902,   797,  9842]]], device='cuda:0')
Batch 35, 51.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 16417,    13,  ...,  8673,    13, 12015]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-8.0312e+00, -1.1055e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-1.0695e+01, -1.1781e+01, -5.2188e+00,  ..., -6.0781e+00,
          -9.1250e+00, -6.8477e+00],
         [-1.1531e+01, -1.2391e+01, -3.2480e+00,  ..., -5.0195e+00,
          -5.4805e+00, -3.9707e+00],
         ...,
         [-1.2178e+00,  5.3203e+00,  1.3945e+01,  ...,  2.3340e+00,
          -2.0664e+00,  1.5723e+00],
         [-1.2939e+00,  5.0352e+00,  1.4086e+01,  ...,  2.2148e+00,
          -2.1094e+00,  1.4570e+00],
         [-1.2227e+00,  4.8867e+00,  1.4172e+01,  ...,  2.2480e+00,
          -2.0117e+00,  1.4648e+00]],

        [[-8.0312e+00, -1.1055e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-1.2727e+01, -1.2469e+01, -7.2734e+00,  ..., -7.9336e+00,
          -8.8828e+00, -1.0320e+01],
         [-5.8789e+00, -1.0107e+00, -1.0146e+00,  ...,  4.1821e-01,
          -2.9346e-01, -8.0518e-01],
         ...,
         [ 4.6362e-01,  1.8135e+00,  3.7559e+00,  ...,  5.2295e-01,
           1.8633e+00,  5.9912e-01],
         [ 1.1154e-02,  4.0381e-01,  4.8906e+00,  ...,  6.0303e-01,
           2.4258e+00,  1.8662e+00],
         [-1.7688e-01,  9.8694e-02,  9.4629e-01,  ...,  1.2168e+00,
           3.4375e+00, -1.5259e-01]]], device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [   13]],

        [[29892],
         [30010],
         [29328],
         ...,
         [   13],
         [12015],
         [ 1254]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13, 29871,     2,  ..., 29912, 29896, 29900],
         [   13, 29871,     2,  ..., 29912, 29896, 29900],
         [   13, 29871,     2,  ..., 29912, 29896, 29900]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [30010, 10130, 29928,  ..., 14662, 29914, 29909],
         [29328, 19658,  8050,  ..., 30015,  2059, 29955],
         ...,
         [   13, 19838, 18627,  ..., 26077, 23196, 23774],
         [12015, 19474,    13,  ...,  1177,  2891,  1164],
         [ 1254, 11235, 14411,  ..., 26077, 31779, 14558]]], device='cuda:0')
Batch 36, 55.7% of total tokens
encoded shape: torch.Size([2, 2427])
torch.Size([2, 2427]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   450,   317,  ...,  1781,  8589, 29991]], device='cuda:0')
torch.Size([2, 2427, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7812,  -5.2188,  ...,  -6.0781,  -9.1250,  -6.8477],
         [-11.5312, -12.3906,  -3.2480,  ...,  -5.0195,  -5.4805,  -3.9707],
         ...,
         [ -8.5781,   4.9844,  -0.3945,  ...,  -3.8574,  -5.8281,  -4.6875],
         [ -8.5781,   4.9492,  -0.2888,  ...,  -3.8730,  -5.8711,  -4.6797],
         [ -8.6328,   5.1172,  -0.1188,  ...,  -3.9395,  -5.9648,  -4.6953]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.8203, -10.7266,  -8.4219,  ...,  -8.2422,  -8.7500,  -7.5703],
         [ -8.6953,  -9.1719,  -3.3945,  ...,  -5.9844,  -4.2461,  -5.4805],
         ...,
         [ -0.4517,  -0.0660,   0.4155,  ...,   2.9941,   2.1270,  -0.1129],
         [  0.4155,   1.0479,   2.7695,  ...,   2.3789,   3.9668,  -0.1156],
         [  1.1865,   0.5317,   4.4180,  ...,   2.2734,   1.1992,   1.0342]]],
       device='cuda:0')
torch.Size([2, 2427, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29892],
         [29871],
         [28935],
         ...,
         [26077],
         [26077],
         [18627]]], device='cuda:0')
torch.Size([2, 2427, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [29871,  7228, 29879,  ..., 29906,   229, 29945],
         [29871,  7228, 29879,  ..., 29885,   229, 29945],
         [29871,  7228, 29879,  ..., 29885,   229, 29945]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,  1570,   937,  ...,   317,   319,   390],
         [28935,   504, 29987,  ...,  1742,   339,  1111],
         ...,
         [26077,   664, 23196,  ..., 14262, 31079, 12879],
         [26077, 23196, 14332,  ..., 17391,  6610, 12879],
         [18627, 19838, 23196,  ..., 24366,  8258, 18029]]], device='cuda:0')
Batch 37, 58.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,    13,  ...,     2,     2,     2],
        [    1,   869,  2803,  ..., 29906, 29953, 29947]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.3984,   0.6221,  -1.6709,  ...,   2.6641,   0.4211,   0.0731],
         [ -5.4297,  -0.6924,  -2.2090,  ...,  -0.5454,  -0.5952,   1.4268],
         ...,
         [ -8.9297,   7.2930,   6.8516,  ...,  -4.5781,  -7.4414,  -3.4707],
         [ -8.9062,   7.3203,   6.8906,  ...,  -4.5273,  -7.4297,  -3.4316],
         [ -8.8516,   7.0234,   7.3945,  ...,  -4.4297,  -7.4297,  -3.3340]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.2969,  -9.2812,  -3.2031,  ...,  -6.7266,  -5.2656,  -6.0508],
         [-11.9062, -13.5547,  -2.7188,  ...,  -6.5352,  -7.7305,  -8.6641],
         ...,
         [ -1.9854,  -3.7266,   4.1641,  ...,   0.5703,  -0.0995,  -0.4167],
         [ -1.2500,  -2.7637,   5.0625,  ...,   1.4102,   0.4626,   0.2935],
         [ -1.5205,  -3.4570,   4.9414,  ...,   1.0459,   0.5322,   0.6890]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [29896],
         [29871],
         ...,
         [29889],
         [29889],
         [29889]],

        [[29892],
         [29941],
         [  502],
         ...,
         [ 6802],
         [ 6802],
         [ 6802]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29871,  1678,   462,  ...,    12, 16595,    13],
         ...,
         [29889, 29879, 29899,  ..., 29900, 29892, 29918],
         [29889, 29879, 29899,  ..., 29900, 29892, 29918],
         [29889, 29879, 29899,  ..., 29900, 29918, 29892]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29941, 29906,  6006,  ..., 29945, 29929,  1212],
         [  502, 30010, 29915,  ...,   596,   963,   395],
         ...,
         [ 6802, 29941, 29945,  ..., 29953, 29896, 29906],
         [ 6802, 29945, 29946,  ..., 29941, 29906, 29953],
         [ 6802, 29929, 29955,  ..., 29914, 29953, 29906]]], device='cuda:0')
Batch 38, 62.7% of total tokens
encoded shape: torch.Size([2, 664])
torch.Size([2, 664]) tensor([[    1,  7646,  1551,  ..., 29892,   390,  6895],
        [    1, 16208,   590,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 664, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -5.1953,  -7.9727,  -3.6309,  ...,  -3.3809,  -1.3555,  -5.6602],
         [ -8.1562, -12.0938,  -4.4570,  ...,  -3.7109,  -2.1992,  -4.3828],
         ...,
         [ -0.6025,  -1.3691,   0.1140,  ...,   2.4258,   1.2441,   1.4209],
         [ -3.2129,  -1.3984,   1.0615,  ...,  -3.0391,  -3.7559,  -2.4551],
         [ -0.3262,  -0.5771,   5.1875,  ...,   2.0918,   1.3564,   1.3447]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -4.4531,  -6.3906,  -2.4258,  ...,  -4.5078,  -2.7383,  -4.9375],
         [ -7.8398,  -8.1406,  -2.0176,  ...,  -7.4297,  -4.2734,  -4.9023],
         ...,
         [ -3.6230,   3.5117,  -1.1191,  ...,  -0.4062,   1.4854,  -0.4385],
         [ -3.4883,   3.5547,  -1.0654,  ...,  -0.3647,   1.5645,  -0.4250],
         [ -3.2793,   3.6270,  -1.0723,  ...,  -0.2532,   1.6338,  -0.3162]]],
       device='cuda:0')
torch.Size([2, 664, 1]) tensor([[[29892],
         [ 4909],
         [  291],
         ...,
         [18627],
         [30488],
         [24366]],

        [[29892],
         [  322],
         [  542],
         ...,
         [23196],
         [23196],
         [23196]]], device='cuda:0')
torch.Size([2, 664, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 4909, 16416,  9173,  ...,  2552,  2671, 29890],
         [  291,  1080,   267,  ...,  3575,  6054,   278],
         ...,
         [18627, 23196,  8629,  ..., 26077, 12879, 20189],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [24366, 14967, 28718,  ..., 26077, 20189, 23726]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  322, 15944, 14650,  ...,  3599, 16377, 21400],
         [  542,   295,  9564,  ..., 29883,   359, 21553],
         ...,
         [23196, 26077,     1,  ..., 14332, 23522,  8629],
         [23196, 26077,     1,  ...,  8629, 14332, 23522],
         [23196, 26077, 14262,  ..., 31779,  8629, 28044]]], device='cuda:0')
Batch 39, 63.8% of total tokens
encoded shape: torch.Size([2, 2150])
torch.Size([2, 2150]) tensor([[    1,  8335,   957,  ...,     2,     2,     2],
        [    1, 15050,  4515,  ...,   352,  8492, 29889]], device='cuda:0')
torch.Size([2, 2150, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.7578,  -5.4102,  -2.7578,  ...,  -3.6055,  -2.5781,  -1.7910],
         [-11.8906, -13.6484,  -6.2344,  ...,  -9.6406,  -5.8242,  -8.9062],
         ...,
         [-11.1172,  -0.6611,  -0.5703,  ...,  -5.7031,  -3.2617,  -5.9844],
         [-11.1250,  -0.6577,  -0.5913,  ...,  -5.7188,  -3.2695,  -6.0078],
         [-11.0938,  -0.6416,  -0.6069,  ...,  -5.7344,  -3.2637,  -6.0273]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.0859,  -9.5469,  -2.6426,  ...,  -6.7656,  -8.1094,  -5.0898],
         [ -3.2168,  -1.2432,   1.0674,  ...,  -3.0391,  -3.7207,  -2.4512],
         ...,
         [ -1.8145,  -6.2422,   0.7554,  ...,  -0.3113,   2.4082,  -0.5312],
         [ -3.1406,  -5.2461,   3.6445,  ...,  -2.2949,  -0.1693,  -3.3242],
         [ -3.2227,  -4.4062,   3.2559,  ...,  -0.9492,   1.2461,  -0.3918]]],
       device='cuda:0')
torch.Size([2, 2150, 1]) tensor([[[29892],
         [  957],
         [ 9865],
         ...,
         [ 1516],
         [ 1516],
         [ 1516]],

        [[29892],
         [ 4515],
         [30488],
         ...,
         [ 6230],
         [29889],
         [ 1105]]], device='cuda:0')
torch.Size([2, 2150, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  957, 18168,   459,  ..., 20272,  2496, 29891],
         [ 9865,   292, 29892,  ..., 29915,  4909,   383],
         ...,
         [ 1516, 29900, 29929,  ..., 29906, 29947, 29946],
         [ 1516, 29900, 29929,  ..., 29906, 29947, 29946],
         [ 1516, 29900, 29929,  ..., 29906, 29947, 29946]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 4515,  8497, 29881,  ...,   908,  1085,  2627],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         ...,
         [ 6230,   304, 29889,  ...,  4833, 12945,  2585],
         [29889,   304, 29892,  ...,   297,   448, 29915],
         [ 1105,   306,    13,  ..., 10811,  2180, 24380]]], device='cuda:0')
Batch 40, 67.5% of total tokens
encoded shape: torch.Size([2, 1046])
torch.Size([2, 1046]) tensor([[    1, 25701,   866,  ...,  5199,  9045, 29889],
        [    1, 24328,  2347,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1046, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -9.5703, -13.6328,  -6.1367,  ...,  -5.6836,  -4.0352,  -6.2461],
         [  3.5391,   3.9648,  -6.6719,  ...,   7.5898,   5.1641,   5.5117],
         ...,
         [ -3.6465,  -1.6816,   1.3623,  ...,  -3.3145,  -3.8770,  -2.6680],
         [ -2.5605,   0.3335,   8.7031,  ...,  -0.8584,   0.1610,  -1.1396],
         [ -3.8789,  -2.1328,   8.5547,  ...,   0.8433,   1.0381,   0.2991]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -9.0547,  -5.6406,  -1.4678,  ...,  -2.5605,  -3.4355,  -3.7930],
         [-10.6953, -11.9609,  -7.5586,  ...,  -6.2188,  -4.4883,  -8.1250],
         ...,
         [ -3.3672,   5.8086,  -0.3818,  ...,  -0.6133,   0.0258,  -0.1077],
         [ -3.4004,   6.0820,  -0.3220,  ...,  -0.6274,   0.0334,  -0.0765],
         [ -3.3262,   6.1758,  -0.2817,  ...,  -0.5752,   0.1049,  -0.0138]]],
       device='cuda:0')
torch.Size([2, 1046, 1]) tensor([[[29892],
         [14174],
         [ 3049],
         ...,
         [30488],
         [29889],
         [  910]],

        [[29892],
         [  573],
         [29871],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 1046, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14174,   866,  2353,  ...,   711, 29926,   356],
         [ 3049,   305,   486,  ...,   384,  9733,  5083],
         ...,
         [30488, 30879, 31147,  ...,   313, 30555, 31488],
         [29889,   515,   322,  ...,   408,   491,   411],
         [  910,  8680,  1334,  ...,  4525, 25701,     2]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  573,  2347,  4357,  ..., 29875,  3145,  2028],
         [29871,   263,   278,  ...,   590,   491,   297],
         ...,
         [    1,  7228, 14262,  ...,  4345, 24708, 28498],
         [    1,  7228, 14262,  ...,  4345, 24708, 28498],
         [    1,  7228, 14262,  ..., 24708,  4345, 28498]]], device='cuda:0')
Batch 41, 69.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 11474,    13,  ..., 29892,   263,  4656],
        [    1,   450,   716,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -4.3828,   3.3477,   5.5898,  ...,  -1.9590,  -5.9844,  -1.4531],
         [ -1.5225,  -1.7930,  -2.4043,  ...,   0.2106,  -1.1865,   0.8462],
         ...,
         [ -8.0469,  -8.1875,  -0.3760,  ...,  -1.8350,  -2.5586,  -6.3672],
         [ -3.6211,  -1.6484,   1.0605,  ...,  -3.1113,  -3.8828,  -2.5352],
         [ -3.8789,  -2.0566,   1.3809,  ...,  -3.2246,  -3.8848,  -2.4863]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.8203, -10.7266,  -8.4219,  ...,  -8.2422,  -8.7500,  -7.5703],
         [-12.6797, -11.8594, -10.9844,  ...,  -9.3359,  -8.6250,  -9.0781],
         ...,
         [ -6.2227,   9.6016,   4.5781,  ...,  -2.7695,  -4.6719,  -2.7559],
         [ -5.8516,   9.3906,   4.7969,  ...,  -2.6211,  -4.4453,  -2.6875],
         [ -5.1055,   8.3672,   5.7773,  ...,  -2.2598,  -4.0273,  -2.6133]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [   13],
         [ 3257],
         ...,
         [  278],
         [30488],
         [30488]],

        [[29892],
         [29871],
         [29871],
         ...,
         [29879],
         [29879],
         [29879]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [   13, 30004, 29992,  ...,  6805, 26833, 22415],
         [ 3257,  3611,  2680,  ...,   358,  7030,  1725],
         ...,
         [  278,  3138,   373,  ...,   697,   408,   385],
         [30488, 30879, 31147,  ...,   313, 31256, 29892],
         [30488, 30879, 31147,  ..., 30186, 29871, 29899]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,  1570,   937,  ...,   317,   319,   390],
         [29871,   342,  1629,  ...,  1873,  3762,   319],
         ...,
         [29879, 29900, 29906,  ..., 29889, 29946, 29955],
         [29879, 29900, 29906,  ..., 29955, 29946, 29889],
         [29879, 29900, 29906,  ..., 29946,   229, 29889]]], device='cuda:0')
Batch 42, 73.5% of total tokens
encoded shape: torch.Size([2, 2234])
torch.Size([2, 2234]) tensor([[    1,   910,   297,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,  2992, 29889,    13]], device='cuda:0')
torch.Size([2, 2234, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-13.1641, -11.2188,  -6.8008,  ...,  -8.4766,  -8.0312,  -9.4766],
         [-11.4531, -11.9297,  -5.2891,  ...,  -8.5234,  -7.0078,  -8.7109],
         ...,
         [ -9.0469,   5.1602,  -3.0391,  ...,  -4.5312,  -3.2695,  -4.4688],
         [ -7.6484,   5.4336,  -2.9824,  ...,  -3.2871,  -2.2656,  -3.5586],
         [ -6.6836,   5.5586,  -2.8652,  ...,  -2.5293,  -1.6016,  -2.9316]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.3984,   0.6221,  -1.6709,  ...,   2.6641,   0.4211,   0.0731],
         [ -5.4297,  -0.6924,  -2.2090,  ...,  -0.5454,  -0.5952,   1.4268],
         ...,
         [ -1.2354,  -0.2251,   3.2266,  ...,   0.9697,   2.1074,  -0.6118],
         [ -1.8652,  -3.7969,   4.9531,  ...,  -0.5757,   2.0527,   0.6294],
         [ -1.3848,  -4.4492,   0.5371,  ...,  -0.5396,   2.1719,   1.7939]]],
       device='cuda:0')
torch.Size([2, 2234, 1]) tensor([[[29892],
         [  338],
         [ 7316],
         ...,
         [ 7228],
         [ 7228],
         [ 7228]],

        [[29892],
         [29896],
         [29871],
         ...,
         [ 1308],
         [ 8170],
         [17061]]], device='cuda:0')
torch.Size([2, 2234, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  338,  6251,  4723,  ...,  1400,  1629,  4700],
         [ 7316, 29899,  4548,  ...,   263, 13901,   385],
         ...,
         [ 7228,     1,  4345,  ..., 29896,   229,  8132],
         [ 7228,     1,  4345,  ..., 29929,   263,   450],
         [ 7228,     1,  4345,  ...,    10, 30477, 29929]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29871,  1678,   462,  ...,    12, 16595,    13],
         ...,
         [ 1308,  1696, 29889,  ..., 23196, 25432,  8258],
         [ 8170, 26077,    13,  ..., 14546,  6461, 26817],
         [17061, 11746, 29209,  ..., 31083,  3919, 23196]]], device='cuda:0')
Batch 43, 76.6% of total tokens
encoded shape: torch.Size([2, 275])
torch.Size([2, 275]) tensor([[    1,   660, 29901,    13,    13,  2577,  1259,  2609,  3588,  1203,
           304,  9791,  1059,   746,  5663, 15387,  9791,   515,  9056,  7317,
            13,    13, 29902,   505,  7160,   385,  9791,   304,   278,  4867,
          1203, 29889,   306,   626,  1811,   304, 10563,   372,   773,    13,
         29879,   374,  1293,   353,  4867, 29889,   657,  6708,   703,  1557,
         11310,  9652,   267,  1496,    13,    13, 29902,   626,  2805,   278,
          6633,   931,  1059,   376, 29089,  3588,   515,  4669,   304,  9791,
          1642,  1128,   508,   306,   679,   590,  9791,  1250,   515,   278,
          4867,  1203, 29889,    13,    13, 29909, 29901,    13,    13,  1576,
          9056,  7317, 29937,   657,  6708,   580,  1158,  3639,  2115, 29889,
          3893, 29889,  2061, 29901,    13,  3597,  2115, 29889,  3893, 29889,
          2061,   679,  6708, 29898,  1645, 29889,  3893, 29889,  1231,  1024,
         29897,    13,    13,  9260,   366,  1018,   304,  4320,   278,  4133,
          1203, 29973,    13, 29879,   374,  1293,   353,   313, 20165, 29897,
          7924, 29889,   657,  6708,   703,  1557, 11310,  9652,   267,  1496,
            13,    13, 29909, 29901,    13,    13,  3492,   505,   304,  4320,
           372, 29889,    13, 29879,   374,  1293,   353,   313, 20165, 29897,
          7924, 29889,   657,  6708,   703,  1557, 11310,  9652,   267,  1496,
            13,    13,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13,  2605,   373,  5669,   363, 11171,
            13,    13, 29902,   626,  1985,   297, 20872, 29892,   322,   306,
           626,   773,  7609,   577,   590,   623,   723,  7150,   278,   934,
          2224,   310,   278,   934,   393,   306,  1304,   304,  6826,   590,
           623,   607,   297,   445,  1206,   338,   263,   869, 29907,  7597,
           934, 29889,    13,  8136,  8404,  2385, 20872,  9075,   353,   716,
          5669,  8404,  2385,   703,   510, 29889,  6997, 29941, 29881, 29889,
          9106, 29889,  2525,   537,  9075,  1496,    13,  8136,  8404,  2061,
          1857,  3886,   353, 20872,  9075, 29889,  2577, 17046, 29966,  8136,
          8404,  2061, 29958,   703,  3784,  3886,  1496,    13,    13,  1678,
          5669,  8404,  2061,  7609,   353,  1857,  3886, 29889,  5594, 29966,
          8136,  8404,  2061, 29958,   703,   657, 10286,  1496,    13,    13,
          4013,   338,   920,   306,   679,   278,   848,  2224, 29889,    13,
          1807,  1121,   353,  7609, 29889,  5594, 29966,  1807, 29958,   703,
           657,  1469,  1231,  1496,    13,    13,  4013,   338,   278,  2224,
           372,  4076, 29901,    13,  1445,   597, 29914, 12925, 29914,   331,
          7964, 29914, 29900, 29914,  1958, 29946, 29889,  7638,    13,    13,
          1576,  2224,   306,   817, 29901,    13, 29914, 12925, 29914,  4928,
          7543, 29900, 29914,  1958, 29946, 29889,  7638,    13,    13, 16107,
          3538,   306,   508, 29915, 29873,  1035,   267,   278,   934,   373,
           393,  2224, 29889,    13,  5328,  1033,   306,   679,   278, 29871,
         29906,   299,  1134,   310,  2224, 29973,    13,    13, 29909, 29901,
            13,    13,  1576,  5669, 10854,   362,  1544,  3697, 29901,    13,
           657,  1469,  1231,   580,    13,  1678,   376,  1576,  1021,   408,
           679,  1469,  3285,   541,  3639,   278, 23539,   408,   385, 18511,
          1714,  1213,    13,    13,  6295,   372,  3732,  4060,   304,   817,
           304,   376, 29956, 29956, 29956, 29889,  2525, 14190,  5738,  4219,
         29898,  2914,  5513,    13,    13]], device='cuda:0')
torch.Size([2, 275, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [-10.6953, -11.7812,  -5.2227,  ...,  -6.0820,  -9.1250,  -6.8516],
         [-11.5234, -12.3828,  -3.2461,  ...,  -5.0078,  -5.4727,  -3.9609],
         ...,
         [ -3.2285,  -1.3252,   1.0518,  ...,  -3.0566,  -3.7422,  -2.4668],
         [ -3.2266,  -1.3506,   1.0605,  ...,  -3.0586,  -3.7461,  -2.4648],
         [ -3.2344,  -1.3535,   1.0674,  ...,  -3.0625,  -3.7480,  -2.4668]],

        [[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [-10.6953, -11.7812,  -5.2227,  ...,  -6.0820,  -9.1250,  -6.8516],
         [-11.5234, -12.3828,  -3.2461,  ...,  -5.0078,  -5.4727,  -3.9609],
         ...,
         [ -4.6445,  -9.1484,  12.3438,  ...,  -2.7852,  -2.2168,  -3.4082],
         [ -7.4375,  -6.6484,   4.8242,  ...,  -6.6680,  -3.6016,  -4.2266],
         [ -9.0391, -12.0938,   0.2732,  ...,  -3.7793,  -2.5195,  -1.4238]]],
       device='cuda:0')
torch.Size([2, 275, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [ 1259],
         [ 7370],
         [ 1284],
         [  515],
         [  310],
         [ 1347],
         [29966],
         [   13],
         [  306],
         [15387],
         [  848],
         [  515],
         [ 2566],
         [ 5103],
         [   13],
         [   13],
         [29902],
         [  626],
         [  263],
         [ 9791],
         [ 9791],
         [  297],
         [ 9056],
         [ 9056],
         [  322],
         [  322],
         [  306],
         [  626],
         [ 1811],
         [  304],
         [10563],
         [  372],
         [ 1250],
         [  278],
         [   13],
         [ 9524],
         [  415],
         [  353],
         [  313],
         [29889],
         [  657],
         [ 6708],
         [  703],
         [29879],
         [ 2361],
         [ 1293],
         [  267],
         [ 1496],
         [   13],
         [   13],
         [ 6246],
         [  626],
         [ 2805],
         [  278],
         [ 1494],
         [  931],
         [ 1059],
         [29901],
         [29089],
         [ 3588],
         [ 1203],
         [ 9791],
         [  304],
         [ 9791],
         [ 1642],
         [   13],
         [  437],
         [  306],
         [10563],
         [  278],
         [ 9791],
         [ 1250],
         [  515],
         [  278],
         [ 9056],
         [ 1203],
         [29973],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [ 3492],
         [ 1108],
         [ 7317],
         [ 1203],
         [  657],
         [ 6708],
         [  580],
         [ 1158],
         [ 3639],
         [  385],
         [29889],
         [ 3893],
         [29889],
         [ 2061],
         [29889],
         [   13],
         [   13],
         [ 4669],
         [29889],
         [ 3893],
         [29889],
         [ 2061],
         [  679],
         [ 6708],
         [29898],
         [ 1231],
         [29889],
         [ 3893],
         [30488],
         [ 1231],
         [ 1024],
         [29897],
         [   13],
         [   13],
         [ 1576],
         [  366],
         [ 1018],
         [  304],
         [ 4320],
         [  372],
         [ 4133],
         [ 4669],
         [  304],
         [   13],
         [   13],
         [  374],
         [ 1293],
         [  353],
         [  313],
         [20165],
         [29966],
         [ 4867],
         [29889],
         [  657],
         [ 6708],
         [  703],
         [ 1557],
         [11310],
         [ 9652],
         [  267],
         [ 1496],
         [   13],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [29902],
         [  508],
         [  304],
         [30488],
         [  278],
         [  304],
         [   13],
         [   13],
         [  374],
         [ 1293],
         [  353],
         [  313],
         [20165],
         [29897],
         [ 4867],
         [29889],
         [  657],
         [ 6708],
         [  703],
         [ 1557],
         [11310],
         [ 9652],
         [  267],
         [ 1496],
         [   13],
         [   13],
         [20001],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 2277],
         [ 2277],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29889],
         [30488],
         [30488],
         [30488],
         [29871],
         [ 1576],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [ 2886],
         [  263],
         [   13],
         [10012],
         [ 3170],
         [   13],
         [29902],
         [  505],
         [ 1811],
         [  373],
         [  263],
         [29941],
         [  322],
         [  306],
         [  626],
         [ 1811],
         [  278],
         [  304],
         [  393],
         [  623],
         [  508],
         [ 1722],
         [  278],
         [ 7609],
         [ 2224],
         [  310],
         [  278],
         [ 1967],
         [  393],
         [  278],
         [  626],
         [  304],
         [ 1722],
         [  278],
         [  623],
         [29889],
         [  338],
         [ 2507],
         [ 1206],
         [  338],
         [  263],
         [ 4863],
         [ 1526],
         [ 7597],
         [  934],
         [29889],
         [   13],
         [   13],
         [ 7448],
         [ 3886],
         [29889],
         [15280],
         [ 3886],
         [  716],
         [ 5669],
         [ 8404],
         [ 2385],
         [  703],
         [  510],
         [29889],
         [ 6997],
         [29941],
         [29881],
         [29889],
         [ 9106],
         [29889],
         [ 2525],
         [  537],
         [ 9075],
         [ 3886],
         [   13],
         [ 8136],
         [ 8404],
         [ 2061],
         [ 7609],
         [ 3886],
         [  353],
         [20872],
         [ 9075],
         [29889],
         [ 2577],
         [11024],
         [29966],
         [ 8136],
         [ 8404],
         [ 2061],
         [29958],
         [  703],
         [ 3784],
         [ 3886],
         [ 1496],
         [   13],
         [ 8136],
         [ 8136],
         [ 5669],
         [ 8404],
         [ 2061],
         [ 7609],
         [  353],
         [ 1857],
         [ 3886],
         [29889],
         [ 8251],
         [29966],
         [ 8136],
         [ 8404],
         [ 2061],
         [29958],
         [  703],
         [  657],
         [10286],
         [ 1496],
         [   13],
         [ 1678],
         [ 1678],
         [  338],
         [  278],
         [  306],
         [  626],
         [  278],
         [ 7609],
         [  515],
         [  310],
         [   13],
         [   13],
         [ 2224],
         [  353],
         [ 7609],
         [29889],
         [ 5594],
         [29966],
         [ 1807],
         [29958],
         [  703],
         [  657],
         [ 1469],
         [ 1231],
         [ 1496],
         [   13],
         [   13],
         [ 6246],
         [  338],
         [  920],
         [  775],
         [  393],
         [ 3639],
         [  592],
         [   13],
         [29914],
         [  597],
         [29914],
         [ 2843],
         [29914],
         [  331],
         [ 7964],
         [29914],
         [29900],
         [29914],
         [ 8136],
         [29914],
         [29889],
         [ 7638],
         [   13],
         [   13],
         [29902],
         [ 1108],
         [  306],
         [  864],
         [  338],
         [   13],
         [ 1445],
         [12925],
         [29914],
         [  331],
         [ 7543],
         [29900],
         [29914],
         [ 1958],
         [29946],
         [29889],
         [ 7638],
         [   13],
         [   13],
         [29902],
         [ 3538],
         [29892],
         [  508],
         [29915],
         [29873],
         [ 2130],
         [  267],
         [  278],
         [  934],
         [29889],
         [  590],
         [ 2224],
         [29889],
         [   13],
         [   13],
         [  508],
         [  306],
         [  679],
         [  278],
         [ 2224],
         [29906],
         [  299],
         [ 2224],
         [  310],
         [ 2224],
         [29973],
         [   13],
         [   13],
         [22550],
         [29901],
         [   13],
         [   13],
         [29902],
         [ 7609],
         [ 3355],
         [  362],
         [  756],
         [  338],
         [  920],
         [   13],
         [  991],
         [ 1469],
         [ 1231],
         [  580],
         [   13],
         [11609],
         [16969],
         [11609],
         [  848],
         [  408],
         [  679],
         [10286],
         [29892],
         [  541],
         [  278],
         [  263],
         [  848],
         [  408],
         [  263],
         [18511],
         [ 1347],
         [ 1213],
         [   13],
         [   13],
         [ 6295],
         [29892],
         [ 3430],
         [ 4060],
         [  393],
         [  592],
         [  304],
         [21822],
         [13808],
         [ 2390],
         [29889],
         [29899],
         [  657],
         [  537],
         [ 5738],
         [ 5983],
         [29898],
         [ 2914],
         [29889],
         [  304],
         [   13],
         [  991]]], device='cuda:0')
torch.Size([2, 275, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [  304,    13,   297,  ...,   937,   565,   363],
         [   13,   517,   991,  ...,  2525,  6246,  4013],
         [  991, 20001,  1124,  ..., 29933, 10605, 29984]]], device='cuda:0')
Batch 44, 77.0% of total tokens
encoded shape: torch.Size([2, 279])
torch.Size([2, 279]) tensor([[    1, 24032,  2626,  3842, 29901,  7113,   263, 25323,  3321,   452,
          2192,  5365,  3002,   310,  3805,   768,   519, 12580,   295, 22898,
          4871, 29889,    13,  1576, 17294,   322,   278, 22341,   526, 17785,
           297,  2145,   950,   274,  1883,   303,  2235,  3412,   263,  1353,
           310,  2224,  1994,  6314,  3598,  1840,   287,   278,   525,  2634,
           262, 29899, 29887,   329,  9685,  4286,  6811,  7786,  2440,   372,
           756,  4953, 10231,   368,  2821,   393,   270,   952,  1727,  2785,
           310,   278,  9685,   472,   263,  1353,   310, 11174,   508,  1121,
           297,   766, 20488,  1316,   408,  3805,   768,   519, 12580,   295,
         22898,  4871,   313,  8979, 29903,   467,  2973,  7786,  3061,  2925,
           297,   452,  2192,   326,  6751,  5722, 11763, 29892,  1663,  5861,
           964,   278,   452,  2192,  5365,  3002,   310,   306,  9851,   526,
          6763,   304, 11176,   479, 29889,  2398,   278, 25323,  3321,   452,
          2192,  5365,  3002,   310,   306,  9851,   756,  9488, 13774,   443,
         24516,  4395,   304,  2635, 29889,   512,   445,  9076,   591, 19138,
           895,   278,  3625,   848,   373, 25323,  3321,   740,   297,   306,
          9851, 29889, 12808, 29892,   591, 10816,  3211,  2211,  1820,  2224,
          3021,   952, 29875,  5996, 13879, 29892, 18451, 29936, 22884, 29892,
          5198,  1540, 26229,   322, 17168,   293,  6788, 29892,  4208,   411,
           916, 13879,  9701,   297,   278, 10419,   362,   310,   306,  9851,
         29892,   322, 26987,   920,  1269,   310,  1438,  7117,  1122, 10879,
          1644, 29878,   635, 29892,   825,   452,  2192,  5365,  5996,  7208,
         12903,  1795,   367,  9701, 29892,   322,  2050,   278,  2411,  5795,
           363, 25323,  3321,   740,   292,   297,   306,  9851, 29889,  1334,
         17668,   393,  1269,  7329, 20976,  1033, 16951,  2411, 19144,   373,
          6555, 23547,   681,  1788,   740, 29892, 20382,   278,  1776,   393,
          5434,  5925, 14231,  1818,   367, 10624,  7113,   263, 13173, 24809,
           358,   310, 25323,  3321,   740,   297,   306,  9851, 29889],
        [    1,   660, 29901,    13,    13, 11980, 29694,   322,  6597,   292,
           995,   310,   503,   363,   921,   322,   343, 29973,    13,    13,
         29956,   483,   366,  3113,  1371,    13, 29902,   505,   445,   848,
           988,   503,   338,   263,   740,   363,  2702,   921,   322,   343,
            13, 10351,   353,   518, 29900, 29889, 29896, 29945, 29892, 29871,
         29900, 29889, 29941, 29945, 29892, 29871, 29900, 29889, 29945, 29892,
         29871, 29900, 29889, 29953, 29955, 29892, 29871, 29900, 29889, 29947,
         29962,    13,   952,   353,   518, 29900, 29889, 29900, 29896, 29892,
         29900, 29889, 29900, 29896, 29892, 29871, 29900, 29889, 29900, 29896,
         29892, 29871, 29900, 29889, 29900, 29896, 29892, 29871, 29900, 29889,
         29900, 29896, 29962,    13, 29920,   353,   518, 29900, 29889, 29955,
         29945, 29892, 29871, 29900, 29889, 29947, 29941, 29892, 29871, 29896,
         29889, 29900, 29900, 29892, 29871, 29900, 29889, 29929, 29906, 29892,
         29871, 29900, 29889, 29929, 29896, 29962,    13,    13, 29902, 21050,
           278,  1819,   297,   445,  8267,    13,  5328,   508,   306,   437,
         29694,   363,   278,  3291,   577,   306,   508,  1246,   503,   995,
          2678,  1422,  1135,   278,   278,   697,   306,   505, 29973,    13,
            13, 29909, 29901,    13,    13, 29873,   384,   353, 20064,   403,
         29889, 18809,   572,  3445, 29898, 29916, 29892,   343, 29892,   503,
         29892,   269, 29922, 29900, 29897,    13,  1753,  1517,  2004, 29999,
         29898, 29916, 29892, 29891,  1125,    13,  1678,   736, 20064,   403,
         29889, 18809,   552, 29894, 29898, 29916, 29892, 29891, 29892, 29873,
           384, 29897,    13,    13, 10454,   491,  2734,   278,   775, 29892,
           372,   674,  2367,   503,   363,  2702,   921,   322,   343, 29889,
            13,  4013,   508,   367,  1304,  1728,  6492, 29889,   925,  1925,
           372,  1090,   278,  1819,   322,  1207,  1854,   393,   278,  1819,
           526, 21050,   297,   278,  1021,   982,    13,    13,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 279, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -9.6562, -11.3516,  -3.2480,  ...,  -4.6328,  -3.4648,  -4.8711],
         [ -9.9375, -10.4453,  -0.6069,  ...,  -5.7070,  -1.3105,  -7.1133],
         ...,
         [ -5.2656,  -5.7695,   7.2891,  ...,  -3.5234,  -3.2266,  -3.7793],
         [ -4.9531,  -6.7852,   6.0078,  ...,  -3.5957,  -1.5830,  -4.9023],
         [ -8.8672,  -9.5547,  11.8828,  ...,  -4.6406,  -4.3281,  -4.6758]],

        [[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [-10.6953, -11.7812,  -5.2227,  ...,  -6.0820,  -9.1250,  -6.8516],
         [-11.5234, -12.3828,  -3.2461,  ...,  -5.0078,  -5.4727,  -3.9609],
         ...,
         [ -3.3809,  -0.2581,   1.2119,  ...,  -3.0195,  -3.6133,  -2.4414],
         [ -3.3203,  -0.6665,   1.1592,  ...,  -3.0312,  -3.6621,  -2.4512],
         [ -3.2676,  -0.8721,   1.1152,  ...,  -3.0234,  -3.6797,  -2.4473]]],
       device='cuda:0')
torch.Size([2, 279, 1]) tensor([[[29892],
         [ 1092],
         [ 3842],
         [  310],
         [  450],
         [  263],
         [ 6368],
         [ 3321],
         [17167],
         [ 2192],
         [ 5365],
         [ 3002],
         [  310],
         [ 3370],
         [  768],
         [  519],
         [12580],
         [  295],
         [22898],
         [ 4871],
         [29889],
         [24032],
         [29907],
         [ 3805],
         [29899],
         [22341],
         [22341],
         [  526],
         [  938],
         [  297],
         [  263],
         [  950],
         [ 7928],
         [ 1883],
         [  303],
         [ 2235],
         [29892],
         [  278],
         [19677],
         [  310],
         [ 2224],
         [ 1994],
         [29889],
         [ 3598],
         [ 1840],
         [  287],
         [  278],
         [22341],
         [29887],
         [  262],
         [29899],
         [29887],
         [  329],
         [ 9685],
         [ 4286],
         [  450],
         [  278],
         [ 2440],
         [29892],
         [  756],
         [ 4953],
         [10231],
         [  368],
         [20295],
         [  393],
         [  278],
         [  952],
         [ 1727],
         [ 2785],
         [  310],
         [  445],
         [17294],
         [  338],
         [  278],
         [ 1353],
         [  310],
         [11174],
         [  508],
         [ 3275],
         [  297],
         [  263],
         [20488],
         [  310],
         [  408],
         [ 3805],
         [  768],
         [  519],
         [12580],
         [  295],
         [22898],
         [ 4871],
         [  313],
         [ 8979],
         [29903],
         [  467],
         [  450],
         [  278],
         [ 3061],
         [ 2925],
         [  297],
         [  452],
         [ 2192],
         [  326],
         [ 6751],
         [  322],
         [11763],
         [29892],
         [  372],
         [ 5861],
         [  964],
         [  278],
         [  452],
         [ 2192],
         [ 5365],
         [ 5996],
         [  310],
         [  306],
         [ 9851],
         [  505],
         [11176],
         [  304],
         [11176],
         [30488],
         [29889],
         [  512],
         [29892],
         [ 1746],
         [ 3321],
         [17167],
         [ 2192],
         [ 5365],
         [ 3002],
         [  310],
         [  306],
         [ 9851],
         [  338],
         [ 4520],
         [18425],
         [  443],
         [24516],
         [ 4395],
         [29889],
         [ 2635],
         [29889],
         [  512],
         [  445],
         [30488],
         [29892],
         [ 5353],
         [  895],
         [  278],
         [ 3625],
         [  452],
         [  373],
         [  278],
         [ 3321],
         [10174],
         [  297],
         [  306],
         [ 9851],
         [  322],
         [ 1334],
         [29892],
         [  591],
         [ 5353],
         [ 8569],
         [  278],
         [ 5155],
         [29892],
         [29899],
         [  952],
         [29875],
         [ 5996],
         [30488],
         [  393],
         [18451],
         [ 1998],
         [ 1998],
         [29892],
         [ 1998],
         [30488],
         [  270],
         [  322],
         [10551],
         [30488],
         [  313],
         [29892],
         [  607],
         [  411],
         [ 1009],
         [13879],
         [ 1316],
         [  297],
         [  278],
         [25323],
         [30488],
         [  310],
         [  306],
         [ 9851],
         [25828],
         [ 1316],
         [ 5353],
         [  920],
         [ 1438],
         [  310],
         [ 1438],
         [13879],
         [ 1122],
         [29126],
         [ 2501],
         [29878],
         [  635],
         [14457],
         [  322],
         [  525],
         [ 2192],
         [ 5365],
         [ 5996],
         [ 7208],
         [12903],
         [ 1122],
         [  367],
         [ 9701],
         [29892],
         [  322],
         [  920],
         [  278],
         [30488],
         [30488],
         [  363],
         [25323],
         [ 3321],
         [29220],
         [29889],
         [29889],
         [  306],
         [ 9851],
         [29889],
         [ 1334],
         [  884],
         [  393],
         [  278],
         [  310],
         [  756],
         [  297],
         [19998],
         [10879],
         [29874],
         [  373],
         [25323],
         [30488],
         [  681],
         [30488],
         [  313],
         [  292],
         [  322],
         [  278],
         [17837],
         [  393],
         [25323],
         [ 5925],
         [  881],
         [  881],
         [  367],
         [10624],
         [ 7113],
         [  278],
         [25323],
         [  322],
         [  358],
         [  310],
         [  278],
         [ 3321],
         [  740],
         [  297],
         [  306],
         [ 9851],
         [29889],
         [   13]],

        [[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [29871],
         [  310],
         [ 1294],
         [  292],
         [  848],
         [  515],
         [  263],
         [  515],
         [  263],
         [  322],
         [  343],
         [   13],
         [   13],
         [   13],
         [29902],
         [  483],
         [11188],
         [ 1073],
         [ 1371],
         [  592],
         [   13],
         [  505],
         [  263],
         [  848],
         [ 3515],
         [  306],
         [  338],
         [  278],
         [  740],
         [  310],
         [  921],
         [  921],
         [  322],
         [  343],
         [ 1819],
         [   13],
         [  353],
         [ 7442],
         [29896],
         [29892],
         [29900],
         [29892],
         [29892],
         [29871],
         [29900],
         [29889],
         [29906],
         [29892],
         [29892],
         [29871],
         [29900],
         [29889],
         [29945],
         [29945],
         [29871],
         [29900],
         [29889],
         [29953],
         [29945],
         [29892],
         [29871],
         [29900],
         [29889],
         [29947],
         [29892],
         [   13],
         [  952],
         [  353],
         [  518],
         [29900],
         [29889],
         [29896],
         [29945],
         [29892],
         [29871],
         [29889],
         [29900],
         [29906],
         [29892],
         [29900],
         [29900],
         [29889],
         [29900],
         [29896],
         [29892],
         [29871],
         [29900],
         [29889],
         [29900],
         [29896],
         [29892],
         [29871],
         [29900],
         [29889],
         [29900],
         [29896],
         [29962],
         [   13],
         [22381],
         [  353],
         [ 7442],
         [29900],
         [29889],
         [29900],
         [29892],
         [29892],
         [29871],
         [29900],
         [29889],
         [29955],
         [29892],
         [29892],
         [29871],
         [29900],
         [29889],
         [29900],
         [29892],
         [29892],
         [29871],
         [29896],
         [29889],
         [29929],
         [29900],
         [29892],
         [29871],
         [29900],
         [29889],
         [29947],
         [29945],
         [29962],
         [   13],
         [   13],
         [29902],
         [  864],
         [  278],
         [  848],
         [  297],
         [  263],
         [  982],
         [29901],
         [   13],
         [  508],
         [  306],
         [ 6597],
         [29694],
         [  322],
         [  921],
         [  503],
         [  322],
         [  393],
         [  508],
         [  679],
         [  278],
         [  363],
         [  363],
         [29973],
         [  363],
         [  278],
         [ 2441],
         [ 2441],
         [  306],
         [  505],
         [29973],
         [   13],
         [   13],
         [29902],
         [29901],
         [   13],
         [   13],
         [29902],
         [ 1255],
         [  353],
         [20064],
         [  403],
         [29889],
         [29879],
         [29889],
         [ 3445],
         [29898],
         [10351],
         [29892],
         [  343],
         [29892],
         [  503],
         [29897],
         [ 2924],
         [30488],
         [29900],
         [29897],
         [   13],
         [29873],
         [  285],
         [  575],
         [29898],
         [29898],
         [29916],
         [29892],
         [  343],
         [ 1125],
         [   13],
         [ 1678],
         [  736],
         [20064],
         [  403],
         [29889],
         [29879],
         [29889],
         [30488],
         [29898],
         [29916],
         [29892],
         [  343],
         [29892],
         [29873],
         [  384],
         [29897],
         [   13],
         [   13],
         [29887],
         [  306],
         [ 5432],
         [  445],
         [  775],
         [ 2400],
         [  306],
         [  674],
         [  736],
         [  592],
         [  995],
         [  738],
         [  921],
         [  322],
         [  343],
         [29889],
         [   13],
         [   13],
         [  338],
         [  367],
         [ 1304],
         [  363],
         [  278],
         [ 1259],
         [   13],
         [ 1246],
         [  278],
         [  297],
         [  278],
         [ 2425],
         [  310],
         [ 1246],
         [  263],
         [  304],
         [  278],
         [  921],
         [  526],
         [  297],
         [  297],
         [  278],
         [ 1021],
         [ 1797],
         [  408],
         [   13],
         [20001],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 279, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1092,  6349, 20140,  ...,  1259, 15202,  1423],
         [ 3842,  6390,  9020,  ...,  7661, 14119,  1182],
         ...,
         [ 9851, 12445,  5824,  ...,  6530, 14851, 22069],
         [29889, 29892, 22069,  ..., 23093,   304,   411],
         [   13, 12808,   910,  ...,   450,     2, 14187]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [30488, 30879, 31147,  ..., 30300, 31256, 30331],
         [30488, 30879, 31147,  ..., 31256, 30331, 30300],
         [30488, 30879, 31147,  ..., 31256, 30331, 30300]]], device='cuda:0')
Batch 45, 77.6% of total tokens
encoded shape: torch.Size([2, 156])
torch.Size([2, 156]) tensor([[    1,   518, 29925,  1267,  2075, 24876, 19263,  1822,    13,  8439,
           338,  3117,   694,   916, 16083,  1746,   607,   756,  1090, 29887,
           650,  1316, 10952,  5849,  2645,   278,  4940, 29871, 29906, 29900,
          2440,   408,   544,   264,  2075, 24876, 19263, 29889,   450,  1353,
           310,  5866,  1058, 13521,   445, 18872,   338, 28325,  2354, 10231,
           322,   901,   322,   901, 13698,   505,  4953,  3625,   607,  9025,
           263, 15678,  1353,   310,  2531,  7492, 23503, 29879,   304,   367,
         24876,  2662,   411,  3058,  1017,  7536,   304, 12060, 29889,   349,
          1267,  2075, 24876, 19263,   338,   263,  7282,  5780,   310,  2531,
          7492,  2613, 29879,  7807, 29889,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13,  3525,   304,   788,  4576,  1923,
         17752,   297,  3989,   773,   281,  1160,    13,    13, 29902,   626,
          1811,   304,   788,  4576,  1923, 29871, 17752,   304,  3989, 29871,
           541,   372,  4076,  1059,   310,  4567,  7156,    13, 17588, 29922,
          1961, 29918,  2850, 29879, 15291, 29889, 12396, 29936,    13,    13,
         29909, 29901,    13,    13,  3492,   505,   304,  5142,   278, 24415,
           937, 29889,  1126,   445,  7111,   373,   596,  5048, 29899,  6594,
         29889, 29871,    13,  1124,   597,  1636, 29889,  4994, 29889,   510,
         29914,   264, 29899,   375, 29914, 10382, 29914, 14144, 29889,  6307,
         29973,   333, 29922, 29906, 29900, 29900, 29929, 29947,    13, 10605,
           366,   508,  5142,   278,  7156, 29889, 29871,    13, 18743,  1423,
           278,  2684,  5048, 29899,  6594,   322,  5142,   278,  1959, 10480,
         29899, 17618,  1725,  1873,   363,  3852, 29889, 29871,    13,  6103,
         29901,    13,  3492,   505,   304,  2601,   278,   341,  1799,  2239,
         29899,  4032,   373,   596,  1788, 29889, 13466,   366,   508, 29915,
         29873,  4511, 29889, 29871,    13,    13]], device='cuda:0')
torch.Size([2, 156, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5298,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.3828,  -8.2422,   0.0777,  ...,  -0.7261,  -1.1533,  -0.9648],
         [ -7.1836, -12.5156,  -1.0107,  ...,  -5.0039,  -2.5137,  -3.6914],
         ...,
         [ -3.2402,  -1.3730,   1.1064,  ...,  -3.0684,  -3.7441,  -2.4668],
         [ -3.2363,  -1.3730,   1.1064,  ...,  -3.0664,  -3.7441,  -2.4629],
         [ -3.2344,  -1.3672,   1.1045,  ...,  -3.0605,  -3.7441,  -2.4609]],

        [[ -8.0312,  -1.1074,  -0.5298,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7734,  -5.2148,  ...,  -6.0742,  -9.1250,  -6.8438],
         [-11.5156, -12.3750,  -3.2422,  ...,  -5.0078,  -5.4688,  -3.9551],
         ...,
         [ -0.4910,  -2.1914,  15.6094,  ...,  -1.7510,  -0.8140,  -1.2432],
         [ -9.7734, -10.0625,   8.9062,  ...,  -7.0312,  -5.1719,  -4.4727],
         [ -8.9219,  -9.1562,   5.0898,  ...,  -5.2344,  -2.3926,  -1.5742]]],
       device='cuda:0')
torch.Size([2, 156, 1]) tensor([[[29892],
         [12614],
         [ 1745],
         [ 2075],
         [24876],
         [19263],
         [  310],
         [   13],
         [ 1576],
         [  338],
         [  263],
         [  694],
         [16083],
         [16083],
         [ 4266],
         [  297],
         [  756],
         [ 8906],
         [29887],
         [30488],
         [ 1316],
         [  263],
         [ 5849],
         [  297],
         [  278],
         [ 1833],
         [29871],
         [29896],
         [29900],
         [ 2440],
         [  408],
         [  544],
         [  264],
         [30488],
         [24876],
         [19263],
         [29889],
         [  450],
         [  937],
         [  310],
         [  758],
         [30488],
         [  526],
         [  304],
         [ 2924],
         [30488],
         [30488],
         [30488],
         [10231],
         [29889],
         [  278],
         [  322],
         [  901],
         [ 3581],
         [  526],
         [ 1063],
         [ 3625],
         [29889],
         [ 2758],
         [  278],
         [30488],
         [30488],
         [  310],
         [ 3581],
         [29899],
         [  322],
         [29879],
         [  304],
         [  367],
         [17809],
         [ 2662],
         [  297],
         [ 7621],
         [30488],
         [29889],
         [  304],
         [12060],
         [29889],
         [  450],
         [ 1267],
         [30488],
         [24876],
         [19263],
         [  338],
         [  263],
         [30879],
         [29892],
         [  297],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 7807],
         [  322],
         [  739],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [29871],
         [29871],
         [29871],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [14873],
         [ 1724],
         [29984],
         [ 5618],
         [  304],
         [  679],
         [  263],
         [ 1923],
         [ 2566],
         [  304],
         [ 7604],
         [ 1357],
         [16446],
         [ 1160],
         [ 1923],
         [   13],
         [22550],
         [  505],
         [  773],
         [  304],
         [  788],
         [ 4576],
         [ 1923],
         [17752],
         [29906],
         [  297],
         [ 3989],
         [  773],
         [29945],
         [  474],
         [  338],
         [  592],
         [  763],
         [ 4576],
         [24415],
         [29889],
         [   13],
         [ 4576],
         [ 1961],
         [29918],
         [ 2850],
         [29879],
         [15291],
         [29918],
         [12396],
         [   13],
         [ 4576],
         [   13],
         [20001],
         [29901],
         [   13],
         [   13],
         [ 3492],
         [  817],
         [  304],
         [ 2601],
         [  278],
         [ 4576],
         [  934],
         [  322],
         [   13],
         [  769],
         [  338],
         [  373],
         [  278],
         [ 6570],
         [ 1873],
         [ 3421],
         [29889],
         [   13],
         [   13],
         [   13],
         [  597],
         [ 1636],
         [30488],
         [ 4994],
         [29889],
         [  510],
         [29914],
         [  264],
         [29899],
         [  375],
         [29914],
         [10382],
         [29914],
         [14144],
         [29889],
         [ 6307],
         [29973],
         [  333],
         [29922],
         [29906],
         [29900],
         [29900],
         [30488],
         [29947],
         [   13],
         [   13],
         [  338],
         [  508],
         [ 1284],
         [  278],
         [24415],
         [  363],
         [   13],
         [   13],
         [   13],
         [  366],
         [  278],
         [ 1873],
         [ 1873],
         [ 1873],
         [ 6594],
         [  366],
         [  278],
         [  278],
         [ 1959],
         [ 1873],
         [30488],
         [17618],
         [30488],
         [10079],
         [29889],
         [  596],
         [29889],
         [   13],
         [   13],
         [   13],
         [  278],
         [   13],
         [   13],
         [  508],
         [  304],
         [ 2601],
         [  278],
         [ 7156],
         [ 1799],
         [ 2239],
         [29899],
         [ 6004],
         [29899],
         [  596],
         [  399],
         [29889],
         [29871],
         [  366],
         [  508],
         [29915],
         [30488],
         [ 4511],
         [  304],
         [   13],
         [   13],
         [   13],
         [20001]]], device='cuda:0')
torch.Size([2, 156, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [12614, 26336, 30098,  ..., 29896, 29950, 29990],
         [ 1745, 14789,  3028,  ...,  9415,  5607,   545],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,   306,  1128,  ...,  1932,  1317,   450],
         ...,
         [   13,     2,  1126,  ...,  4248,   910,  1732],
         [   13,  1124,  3492,  ..., 13555,   991, 17351],
         [20001, 22550,  1124,  ..., 29984, 29902,  4597]]], device='cuda:0')
Batch 46, 77.8% of total tokens
encoded shape: torch.Size([2, 581])
torch.Size([2, 581]) tensor([[    1,  8286,   338,  ...,  4340,  2472, 29889],
        [    1,   405, 29519,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 581, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -8.2891,  -9.0469,  -4.1406,  ...,  -4.7188,  -4.1992,  -4.2734],
         [ -8.7500, -11.5547,   0.7188,  ...,  -3.9844,  -3.6953,  -3.6660],
         ...,
         [ -5.9375,  -4.7891,   2.6973,  ...,  -4.9570,  -4.0000,  -3.1719],
         [ -2.3906,  -3.1250,  10.8594,  ...,  -2.3438,   1.1602,  -3.3594],
         [ -0.7534,  -0.3489,  14.0938,  ...,   0.6211,   0.0906,   0.1271]],

        [[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -6.1680,  -6.3984,   1.9893,  ...,  -2.8633,  -2.9043,  -4.8320],
         [-12.1250, -12.8281,  -7.1094,  ...,  -5.6992,  -7.8281,  -7.1133],
         ...,
         [ -7.1211,  -0.1562,  -3.7871,  ...,  -2.6270,  -0.2412,  -3.4492],
         [-11.6406,  -4.2773,  -4.3828,  ...,  -5.8008,  -3.6348,  -6.7812],
         [-12.6562,  -5.6836,  -4.3906,  ...,  -6.6055,  -4.9805,  -7.6562]]],
       device='cuda:0')
torch.Size([2, 581, 1]) tensor([[[29892],
         [  338],
         [12708],
         ...,
         [  297],
         [29889],
         [   13]],

        [[29892],
         [ 2749],
         [29933],
         ...,
         [ 1516],
         [ 1516],
         [29896]]], device='cuda:0')
torch.Size([2, 581, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  338, 29892,   756,  ...,   363,   297,   518],
         [12708,   263,   278,  ...,  5279,  1304,  6077],
         ...,
         [  297,   322,  2472,  ...,   263,    13,  4902],
         [29889,   322,   470,  ..., 29892, 29901,   472],
         [   13,     2,  1334,  ...,  1152,   518,  3529]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 2749,  1682,  5371,  ..., 23249,   329,  3723],
         [29933, 29925, 29956,  ..., 29950,  7228, 29906],
         ...,
         [ 1516,  4345, 29900,  ...,   375, 10888, 10887],
         [ 1516, 29896, 29900,  ..., 29941, 29889, 29892],
         [29896, 29900,  1516,  ..., 29901, 29941,   375]]], device='cuda:0')
Batch 47, 78.9% of total tokens
encoded shape: torch.Size([2, 1719])
torch.Size([2, 1719]) tensor([[    1,   450,  1162,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,  8794, 29889,    13]], device='cuda:0')
torch.Size([2, 1719, 32000]) tensor([[[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [-11.8125, -10.7266,  -8.4219,  ...,  -8.2422,  -8.7500,  -7.5703],
         [-10.0156, -11.4453,  -2.4707,  ...,  -4.0898,  -5.7930,  -5.4336],
         ...,
         [ -8.0156,   9.3828,  -2.2168,  ...,  -4.3359,  -5.2891,  -4.1680],
         [ -7.7695,   9.7266,  -2.1621,  ...,  -4.2539,  -5.1328,  -4.0352],
         [ -7.6133,   9.7344,  -2.0312,  ...,  -4.1562,  -5.0781,  -3.9102]],

        [[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [ -8.3906,   0.6343,  -1.6660,  ...,   2.6660,   0.4187,   0.0745],
         [ -5.4141,  -0.6865,  -2.2129,  ...,  -0.5303,  -0.5796,   1.4326],
         ...,
         [ -2.0312,  -4.7109,   6.2344,  ...,   0.3311,   1.6533,  -0.0182],
         [ -1.3574,  -2.9141,   8.9766,  ...,   0.2213,   2.9375,  -0.4019],
         [ -0.9219,  -2.9668,   0.3230,  ...,  -0.0371,   2.3926,   0.7705]]],
       device='cuda:0')
torch.Size([2, 1719, 1]) tensor([[[29892],
         [29871],
         [ 9216],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [29896],
         [29871],
         ...,
         [  491],
         [   13],
         [24366]]], device='cuda:0')
torch.Size([2, 1719, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,  1570,   937,  ...,   349,   319,   390],
         [ 9216,  1038, 29891,  ...,  2410,  1264,   481],
         ...,
         [    1, 29900, 29896,  ..., 29929, 29946, 29947],
         [    1, 29900, 29896,  ..., 29946, 29879, 29947],
         [    1, 29900, 29896,  ..., 29946, 29879, 29947]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29871,  1678,   462,  ...,    12, 16595,    13],
         ...,
         [  491, 29889,   322,  ...,  1434,  7536,  1090],
         [   13, 15225,     2,  ...,  1334, 10255,  8512],
         [24366, 25145, 23196,  ..., 23177, 30350, 11635]]], device='cuda:0')
Batch 48, 80.9% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,  9772,  4062, 29898],
        [    1,   319, 23399,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7812,  -5.2188,  ...,  -6.0781,  -9.1250,  -6.8477],
         [-11.5312, -12.3906,  -3.2480,  ...,  -5.0195,  -5.4805,  -3.9707],
         ...,
         [ -2.9941,  -7.0195,   0.1750,  ...,  -0.8042,  -0.1785,   1.4268],
         [ -4.2773,  -2.4551,   0.7876,  ...,  -2.9082,  -0.0515,   2.0840],
         [ -2.8984,  -0.9014,   3.9141,  ...,  -1.2373,   1.7627,  -1.8652]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-11.2891,  -9.5703,  -6.6523,  ...,  -7.2969,  -8.5625,  -9.8438],
         [ -8.1484,  -8.7578,  -3.9902,  ...,  -5.0039,  -6.3789,  -5.4102],
         ...,
         [ -7.4805,   9.1016,   5.7969,  ...,  -3.3613,  -6.2461,  -2.5391],
         [ -7.4688,   9.3047,   5.4727,  ...,  -3.4453,  -6.2266,  -2.5938],
         [ -7.4219,   9.5234,   5.2070,  ...,  -3.4648,  -6.1719,  -2.5742]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [14873],
         [ 1724],
         ...,
         [ 4062],
         [ 2951],
         [19346]],

        [[29892],
         [  716],
         [ 6890],
         ...,
         [29889],
         [29889],
         [29889]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [ 4062, 17046, 18552,  ..., 29898,  2855, 29907],
         [ 2951, 29898,  6647,  ...,  2831, 20074,   373],
         [19346, 20553,  7299,  ..., 17170,  9118, 29954]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  716,  2846, 16886,  ...,  8456,  1783,   558],
         [ 6890,  1904,  7418,  ...,  2948,  8405, 17558],
         ...,
         [29889, 29906, 29879,  ..., 29946, 29892, 29898],
         [29889, 29906, 29879,  ..., 29946, 29892,   229],
         [29889, 29906, 29879,  ..., 29946, 29892,   229]]], device='cuda:0')
Batch 49, 85.2% of total tokens
encoded shape: torch.Size([2, 282])
torch.Size([2, 282]) tensor([[    1,   518,  2568, 29884,   428,   310,  1663,   352,   262, 29899,
          4561, 14321,  7329,   306,  4603,   304,  9619,   747,  1070,  3061,
         27967,   297, 15678,  7548,  2148,  2904,   279,  7774,   309,   482,
          1822,    13,  3112,   471, 12399,  9545,   310, 13303,  9619,   747,
          1070,  3061, 27967,   373,   306, 29954, 29943, 29899, 29902,  1236,
           415,   680,   310,  2148,  2904,   279,  7774,   309,   482,   310,
         29871, 29953, 29900, 29871, 29945, 29899, 18448, 29899,  1025, 14263,
           364,  1446, 29889, 24980,  1338,   892, 20459, 13931,   964,   278,
         17986,   322,  2761,  6471, 29892,   322,   278,   286,   326,   293,
         13303,   623,   492,  2925,   892,  1304,   297, 17986,  2318, 29889,
           450,   364,  1446,   892,  9445,  1156, 29871, 29896, 29892, 29871,
         29941, 29892, 29871, 29955, 29892, 29871, 29896, 29946, 29892, 29871,
         29906, 29896,   322, 29871, 29906, 29947,  3841, 29889,   450,  2582,
         10018,   393,   278,  2148,  2904,   279,  7774,   309,   482,   310,
         15678,   364,  1446, 13384,   306, 29954, 29943, 29899, 29902,   278,
          4549,   342,   297,   278, 22593,   979,  7546, 29892,  1612,   616,
           297,   278,  1301,  3245,  7546, 29892,   322,   278,  3203,   297,
           278,   286,  1337,  1288,  7546, 29889,   306, 29954, 29943, 29899,
         29902,  6374,  9101,   322,  1009,  5198,   348,   487,  4925, 11174,
         11664,  1156, 29871, 29896,  4723,   310, 13303,  9619,   747,  1070,
          3061, 27967, 29892,   322,  7450,   278, 19224,  3233,   472, 29871,
         29906, 11405, 29889,   450,  2582,  4368,   306, 29954, 29943, 29899,
         29902,   297,  9619,   747,  1070,  2148,  1508,   310,  7548,   338,
          4475,   304,   967, 14321,   322,  1422, 11685,  6354, 29892,   322,
          3620,   310,  2148,  2904,   279,   306, 29954, 29943, 29899, 29902,
          1156, 13303,   410,   509,  3958,   526,  8018,   304,   278,  9825,
          1189,   293,  3620,   322,  3038,  1070,  3168,   607, 12266,  1009,
          5297, 29841,   411,  6136,   289,   650, 14321,   322,  1083,   397,
         14067, 29889],
        [    1,  4124,  1491,  5563,  6683,   307,  1557,  2270,   373,  2323,
           512,  2887, 29899, 12150,   398,   270,  1862,   491,  1935,   801,
           814, 29920,  2978, 29899,  2671,  9200,  1557,  2270, 29889,    13,
         15156, 14801,   292, 29899,  1853,  2978, 29899,  2671,  3041,   336,
          1127,  9200,  1557,  2270,   297, 10296,   411,   263,  3889, 29899,
         15436,  1617,  1869,   261, 29892,  1006,  1491,  5563,  1301,  2187,
           297, 18550,  2323,   512,  2887, 12101,   270,  1862,   526,  7405,
           630, 29889,   450, 15729,   526,  8560,   472,  5716, 10430,   373,
           437,  9795,  1583, 29899,   465,  6967, 29881, 12101,   270,  1862,
           274, 17280,   411,   263, 29871, 29955, 29900,   302, 29885, 10415,
          2887,  7546, 29889, 17732,  2978, 29899,  2671, 12814,   310,  2323,
           270,  1862,   338,  8900,   746,   278,  6731,   265,  5864,   310,
           278, 15134, 22913,  7087,  1006,  1491,  5563,  9558, 18190,   583,
         29892, 18451,   278,   282, 29899, 29881,   322,   269, 29899, 29881,
          9558,   310, 13417,   428,  3719, 27149,  1970,  1312,   297,   278,
           270,  1862, 29889,   450,  8900,  5716, 29899, 12863,  1535,  1196,
          2920,   310, 29871, 29945, 29899, 29947,   592, 29963,   310,  1438,
         27396,  2925,   297,   278,  7145, 29899,  7192,   336,  1127,  3464,
           338, 16951,  2400,   278,   297,  9706, 16603,  5794,  2545,  4858,
           287, 23161,  3454,   310, 12101,  8329,  5662,  1590,   793, 29889,
           450,  7639, 12141, 29879,   278,  9324,   310,  2978, 29899,  2671,
         20710,  1883,  1103,   307,  1557,  2270,   491,  9004,  1218, 18470,
           515,  3216, 29899,   517, 29899,  9917,  1301,  2187,   310,  2323,
         27149,   297,   263,   410,   915,  7977,   310,   278,  1797,   310,
           313, 29896, 29900, 29900,   302, 29885,  5033, 29941,   467,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 282, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -6.3867,  -8.2422,   0.0701,  ...,  -0.7295,  -1.1436,  -0.9658],
         [ -7.4648, -10.7109,  -2.9688,  ...,  -4.0391,  -4.1172,  -2.3125],
         ...,
         [  2.0703,  -0.6440,   3.1250,  ...,   4.7383,   4.1914,   5.3984],
         [ -5.8203,  -7.2148,   8.7266,  ...,  -2.2871,  -3.2070,  -5.4531],
         [ -6.2422,  -8.6562,  13.0938,  ...,  -1.7402,  -1.8447,  -3.3105]],

        [[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -5.7539,  -7.2500,  -1.2295,  ...,  -3.5020,  -0.9058,  -3.5762],
         [ -4.9219, -10.4375,  -2.4238,  ...,  -4.0820,  -3.3281,  -1.1016],
         ...,
         [-10.6953,  -4.1797,   0.7720,  ...,  -3.1133,  -3.8242,  -2.4648],
         [-10.6406,  -4.0820,   0.7896,  ...,  -3.0664,  -3.7715,  -2.4395],
         [-10.5781,  -4.0195,   0.8174,  ...,  -3.0371,  -3.7148,  -2.3945]]],
       device='cuda:0')
torch.Size([2, 282, 1]) tensor([[[29892],
         [12614],
         [  504],
         [  428],
         [  310],
         [16798],
         [  352],
         [  262],
         [17711],
         [ 4561],
         [14321],
         [ 7329],
         [29899],
         [  337],
         [  297],
         [27391],
         [  747],
         [ 1070],
         [ 2148],
         [27967],
         [  297],
         [  364],
         [  364],
         [ 9619],
         [ 2904],
         [  279],
         [ 7774],
         [  309],
         [  482],
         [ 9101],
         [   13],
         [ 1451],
         [  338],
         [ 7405],
         [  278],
         [  310],
         [ 9619],
         [ 8363],
         [  747],
         [ 1070],
         [ 3061],
         [27967],
         [  373],
         [  278],
         [29954],
         [29943],
         [29899],
         [29902],
         [ 4603],
         [  415],
         [  680],
         [ 4603],
         [ 7774],
         [ 2904],
         [  279],
         [ 7774],
         [  309],
         [  482],
         [  297],
         [15678],
         [29906],
         [29899],
         [29899],
         [29896],
         [29899],
         [ 3250],
         [29899],
         [ 1025],
         [  364],
         [  364],
         [ 1446],
         [29889],
         [  450],
         [ 1338],
         [  892],
         [13931],
         [13931],
         [  964],
         [29871],
         [ 2761],
         [ 2318],
         [ 2761],
         [ 6471],
         [29889],
         [29871],
         [  278],
         [ 9619],
         [ 6288],
         [ 7492],
         [ 9619],
         [ 9619],
         [13036],
         [ 2925],
         [  892],
         [ 7436],
         [  304],
         [  278],
         [ 2318],
         [29889],
         [  450],
         [ 9619],
         [ 1446],
         [  892],
         [26285],
         [  472],
         [29871],
         [29896],
         [29892],
         [29871],
         [29906],
         [29892],
         [29871],
         [29955],
         [29892],
         [29871],
         [29896],
         [29946],
         [29892],
         [29871],
         [29906],
         [29896],
         [29892],
         [29871],
         [29906],
         [29947],
         [ 3841],
         [  310],
         [  450],
         [ 7774],
         [10018],
         [  393],
         [  278],
         [  306],
         [ 2904],
         [  279],
         [ 7774],
         [  309],
         [  482],
         [  310],
         [17986],
         [  364],
         [30488],
         [  471],
         [  306],
         [29954],
         [29943],
         [29899],
         [29902],
         [ 1236],
         [ 1236],
         [  342],
         [  472],
         [  278],
         [29871],
         [  979],
         [ 7546],
         [29892],
         [  322],
         [29874],
         [ 7546],
         [  278],
         [ 7774],
         [29899],
         [ 7546],
         [  322],
         [  322],
         [ 8062],
         [ 8062],
         [  297],
         [  278],
         [23603],
         [30488],
         [  362],
         [ 7546],
         [29889],
         [  450],
         [29954],
         [29943],
         [29899],
         [29902],
         [ 4603],
         [ 9101],
         [  892],
         [18755],
         [ 1353],
         [  348],
         [  487],
         [10072],
         [10161],
         [11664],
         [16951],
         [ 9619],
         [29896],
         [ 2462],
         [  310],
         [13303],
         [ 9619],
         [  747],
         [ 1070],
         [ 3061],
         [30879],
         [29892],
         [  322],
         [  278],
         [  278],
         [19224],
         [  472],
         [  472],
         [29871],
         [29941],
         [29896],
         [29889],
         [  450],
         [ 6374],
         [18694],
         [  393],
         [29954],
         [29943],
         [29899],
         [29902],
         [ 1236],
         [ 2148],
         [  747],
         [ 1070],
         [ 7774],
         [ 2904],
         [ 7774],
         [15678],
         [  338],
         [  263],
         [  304],
         [  278],
         [14321],
         [  322],
         [ 5849],
         [11685],
         [29889],
         [29889],
         [  322],
         [13303],
         [  310],
         [  306],
         [ 2904],
         [  279],
         [ 7774],
         [29954],
         [29943],
         [29899],
         [29902],
         [ 4603],
         [13303],
         [ 9619],
         [  509],
         [  375],
         [ 1122],
         [ 4475],
         [  304],
         [  278],
         [ 1889],
         [ 5996],
         [  293],
         [ 3620],
         [  310],
         [ 4768],
         [ 1070],
         [14188],
         [  310],
         [  526],
         [  278],
         [ 7037],
         [29841],
         [  297],
         [  278],
         [ 7774],
         [  650],
         [12409],
         [29889],
         [ 7774],
         [  397],
         [14067],
         [29889],
         [   13]],

        [[29892],
         [ 1611],
         [ 4980],
         [  292],
         [  336],
         [ 1557],
         [30488],
         [  310],
         [  278],
         [29899],
         [29954],
         [29914],
         [30488],
         [30488],
         [  270],
         [30488],
         [ 7405],
         [ 2794],
         [30488],
         [30879],
         [29920],
         [ 6731],
         [29899],
         [ 2671],
         [27070],
         [ 1557],
         [ 2270],
         [   13],
         [  435],
         [ 7030],
         [  263],
         [30488],
         [30488],
         [30488],
         [ 2978],
         [29899],
         [ 2671],
         [ 9200],
         [30488],
         [ 1127],
         [ 9200],
         [ 1557],
         [ 2270],
         [29892],
         [  278],
         [  411],
         [  263],
         [ 7300],
         [29899],
         [11235],
         [ 1617],
         [30488],
         [  261],
         [29892],
         [  591],
         [29899],
         [ 5563],
         [ 6683],
         [ 2187],
         [  297],
         [ 2323],
         [  512],
         [  512],
         [ 2887],
         [12101],
         [  270],
         [30879],
         [  892],
         [ 7405],
         [  630],
         [29889],
         [  450],
         [ 2978],
         [  526],
         [ 8560],
         [  472],
         [ 5716],
         [10430],
         [  322],
         [30488],
         [30488],
         [29892],
         [29899],
         [  465],
         [30488],
         [29881],
         [12101],
         [  270],
         [30488],
         [  411],
         [30488],
         [  411],
         [  263],
         [30488],
         [29896],
         [  302],
         [  302],
         [29885],
         [30488],
         [30488],
         [30488],
         [29889],
         [  450],
         [29892],
         [29899],
         [ 2671],
         [ 6683],
         [  338],
         [  278],
         [29899],
         [30488],
         [  338],
         [ 8900],
         [29889],
         [  278],
         [  270],
         [30488],
         [ 5864],
         [  338],
         [  278],
         [ 1869],
         [ 1869],
         [  338],
         [  278],
         [30488],
         [29899],
         [ 1301],
         [18190],
         [  583],
         [29889],
         [  607],
         [  278],
         [30488],
         [30488],
         [29886],
         [30488],
         [  282],
         [29899],
         [29881],
         [29889],
         [18190],
         [  278],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1312],
         [  297],
         [30488],
         [30488],
         [29899],
         [29889],
         [  450],
         [31147],
         [31147],
         [10430],
         [12863],
         [ 1535],
         [ 2978],
         [30879],
         [29879],
         [  278],
         [31186],
         [  592],
         [29896],
         [  592],
         [29963],
         [  338],
         [  278],
         [31147],
         [30488],
         [  338],
         [  278],
         [29871],
         [29899],
         [ 8193],
         [30488],
         [ 1127],
         [30488],
         [  338],
         [  297],
         [ 2545],
         [30488],
         [30488],
         [30488],
         [30488],
         [  537],
         [30488],
         [ 4858],
         [  287],
         [30488],
         [30488],
         [  310],
         [  278],
         [  270],
         [29899],
         [30488],
         [30488],
         [29889],
         [  450],
         [ 1196],
         [  635],
         [29879],
         [  278],
         [ 7037],
         [  310],
         [ 2978],
         [29899],
         [ 2671],
         [ 9200],
         [ 1883],
         [ 1103],
         [  307],
         [ 1557],
         [ 2270],
         [  363],
         [10320],
         [ 1218],
         [  278],
         [  515],
         [  263],
         [30488],
         [  322],
         [29899],
         [ 9917],
         [30488],
         [  313],
         [  297],
         [  263],
         [29899],
         [  297],
         [  263],
         [30879],
         [30488],
         [30488],
         [  310],
         [29871],
         [30488],
         [  310],
         [  278],
         [24366],
         [29900],
         [29900],
         [  302],
         [29885],
         [29897],
         [29906],
         [  467],
         [    2],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576]]], device='cuda:0')
torch.Size([2, 282, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [12614, 26336, 30098,  ..., 29896, 29950, 29990],
         [  504,   347,   423,  ..., 29872, 29891,   440],
         ...,
         [14067,  7807,  1379,  ..., 12818,  7367,   824],
         [29889,  1889,  6354,  ...,  2645, 14188,   322],
         [   13,     2,   450,  ...,   739,  7857,   910]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1611,  2868,  1493,  ..., 20308,   794,   336],
         [ 4980,  6577,  9761,  ...,  3719,  1582,  6831],
         ...,
         [ 1576, 29902, 11184,  ..., 29896,  3112,  5618],
         [ 1576, 29902, 11184,  ..., 29896,  3112,  5618],
         [ 1576, 29902, 11184,  ..., 29896,  3112,  5618]]], device='cuda:0')
Batch 50, 85.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   518,  1184,  ...,     2,     2,     2],
        [    1,   321,   448,  ...,   448, 29941, 29946]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.3789,  -8.2422,   0.0657,  ...,  -0.7300,  -1.1484,  -0.9614],
         [ -5.6445,  -6.4727,  -2.8789,  ...,  -4.1133,  -5.5039,  -3.7188],
         ...,
         [ -6.4062,   9.3984,   0.7915,  ...,  -2.9883,  -4.3867,  -2.5234],
         [ -6.5898,   9.3359,   0.9351,  ...,  -3.0137,  -4.4766,  -2.5918],
         [ -6.8164,   9.4297,   1.2695,  ...,  -3.0098,  -4.5586,  -2.6348]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -4.7773,  -6.2383,   0.5830,  ...,  -3.5293,  -6.2812,  -4.0859],
         [-11.5625, -16.3594,  -8.3125,  ...,  -6.6914,  -8.0234,  -8.2266],
         ...,
         [ -6.2812, -10.3672,   1.4980,  ...,  -1.7637,   0.2493,   0.5073],
         [ -2.0117,  -6.5234,   2.8340,  ...,  -1.1582,   1.2109,   1.6270],
         [ -0.8066,  -3.6836,   4.6406,  ...,  -0.9390,   1.3457,   1.5439]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [12614],
         [ 1688],
         ...,
         [    1],
         [    1],
         [29900]],

        [[29892],
         [29899],
         [ 2549],
         ...,
         [29906],
         [29930],
         [  353]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [12614, 26336, 30098,  ..., 29896, 29950, 29990],
         [ 1688,  1066, 29888,  ...,  1730,  1188, 29879],
         ...,
         [    1, 29900, 29896,  ..., 29879, 29929, 29899],
         [    1, 29900, 29896,  ..., 29879, 29929, 29947],
         [29900, 29896, 29906,  ..., 29889, 29929, 29947]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29899, 29933, 29911,  ..., 29931,  1111, 29893],
         [ 2549,   450,   278,  ...,   306,   448,  9763],
         ...,
         [29906, 29896, 29941,  ..., 29876, 29953, 29955],
         [29930,   353, 29945,  ..., 29896, 29953, 29955],
         [  353, 29930, 29945,  ..., 29947, 29906, 29941]]], device='cuda:0')
Batch 51, 90.3% of total tokens
encoded shape: torch.Size([2, 828])
torch.Size([2, 828]) tensor([[    1, 21882,   260,  ...,     2,     2,     2],
        [    1,   660, 29901,  ...,  1800,    13,    13]], device='cuda:0')
torch.Size([2, 828, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.9180,  -5.5469,  -1.5020,  ...,  -5.3555,  -5.1211,  -3.7949],
         [ -8.6406,  -8.8906,   0.7939,  ...,  -5.1367,  -2.9844,  -4.2656],
         ...,
         [ -1.3623,  10.2266,  -2.7832,  ...,   0.9526,   2.1250,   0.7832],
         [ -1.3330,  10.0781,  -2.8203,  ...,   0.9980,   2.1289,   0.7827],
         [ -1.3545,  10.1719,  -2.8477,  ...,   0.9912,   2.1309,   0.7788]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7734,  -5.2109,  ...,  -6.0781,  -9.1250,  -6.8438],
         [-11.5312, -12.3828,  -3.2441,  ...,  -5.0117,  -5.4766,  -3.9609],
         ...,
         [ -0.2815,  -0.9111,  12.9922,  ...,  -0.0784,   1.2324,  -0.7256],
         [  0.4131,  -0.4802,  11.1406,  ...,  -1.1816,  -0.1185,  -0.7563],
         [ -5.5352,  -8.8281,   3.5195,  ...,  -2.3281,  -0.9771,  -1.7207]]],
       device='cuda:0')
torch.Size([2, 828, 1]) tensor([[[29892],
         [ 2440],
         [ 2470],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [20001]]], device='cuda:0')
torch.Size([2, 828, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 2440,  7378,   310,  ...,  3841,  5144,   716],
         [ 2470,  7844, 24729,  ...,   820,  1237,  2658],
         ...,
         [    1, 14262, 31779,  ..., 24366, 26502, 25528],
         [    1, 14262, 31779,  ..., 24366, 26502, 25528],
         [    1, 14262, 31779,  ..., 24366, 26502, 25528]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13,     2,   849,  ...,   869,   470,   467],
         [   13,   259, 29871,  ...,  1678, 29902,  3112],
         [20001,  2855, 22550,  ...,  9842, 29909, 29902]]], device='cuda:0')
Batch 52, 91.2% of total tokens
encoded shape: torch.Size([2, 349])
torch.Size([2, 349]) tensor([[    1, 23212, 21603,    13,    13, 29931,   485, 21603,   313, 29892,
           884,  5917,  1891,   408,   365, 30107, 29894, 30150, 29879, 30107,
         29876, 29897,   338,   263,  5720,   297,   476,   398,  6840,   390,
          3631,  7457, 29892,   297,   278,  8068,  7457,   310,  1085, 20595,
          5127, 29892,  9742,  5721,   273, 17325, 29892, 14883, 29889,  2180,
           278, 29871, 29906, 29900, 29900, 29953, 16411, 29892,   967,  4665,
           471, 29871, 29906, 29906, 29900, 29892,   297, 29871, 29946, 29953,
         13175, 29889,    13,    13,  1123, 10662, 29871,    13,    13, 10900,
         29901, 29911,   776, 29879,   322, 18481,   297,  1085, 20595,  5127,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,   624,  3097,   310,   278,  7960, 29899,   517, 29899,  1509,
          6851,   310,   604,   747,   352,   262,   363,   938,   336,   854,
           681,  3041,  3958, 29889,    13, 29909,  2560,   379,  7390, 29907,
         29899, 29965, 29963,  1158,   471,  8906,   304,  8161,   278, 25806,
           310,  7960, 29899,   517, 29899,  1509,   604,   747,   352,   262,
          6851,  1090,  1422,  8635,  5855, 29889,   450,  8906,  1158,   471,
          2854,   630,   411,  3390,   304,  5608,   537, 29892, 13600, 29892,
         16716,   322, 29833,  3192,  2264, 29889,   450,  1494,   594,  2460,
           486,  1973,   892, 13240, 29901, 29871, 29941, 29899, 29885, 29931,
         15680,   771,  2272, 29880,  1600,   269,  4316,   292,   267,   472,
         26702,   310, 29871, 29946, 29946, 29900, 29871, 30167, 29887, 29914,
         29885, 29931,   322,  1773,   309,  2747,   301,  9103,   403, 15680,
          1772,  4951, 22637,  6943, 29871, 29900, 29889, 29929, 29995, 20892,
          1974,   521,  5095,   680,   313, 29945, 29900,   286, 29931, 29897,
           472, 14953,   800,   310, 29871, 29896, 29945, 29889, 29946,   322,
         29871, 29946, 29941, 29889, 29941, 29871, 30167, 29887, 29914, 29885,
         29931, 29889,   450,  1722, 29899, 29894,   616, 25806,   310,   604,
           747,   352,   262,   471,   884, 19030, 29889,   450,  1494,  8635,
          5855,   892,  9528, 29901, 29871, 29946,  6719, 29907,   297,   278,
           337,  1341,  4087,  1061, 29936, 29871, 29906, 29900,  6719, 29907,
          1090,  5716,  3578, 14060,   545, 29936,   322, 29871, 29906, 29900,
          6719, 29907,   411,  3578, 29899, 14676,   428, 29889,   450, 15721,
           471,   884,  4967,   287,   304, 22884,  5855,   310, 17546,   368,
         29879,   275, 29892, 19100,   333,   362, 29892,  6731,   324,  4848,
           322, 26963,   316,  5105,   362, 29889,   450,  3240,  2509,   931,
           310,   604,   747,   352,   262,   471, 29871, 29946, 29889, 29929,
          1375, 29889,  2087,  2460,   486,  1973,   310,   604,   747,   352,
           262,  6851,   297,   325,   616, 29879, 29892,   269,  4316,   292,
           267,   470, 15680,  1772,  4951,   289,   810,   472, 24899,  1711,
          8018, 14953,   800,   892,  4824,  1711, 15878,   322,  8950,  1711,
         13714,   363,   472,  3203, 29871, 29896, 29946,  3841,   472, 29871,
         29946,  6719, 29907,   297,   278,   337,  1341,  4087,  1061,   322,
           472, 29871, 29906, 29900,  6719, 29907,   411,   470,  1728,   738,
         13047,  2750,  3578, 29889,   360,   387,  3665,   362,   471,   871,
          1476,   304,  6403,  1090, 19100,   333,   362,  5855, 29889]],
       device='cuda:0')
torch.Size([2, 349, 32000]) tensor([[[-8.0312e+00, -1.1074e+00, -5.2881e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-6.8711e+00, -6.4375e+00, -1.7910e+00,  ..., -4.1602e+00,
          -7.5195e-01, -5.6602e+00],
         [-1.0172e+01, -1.4562e+01, -4.2578e+00,  ..., -7.1953e+00,
          -4.2188e+00, -9.3672e+00],
         ...,
         [-2.1992e+00,  4.8359e+00, -1.3906e+00,  ...,  1.7366e-03,
           5.9521e-01,  4.5190e-01],
         [-2.1738e+00,  4.8398e+00, -1.3848e+00,  ...,  2.1103e-02,
           6.2695e-01,  4.6021e-01],
         [-2.1113e+00,  4.9219e+00, -1.3467e+00,  ...,  5.4565e-02,
           6.5576e-01,  4.9390e-01]],

        [[-8.0312e+00, -1.1074e+00, -5.2881e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-6.6250e+00, -6.2305e+00, -3.9282e-01,  ..., -3.3535e+00,
          -4.0117e+00, -2.5742e+00],
         [-1.2969e+01, -1.4945e+01, -8.7500e+00,  ..., -9.5469e+00,
          -8.9531e+00, -1.1094e+01],
         ...,
         [-3.6016e+00, -5.4844e+00,  5.7695e+00,  ..., -3.1211e+00,
          -7.5488e-01, -4.1797e+00],
         [-4.8711e+00, -6.2656e+00,  6.1172e+00,  ..., -3.2812e+00,
          -2.1660e+00, -3.6680e+00],
         [-8.4062e+00, -1.1539e+01,  1.0234e+01,  ...,  2.9565e-01,
          -2.5449e+00, -4.3867e+00]]], device='cuda:0')
torch.Size([2, 349, 1]) tensor([[[29892],
         [ 1581],
         [  801],
         [29931],
         [29931],
         [  485],
         [21603],
         [  313],
         [15136],
         [  884],
         [ 2998],
         [ 1891],
         [  408],
         [23212],
         [30107],
         [29894],
         [30150],
         [29879],
         [30107],
         [29876],
         [29897],
         [  338],
         [  263],
         [ 5720],
         [  297],
         [23212],
         [31147],
         [ 1249],
         [10094],
         [ 3631],
         [ 7457],
         [29892],
         [30488],
         [18622],
         [ 8068],
         [ 7457],
         [  310],
         [31147],
         [30879],
         [ 5127],
         [29892],
         [ 9742],
         [ 5721],
         [  273],
         [17325],
         [29892],
         [14883],
         [29889],
         [ 2180],
         [  278],
         [29871],
         [29906],
         [30488],
         [29900],
         [29953],
         [16411],
         [29892],
         [  967],
         [30488],
         [  471],
         [29871],
         [29896],
         [29945],
         [29947],
         [29892],
         [  297],
         [29871],
         [29946],
         [29945],
         [13175],
         [29889],
         [  450],
         [   13],
         [ 2831],
         [10662],
         [29901],
         [   13],
         [   13],
         [ 2277],
         [18383],
         [12310],
         [  776],
         [29879],
         [  322],
         [30488],
         [  297],
         [ 1085],
         [30488],
         [ 5127],
         [    2],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [29871],
         [29871],
         [29871],
         [30488],
         [30488],
         [29871],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29892],
         [  450],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [ 7228],
         [ 7228],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [    1],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262],
         [14262]],

        [[29892],
         [29889],
         [  310],
         [  278],
         [29871],
         [29899],
         [  517],
         [29899],
         [ 1509],
         [  266],
         [  310],
         [  278],
         [29873],
         [  352],
         [30488],
         [ 4883],
         [20859],
         [  336],
         [  854],
         [  681],
         [17517],
         [ 3958],
         [  297],
         [  450],
         [13720],
         [  326],
         [  322],
         [ 7390],
         [29907],
         [ 1223],
         [ 6707],
         [29963],
         [ 1158],
         [  363],
         [ 8906],
         [  322],
         [24809],
         [  278],
         [25806],
         [  310],
         [  278],
         [29899],
         [  517],
         [29899],
         [ 1509],
         [ 6851],
         [  747],
         [30879],
         [30488],
         [ 6851],
         [  363],
         [  337],
         [ 8635],
         [ 5855],
         [29889],
         [  450],
         [ 6851],
         [ 1158],
         [  471],
         [ 2854],
         [  630],
         [ 5034],
         [ 3390],
         [  304],
         [ 5608],
         [  537],
         [29892],
         [13600],
         [29892],
         [16716],
         [29892],
         [ 4771],
         [ 3192],
         [ 2264],
         [29889],
         [  450],
         [ 2582],
         [ 4128],
         [ 3901],
         [  486],
         [30488],
         [  892],
         [ 7405],
         [29901],
         [29871],
         [29896],
         [29900],
         [29885],
         [29887],
         [  325],
         [30488],
         [30488],
         [30488],
         [ 1600],
         [  313],
         [30488],
         [30488],
         [  267],
         [ 6943],
         [30488],
         [  310],
         [29871],
         [29896],
         [  286],
         [  286],
         [  286],
         [30167],
         [29887],
         [29914],
         [29885],
         [29931],
         [29892],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [  630],
         [  325],
         [30488],
         [30488],
         [ 3041],
         [  472],
         [29871],
         [29896],
         [29889],
         [29945],
         [29995],
         [ 4497],
         [ 1974],
         [  521],
         [30488],
         [  680],
         [ 1650],
         [13695],
         [29900],
         [  286],
         [29931],
         [29892],
         [  472],
         [26702],
         [  800],
         [  310],
         [29871],
         [29946],
         [29900],
         [29900],
         [29953],
         [29892],
         [29871],
         [29946],
         [29946],
         [29889],
         [29945],
         [29871],
         [30167],
         [29887],
         [29914],
         [29885],
         [29931],
         [29889],
         [  450],
         [ 6851],
         [30488],
         [30488],
         [30488],
         [30488],
         [  310],
         [  278],
         [30488],
         [30488],
         [  262],
         [ 6851],
         [ 7405],
         [19030],
         [29889],
         [  450],
         [ 2582],
         [ 4128],
         [ 5855],
         [  892],
         [19030],
         [29901],
         [29871],
         [29906],
         [30073],
         [29907],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1061],
         [29892],
         [29871],
         [29906],
         [29945],
         [ 6719],
         [29907],
         [  297],
         [30488],
         [ 3578],
         [ 5855],
         [  545],
         [29936],
         [29871],
         [29871],
         [29906],
         [29945],
         [ 6719],
         [29907],
         [ 1090],
         [30488],
         [30488],
         [29914],
         [  428],
         [ 2706],
         [  450],
         [ 6851],
         [29899],
         [ 1476],
         [ 6087],
         [  287],
         [  304],
         [30488],
         [29899],
         [  310],
         [29871],
         [30488],
         [30488],
         [  275],
         [29892],
         [30488],
         [  333],
         [29889],
         [29892],
         [  322],
         [30488],
         [29889],
         [  322],
         [30488],
         [29889],
         [30488],
         [  362],
         [29889],
         [  450],
         [ 2582],
         [30488],
         [ 3064],
         [  310],
         [  604],
         [30488],
         [  352],
         [  262],
         [  471],
         [29871],
         [29941],
         [29889],
         [29929],
         [ 1375],
         [29889],
         [  450],
         [ 2460],
         [30488],
         [ 1973],
         [  892],
         [  604],
         [30488],
         [  352],
         [  262],
         [ 6851],
         [  892],
         [15680],
         [30488],
         [29879],
         [  322],
         [15680],
         [30488],
         [  292],
         [  267],
         [  322],
         [15680],
         [ 1772],
         [30488],
         [22637],
         [30488],
         [  892],
         [14953],
         [30488],
         [ 8018],
         [  313],
         [  800],
         [  892],
         [13714],
         [30488],
         [  322],
         [  322],
         [ 8950],
         [ 1711],
         [13714],
         [ 1090],
         [  472],
         [ 3203],
         [29871],
         [29906],
         [29946],
         [ 3841],
         [  472],
         [29871],
         [29906],
         [ 6719],
         [29907],
         [  322],
         [  278],
         [  337],
         [ 1341],
         [30488],
         [ 1061],
         [  322],
         [29871],
         [ 3203],
         [29906],
         [29900],
         [ 6719],
         [29907],
         [ 1090],
         [  470],
         [ 1728],
         [ 3578],
         [  313],
         [  515],
         [ 3578],
         [14060],
         [  450],
         [30488],
         [29889],
         [  362],
         [ 9316],
         [  451],
         [ 8900],
         [  297],
         [  367],
         [  472],
         [  278],
         [30488],
         [30488],
         [ 5855],
         [29889],
         [  450]]], device='cuda:0')
torch.Size([2, 349, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1581, 10139,   728,  ...,   834,  2993,   990],
         [  801, 29892,   283,  ...,  4273, 27017,  5863],
         ...,
         [14262, 26077, 23196,  ..., 26502, 28044, 24708],
         [14262, 26077, 23196,  ..., 26502, 28044, 24708],
         [14262, 26077, 23196,  ..., 26502, 28044, 24708]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29889,   388, 23693,  ...,  2707,   860,   519],
         [  310,   322, 29892,  ...,   363,   472,  6607],
         ...,
         [ 5855,   322, 22884,  ..., 29899,  4195, 29889],
         [29889, 29892,   472,  ...,   310,   363,  1156],
         [  450,    13,   910,  ...,  7857,  4525,  2398]]], device='cuda:0')
Batch 53, 91.7% of total tokens
encoded shape: torch.Size([2, 126])
torch.Size([2, 126]) tensor([[    1,  5430,   600,   566, 29881,   633,  3462, 29874,    13,    13,
         29954,   582,   600,   566, 29881,   633,  3462, 29874,   313,  1579,
         29889,  7145, 29871, 29896, 29946,   386,  6462, 29897,   471,   263,
         10458,   845,  4086,  9821,   322,  4696,   713, 29889, 29871,  5430,
           600,   566, 29881,   471,   263, 24952,   310,   360,  2142, 29891,
          1289,  3095,   402, 29893,   309,   962, 29892,  5069,  4892,   540,
           286,  2905,   287,   297, 10618, 29891, 29889,    13,    13, 13393,
           884,    13,    13,  5430,   600,   566, 29881,   633,  3462, 29874,
           472,  3772,   275,  1167,    13,    13, 10900, 29901, 19302, 16837,
         10458,   845,   772,  1691,    13, 10900, 29901, 28862,   845, 29899,
         11675,   772,  1691,    13, 10900, 29901, 29896, 29946,   386, 29899,
         27371, 10458,   845,   772,  1691,    13, 10900, 29901, 29896, 29946,
           386, 29899, 27371, 10458,   845,  2305],
        [    1,  1094,   376, 29923, 29965,  1672,  4162,  2190,   315,  3289,
          1177,  3267,   448,  1576,  1260,   568, 29908,   338,   263, 10257,
         14853, 29892,   591,   674,   871, 14333,   304, 21696,  1980,   515,
           278,   767, 18150,   310,  6960,  8226,   322,   330, 11500,  5518,
           322,  2243,  1862, 12012,   332,   414, 29892,   330, 11500, 24378,
          4097,   322,  5874, 21142, 29892, 12768,   322,   278, 15883,   310,
         17535, 29899, 12817, 27733, 29889,  1576, 25691, 29892,   607,   338,
         14909,  3889, 29892,   674,   367,  2665,   871,   304, 10257, 14157,
         29892,   451,   304,  2024, 17774, 29889,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 126, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5381,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -7.2773,  -4.5664,  -3.4766,  ...,  -6.2930,   0.3833,  -3.4570],
         [-10.3984, -14.5781, -10.0703,  ...,  -6.2070,  -2.6758,  -7.2773],
         ...,
         [ -3.8184,  -0.2424,   1.4404,  ...,  -3.2109,  -3.9141,  -2.5645],
         [ -5.0117,  -6.5000,   1.4043,  ...,  -2.6855,   0.4888,  -0.4998],
         [ -0.6221,   0.6841,  14.7656,  ...,  -1.5889,   2.5527,  -1.4600]],

        [[ -8.0234,  -1.1396,  -0.5381,  ...,  -4.1914,  -5.6680,  -4.5898],
         [-12.1562, -13.3906,  -5.2422,  ...,  -6.0742,  -7.1289,  -8.5391],
         [ -8.1328, -10.2031,  -3.4688,  ...,  -2.7520,  -3.9492,  -2.9688],
         ...,
         [ -3.1582,  -1.3438,   1.0234,  ...,  -3.0234,  -3.7227,  -2.4375],
         [ -3.1582,  -1.3418,   1.0254,  ...,  -3.0234,  -3.7227,  -2.4375],
         [ -3.1973,  -1.3389,   1.0439,  ...,  -3.0430,  -3.7324,  -2.4551]]],
       device='cuda:0')
torch.Size([2, 126, 1]) tensor([[[29892],
         [ 1129],
         [ 7003],
         [29881],
         [  633],
         [31147],
         [16260],
         [  313],
         [29954],
         [29954],
         [  582],
         [  600],
         [  566],
         [29881],
         [  633],
         [ 3462],
         [29874],
         [  313],
         [13989],
         [29889],
         [30080],
         [29899],
         [29896],
         [29906],
         [  386],
         [ 6462],
         [29897],
         [  471],
         [  263],
         [10458],
         [  845],
         [ 9821],
         [ 9821],
         [29889],
         [28238],
         [  713],
         [29889],
         [  940],
         [   13],
         [  600],
         [  566],
         [29881],
         [  633],
         [  263],
         [ 4509],
         [  310],
         [  360],
         [ 2142],
         [29891],
         [ 1289],
         [31147],
         [  402],
         [29893],
         [18477],
         [  962],
         [  322],
         [  322],
         [  772],
         [  540],
         [10478],
         [ 2905],
         [  287],
         [  297],
         [  263],
         [13544],
         [29889],
         [ 5430],
         [   13],
         [ 2277],
         [  884],
         [29901],
         [   13],
         [29930],
         [  600],
         [  566],
         [29881],
         [  633],
         [ 3462],
         [29874],
         [  313],
         [ 3772],
         [  275],
         [ 1167],
         [   13],
         [   13],
         [ 5653],
         [29901],
         [28862],
         [16837],
         [10458],
         [  845],
         [  772],
         [ 1691],
         [    2],
         [10900],
         [29901],
         [28862],
         [  845],
         [  772],
         [11675],
         [  772],
         [ 1691],
         [   13],
         [10900],
         [29901],
         [28862],
         [29946],
         [  386],
         [29899],
         [27371],
         [  772],
         [  845],
         [  772],
         [ 1691],
         [   13],
         [10900],
         [29901],
         [28862],
         [29946],
         [  386],
         [29899],
         [27371],
         [10458],
         [30488],
         [ 2305],
         [   13]],

        [[29892],
         [  263],
         [ 1576],
         [ 1050],
         [ 1672],
         [ 4162],
         [ 2190],
         [  315],
         [ 3301],
         [ 1177],
         [29949],
         [29908],
         [19007],
         [ 7824],
         [  568],
         [  310],
         [  591],
         [  263],
         [ 4509],
         [ 3209],
         [  363],
         [  591],
         [  526],
         [  451],
         [ 3544],
         [  304],
         [ 7274],
         [ 1980],
         [  515],
         [14582],
         [ 3209],
         [18150],
         [  310],
         [ 3209],
         [ 8226],
         [29892],
         [  402],
         [11500],
         [10127],
         [12012],
         [21083],
         [ 1862],
         [12012],
         [  332],
         [30488],
         [29889],
         [  408],
         [11500],
         [ 4933],
         [ 4097],
         [29892],
         [24378],
         [  284],
         [29892],
         [  322],
         [  310],
         [ 1462],
         [  330],
         [  310],
         [  278],
         [29899],
         [30488],
         [14582],
         [29889],
         [   13],
         [14853],
         [27684],
         [  607],
         [  338],
         [ 2854],
         [ 3889],
         [  310],
         [  338],
         [  367],
         [ 2854],
         [  304],
         [  304],
         [  278],
         [21696],
         [29889],
         [  322],
         [30488],
         [30488],
         [ 6743],
         [29889],
         [   13],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [29871],
         [29871],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 126, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1129, 14151,  7807,  ...,  3274, 29891, 29894],
         [ 7003,  7861, 29891,  ...,   566,   536,   583],
         ...,
         [30488, 30879, 31147,  ..., 29892, 30555,   856],
         [ 2305, 23550, 22182,  ..., 14263,  8541,  4824],
         [   13,     2, 17943,  ...,   313, 29984,  5262]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  263,   278,   306,  ...,   310,  2215,   697],
         [ 1576,  1552, 29903,  ..., 29950, 29931, 29954],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]]], device='cuda:0')
Batch 54, 91.9% of total tokens
encoded shape: torch.Size([2, 785])
torch.Size([2, 785]) tensor([[    1,   450,   297,  ...,     2,     2,     2],
        [    1,   660, 29901,  ...,  3482,    13,    13]], device='cuda:0')
torch.Size([2, 785, 32000]) tensor([[[-8.0312e+00, -1.1064e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-1.1812e+01, -1.0727e+01, -8.4219e+00,  ..., -8.2422e+00,
          -8.7500e+00, -7.5703e+00],
         [-1.0086e+01, -9.6641e+00, -6.3633e+00,  ..., -6.3633e+00,
          -6.3750e+00, -5.7227e+00],
         ...,
         [-8.7952e-02,  7.5625e+00, -2.0684e+00,  ...,  1.6455e+00,
           2.4375e+00,  1.6172e+00],
         [-1.8616e-02,  7.5391e+00, -2.0703e+00,  ...,  1.6885e+00,
           2.4766e+00,  1.6484e+00],
         [-4.5044e-02,  7.5859e+00, -2.0918e+00,  ...,  1.6787e+00,
           2.4727e+00,  1.6387e+00]],

        [[-8.0312e+00, -1.1064e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-1.0695e+01, -1.1773e+01, -5.2109e+00,  ..., -6.0781e+00,
          -9.1250e+00, -6.8438e+00],
         [-1.1531e+01, -1.2391e+01, -3.2441e+00,  ..., -5.0117e+00,
          -5.4766e+00, -3.9609e+00],
         ...,
         [ 7.7858e-03,  7.3682e-01,  1.7516e+01,  ..., -2.0508e+00,
           1.6885e+00, -1.8389e+00],
         [-7.1328e+00, -5.9609e+00,  6.7109e+00,  ..., -6.2734e+00,
          -3.3047e+00, -4.1211e+00],
         [-7.2031e+00, -8.7109e+00,  2.3574e+00,  ..., -3.0469e+00,
          -1.0107e+00, -3.9014e-01]]], device='cuda:0')
torch.Size([2, 785, 1]) tensor([[[29892],
         [29871],
         [ 7316],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [20001]]], device='cuda:0')
torch.Size([2, 785, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,  1570,   341,  ...,   317,   319,   390],
         [ 7316, 29895,  3097,  ...,   326,  1441,  6335],
         ...,
         [    1, 14262, 24366,  ..., 26077, 19838,  6610],
         [    1, 14262, 24366,  ..., 26077, 19838,  6610],
         [    1, 14262, 24366,  ..., 26077, 19838,  6610]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13,     2,   849,  ...,   762,   396,   259],
         [   13,  6246, 29938,  ..., 29902, 11760,  8057],
         [20001, 22550, 29902,  ..., 23444,  3492,  6246]]], device='cuda:0')
Batch 55, 92.9% of total tokens
encoded shape: torch.Size([2, 854])
torch.Size([2, 854]) tensor([[    1,  8155,  9362,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29889,    13,    13]], device='cuda:0')
torch.Size([2, 854, 32000]) tensor([[[ -8.0078,  -1.2354,  -0.5391,  ...,  -4.2148,  -5.6875,  -4.6211],
         [-12.0625, -15.2656,  -6.9258,  ...,  -7.7539,  -6.0547,  -9.7891],
         [-10.4375, -12.6328,  -4.5898,  ...,  -4.3320,  -3.9980,  -4.2031],
         ...,
         [ -0.1917,   7.5156,  -0.6611,  ...,   1.4785,   1.8584,   1.6904],
         [ -0.1647,   7.3516,  -0.6904,  ...,   1.4990,   1.8926,   1.6680],
         [ -0.1131,   7.2070,  -0.7114,  ...,   1.5322,   1.9414,   1.6670]],

        [[ -8.0078,  -1.2354,  -0.5391,  ...,  -4.2148,  -5.6875,  -4.6211],
         [-10.7031, -11.8047,  -5.2344,  ...,  -6.0820,  -9.1328,  -6.8594],
         [-11.5078, -12.3750,  -3.2578,  ...,  -5.0039,  -5.4609,  -3.9570],
         ...,
         [ -8.0781, -10.3906,  10.5703,  ...,  -4.1875,  -2.1055,  -3.1348],
         [ -6.8164,  -3.4727,  10.1016,  ...,  -5.8984,  -3.8984,  -2.0469],
         [ -9.0000,  -9.3750,   4.4609,  ...,  -4.7891,  -3.7871,  -2.0234]]],
       device='cuda:0')
torch.Size([2, 854, 1]) tensor([[[29892],
         [  338],
         [  310],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [20001]]], device='cuda:0')
torch.Size([2, 854, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  338, 29892,   278,  ...,   304,  7935,  1317],
         [  310,   304,   363,  ...,   313, 29892, 29901],
         ...,
         [    1, 14262, 24366,  ..., 26077, 26502, 19838],
         [    1, 14262, 24366,  ..., 26077, 26502, 19838],
         [    1, 14262, 24366,  ..., 26077, 19838, 26502]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13,   887,   306,  ...,   960,     2,  2193],
         [   13, 29902, 29950,  ...,  3644, 29905,   797],
         [20001, 22550, 29950,  ..., 29909, 10454,  4013]]], device='cuda:0')
Batch 56, 94.1% of total tokens
encoded shape: torch.Size([2, 1182])
torch.Size([2, 1182]) tensor([[    1,  1724,   947,  ...,     2,     2,     2],
        [    1, 25022,  3174,  ..., 16422,   532, 29889]], device='cuda:0')
torch.Size([2, 1182, 32000]) tensor([[[     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         ...,
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan],
         [     nan,      nan,      nan,  ...,      nan,      nan,      nan]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.5000,  -5.1445,  -3.6328,  ...,  -4.2695,  -5.1797,  -6.9570],
         [-13.1406, -12.8438,  -6.7773,  ...,  -7.1992,  -6.9688,  -7.8594],
         ...,
         [ -2.9629,  -4.6758,   0.1313,  ...,   0.5708,   1.1641,  -0.9521],
         [ -6.9492, -10.0156,   2.9121,  ...,  -4.6172,  -3.0449,  -3.6484],
         [ -9.1406,  -9.4922,   6.9492,  ...,  -3.5898,  -1.7705,  -7.3867]]],
       device='cuda:0')
torch.Size([2, 1182, 1]) tensor([[[    0],
         [    0],
         [    0],
         ...,
         [    0],
         [    0],
         [    0]],

        [[29892],
         [ 2256],
         [29892],
         ...,
         [  532],
         [  363],
         [   13]]], device='cuda:0')
torch.Size([2, 1182, 10]) tensor([[[    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         ...,
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 2256,  3174, 16470,  ...,  1505,   305, 21155],
         [29892,   322,   297,  ...,   512,   669,   505],
         ...,
         [  532,  2454,  2075,  ...,  1446,   403, 25145],
         [  363, 29889,   297,  ...,   310,   393,   313],
         [   13,   450,  3834,  ...,  4525,  1670,  7849]]], device='cuda:0')
Batch 57, 96.4% of total tokens
encoded shape: torch.Size([2, 207])
torch.Size([2, 207]) tensor([[    1, 13987, 29901,  1551,   278, 14802, 10130, 17368, 29915, 29879,
           376, 29048, 29915, 29879, 10130,   379, 29984,  1699,  4335,  6780,
          5481,  5353,   267, 10757,   393,   278,   382,  7228,  3984,   839,
           278,   970,  1048,   278, 10879,   310,   967,   716,  1072,  8250,
           373,   278, 12536,  3097,   310,   278,  5233, 29915, 29879, 12646,
           537, 13284,    13,    13, 10923, 23708, 29901,  6666,   882,   310,
          3086,  7817,   363,  5236, 25219, 10550,  7178, 28533,   390,  3615,
           473,   373,  4250,  3304, 23303, 16499,   291,   393,   278,  5282,
          1947,   310,  1085,  9081,  3185, 10630,   324,  1078,   278, 20063,
         29915, 29879, 11243,   284, 14409,   428,  6015,  1509,    13,    13,
         10923, 23708, 29901,  4250,  3304, 29915, 29879,  5282,  1947,   310,
         28832,  1085,  9081,  6811, 27308,   310,  7927,   678, 16047,   287,
           491,  6054, 15312,  5056,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2],
        [    1,   405,   277, 13816, 29899,  1285, 17225, 17292,   324,   293,
          3144,  1682,   359,  2247,   515,   278, 11308,   310, 21806,   305,
           333,   291,  1274,  9735, 21048, 29889,    13,  4591,   278,  8748,
         29949, 10644, 29899,  2929,   431,   280, 15958,   310,   263,  2191,
         23170,  6597,   310,   278, 11308,   310, 21806,   305,   333,   291,
          1274,  9735, 21048, 29892,  4832,   716,   752,  3885,  3412,   411,
          5320,  2998,  6743,   892, 23968, 29889,   450, 12286,   310,   278,
           716,   752,  3885,   892,   560,  1682,   333,   630,   304,   367,
          1023, 11798,  1078, 29892,   263,   282, 29899, 29882, 11279,  3594,
          1785,  2502,   403,   322,   385,   313, 29903,  6817, 29906, 17722,
         29946, 29899, 29882, 11279,  3594,  8798,   417, 20970, 29899, 29896,
         29899,   264, 29899, 29896, 29899,  2904, 29897,   562,   300,   403,
           310,   263, 21767, 13816, 29899,  1285, 17225, 17292,   324,   293,
          3144,  1682,   359,   680, 29892,   286,   621,  2904, 29871, 29906,
         17722, 29906, 29899, 29882, 11279,  3594,  9789,  2904, 29897,   562,
           300,   403, 29871, 30187, 29899, 29928, 29899,  3820,  1682,  2270,
           661,   359,   680, 29892,   322,   313, 29903,  6817, 29885,   621,
          2904, 29871, 29906, 29899, 29961, 29946, 29899, 29879,   352,  1181,
          2251, 29891,  8798,   417, 20970, 29899, 29896, 29899,   264, 29899,
         29896, 29899,  2904, 29962,   562,   300,   403,   373,   278,  8405,
           310,  6683,   307, 21785,   293, 10757, 29889]], device='cuda:0')
torch.Size([2, 207, 32000]) tensor([[[ -8.0469,  -1.2861,  -0.5547,  ...,  -4.2422,  -5.7148,  -4.6523],
         [-10.2500,  -5.8281,  -3.8203,  ...,  -6.6680,  -9.7578,  -5.5859],
         [ -9.4219,  -8.0859,  -3.0273,  ...,  -5.6406,  -6.4102,  -5.3281],
         ...,
         [ -3.2656,  -1.3018,   1.0635,  ...,  -3.0684,  -3.7461,  -2.4785],
         [ -3.2559,  -1.3291,   1.0605,  ...,  -3.0684,  -3.7500,  -2.4766],
         [ -3.2402,  -1.3457,   1.0625,  ...,  -3.0645,  -3.7461,  -2.4668]],

        [[ -8.0469,  -1.2861,  -0.5547,  ...,  -4.2422,  -5.7148,  -4.6523],
         [ -6.1680,  -6.3984,   1.9922,  ...,  -2.8613,  -2.9023,  -4.8320],
         [ -9.6484, -12.7266,  -5.8203,  ...,  -5.3711,  -4.7578,  -5.3164],
         ...,
         [ -5.0430,  -7.7734,   2.8828,  ...,  -2.0430,  -3.8203,  -3.1602],
         [ -3.6641,  -6.6016,   6.2695,  ...,   1.2910,  -1.0312,  -2.6016],
         [ -8.5234, -12.3359,  11.3516,  ...,  -1.2256,  -3.1973,  -5.3594]]],
       device='cuda:0')
torch.Size([2, 207, 1]) tensor([[[29892],
         [29901],
         [  450],
         [  278],
         [ 9321],
         [13082],
         [17368],
         [29892],
         [30488],
         [30488],
         [30879],
         [30488],
         [29879],
         [30488],
         [30879],
         [30488],
         [30488],
         [  313],
         [30488],
         [30488],
         [30488],
         [  267],
         [  278],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 1048],
         [30488],
         [30488],
         [30488],
         [30488],
         [  315],
         [  315],
         [30488],
         [  373],
         [30488],
         [30488],
         [30488],
         [  310],
         [30488],
         [30488],
         [29915],
         [29879],
         [ 3081],
         [ 6856],
         [ 6856],
         [29889],
         [21599],
         [15167],
         [23708],
         [  891],
         [ 4335],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29915],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  373],
         [  278],
         [30488],
         [23303],
         [30879],
         [  291],
         [  393],
         [  382],
         [30488],
         [30488],
         [  310],
         [30488],
         [30488],
         [ 3185],
         [  313],
         [  324],
         [ 1078],
         [20063],
         [20063],
         [   13],
         [29879],
         [23658],
         [30488],
         [14409],
         [  428],
         [ 6015],
         [ 1509],
         [   13],
         [10923],
         [10923],
         [23708],
         [29901],
         [ 6666],
         [ 3304],
         [23303],
         [29879],
         [11662],
         [30488],
         [  310],
         [ 1085],
         [ 1085],
         [ 9081],
         [  338],
         [29892],
         [  310],
         [ 7927],
         [   13],
         [16047],
         [  287],
         [  491],
         [ 3086],
         [30488],
         [  856],
         [  472],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [29871],
         [29871],
         [29871],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29902],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [ 2749],
         [  307],
         [21806],
         [ 1111],
         [17225],
         [15680],
         [  720],
         [  293],
         [  620],
         [ 1041],
         [  359],
         [ 2247],
         [  515],
         [  278],
         [14911],
         [  310],
         [  315],
         [ 1327],
         [  333],
         [  291],
         [16424],
         [20323],
         [21048],
         [  313],
         [  405],
         [29909],
         [  278],
         [11308],
         [  962],
         [10644],
         [ 6597],
         [ 2929],
         [  431],
         [  280],
         [ 6597],
         [  310],
         [  278],
         [12658],
         [23170],
         [ 6597],
         [  310],
         [  278],
         [11308],
         [  310],
         [21806],
         [  305],
         [  333],
         [  291],
         [ 1274],
         [ 9735],
         [21048],
         [29892],
         [  263],
         [  716],
         [17292],
         [ 3885],
         [29892],
         [  411],
         [ 1023],
         [ 2998],
         [ 6743],
         [  892],
         [23968],
         [29889],
         [11275],
         [12286],
         [  310],
         [  278],
         [  716],
         [  752],
         [ 3885],
         [  892],
         [ 7841],
         [ 1682],
         [30488],
         [  630],
         [  408],
         [  367],
         [21767],
         [17292],
         [30488],
         [29892],
         [ 1023],
         [ 3581],
         [30488],
         [29882],
         [30488],
         [ 3594],
         [ 1785],
         [30488],
         [  403],
         [29892],
         [ 2211],
         [12302],
         [29923],
         [29899],
         [29906],
         [29899],
         [29941],
         [29899],
         [26129],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29896],
         [29899],
         [  264],
         [30488],
         [29896],
         [29899],
         [ 2904],
         [ 6817],
         [ 8798],
         [30488],
         [30488],
         [29892],
         [17292],
         [21767],
         [30488],
         [29899],
         [ 1285],
         [17225],
         [17292],
         [30488],
         [  293],
         [ 3144],
         [30488],
         [  359],
         [  680],
         [29889],
         [  322],
         [  621],
         [30488],
         [29871],
         [29906],
         [17722],
         [29946],
         [29899],
         [26129],
         [30488],
         [ 3594],
         [29899],
         [29891],
         [ 6817],
         [  562],
         [30488],
         [  403],
         [29892],
         [29896],
         [29899],
         [ 3820],
         [29899],
         [ 3820],
         [30488],
         [  359],
         [  661],
         [30488],
         [  680],
         [  313],
         [  322],
         [  263],
         [29903],
         [ 6817],
         [29906],
         [  621],
         [30879],
         [29871],
         [29906],
         [17722],
         [ 9789],
         [29906],
         [17722],
         [29882],
         [  313],
         [ 1181],
         [ 3594],
         [30488],
         [ 8798],
         [  417],
         [20970],
         [ 2904],
         [29896],
         [29899],
         [  264],
         [ 2904],
         [29896],
         [29899],
         [ 2904],
         [29962],
         [  562],
         [  300],
         [  403],
         [29871],
         [  278],
         [ 8405],
         [  310],
         [ 6683],
         [  307],
         [21785],
         [  293],
         [  848],
         [  322],
         [  450]]], device='cuda:0')
torch.Size([2, 207, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29901,   310, 21388,  ...,   535,  8448,  3697],
         [  450, 29871,   319,  ...,   323,   341,   360],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 2749,  1682,  5371,  ..., 23249,   329,  3723],
         [  307,   728,   262,  ...,   336, 26840,  1617],
         ...,
         [  848,  3483, 11898,  ..., 13698,   313, 29892],
         [  322, 29889,  3704,  ...,  1316,   310,  6969],
         [  450,    13, 11275,  ..., 20532,   319,   910]]], device='cuda:0')
Batch 58, 96.7% of total tokens
encoded shape: torch.Size([2, 754])
torch.Size([2, 754]) tensor([[    1,   306,   505,  ...,     2,     2,     2],
        [    1,   660, 29901,  ...,  2670,    13,    13]], device='cuda:0')
torch.Size([2, 754, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -9.6094, -13.2500,  -2.8848,  ...,  -4.9648,  -8.0234,  -3.3398],
         [ -8.7266, -12.7344,  -5.9727,  ...,  -5.1797,  -7.7969,  -6.3945],
         ...,
         [-11.7031,  -3.1094,  -1.7891,  ...,  -7.6250,  -5.2539,  -8.3750],
         [-11.7422,  -3.0273,  -1.6562,  ...,  -7.7500,  -5.2852,  -8.4375],
         [-11.7422,  -2.9316,  -1.6113,  ...,  -7.7422,  -5.2891,  -8.4141]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [-10.6953, -11.7734,  -5.2109,  ...,  -6.0781,  -9.1250,  -6.8438],
         [-11.5312, -12.3828,  -3.2441,  ...,  -5.0117,  -5.4766,  -3.9609],
         ...,
         [  0.7959,   0.1704,  17.2500,  ...,  -3.0176,   0.0515,  -1.5400],
         [ -1.5234,   0.1212,  14.5312,  ...,   0.3984,   1.0703,   2.6230],
         [ -6.6914, -10.1406,  -0.1231,  ...,  -1.8643,  -2.9609,   0.5596]]],
       device='cuda:0')
torch.Size([2, 754, 1]) tensor([[[29892],
         [30010],
         [ 1063],
         ...,
         [29900],
         [29900],
         [29900]],

        [[29892],
         [14873],
         [ 1724],
         ...,
         [   13],
         [   13],
         [20001]]], device='cuda:0')
torch.Size([2, 754, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [30010, 29915,   505,  ...,  3580,  5360,  1348],
         [ 1063,   263,   304,  ...,  2360,   694,   278],
         ...,
         [29900,  1516, 29896,  ..., 29946, 29945, 29955],
         [29900, 29896,  1516,  ..., 29946, 29945, 29955],
         [29900, 29896,  1516,  ..., 29946, 29945, 29955]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [14873, 29901, 29965,  ..., 29896, 29934,  3120],
         [ 1724,  1128,   306,  ...,  1932,  1317,   450],
         ...,
         [   13, 29871,   849,  ...,   470, 29936,  1925],
         [   13,   649, 29893,  ...,  4013,     2,  4172],
         [20001,  4013, 22550,  ...,  2816,  2855,   272]]], device='cuda:0')
Batch 59, 98.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  4918, 11322,  ...,     2,     2,     2],
        [    1, 29871, 29945,  ..., 12084,   322,  8465]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.9648,  -8.3750,  -4.8906,  ...,  -2.9980,  -5.4414,  -5.2539],
         [-13.3438, -11.5078,  -6.5000,  ...,  -2.8926,  -6.3555,  -7.9766],
         ...,
         [ -3.4609,   5.6836,   9.2734,  ...,   0.3350,  -2.6621,  -0.5049],
         [ -3.6270,   6.0508,   9.0625,  ...,   0.1685,  -2.7480,  -0.5229],
         [ -3.2910,   6.0156,   9.1328,  ...,   0.3699,  -2.5059,  -0.3467]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.3984,   0.6221,  -1.6709,  ...,   2.6641,   0.4211,   0.0731],
         [-12.0703,  -8.2422,  -4.7305,  ...,  -9.4375,  -8.8906,  -7.8789],
         ...,
         [ -1.9980,  -2.9648,   1.1855,  ...,   0.2328,   2.3750,  -0.4453],
         [ -3.1309,  -6.3555,   0.3857,  ...,  -0.7476,  -1.0801,  -1.8818],
         [ -1.2490,  -1.7559,   2.5898,  ...,  -0.8301,   1.4092,   0.8755]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [  287],
         [29871],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29892],
         [29896],
         [29900],
         ...,
         [  515],
         [ 8465],
         [  304]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  287, 29879,  4967,  ..., 29899,  5105,   292],
         [29871, 29896, 29906,  ..., 29947, 29955, 29900],
         ...,
         [29871,    13, 29906,  ..., 29929, 29947, 29955],
         [29871, 29906, 29896,  ..., 29929, 29947, 29955],
         [29871, 29906, 29896,  ..., 29947, 29929, 29955]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29900, 28706, 29906,  ...,   323,   386, 29946],
         ...,
         [  515, 12879,  5999,  ...,   607,   540,  9561],
         [ 8465, 14874,   947,  ...,  3732, 23196,  2143],
         [  304,  1584, 12879,  ...,   470, 19967,  2845]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 922])
torch.Size([2, 922]) tensor([[    1, 29871, 29906,  ...,     2,     2,     2],
        [    1, 29871, 29896,  ...,   322, 21561, 29889]], device='cuda:0')
torch.Size([2, 922, 32000]) tensor([[[-9.0156,  0.8428,  0.8081,  ..., -3.0449, -5.3750, -2.3594],
         [-5.7266, -4.3750,  3.1660,  ..., -3.7793, -4.3516, -3.3809],
         [-6.0742, -4.0352,  2.3262,  ..., -3.9258, -4.3047, -3.4473],
         ...,
         [-5.9062, -2.5078,  0.7563,  ..., -3.7363, -4.1484, -3.2949],
         [-5.9609, -2.5352,  0.7461,  ..., -3.7520, -4.1641, -3.3105],
         [-5.9844, -2.5645,  0.7661,  ..., -3.7617, -4.1719, -3.3223]],

        [[-9.0156,  0.8428,  0.8081,  ..., -3.0449, -5.3750, -2.3594],
         [-5.7266, -4.3750,  3.1660,  ..., -3.7793, -4.3516, -3.3809],
         [-6.7617, -4.9180,  3.0234,  ..., -3.6543, -4.2422, -4.0039],
         ...,
         [-4.4844, -2.9551,  1.2500,  ..., -3.4727, -3.8496, -3.0742],
         [-4.3203, -2.7910,  1.0146,  ..., -3.3242, -3.9668, -2.9785],
         [-4.3750, -3.1387,  1.0938,  ..., -3.4336, -3.8887, -2.9961]]],
       device='cuda:0')
torch.Size([2, 922, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [  313],
         [  313],
         [  313]],

        [[29918],
         [29871],
         [29871],
         ...,
         [30488],
         [30488],
         [29889]]], device='cuda:0')
torch.Size([2, 922, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29899, 29892,  ...,   376, 29915,   349],
         ...,
         [  313, 29892,   349,  ..., 29871,   376,   317],
         [  313, 29892,   349,  ..., 29871,   376,   317],
         [  313, 29892,   349,  ..., 29889,   376,   317]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29874, 29899,  ...,   376,   313,   856],
         ...,
         [30488, 30879, 29889,  ..., 31147, 29871, 29915],
         [30488, 31147, 30879,  ..., 29899, 29871, 29874],
         [29889, 29892, 29899,  ...,   856,   313, 29874]]], device='cuda:0')
Batch 1, 1.3% of total tokens
encoded shape: torch.Size([2, 1003])
torch.Size([2, 1003]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   450, 29871,  ...,  6017,   749, 29889]], device='cuda:0')
torch.Size([2, 1003, 32000]) tensor([[[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [ -7.1445,  -6.3789,   3.4844,  ...,  -4.6406,  -5.0742,  -3.9863],
         [ -9.1562,  -8.0156,   0.0959,  ...,  -4.9375,  -3.4062,  -4.9102],
         ...,
         [ -7.2539,  -4.1406,   1.9180,  ...,  -4.6875,  -4.3516,  -4.0352],
         [ -7.4102,  -4.3008,   1.9199,  ...,  -4.7695,  -4.3633,  -4.1172],
         [ -7.4180,  -4.3125,   1.9365,  ...,  -4.7734,  -4.3633,  -4.1289]],

        [[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [ -9.5547, -13.0391,   0.3970,  ...,  -6.6055,  -1.0117,  -7.5977],
         [-10.0391, -15.0859,  -1.0439,  ...,  -6.7695,  -1.6846,  -7.6094],
         ...,
         [ -6.5039,  -5.4141,  -1.5439,  ...,  -1.5557,  -3.3516,  -4.0195],
         [ -6.4844,  -6.3516,  -5.6914,  ...,  -2.2539,   0.0165,  -4.4844],
         [ -5.4258,  -4.3711,   0.9116,  ...,  -3.8105,  -3.8809,  -4.1836]]],
       device='cuda:0')
torch.Size([2, 1003, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [  313],
         [  313],
         [  313]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29886],
         [  705],
         [29915]]], device='cuda:0')
torch.Size([2, 1003, 10]) tensor([[[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [  313, 29892, 29899,  ...,   315, 29874, 29889],
         [  313, 29892, 29899,  ...,   315, 29874,   856],
         [  313, 29892, 29899,  ...,   315, 29874,   856]],

        [[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29871, 29896, 29906,  ..., 29941, 29879, 29945],
         ...,
         [29886, 29899,  2454,  ..., 29933, 29911, 29924],
         [  705, 29874,  1022,  ...,   557,   331,  5828],
         [29915, 29889,   313,  ..., 29898,   376, 30010]]], device='cuda:0')
Batch 2, 2.8% of total tokens
encoded shape: torch.Size([2, 1257])
torch.Size([2, 1257]) tensor([[    1, 21892, 14717,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29889,    13,    13]], device='cuda:0')
torch.Size([2, 1257, 32000]) tensor([[[-9.0156,  0.8433,  0.8076,  ..., -3.0449, -5.3789, -2.3613],
         [-6.8711, -5.7148,  2.7812,  ..., -4.2344, -4.0352, -3.5625],
         [-6.0664, -4.9336,  1.6768,  ..., -3.7500, -3.9922, -3.4883],
         ...,
         [-4.2500, -2.1309,  1.5430,  ..., -3.3906, -3.9727, -2.8711],
         [-4.2539, -2.1387,  1.5439,  ..., -3.3926, -3.9766, -2.8750],
         [-4.2344, -2.1270,  1.5400,  ..., -3.3848, -3.9707, -2.8672]],

        [[-9.0156,  0.8433,  0.8076,  ..., -3.0449, -5.3789, -2.3613],
         [-7.1406, -6.3711,  3.4824,  ..., -4.6367, -5.0703, -3.9824],
         [-9.1250, -7.9688,  0.1106,  ..., -4.9141, -3.4043, -4.8945],
         ...,
         [-5.8516, -5.3945,  0.7407,  ..., -4.5078, -2.1543, -5.1016],
         [-5.6562, -4.2305,  1.8320,  ..., -4.8008, -4.5742, -4.1758],
         [-4.8047, -3.5312,  1.2383,  ..., -4.4922, -3.9395, -3.3262]]],
       device='cuda:0')
torch.Size([2, 1257, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [30488],
         [30488],
         [30488]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29915],
         [29892],
         [  315]]], device='cuda:0')
torch.Size([2, 1257, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ..., 29896,   392,   313],
         [29871, 29899, 29903,  ..., 29874,   313, 29882],
         ...,
         [30488, 30879, 31147,  ..., 29871, 29899,   856],
         [30488, 30879, 31147,  ..., 29871, 29899,   856],
         [30488, 30879, 31147,  ..., 29871, 29899,   856]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29915,   313, 30010,  ...,   297, 29908,   315],
         [29892, 29899,   313,  ..., 29898, 29871,   349],
         [  315, 29892, 29915,  ..., 29898,   349, 29914]]], device='cuda:0')
Batch 3, 4.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 11474,    13,  ...,  4678,  2003,   320],
        [    1,  2088,   404,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.5508,  -3.0449,   1.9414,  ...,  -3.4023,  -4.0625,  -3.0234],
         [ -5.8359,   3.2266,   6.0742,  ...,  -0.1229,  -2.0488,   0.7637],
         ...,
         [ -8.9844, -12.6484,  -3.7617,  ...,  -6.7734,  -3.0781,  -8.0078],
         [ -9.4062, -14.7266,  -1.6035,  ...,  -7.8203,  -1.8799,  -6.0195],
         [ -9.1719, -12.6406,  -3.3594,  ...,  -7.7266,  -3.4785,  -8.4844]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -9.6328,  -9.7109,   4.5586,  ...,  -5.2891,  -4.9688,  -6.6133],
         [ -6.5898,  -5.3711,   1.7783,  ...,  -3.8965,  -4.2148,  -4.3984],
         ...,
         [ -7.3711,   2.3906,  -1.5586,  ...,  -2.4512,  -4.5742,  -2.1211],
         [ -7.2969,   2.4277,  -1.6592,  ...,  -2.4258,  -4.5195,  -2.1094],
         [ -7.2734,   2.4219,  -1.7080,  ...,  -2.4277,  -4.5078,  -2.1133]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29889],
         [   13],
         ...,
         [29892],
         [  294],
         [29892]],

        [[29918],
         [29871],
         [29871],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 30488,  ...,   313, 31147,   856],
         [   13,   313,    12,  ..., 29918, 29915, 30024],
         ...,
         [29892, 29875,   514,  ...,   313,   302, 29950],
         [  294, 29874, 29875,  ...,   680, 29915,   370],
         [29892, 29875, 29874,  ...,   376, 29968, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29892,  ...,   315,    13,   376],
         [29871, 29874, 29915,  ...,   856, 29898, 29882],
         ...,
         [30010, 29915, 29918,  ..., 29899, 29973,   392],
         [30010, 29915, 29918,  ...,   392, 29973, 29899],
         [30010, 29915, 29918,  ...,   392, 29973, 29899]]], device='cuda:0')
Batch 4, 9.2% of total tokens
encoded shape: torch.Size([2, 743])
torch.Size([2, 743]) tensor([[    1,   660, 29901,  ...,  1504,    13,    13],
        [    1,   349,   335,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 743, 32000]) tensor([[[ -9.0156,   0.8423,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -7.1406,  -6.3711,   3.4844,  ...,  -4.6367,  -5.0703,  -3.9824],
         [ -9.1250,  -7.9688,   0.1140,  ...,  -4.9180,  -3.4082,  -4.8984],
         ...,
         [ -7.2461,  -8.3828,  -0.8384,  ...,  -7.3320,  -0.9917,  -8.5156],
         [ -8.6562, -10.8203,  -0.9517,  ...,  -8.9922,  -5.0469,  -7.5625],
         [ -7.5000, -11.3750,  -2.7988,  ...,  -8.2109,  -4.0547,  -6.8281]],

        [[ -9.0156,   0.8423,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -9.8516, -10.9141,   4.2734,  ...,  -6.6914,  -4.3438,  -6.0625],
         [ -8.5156, -14.2656,  -1.8291,  ...,  -7.6875,  -2.9922,  -8.3672],
         ...,
         [ -4.8008,  -3.2227,   2.1562,  ...,  -3.6172,  -4.2461,  -3.1211],
         [ -4.8008,  -3.2324,   2.1582,  ...,  -3.6172,  -4.2500,  -3.1230],
         [ -4.8125,  -3.2402,   2.1641,  ...,  -3.6211,  -4.2500,  -3.1289]]],
       device='cuda:0')
torch.Size([2, 743, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [30166],
         [29892],
         [  319]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29889],
         [29889],
         [29889]]], device='cuda:0')
torch.Size([2, 743, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [30166, 29874,   313,  ..., 29933, 30262, 29875],
         [29892, 29899, 29915,  ..., 29874,    13,   319],
         [  319, 29899, 29909,  ..., 29871,   313,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ...,   376, 29889,   317],
         [29871, 29892, 29899,  ...,   294, 29874,   313],
         ...,
         [29889, 29871, 29892,  ..., 29915,   349,   315],
         [29889, 29871, 29892,  ..., 29915,   349,   315],
         [29889, 29871, 29892,  ..., 29915,   349,   315]]], device='cuda:0')
Batch 5, 10.5% of total tokens
encoded shape: torch.Size([2, 1133])
torch.Size([2, 1133]) tensor([[    1,   450,   399,  ...,  3082, 11456, 23238],
        [    1,   450, 11747,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1133, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -9.5547, -13.0312,   0.3982,  ...,  -6.6094,  -1.0088,  -7.5977],
         [ -9.3438,  -9.4766,   3.0957,  ...,  -5.6523,  -5.1719,  -6.4883],
         ...,
         [ -4.2070,  -2.3652,   1.0020,  ...,  -2.9141,  -3.8887,  -2.8105],
         [ -4.1562,  -2.5020,   0.8066,  ...,  -2.8555,  -3.7559,  -2.6836],
         [ -5.4297,  -3.9629,   1.4805,  ...,  -3.4609,  -3.9297,  -3.3984]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -9.5547, -13.0312,   0.3982,  ...,  -6.6094,  -1.0088,  -7.5977],
         [ -9.9375, -14.0312,  -0.5225,  ...,  -6.4375,  -3.3125,  -7.1719],
         ...,
         [ -6.6875,  -3.6914,   1.9219,  ...,  -4.3633,  -4.3516,  -3.7656],
         [ -6.6719,  -3.6426,   1.8721,  ...,  -4.3477,  -4.3359,  -3.7539],
         [ -6.6602,  -3.6133,   1.8438,  ...,  -4.3398,  -4.3281,  -3.7422]]],
       device='cuda:0')
torch.Size([2, 1133, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [30488],
         [30488],
         [29874]],

        [[29918],
         [29871],
         [  774],
         ...,
         [  313],
         [  313],
         [  313]]], device='cuda:0')
torch.Size([2, 1133, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29871, 29899, 29892,  ..., 29915,   448, 29896],
         ...,
         [30488, 31147, 30879,  ..., 30186, 29882, 29892],
         [30488, 31147, 30879,  ..., 29882, 29889, 29899],
         [29899, 29874, 29882,  ..., 29915,   262,   313]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [  774,   300,   376,  ...,   262,   856, 29884],
         ...,
         [  313, 29892, 29871,  ...,   315,   376,   856],
         [  313, 29892, 29871,  ...,   315,   376,   856],
         [  313, 29892, 29871,  ...,   315,   376,   856]]], device='cuda:0')
Batch 6, 12.1% of total tokens
encoded shape: torch.Size([2, 513])
torch.Size([2, 513]) tensor([[    1,   660, 29901,  ..., 29889,    13,    13],
        [    1,   498,   329,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 513, 32000]) tensor([[[ -9.0156,   0.8477,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -7.1562,  -6.3906,   3.4863,  ...,  -4.6484,  -5.0781,  -3.9922],
         [ -9.1328,  -7.9805,   0.1039,  ...,  -4.9219,  -3.4062,  -4.9023],
         ...,
         [ -6.4102,  -5.2539,   0.4963,  ...,  -6.0430,  -1.6885,  -5.0039],
         [ -5.9453,  -4.1211,   2.2734,  ...,  -4.7617,  -4.4727,  -3.8711],
         [ -4.8750,  -3.2871,   1.6738,  ...,  -4.0078,  -3.8965,  -3.0000]],

        [[ -9.0156,   0.8477,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [-11.2109, -13.7031,   1.8271,  ...,  -7.2617,  -4.9648,  -8.5000],
         [ -6.5977,  -5.3711,   2.9062,  ...,  -4.1172,  -4.8945,  -3.7520],
         ...,
         [ -7.3945,  -8.6484,  -6.7344,  ...,  -5.5000,  -2.1602,  -5.9453],
         [ -7.5391,  -8.6953,  -6.7031,  ...,  -5.6211,  -2.3516,  -6.0547],
         [ -7.8945,  -8.5703,  -6.5938,  ...,  -5.7695,  -2.6465,  -6.1875]]],
       device='cuda:0')
torch.Size([2, 513, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29915],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29871],
         ...,
         [23333],
         [23333],
         [30057]]], device='cuda:0')
torch.Size([2, 513, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29915,   282, 30010,  ..., 29902, 29892, 29908],
         [29892, 29899,   313,  ...,   282, 29914,    13],
         [29892, 29899,   313,  ...,   282, 29914,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29892,  ...,   376,   349,   313],
         [29871, 29892, 29899,  ...,   856,   376,   315],
         ...,
         [23333, 12254, 14131,  ...,   514,  1131, 29915],
         [23333, 12254, 30057,  ...,   538,   514, 29915],
         [30057, 30010, 29879,  ...,   538,   514, 29873]]], device='cuda:0')
Batch 7, 12.8% of total tokens
encoded shape: torch.Size([2, 408])
torch.Size([2, 408]) tensor([[    1,   660, 29901,    13,    13,  4074,   342,   390,   403,   826,
          2966,  6617,   448, 14617,  1283, 24806,    13,    13, 29902,   626,
         18987,   363,  4066,  6554,   564,  2966,  6617,   304,  5146,  1283,
           590,  9793, 24806,   297,  7513,   472, 29871, 29896, 29896, 29889,
         29906, 29945, 29995,  4066,  6554,   773,   263,  7333, 24806,   472,
         29871, 29941, 29889, 29929, 29995,  4066,  6554,   515,   385,  7824,
          4234,   988,   306,   664, 11580,  4098,   368, 17869, 29889,    13,
         29902,  1073,   393,   727,   338,   382,  4574, 29899,  1177, 29934,
         19358, 14523, 12045, 29889,  1205,   306,   626, 14238,   472,   280,
           579, 29871, 29955, 29995,   491,  5146,   292,  1283,  1880,  4066,
          6554, 24806,  1250,  3271, 29889, 29871,    13, 29902,   505,  2400,
          1023,  3987, 29901,    13,    13,  9984,  4098,   368,  5146,  1860,
           408,  1568,   408,  1950,  1549,  9117, 14523,  6782,  7113,  9793,
         24806,   297,  7513, 29889,   910,   674, 10032,  9117, 14523, 12045,
          2861,   304,  4759,  6751,   975,  2846,  2440, 29892,   541,   278,
          1880,  4066,  6554,   732, 29871, 29896, 29896, 29889, 29906, 29945,
         29995,   674,   367,   752, 12449, 29889,    13, 11123,   445,  9793,
         24806,   297,  7513,   773,  7333, 24806,   472, 29871, 29941, 29889,
         29929, 29995,  4066,  6554, 29889,   306,   674,  1018,   304,  3802,
           445,  4482,  4066,  7333, 24806,   408,   481,   408,   727,   338,
           694,  8273,   388,   358, 27368, 29889,  2648,   445,   982, 29892,
           306,   505, 10631,   310,  4482,  4066,  6554,   541, 19884,   304,
          9117, 14523, 12045,   491,  6782,  5393, 12176,  5253,   310,  6909,
           304,  7513,   411,  1857,  4482, 11301,  6554, 29889,    13,    13,
         12148,  3867,   596, 21114,  1663,  5861, 29889,    13, 16894,   599,
         29889,    13,    13, 29909, 29901,    13,    13,  3644,   366,   679,
           596, 17869,   297,   278, 27550,   366,   505,   278,   716, 24806,
           297, 29892,   727,   338,   694, 14523, 12045,   363,   278,  5434,
         29889,    13,  7900,  9929,   393,   366,   526,  2221,   304,   679,
           322,  9080,   393, 24806, 29892,   372, 26830,   596,  3438, 29892,
           577,   748,   363,   372, 29889,    13,  8241, 29892,   565,   278,
         27550, 14523,  6554,  3620,   278,  1492,   982,   975,   278,  2446,
          2440, 29892,   366,  1033,   505,  1754,   263,  2253,  5376,   448,
           541,  2050,   372,  1033,   884,   748,   278,   916,   982, 29889,
           960,   366,  2289,   864,   304,  1708,   445,  3748, 29892,   437,
           372, 16949, 29892,   491,  3534,   292,  5717, 29914,   649, 29879,
           373,   278, 27550, 14523,  6554, 29889,  2823,   372,   408,   263,
          5004,   322,  1602,   283,   552, 29881, 13258,   358,  2984, 29889,
            13,    13,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13,  5328,   304, 17432,  9810,   515,
         18531, 21454,   304,   278,  1021,  4423,   306, 20373,   372,   964,
         18531, 21454, 29973,    13,    13, 29902,   505,   278,  1494,  2060,
         29901,    13,    13, 29902,  1492, 29899,  3808,   287,   297,   393,
          4138,  1919, 29902, 11484, 11786, 29933,  1161,  1244, 29892,  1754,
           278,  5181,  8260,   304,  9063,   322,  5503,   393,  2060,   964,
         18531, 29933,  2707,   300,   988,   372,  3430,   763,   445, 29901,
            13,    13,  2855,   278,  9063,  3430,   763,   393,   297,  1876,
          1169,  4004, 29901,    13,    13, 29902,   864,   304,  1207,   777,
          3620,   297,   278,  2060,   297,  7623, 29871, 29896,   773,  9249,
          7448, 29892,   541,   306, 29915, 29885,   451,  1854,   565,  1438,
          3620,   674,   367,  9150, 29892,   577,   565,   896,  9455, 29915,
         29873,   306,   864,   304, 11837,   278,  3620,   304,   278,   376,
          6730,  1876,   277, 29908,   322,   278,  3620,   304,  2125,  2779,
           297,   278,  2066,   515,  7623, 29871, 29896, 29889,   306,  1073,
           393,   372, 29915, 29879,  2309,   491,  1067, 28259, 29889,  1205,
           508,   306, 17432,   297,   278,  1021,  3884,   313,  3166,  7623,
         29871, 29896, 29897,   306, 20373,   278,  2060,   515,   322,   920,
         29973,  1670,   526,  2846,  6455,   297,  8986,   393,   947,  1067,
         28259,   541,   896,  2833,   304,   592,   393,   896,  9455, 29915,
         29873,   363,   825,   306,   864,   963,   363,   322,   306,  8866,
           306,   674, 14455,   590,  2060, 29892,  9063,  2992,  1308, 29874,
         29889,   960,   306,  1735,  1554,   297,   590,  2060,   515,  7623,
           306,   322,   278,  1735,   338,  9150,   306,   864,   304,  9063,
          6820,   777,  1024,   310,   278,  1735,   541,   565,   306,  6773,
          2599,   777,  3620,   322,   306, 14455,  1554,   306,   864,   304,
           748,   304,   278,   758,  1403,   359,  4331,   322,   278, 24187,
          1259,   304,  2125, 19208,   884,   297,  7623, 29871, 29896,  2066,
         29889,    13,    13, 29909, 29901,    13,    13,  3644,   366,  1722,
           596,  2060,   515, 12221,   313, 14037,  3907,   263,   716, 17432,
           511,   322,   437,   278,  3620,   366,   864, 29889,   960,   366,
          1016, 29915, 29873,   763,   963,   322,   864,   304, 29538,   313,
          7900,  9929,   366,   505,   451, 18760,  3099,  3447,   511,   366,
           508,  6222,   278,  1494, 29901,    13,  5559,   788,   448, 29909,
           632,  4949,  3462, 29879,   599,  3620,   366,  1754,  3776,    13,
          5559, 10092, 29871, 29906, 29888, 29953, 29890, 29941, 29872, 29953,
           418,  4949,  2538,  1691,  1250,   304,   278,   937,  9063,  3776,
            13,  5559, 10092,  1192,  6800,   539,  4949,  5240,   586,   267,
           599,  3620,  3776,    13,    13,  3644,   366,  2307, 18760,  3620,
           304,   596, 13761,   322,   864,   304, 29538, 29892,   769,   366,
           881,  1106,   472,  6315, 29538, 29889,    13,    13]],
       device='cuda:0')
torch.Size([2, 408, 32000]) tensor([[[-8.9844,  0.8472,  0.6909,  ..., -3.0449, -5.3633, -2.3750],
         [-7.1484, -6.3867,  3.4844,  ..., -4.6445, -5.0781, -3.9902],
         [-9.1172, -7.9492,  0.1118,  ..., -4.9102, -3.4023, -4.8828],
         ...,
         [-5.0703, -3.3633,  2.2480,  ..., -3.5195, -3.9844, -3.0000],
         [-5.0742, -3.3711,  2.2344,  ..., -3.5078, -3.9785, -3.0098],
         [-5.1133, -3.4121,  2.2402,  ..., -3.5195, -3.9824, -3.0391]],

        [[-8.9844,  0.8472,  0.6909,  ..., -3.0449, -5.3633, -2.3750],
         [-7.1484, -6.3867,  3.4844,  ..., -4.6445, -5.0781, -3.9902],
         [-9.1172, -7.9492,  0.1118,  ..., -4.9102, -3.4023, -4.8828],
         ...,
         [-5.2930, -5.6133,  0.2795,  ..., -4.5508, -2.1035, -4.2070],
         [-6.5625, -8.5234, -1.5723,  ..., -8.0156, -4.5898, -5.6250],
         [-5.0078, -4.1953,  0.8633,  ..., -4.6289, -3.7207, -2.9316]]],
       device='cuda:0')
torch.Size([2, 408, 1]) tensor([[[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29874],
         [  292],
         [29871],
         [29874],
         [29874],
         [29875],
         [29874],
         [29874],
         [  292],
         [  417],
         [29909],
         [29892],
         [29871],
         [29915],
         [29882],
         [  417],
         [29874],
         [29903],
         [29903],
         [29933],
         [  509],
         [ 3534],
         [  262],
         [  417],
         [  417],
         [30488],
         [  417],
         [30488],
         [29871],
         [  262],
         [29874],
         [29871],
         [29896],
         [29995],
         [29906],
         [29945],
         [29995],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29874],
         [30488],
         [30488],
         [29871],
         [29899],
         [29871],
         [29929],
         [  319],
         [30488],
         [30488],
         [30488],
         [29950],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [29915],
         [29892],
         [29915],
         [30488],
         [29874],
         [30488],
         [29899],
         [  262],
         [  856],
         [29874],
         [31147],
         [29903],
         [29898],
         [30879],
         [  306],
         [29915],
         [30488],
         [  382],
         [31147],
         [  856],
         [ 2672],
         [29871],
         [29900],
         [29898],
         [  262],
         [30879],
         [  417],
         [  590],
         [ 2672],
         [  658],
         [  658],
         [30879],
         [30488],
         [30488],
         [31147],
         [29871],
         [30488],
         [  311],
         [29871],
         [30488],
         [31147],
         [30282],
         [29871],
         [29871],
         [29896],
         [29874],
         [29871],
         [  382],
         [29876],
         [29898],
         [30488],
         [30488],
         [  306],
         [29898],
         [29874],
         [30488],
         [29898],
         [29874],
         [29903],
         [29874],
         [30879],
         [ 2672],
         [30879],
         [30879],
         [30879],
         [29876],
         [  382],
         [29909],
         [29903],
         [30488],
         [30488],
         [29874],
         [29874],
         [31147],
         [29903],
         [29903],
         [29898],
         [29889],
         [  306],
         [29899],
         [29899],
         [ 6554],
         [30879],
         [29871],
         [29871],
         [29896],
         [29889],
         [29906],
         [29945],
         [29995],
         [  313],
         [29911],
         [29911],
         [ 2650],
         [29876],
         [  313],
         [29899],
         [ 3410],
         [29903],
         [  417],
         [  376],
         [29902],
         [30488],
         [29874],
         [  417],
         [  376],
         [  262],
         [29871],
         [29889],
         [29871],
         [29995],
         [ 4066],
         [ 6554],
         [  262],
         [  313],
         [  674],
         [  262],
         [24708],
         [  262],
         [ 3410],
         [29903],
         [ 4066],
         [ 3410],
         [  417],
         [  408],
         [  578],
         [29898],
         [  306],
         [ 1454],
         [  382],
         [29874],
         [29871],
         [  358],
         [29903],
         [29898],
         [  313],
         [29909],
         [29892],
         [  306],
         [  306],
         [  674],
         [29882],
         [  310],
         [29899],
         [  292],
         [ 6554],
         [  376],
         [  306],
         [  517],
         [29923],
         [29909],
         [ 1652],
         [  271],
         [29899],
         [ 5393],
         [  382],
         [ 9723],
         [20164],
         [29923],
         [ 1250],
         [  797],
         [30488],
         [29871],
         [29899],
         [ 2672],
         [29903],
         [29923],
         [  313],
         [29892],
         [29899],
         [30488],
         [31147],
         [30879],
         [30879],
         [  376],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [29889],
         [29889],
         [29892],
         [29899],
         [  306],
         [  276],
         [29871],
         [31147],
         [  262],
         [16864],
         [29903],
         [29909],
         [29915],
         [29874],
         [31147],
         [29928],
         [  297],
         [30488],
         [29889],
         [30488],
         [29895],
         [  383],
         [29903],
         [  271],
         [31147],
         [29892],
         [29874],
         [  313],
         [29892],
         [  262],
         [29874],
         [29915],
         [29915],
         [30488],
         [29871],
         [30488],
         [31147],
         [30488],
         [30488],
         [31147],
         [  376],
         [29889],
         [30488],
         [30488],
         [31147],
         [30879],
         [29889],
         [30488],
         [  363],
         [29903],
         [29874],
         [31147],
         [29892],
         [29892],
         [29892],
         [29915],
         [29915],
         [29903],
         [29903],
         [ 1652],
         [30488],
         [29892],
         [29899],
         [30488],
         [29903],
         [29903],
         [29874],
         [  313],
         [29892],
         [29915],
         [29874],
         [29874],
         [30488],
         [31147],
         [29876],
         [  262],
         [29892],
         [  856],
         [29881],
         [30488],
         [29874],
         [29874],
         [  278],
         [29956],
         [  982],
         [29874],
         [31147],
         [  372],
         [  276],
         [30488],
         [  304],
         [30488],
         [31147],
         [30488],
         [  376],
         [  306],
         [  372],
         [  376],
         [29876],
         [ 9176],
         [  262],
         [  292],
         [  383],
         [29987],
         [31147],
         [30879],
         [ 1454],
         [29923],
         [29923],
         [ 3105],
         [  376],
         [ 3105],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29882],
         [30488],
         [  392],
         [  552],
         [29881],
         [29882],
         [  358],
         [  376],
         [30282],
         [31147],
         [29892],
         [29892],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29874],
         [29874],
         [29874],
         [29909],
         [29874],
         [29933],
         [29898],
         [29874],
         [29874],
         [29928],
         [29874],
         [  392],
         [  517],
         [  517],
         [29874],
         [29933],
         [  262],
         [  856],
         [29892],
         [29892],
         [  311],
         [29874],
         [29874],
         [29893],
         [ 8336],
         [29874],
         [29896],
         [29896],
         [  661],
         [ 3808],
         [ 3808],
         [  287],
         [29874],
         [29874],
         [29874],
         [  392],
         [  392],
         [29874],
         [  262],
         [29893],
         [  313],
         [29874],
         [29874],
         [  392],
         [29874],
         [29933],
         [10223],
         [ 6610],
         [ 1129],
         [ 3364],
         [29874],
         [  517],
         [  517],
         [  517],
         [21591],
         [29933],
         [29874],
         [  300],
         [  517],
         [29915],
         [29903],
         [29881],
         [30879],
         [30488],
         [29874],
         [  313],
         [  313],
         [29874],
         [29873],
         [24366],
         [  763],
         [ 1366],
         [  262],
         [18531],
         [  392],
         [ 1761],
         [  262],
         [29874],
         [  313],
         [29892],
         [  311],
         [  517],
         [16513],
         [14202],
         [ 3620],
         [ 1129],
         [17519],
         [29874],
         [17519],
         [  590],
         [29896],
         [29871],
         [  392],
         [29874],
         [ 7448],
         [  392],
         [  392],
         [  306],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  306],
         [30879],
         [30488],
         [30488],
         [  262],
         [  287],
         [  392],
         [  306],
         [  306],
         [30488],
         [29915],
         [29889],
         [  306],
         [30488],
         [  304],
         [ 2233],
         [  517],
         [29876],
         [  306],
         [ 1552],
         [29874],
         [29892],
         [  392],
         [  277],
         [  392],
         [29898],
         [29874],
         [  392],
         [  306],
         [ 1552],
         [ 1627],
         [  262],
         [12095],
         [29933],
         [  680],
         [12095],
         [29906],
         [29871],
         [29898],
         [29915],
         [29915],
         [ 1491],
         [29915],
         [29915],
         [29874],
         [  392],
         [  262],
         [14202],
         [ 1129],
         [29874],
         [29915],
         [  920],
         [  306],
         [17432],
         [ 4836],
         [ 1491],
         [29903],
         [ 2084],
         [ 2084],
         [29896],
         [12095],
         [29896],
         [29871],
         [29874],
         [  517],
         [24366],
         [ 4836],
         [ 4836],
         [ 1445],
         [12095],
         [29874],
         [  517],
         [  313],
         [ 1454],
         [  517],
         [29881],
         [  991],
         [29911],
         [20509],
         [13075],
         [  344],
         [ 1129],
         [  517],
         [  509],
         [16513],
         [29881],
         [16513],
         [  517],
         [16513],
         [16513],
         [29915],
         [29874],
         [ 1067],
         [29933],
         [  306],
         [26180],
         [  517],
         [  517],
         [29874],
         [  306],
         [29915],
         [  941],
         [ 1129],
         [ 4473],
         [ 1552],
         [ 9026],
         [ 1129],
         [  392],
         [  292],
         [  856],
         [29874],
         [29882],
         [  313],
         [  306],
         [29915],
         [ 1552],
         [  297],
         [12095],
         [ 4836],
         [16447],
         [12095],
         [29896],
         [29915],
         [  306],
         [29874],
         [24366],
         [  593],
         [  306],
         [29893],
         [  304],
         [ 9009],
         [  372],
         [ 1004],
         [14380],
         [  517],
         [17519],
         [29874],
         [ 1188],
         [  306],
         [  306],
         [  392],
         [  392],
         [ 3620],
         [ 3620],
         [  271],
         [ 1552],
         [28301],
         [  590],
         [  306],
         [29893],
         [  517],
         [25772],
         [ 1250],
         [ 6730],
         [ 3824],
         [29899],
         [  375],
         [29881],
         [19552],
         [ 9009],
         [29874],
         [  392],
         [  517],
         [ 6730],
         [ 2779],
         [29879],
         [  262],
         [12095],
         [29896],
         [29896],
         [29874],
         [29881],
         [29902],
         [29892],
         [29892],
         [29874],
         [  313],
         [29892],
         [29892],
         [  306],
         [  276],
         [19409],
         [ 2929],
         [  976],
         [24380],
         [29906],
         [  465],
         [ 8718],
         [ 3620],
         [ 1131],
         [ 4836],
         [ 4836],
         [ 2139],
         [29874],
         [ 2283],
         [  392],
         [29882],
         [26180],
         [ 6610],
         [31147],
         [  366],
         [20130],
         [29915],
         [29871],
         [30488],
         [30488],
         [31147],
         [30488],
         [  304],
         [  563],
         [  517],
         [  272],
         [30879],
         [29881],
         [17519],
         [  593],
         [ 5910],
         [29987],
         [  517],
         [  517],
         [ 1492],
         [  508],
         [ 1266],
         [29874],
         [29893],
         [29893],
         [29874],
         [  313],
         [29895],
         [  392],
         [29892],
         [  392],
         [  313],
         [  392],
         [29879],
         [29881],
         [11294],
         [29924],
         [29881],
         [29881],
         [29874],
         [31147],
         [31147],
         [29950],
         [29950],
         [29899],
         [29896],
         [29874],
         [29896],
         [29874],
         [29896],
         [29874],
         [29874],
         [  276],
         [  300],
         [25990],
         [  304],
         [17519],
         [  271],
         [17519],
         [24366],
         [29874],
         [30879],
         [29895],
         [29950],
         [29899],
         [29899],
         [29899],
         [  392],
         [  586],
         [29879],
         [  392],
         [11294],
         [ 1356],
         [29874],
         [29892],
         [29892],
         [  366],
         [ 5910],
         [ 5910],
         [  517],
         [  392],
         [21591],
         [25889],
         [  271],
         [29893],
         [  304],
         [25772],
         [  517],
         [  465],
         [ 3150],
         [  817],
         [ 1129],
         [  991],
         [  991],
         [ 1131],
         [  517],
         [29915],
         [  991],
         [29892]]], device='cuda:0')
torch.Size([2, 408, 10]) tensor([[[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29892, 29899, 29871,  ..., 29914,    13,   349],
         [29892, 29899, 29871,  ..., 29914,    13,   349],
         [29892, 29899, 29871,  ...,    13, 29914,   349]],

        [[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29915,   991, 30010,  ...,   313, 29889, 29903],
         [  991,  2045, 29892,  ..., 29903, 30166,   313],
         [29892, 29899, 29915,  ...,   376, 29924, 29909]]], device='cuda:0')
Batch 8, 13.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 23001,    13,  ...,   766,  4561, 29892],
        [    1,   349,  1179,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.6797,  -3.0059,   1.9834,  ...,  -3.5254,  -3.9258,  -3.0430],
         [ -8.9219,   0.3540,   7.8164,  ...,  -2.7207,  -4.7109,  -1.3594],
         ...,
         [ -5.2617,  -3.4219,   0.5752,  ...,  -3.7324,  -5.0586,  -3.0332],
         [-10.7969, -11.1484,   0.6006,  ...,  -7.1562,  -5.1367,  -7.2539],
         [ -5.7539,  -4.3164,   1.2822,  ...,  -4.0898,  -4.0547,  -3.3320]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -9.8516, -10.9219,   4.2695,  ...,  -6.6953,  -4.3398,  -6.0664],
         [ -9.3125,  -7.6875,   2.9199,  ...,  -5.2461,  -4.7031,  -5.7617],
         ...,
         [ -4.8594,  -2.5020,   1.7041,  ...,  -3.6016,  -4.0938,  -3.1250],
         [ -4.8359,  -2.4805,   1.6953,  ...,  -3.5918,  -4.0859,  -3.1133],
         [ -4.8398,  -2.4883,   1.6982,  ...,  -3.5938,  -4.0859,  -3.1172]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [29950],
         [29874],
         [29899]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29892],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29874, 29915,   349],
         [   13,   313,   297,  ...,   304,   376,    12],
         ...,
         [29950, 29874,   262,  ..., 29881, 29896, 29967],
         [29874, 29892, 29882,  ..., 29899, 29876, 29924],
         [29899, 29892, 29874,  ..., 29875, 29896, 29909]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ...,   376, 29889,   317],
         [29874, 29871,   262,  ..., 29915,   376,   313],
         ...,
         [29892,   313, 29889,  ...,   349, 29915,   315],
         [29892,   313, 29889,  ...,   349,   315, 29915],
         [29892,   313, 29889,  ...,   349, 29915,   315]]], device='cuda:0')
Batch 9, 19.9% of total tokens
encoded shape: torch.Size([2, 820])
torch.Size([2, 820]) tensor([[    1,   450,  9949,  ...,     2,     2,     2],
        [    1,  8010,  6991,  ...,  5049, 23507, 29889]], device='cuda:0')
torch.Size([2, 820, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -9.5625, -13.0312,   0.4075,  ...,  -6.6055,  -1.0127,  -7.5977],
         [-11.6250, -16.4219,  -0.1234,  ...,  -5.5625,  -1.6543,  -7.4414],
         ...,
         [ -6.1992,  -2.9688,  -5.7695,  ...,  -2.5508,  -1.5068,  -2.8496],
         [ -6.2188,  -2.9102,  -5.7344,  ...,  -2.5098,  -1.4971,  -2.8184],
         [ -6.1758,  -2.7793,  -5.6289,  ...,  -2.4062,  -1.4473,  -2.7188]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -9.7734, -10.2891,   2.2871,  ...,  -5.9727,  -4.4180,  -5.9219],
         [ -7.5938,  -7.2617,   3.5039,  ...,  -4.3164,  -4.7930,  -4.3984],
         ...,
         [ -4.7969,  -5.8711,  -3.9863,  ...,  -2.4785,   0.9868,  -2.1504],
         [ -6.2461,  -3.2188,  -0.1032,  ...,  -3.4668,  -2.8574,  -3.5879],
         [ -6.3945,  -4.6523,   1.4395,  ...,  -4.1289,  -2.7207,  -3.0801]]],
       device='cuda:0')
torch.Size([2, 820, 1]) tensor([[[29918],
         [29871],
         [29899],
         ...,
         [23333],
         [23333],
         [23333]],

        [[29918],
         [29874],
         [29874],
         ...,
         [ 3803],
         [29874],
         [29892]]], device='cuda:0')
torch.Size([2, 820, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29899, 29874,   376,  ..., 29924, 29872, 29915],
         ...,
         [23333, 10266, 30119,  ..., 30057, 29985, 12254],
         [23333, 10266, 30119,  ..., 14131, 29985,   353],
         [23333, 10266, 30119,  ..., 14131, 29985,   353]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29874, 29871, 29899,  ..., 29896, 29892, 29915],
         [29874, 29871,   262,  ..., 29875, 29896,   856],
         ...,
         [ 3803,  2011,  5140,  ..., 10188, 28337, 23507],
         [29874,   262, 29909,  ..., 29876,  1454, 29889],
         [29892, 29899, 29915,  ...,   262, 29876, 29909]]], device='cuda:0')
Batch 10, 20.9% of total tokens
encoded shape: torch.Size([2, 764])
torch.Size([2, 764]) tensor([[    1,   319, 20305,  ...,     2,     2,     2],
        [    1,   450, 20913,  ...,  3815,  7663, 29889]], device='cuda:0')
torch.Size([2, 764, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [-10.1719, -14.0391,  -0.2433,  ...,  -6.8242,  -2.0039,  -8.5156],
         [ -9.5234, -13.7734,  -1.9258,  ...,  -7.2188,  -1.1875,  -7.6875],
         ...,
         [ -6.3555,  -2.1465,  -1.0244,  ...,  -3.5684,  -3.8633,  -3.4883],
         [ -6.4023,  -2.1543,  -1.0869,  ...,  -3.5742,  -3.8477,  -3.4980],
         [ -6.3867,  -2.1465,  -1.0879,  ...,  -3.5703,  -3.8477,  -3.4883]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -9.5625, -13.0312,   0.4075,  ...,  -6.6055,  -1.0127,  -7.5977],
         [-11.7188, -16.7969,  -1.2168,  ...,  -6.8867,  -2.6953,  -8.3438],
         ...,
         [ -7.2305,  -6.0156,  -0.6343,  ...,  -3.3184,  -2.8535,  -4.5508],
         [ -5.7188,  -7.1133,  -4.5391,  ...,  -2.3887,   1.3887,  -6.2578],
         [ -5.7578,  -3.9004,   1.2568,  ...,  -4.0156,  -3.4121,  -3.8262]]],
       device='cuda:0')
torch.Size([2, 764, 1]) tensor([[[29918],
         [29871],
         [29899],
         ...,
         [  313],
         [  313],
         [  313]],

        [[29918],
         [29871],
         [  292],
         ...,
         [29909],
         [ 3696],
         [29915]]], device='cuda:0')
torch.Size([2, 764, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ...,   349, 29875,   315],
         [29899, 29874, 29903,  ...,   262, 29882, 29871],
         ...,
         [  313, 29892, 29915,  ...,   341,   317,   306],
         [  313, 29892, 29915,  ...,   341,   317,   306],
         [  313, 29915, 29892,  ...,   341,   317,   306]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [  292, 29871, 29874,  ..., 29899, 29924, 29915],
         ...,
         [29909, 29928, 29950,  ..., 29933, 29924, 29876],
         [ 3696, 14131, 29874,  ..., 29895,   262,   517],
         [29915, 29892,   262,  ..., 29899,   376, 29909]]], device='cuda:0')
Batch 11, 21.8% of total tokens
encoded shape: torch.Size([2, 413])
torch.Size([2, 413]) tensor([[    1,  6376,   800,  4034,   310, 23864,   309,  2159,   373,   385,
          4799,  1582,  2908,   482,   767, 12932,   369,   297,  4344,  2645,
          7048,   362, 29889,    13, 29909,  3517,  3461,  7829,   393,  4799,
          1582, 19632,   895,  1728,  1583, 29899,  2616,   276,   428,  1122,
          6403,   297,  8939,  7163,  2200, 12042,   284, 22069,  7048,   630,
           411,   521,  5095,   284, 27246, 10492,   313,  3210, 29897,   322,
         21767, 29878,   681, 19100,   680,   313, 29940, 29906, 29949, 29897,
           322,  1122,   367, 21551,   408,   376, 24535, 29908,  7048,   362,
         29889,   450,  6437,   310,   445, 12666,   635, 23454,  6559,   471,
           304,  8161, 29871, 29896, 29897,   278, 15477,  1546,   278,  2159,
           310,   278, 23864,  2719,   322, 29871, 29906, 29897,   278,  7426,
           310,  1518,  2859, 22004, 20562, 29916,   680,   313,  3217, 29906,
         29897,   322,   288, 28596,   269,  1337,   362,   313, 17618, 29949,
         29906, 29897,  3620,   304,  1027,  7964,  4799,  1582, 14979,  4080,
           773,   278, 18588,  2343, 29899,  1376, 29873,   767, 12932,   369,
           363, 29871, 29941, 29900,  5226,   470,  3109, 29889,   498, 13163,
          9045, 29891,  4344,   313,  3289, 29909,   306,   511, 26552, 29871,
         29906, 29906, 29899, 29946, 29900,  7378, 29892,   892, 19030,   363,
         23864,   309,  2159,   322,  7048,   630,   411,  5868,   313, 29945,
         29900,   286, 29887, 29914,  9415, 29897,   322, 17546, 20230,   457,
           313, 29906,   286, 29887, 29914,  9415, 29897,   322,  1462,   944,
           287,   411,   405, 29906, 29949, 29889,   349, 19994,   288,  2657,
         27184,   322,  2117, 29876,  5275,   892,  1304,   304, 11819,   278,
          2278, 29889,  7133,   278,  1791,   272,  1230,  8576,   746,   278,
         16500,  7470,   408,  5436, 29892,   278,  2343,   471, 29081,  6375,
           411,   278,   521,   262,  6023,   292,   278,   521,   342,   363,
           263,  3785,   310, 29871, 29941, 29900,  5226, 29889,   678,  6916,
           297,  5701, 29949, 29906,   322,  4810, 29906, 10742,   689,   892,
          8900,  2645,   445,  3785, 29889,   450,  2582, 18694,   393,  9881,
          4344,  1058,   750,   427, 27489,   287, 23864,  2719,   750, 24370,
          4799,  1994,   313,   294, 10087,   491,  2117, 29876,  5275, 29897,
          1833,   292, 14235, 29871, 29896, 29945,  5226, 29889,   450,  9886,
          4344,  1258,   451,   505,   427, 27489,   287, 23864,  2719,   322,
          7572,   304, 14523,  4799,  7128,  2486, 29889,   438, 29906, 11174,
          1258,   451,  1735,  2645,   445,  3785, 29889,   450,  2582,  4368,
           393,   278,  4188, 22342,   310,  4799,  1582,  2908,   482, 16415,
           411,   427, 27489,   287, 23864,  2719, 29889,   512,  4344,  1728,
          4799,  1582,  2908,   482, 29892,  9712,  8634, 10008,   443,  6574,
         19226, 29892,   322, 14734,   304,  1303,  5143,   278,  2343,  1122,
           451,  6403, 29889,   450, 15477,  1546,  4799,  1582,  2908,   482,
           322, 16500,  5544, 20193,   338, 15648,   297,  8220,   304,  7048,
           362, 11174, 29889],
        [    1,   660, 29901,    13,    13, 29925,   296, 29745,   805,  6150,
         29901,  7851, 29914,  5504,   947,   360, 29366, 23958, 29127, 29973,
            13,    13, 29902,   626,  2599,  4635, 29914,  5504,  4331,   313,
           726,   934,   304,  6535, 29897,   373,   805,  6150,   322,   306,
           505,   263,  1139, 29889,    13, 20182,   852,   393,   297,   590,
          1426,   934,   306,   505, 29871, 29896, 29900,  4341,   322,   297,
           590,  6535,   306,   505, 29871, 29896, 29947, 29892,  1363, 29871,
         29947,  4341,   674,   367,  8676,   515,  1790,  1426,   934,  2678,
         29889,   259,    13,  2951,  4635, 29914,  5504,  4331, 29892,   306,
         12784,   263,  1820,   304,  1106,   701,   278,   995,   313,  4716,
           338,  3132, 29918,   333, 29892,   363,  1342, 29897,   322,   373,
           376,  6422,  4235,   613,   306,  1258,   611, 27775,   363,  1906,
         29871, 29896, 29900,  4341, 29889,  1932,   306,  7120,  3758,  2346,
         29892,   306,  4446,  1906, 29871, 29947,  4341,   674,   367, 13700,
         29889,    13,  6246,   306,   864,   304,  3013,   963, 29889,  3139,
          1650,   363,   372, 29973,    13,    13, 29909, 29901,    13,    13,
          1576, 24505, 29914,  6422,  4331,   674,  6058,  5768,  4341,   746,
          1065, 12891, 29889,    13,  1576,  3758,  2826, 16096, 29879,   278,
          1591,   322, 14661,  3620,  2729,   373,   278,  4235,   366,  6790,
           297,   278,  4331, 29889,   739, 29915, 29879,   871,   263, 29703,
           363,  4996,   382, 14632,  5849, 29892,   363,  1342,   746,  9348,
          4206,   515,  1426,  2066,   304,   380,  6751,  1591,   773,   263,
          6137, 10604,  4331, 29889,   739,   871,  4441,   567,  4341,   565,
           366,  6222,   278,  2471,   372, 16785, 29889,  3872, 29915, 29873,
           437,   393,   322,   596,  4341,   674,   367,  7970,  9109, 29991,
            13,    13,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2]], device='cuda:0')
torch.Size([2, 413, 32000]) tensor([[[ -8.9844,   0.8472,   0.6909,  ...,  -3.0449,  -5.3633,  -2.3750],
         [ -9.9219,  -9.8984,   4.2188,  ...,  -5.8203,  -5.9375,  -6.2773],
         [ -7.9961, -11.0312,  -2.7129,  ...,  -3.7246,   1.2490,  -4.2891],
         ...,
         [ -4.8086,  -7.8750,  -5.0508,  ...,  -2.6641,   3.0137,  -1.4336],
         [ -5.0273,  -5.7734,  -5.0156,  ...,  -2.7676,   2.1230,  -2.6406],
         [ -6.6836,  -5.7695,   0.9229,  ...,  -4.3945,  -3.5000,  -3.6230]],

        [[ -8.9844,   0.8472,   0.6909,  ...,  -3.0449,  -5.3633,  -2.3750],
         [ -7.1484,  -6.3867,   3.4844,  ...,  -4.6445,  -5.0781,  -3.9902],
         [ -9.1172,  -7.9492,   0.1118,  ...,  -4.9102,  -3.4023,  -4.8828],
         ...,
         [ -4.5352,  -2.5859,   2.0977,  ...,  -3.5332,  -4.0469,  -2.9688],
         [ -4.5430,  -2.5996,   2.1016,  ...,  -3.5410,  -4.0547,  -2.9746],
         [ -4.5508,  -2.5996,   2.1133,  ...,  -3.5430,  -4.0508,  -2.9766]]],
       device='cuda:0')
torch.Size([2, 413, 1]) tensor([[[29918],
         [29871],
         [  354],
         [29899],
         [  262],
         [29874],
         [29899],
         [  392],
         [  856],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29874],
         [  369],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [29874],
         [  313],
         [29892],
         [29874],
         [29874],
         [ 2308],
         [29874],
         [  262],
         [ 1582],
         [29874],
         [  262],
         [25772],
         [29874],
         [29899],
         [29899],
         [29871],
         [29909],
         [29874],
         [10052],
         [ 7192],
         [29874],
         [29871],
         [ 2200],
         [29874],
         [  262],
         [29903],
         [ 5062],
         [29874],
         [ 2541],
         [29874],
         [29871],
         [29871],
         [29933],
         [29874],
         [29874],
         [29871],
         [29874],
         [  392],
         [  856],
         [29933],
         [29933],
         [29949],
         [  680],
         [30064],
         [29871],
         [29906],
         [29949],
         [30064],
         [  392],
         [  856],
         [26180],
         [ 1131],
         [  262],
         [29874],
         [  376],
         [29933],
         [  392],
         [29874],
         [29874],
         [29892],
         [29874],
         [  262],
         [29874],
         [  262],
         [29874],
         [29899],
         [29874],
         [  262],
         [  517],
         [  262],
         [ 3692],
         [29896],
         [29874],
         [29874],
         [29924],
         [ 1546],
         [  262],
         [  392],
         [  392],
         [  392],
         [  262],
         [  295],
         [  392],
         [29874],
         [29871],
         [29874],
         [ 1552],
         [ 2308],
         [29874],
         [  392],
         [  381],
         [29875],
         [29928],
         [29874],
         [29871],
         [29950],
         [  376],
         [29906],
         [29874],
         [  262],
         [29940],
         [29950],
         [29874],
         [  856],
         [29924],
         [24433],
         [  349],
         [29874],
         [29906],
         [29874],
         [24433],
         [29909],
         [29933],
         [29874],
         [29874],
         [ 1582],
         [19632],
         [  300],
         [13604],
         [29874],
         [29874],
         [29874],
         [29899],
         [29899],
         [29874],
         [29924],
         [29874],
         [  369],
         [29874],
         [29874],
         [29871],
         [29899],
         [29899],
         [  262],
         [29871],
         [  262],
         [29892],
         [  856],
         [29899],
         [29899],
         [  392],
         [  392],
         [29892],
         [29874],
         [29874],
         [29874],
         [29896],
         [  392],
         [29871],
         [29874],
         [  392],
         [29871],
         [29874],
         [ 2730],
         [29874],
         [ 5062],
         [  392],
         [29874],
         [29899],
         [  295],
         [ 1188],
         [  392],
         [  392],
         [29933],
         [ 2541],
         [29874],
         [  392],
         [29871],
         [29874],
         [29874],
         [29871],
         [29914],
         [  286],
         [29950],
         [  392],
         [29940],
         [29871],
         [29871],
         [29950],
         [29871],
         [  286],
         [29887],
         [29914],
         [  230],
         [29950],
         [  392],
         [29940],
         [29924],
         [  284],
         [ 2541],
         [29874],
         [29871],
         [29874],
         [30064],
         [29874],
         [29871],
         [29874],
         [29874],
         [27184],
         [  392],
         [29874],
         [29874],
         [29933],
         [11651],
         [29950],
         [  517],
         [ 2407],
         [17618],
         [  392],
         [29915],
         [29874],
         [29874],
         [29874],
         [  392],
         [29899],
         [  392],
         [29874],
         [  262],
         [  262],
         [29915],
         [  517],
         [  376],
         [  705],
         [29874],
         [29874],
         [29899],
         [29911],
         [  517],
         [  392],
         [29874],
         [  262],
         [  262],
         [ 5060],
         [  292],
         [ 1552],
         [  262],
         [  262],
         [22752],
         [29871],
         [  392],
         [24049],
         [29874],
         [29941],
         [29900],
         [30221],
         [  517],
         [29874],
         [  262],
         [  297],
         [17618],
         [29871],
         [29906],
         [  392],
         [ 4810],
         [29906],
         [ 2308],
         [  689],
         [  689],
         [11651],
         [  262],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  276],
         [29874],
         [29874],
         [29899],
         [ 2308],
         [ 1311],
         [29911],
         [29874],
         [29881],
         [29911],
         [  793],
         [29958],
         [29874],
         [29903],
         [ 1994],
         [  354],
         [ 5701],
         [  680],
         [  491],
         [29874],
         [29874],
         [29933],
         [ 8813],
         [  392],
         [  292],
         [23747],
         [  262],
         [29941],
         [29945],
         [30221],
         [ 2308],
         [29874],
         [29874],
         [29906],
         [29874],
         [  451],
         [ 7271],
         [29874],
         [29950],
         [  287],
         [29911],
         [  793],
         [  392],
         [  705],
         [  517],
         [ 2078],
         [29903],
         [ 1582],
         [29874],
         [ 2611],
         [29874],
         [29906],
         [29874],
         [12483],
         [ 1333],
         [ 2308],
         [ 7540],
         [29874],
         [29874],
         [ 1454],
         [29874],
         [29874],
         [ 5924],
         [29874],
         [29874],
         [  262],
         [  295],
         [  310],
         [29874],
         [ 1582],
         [19632],
         [  482],
         [ 3696],
         [  411],
         [  262],
         [29950],
         [  287],
         [29911],
         [  793],
         [  262],
         [29874],
         [ 1037],
         [ 2541],
         [29911],
         [ 1582],
         [19632],
         [  482],
         [29874],
         [  262],
         [29903],
         [ 6543],
         [ 1491],
         [  262],
         [29876],
         [ 5062],
         [  392],
         [  262],
         [  517],
         [  392],
         [29899],
         [  794],
         [  392],
         [29899],
         [29874],
         [ 1311],
         [ 1491],
         [29874],
         [29899],
         [ 1546],
         [29911],
         [ 1582],
         [19632],
         [  482],
         [  392],
         [29911],
         [29899],
         [29874],
         [ 2778],
         [29909],
         [  262],
         [  578],
         [  517],
         [29928],
         [29933],
         [11979],
         [13075],
         [29874]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [  451],
         [29885],
         [29874],
         [  370],
         [  271],
         [29909],
         [29871],
         [29892],
         [29915],
         [ 1457],
         [29874],
         [29914],
         [ 5504],
         [29882],
         [29881],
         [29892],
         [29899],
         [29874],
         [30488],
         [29896],
         [  392],
         [29874],
         [29874],
         [29899],
         [  306],
         [30090],
         [29928],
         [29928],
         [  519],
         [  306],
         [29903],
         [  368],
         [  306],
         [  306],
         [  726],
         [ 1129],
         [ 1445],
         [  306],
         [20771],
         [29874],
         [29906],
         [29900],
         [29900],
         [  392],
         [29902],
         [  590],
         [ 1129],
         [  306],
         [ 2364],
         [29881],
         [29896],
         [29896],
         [29895],
         [ 7070],
         [29902],
         [29871],
         [  976],
         [ 2364],
         [ 1333],
         [26419],
         [  509],
         [29928],
         [  271],
         [ 1445],
         [15135],
         [ 3364],
         [30212],
         [29871],
         [  590],
         [  517],
         [29914],
         [ 5504],
         [  306],
         [  306],
         [  437],
         [16431],
         [29928],
         [  271],
         [  287],
         [ 1356],
         [  363],
         [  590],
         [11651],
         [16431],
         [30057],
         [  726],
         [29928],
         [  333],
         [  333],
         [29896],
         [  392],
         [  331],
         [29881],
         [  392],
         [ 1129],
         [29928],
         [29892],
         [  519],
         [ 1761],
         [  306],
         [24366],
         [ 1333],
         [29874],
         [  271],
         [  509],
         [29928],
         [29871],
         [29900],
         [  976],
         [14131],
         [ 6246],
         [ 1310],
         [  661],
         [29928],
         [29875],
         [  976],
         [  306],
         [27996],
         [29928],
         [29928],
         [29896],
         [29928],
         [ 5729],
         [ 1333],
         [ 5729],
         [ 1356],
         [  306],
         [  590],
         [  306],
         [26180],
         [  304],
         [28385],
         [29928],
         [25377],
         [  306],
         [ 2587],
         [ 1454],
         [ 1366],
         [ 1173],
         [30166],
         [29892],
         [29899],
         [29874],
         [29892],
         [29892],
         [29903],
         [29928],
         [29914],
         [ 6422],
         [  281],
         [29903],
         [29928],
         [29928],
         [ 2328],
         [ 5062],
         [29928],
         [  292],
         [29874],
         [29915],
         [29899],
         [29928],
         [29875],
         [29903],
         [  272],
         [ 1552],
         [29928],
         [29915],
         [29928],
         [29928],
         [ 3959],
         [ 2501],
         [ 1552],
         [29924],
         [  978],
         [  276],
         [ 5062],
         [29924],
         [29924],
         [  976],
         [30212],
         [30057],
         [29871],
         [30488],
         [30879],
         [30879],
         [  667],
         [30488],
         [29899],
         [30488],
         [  292],
         [29885],
         [ 1333],
         [29874],
         [29903],
         [29928],
         [  517],
         [  517],
         [29874],
         [  488],
         [  517],
         [29874],
         [ 2426],
         [ 1129],
         [ 1129],
         [29874],
         [29915],
         [  585],
         [29874],
         [29875],
         [29915],
         [29915],
         [29903],
         [  567],
         [15637],
         [27996],
         [29888],
         [24667],
         [ 1552],
         [29909],
         [  376],
         [14938],
         [29882],
         [29915],
         [29915],
         [29874],
         [29903],
         [ 1366],
         [ 5062],
         [29928],
         [29928],
         [  674],
         [30488],
         [ 2691],
         [ 2691],
         [31765],
         [29903],
         [29899],
         [29892],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [29933],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889]]], device='cuda:0')
torch.Size([2, 413, 10]) tensor([[[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871,   262, 29899,  ...,   349,   376, 29873],
         [  354, 29874,  2308,  ...,  1546, 29881, 29885],
         ...,
         [11979,  1410,   392,  ...,   271, 26179, 12254],
         [13075,   271,   680,  ...,   392, 15425,   816],
         [29874, 29899, 29915,  ..., 29871, 29889,   262]],

        [[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29889, 29892, 29871,  ..., 30879, 31147, 29915],
         [29889, 29892, 29871,  ..., 30879, 31147, 29915],
         [29889, 29892,   313,  ..., 30879, 29915,   349]]], device='cuda:0')
Batch 12, 22.5% of total tokens
encoded shape: torch.Size([2, 2269])
torch.Size([2, 2269]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,  3387,   975,  ...,   468,   434, 29889]], device='cuda:0')
torch.Size([2, 2269, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.1562,  -6.3906,   3.4883,  ...,  -4.6445,  -5.0781,  -3.9922],
         [ -9.1172,  -7.9531,   0.1221,  ...,  -4.9141,  -3.4141,  -4.8906],
         ...,
         [ -4.8477,   1.6904,  -3.6836,  ...,  -2.2402,  -3.3203,  -2.1309],
         [ -4.8594,   1.7256,  -3.6895,  ...,  -2.2285,  -3.3125,  -2.1172],
         [ -4.8438,   1.7109,  -3.6914,  ...,  -2.2246,  -3.3047,  -2.1172]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -8.5781,  -7.1602,   2.0684,  ...,  -4.5352,  -3.8262,  -5.2852],
         [ -7.4414,  -9.6094,  -2.9844,  ...,  -2.7969,   0.9761,  -3.8203],
         ...,
         [ -9.9766, -12.7969,  -3.5703,  ...,  -7.6602,  -2.8984,  -6.6055],
         [ -5.8711,  -2.6895,  -1.8076,  ...,  -3.8945,  -2.5195,  -4.3750],
         [ -5.9883,  -2.3770,  -0.0764,  ...,  -4.7109,  -1.8330,  -4.8867]]],
       device='cuda:0')
torch.Size([2, 2269, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29915],
         [29915],
         [29915]],

        [[29918],
         [29871],
         [  354],
         ...,
         [  434],
         [  262],
         [29915]]], device='cuda:0')
torch.Size([2, 2269, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29915, 30488, 30010,  ...,   392, 30879,   229],
         [29915, 30488, 30010,  ...,   392,   229, 30879],
         [29915, 30488, 30010,  ...,   392, 30879,   229]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874,   262,  ...,   376, 29892, 29899],
         [  354, 11147,  1332,  ..., 29874,  3364,   262],
         ...,
         [  434, 29909, 29903,  ..., 29902,   376, 29925],
         [  262,   856, 29885,  ...,   376, 29874,   294],
         [29915,   376,   313,  ...,   262, 29882,   294]]], device='cuda:0')
Batch 13, 24.9% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 13542,  4956,  ...,     2,     2,     2],
        [    1, 11474,    13,  ...,  1624,   287, 29913]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.5000,  -5.0312,   2.6641,  ...,  -4.0781,  -4.0508,  -4.0000],
         [-11.6328, -15.7969,   1.1416,  ...,  -7.5586,  -5.4453,  -8.4688],
         ...,
         [ -8.3750,   2.1465,   1.0586,  ...,  -2.6543,  -5.2031,  -1.9902],
         [ -8.3828,   2.1426,   1.1328,  ...,  -2.6465,  -5.2109,  -1.9727],
         [ -8.4141,   2.1191,   1.1855,  ...,  -2.6602,  -5.2305,  -1.9814]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.5508,  -3.0449,   1.9414,  ...,  -3.4023,  -4.0625,  -3.0234],
         [ -5.8359,   3.2266,   6.0742,  ...,  -0.1229,  -2.0488,   0.7637],
         ...,
         [ -6.1602,  -5.0586,   2.4102,  ...,  -4.3086,  -4.9609,  -4.2109],
         [ -6.6992,  -5.7070,   2.2910,  ...,  -4.5781,  -4.6328,  -4.3555],
         [ -7.6719, -12.9922,  -2.0371,  ...,  -7.7656,  -2.5586,  -7.2305]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [29918],
         [29918],
         [29918]],

        [[29918],
         [29889],
         [   13],
         ...,
         [29892],
         [29909],
         [29874]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29889,   262,   349],
         [29871, 29874, 29875,  ..., 29915,   349, 29933],
         ...,
         [29918, 29879, 29915,  ..., 29973, 29898,   229],
         [29918, 29879, 29915,  ..., 29973, 29898,   229],
         [29918, 29879, 29915,  ..., 29973, 29898,   229]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 30488,  ...,   313, 31147,   856],
         [   13,   313,    12,  ..., 29918, 29915, 30024],
         ...,
         [29892, 29871,   313,  ..., 29874, 29896,   315],
         [29909, 29899,   313,  ...,   856, 29903, 29896],
         [29874, 30010, 29892,  ..., 29915, 29903, 29871]]], device='cuda:0')
Batch 14, 29.3% of total tokens
encoded shape: torch.Size([2, 152])
torch.Size([2, 152]) tensor([[    1,  9811, 10180, 29879,   313, 20012,   261, 29892,  6345, 29871,
         29896, 29929, 29955, 29953, 29897,    13,    13, 29924,  1131, 10180,
         29879,   313,  4939, 29871, 29929,  3839, 29871, 29896, 29929, 29955,
         29953, 29897,   338,   385,  4223, 19026, 29892,  1058,  5318,   408,
           263,   822,  1581,   297,   278,  8914,  5165,   363,   678,  4156,
          4412, 29889,    13,    13,  1123, 10662,    13,    13, 10900, 29901,
         29896, 29929, 29955, 29953, 12060, 29879,    13, 10900, 29901, 29931,
          4357,  2305,    13, 10900, 29901, 29923,   369,   880,   383, 29889,
         29907, 29889, 10769,    13, 10900, 29901,  1451,  4156,  4412,   383,
         29889, 29907, 29889, 10769,    13, 10900, 29901,   855, 14997, 18419,
           315,  2152,   293,   383, 29889, 29907, 29889, 10769,    13, 10900,
         29901, 24636,  8914,  5165, 10769,    13, 10900, 29901, 29254,   362,
          5733,  6555,   822, 21043,    13, 10900, 29901, 15666,  1991,   515,
           402,   359,   637,    13, 10900, 29901, 24636,  5733,   414,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,   450,   317,  3904, 29979,   315, 11960,  8542,   310, 15740,
         26049,  5476,   510,   287,  5144,   310,   278, 22148,   669, 23992,
          5977,   310, 20807, 21518,  3074,   304, 24165,   373, 27822,   304,
          5221,   403,   297,   263,  1708,  2462,   297, 10894,   362,   310,
          6502, 24760,  4088,  8373, 29889,    13,    13,  2831, 29871, 29929,
         29900,  6233,   278,  4344,  2355,   304, 13389, 12727, 14188,   515,
           385,  1722,  2071,   403,   304, 20305, 29892, 24817,  2135,   322,
         18232,   449, 29889,   450, 14188, 29892,   607,  3614,  2058,   297,
           278,  1528,   359,  5619, 29892,   892,   297,  9589,   651,   411,
           278,   937, 17568,  6502, 24760,  4088, 29892, 13843, 29889,  8373,
           310,  6692, 29889,    13,    13, 29903,  3904, 29979,   315, 11960,
         29892,  3412,   411,   317,  3904, 29979,  4242,  6394,  4822,  1570,
          3088,  4306, 29892, 17791,  4959,   408,   263, 20695, 15130,   304,
          2367,  1250,   304,   278, 24165,   322,   278,  7881,   322,   304,
          6773,  4942, 29889,  4088, 30010, 29879,  2643,   322, 25000,   310,
          2669, 29889]], device='cuda:0')
torch.Size([2, 152, 32000]) tensor([[[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.7812,  -7.1484,   3.5078,  ...,  -4.6680,  -4.8242,  -4.6172],
         [ -8.5000,  -8.5859,   2.9785,  ...,  -4.8750,  -4.6953,  -5.0898],
         ...,
         [ -6.3125,  -4.9375,   4.2227,  ...,  -4.2383,  -4.8555,  -3.6211],
         [ -6.4961,  -4.9258,   4.7188,  ...,  -4.3555,  -4.8438,  -3.6172],
         [ -6.2422,  -4.5352,   4.3164,  ...,  -4.2539,  -4.7070,  -3.4727]],

        [[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -9.5625, -13.0312,   0.4077,  ...,  -6.6133,  -1.0195,  -7.6016],
         [-10.2188, -15.0312,  -0.1979,  ...,  -7.4258,  -3.3926,  -8.3906],
         ...,
         [ -5.5469,  -2.6758,  -0.6309,  ...,  -3.7031,  -2.3535,  -3.6914],
         [ -7.1602,  -4.3828,  -1.7168,  ...,  -3.5273,  -2.6113,  -3.7734],
         [ -5.5586,  -3.3906,   1.2773,  ...,  -4.1523,  -1.4980,  -4.3086]]],
       device='cuda:0')
torch.Size([2, 152, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [   13],
         [29874],
         [29871],
         [29924],
         [29871],
         [29874],
         [29874],
         [  262],
         [29896],
         [  386],
         [29874],
         [29871],
         [29874],
         [29871],
         [30488],
         [  262],
         [29874],
         [29874],
         [29874],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29874],
         [29874],
         [29924],
         [  262],
         [29933],
         [29874],
         [29874],
         [29933],
         [30488],
         [30488],
         [29909],
         [29874],
         [29882],
         [29892],
         [  856],
         [29899],
         [29874],
         [29871],
         [29874],
         [29899],
         [29892],
         [29871],
         [29871],
         [29871],
         [29874],
         [31147],
         [29882],
         [29874],
         [29899],
         [29899],
         [29871],
         [29874],
         [29882],
         [29874],
         [29899],
         [29899],
         [29874],
         [29871],
         [29874],
         [29875],
         [29874],
         [29889],
         [29874],
         [29874],
         [29899],
         [29874],
         [29874],
         [29874],
         [29943],
         [29943],
         [29875],
         [29874],
         [29889],
         [29874],
         [29874],
         [29899],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [29874],
         [29874],
         [29943],
         [  315],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [29875],
         [29874],
         [29874],
         [29874],
         [29882],
         [29899],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29924],
         [29882],
         [29899],
         [29874],
         [29874],
         [29871],
         [29874],
         [  262],
         [29871],
         [29871],
         [29874],
         [29899],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871]],

        [[29918],
         [29871],
         [29899],
         [29871],
         [29899],
         [29871],
         [29875],
         [29909],
         [29874],
         [29933],
         [  392],
         [  510],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [29874],
         [29874],
         [30488],
         [  262],
         [31147],
         [29909],
         [30488],
         [  317],
         [  297],
         [30488],
         [30488],
         [29899],
         [30488],
         [29909],
         [  856],
         [29874],
         [29874],
         [29909],
         [29968],
         [29874],
         [29882],
         [  313],
         [  317],
         [29899],
         [  657],
         [29896],
         [29900],
         [  392],
         [29924],
         [29882],
         [ 5731],
         [  304],
         [29903],
         [29903],
         [  317],
         [29911],
         [29903],
         [29903],
         [29899],
         [29909],
         [29924],
         [29903],
         [29903],
         [29892],
         [ 1884],
         [  392],
         [29903],
         [29899],
         [  262],
         [  317],
         [29874],
         [29893],
         [29892],
         [29903],
         [  392],
         [  262],
         [29874],
         [29899],
         [29871],
         [  262],
         [29874],
         [29899],
         [29882],
         [29903],
         [29933],
         [  411],
         [29903],
         [29903],
         [29899],
         [29903],
         [29931],
         [29928],
         [  292],
         [29928],
         [29909],
         [  262],
         [22752],
         [  392],
         [  392],
         [  317],
         [  317],
         [  317],
         [  315],
         [29871],
         [  315],
         [29871],
         [29915],
         [29874],
         [29874],
         [  317],
         [29899],
         [29874],
         [29899],
         [ 6394],
         [  392],
         [29933],
         [29882],
         [29879],
         [  392],
         [ 2889],
         [29874],
         [  680],
         [  680],
         [  392],
         [  392],
         [29804],
         [13072],
         [ 1250],
         [  304],
         [12459],
         [29909],
         [ 7881],
         [29909],
         [29909],
         [29874],
         [29903],
         [10657],
         [ 4942],
         [29889],
         [29968],
         [30010],
         [29874],
         [30488],
         [ 2504],
         [30879],
         [ 2504],
         [29928],
         [29909],
         [  317]]], device='cuda:0')
torch.Size([2, 152, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ...,   313,   349, 29889],
         [29871, 29874, 29892,  ..., 29875, 29896,   313],
         ...,
         [29871, 29892,    13,  ...,   856, 29915,   315],
         [29871, 29892, 29899,  ...,   856, 29915,   315],
         [29871, 29892, 29899,  ..., 29874, 29915,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29899, 29871, 29892,  ..., 29933, 29896,   315],
         ...,
         [29928,   262, 29911,  ..., 29909, 29925, 29883],
         [29909, 29874, 29928,  ..., 29933,   262, 29950],
         [  317, 29876, 29874,  ..., 29889, 30010, 29911]]], device='cuda:0')
Batch 15, 29.6% of total tokens
encoded shape: torch.Size([2, 1433])
torch.Size([2, 1433]) tensor([[    1,   319,  1571,  ...,   297,  3786, 29889],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1433, 32000]) tensor([[[ -9.0156,   0.8423,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [-10.1641, -14.0391,  -0.2505,  ...,  -6.8203,  -2.0000,  -8.5156],
         [ -9.4297, -15.0703,  -0.6777,  ...,  -7.0547,  -2.7520,  -6.9570],
         ...,
         [ -8.5938,  -8.2266,  -2.5137,  ...,  -3.0684,   2.0488,  -3.8633],
         [ -8.3438, -11.3672,  -5.2266,  ...,  -4.5586,   0.1210,  -6.3906],
         [ -6.3594,  -4.6562,   1.1807,  ...,  -4.4492,  -3.4668,  -3.4414]],

        [[ -9.0156,   0.8423,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -7.1406,  -6.3711,   3.4844,  ...,  -4.6367,  -5.0703,  -3.9824],
         [ -9.1250,  -7.9688,   0.1140,  ...,  -4.9180,  -3.4082,  -4.8984],
         ...,
         [ -5.3008,   0.6489,  -3.3652,  ...,  -2.5488,  -3.4121,  -2.4863],
         [ -5.2578,   0.6670,  -3.3555,  ...,  -2.5410,  -3.3984,  -2.4785],
         [ -5.2852,   0.6597,  -3.3613,  ...,  -2.5469,  -3.4062,  -2.4824]]],
       device='cuda:0')
torch.Size([2, 1433, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [ 4548],
         [  491],
         [29892]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29915],
         [29915],
         [29915]]], device='cuda:0')
torch.Size([2, 1433, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ...,   349, 29875,   315],
         [29874, 29899, 29924,  ...,   262, 29879,   376],
         ...,
         [ 4548,   392, 29943,  ...,   305,  3959, 29987],
         [  491, 29874,  1457,  ..., 29882,   328,  1173],
         [29892, 29915, 29874,  ..., 29882, 29908, 29909]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29915, 30010,   313,  ...,   392,   306, 29987],
         [29915, 30010,   313,  ...,   392,   306,   525],
         [29915, 30010,   313,  ...,   392,   306, 29987]]], device='cuda:0')
Batch 16, 31.2% of total tokens
encoded shape: torch.Size([2, 2062])
torch.Size([2, 2062]) tensor([[    1,   660, 29901,  ..., 29889,    13,    13],
        [    1,  5868, 29923,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2062, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.1562,  -6.3906,   3.4883,  ...,  -4.6445,  -5.0781,  -3.9922],
         [ -9.1172,  -7.9531,   0.1221,  ...,  -4.9141,  -3.4141,  -4.8906],
         ...,
         [ -4.6914,  -3.4277,   1.2461,  ...,  -3.9980,  -3.4453,  -3.3340],
         [ -4.7070,  -3.2559,   1.9248,  ...,  -3.8379,  -4.0547,  -3.1914],
         [ -4.6914,  -3.4570,   1.7031,  ...,  -3.7168,  -3.9180,  -2.8379]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [-11.0312, -13.3516,   1.6914,  ...,  -7.3516,  -4.4688,  -8.1484],
         [ -9.5938, -15.8047,  -3.1953,  ...,  -6.1523,  -2.6855,  -8.0391],
         ...,
         [ -6.1797,  -0.8735,  -3.1523,  ...,  -2.7695,  -3.1621,  -3.0508],
         [ -6.1094,  -0.8784,  -3.0742,  ...,  -2.7656,  -3.1641,  -3.0391],
         [ -6.1328,  -0.8833,  -3.0977,  ...,  -2.7734,  -3.1680,  -3.0508]]],
       device='cuda:0')
torch.Size([2, 2062, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29889],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29874],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 2062, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29889, 29915,   313,  ..., 29908, 29874, 29871],
         [29892,   313, 29899,  ...,    13, 29914, 29901],
         [29892, 29899,   313,  ...,   315, 29914,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29899,  ...,   313, 29915,   294],
         [29874, 29899, 29871,  ...,   349,   315,   313],
         ...,
         [30010, 29915, 30057,  ...,   349,   275, 29892],
         [30010, 29915,   392,  ...,   349, 29892,   275],
         [30010, 29915,   392,  ...,   349,   275, 29892]]], device='cuda:0')
Batch 17, 33.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[   1, 9204, 4925,  ...,  297,  278, 3829],
        [   1, 5556,  388,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [-10.4375, -13.1641,   1.4092,  ...,  -6.6328,  -3.3672,  -7.5469],
         [ -9.9922, -13.3359,  -2.8457,  ...,  -6.6758,  -1.0156,  -7.8945],
         ...,
         [ -5.9883,  -6.7891,  -3.4277,  ...,  -2.8789,   4.1172,  -3.1172],
         [ -6.7109,  -4.0078,  -2.2246,  ...,  -3.9707,   1.3623,  -3.0977],
         [ -3.8164,  -3.7637,  -3.4180,  ...,  -0.9390,   3.2148,  -2.7637]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.4766,  -6.7422,   3.1328,  ...,  -4.6016,  -4.7188,  -3.9785],
         [-12.0312, -16.3906,  -1.1670,  ...,  -7.6445,  -4.8164,  -8.8438],
         ...,
         [ -8.2109,   2.2637,   0.8159,  ...,  -2.5410,  -5.0469,  -2.0234],
         [ -8.1719,   2.2637,   0.6270,  ...,  -2.5449,  -5.0156,  -2.0527],
         [ -8.1328,   2.2812,   0.5200,  ...,  -2.5391,  -4.9922,  -2.0566]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [  278],
         [29874],
         [14131]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29918],
         [29918],
         [29918]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ...,   315,   349, 29875],
         [29874, 29871, 29875,  ...,   271, 29881, 29903],
         ...,
         [  278,  9706,  4926,  ..., 29874, 29985,  4786],
         [29874, 29875, 29909,  ...,   354, 29883,   262],
         [14131, 20164, 29992,  ..., 27996,  2328, 30119]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ..., 29889,   349, 29882],
         [29871, 29899, 29874,  ...,   262,   297, 29875],
         ...,
         [29918, 29915, 29879,  ..., 29973,   229, 29892],
         [29918, 29915, 29879,  ..., 29973,   229, 29892],
         [29918, 29915, 29879,  ..., 29973,   229, 29892]]], device='cuda:0')
Batch 18, 38.1% of total tokens
encoded shape: torch.Size([2, 461])
torch.Size([2, 461]) tensor([[    1,   910,   338,   385, 15129,  4700, 29892,  1732,   597,  1636,
         29889, 29929, 29896, 29896, 18082,   583, 29889,   510,   322,  5457,
          8037,   756,   777, 14154,  8031,  6523,   583,   540,   756,  1754,
           297, 23382,   278, 22901, 12841, 20612,   393,   892,  5492,   491,
           278, 10354, 29889,   940,   756,  1476,  1784, 22435,  8244,  2478,
           322,   714,  1266, 11525,  2785,   310,   278, 17739, 29879, 29892,
           607, 10320,   284,   825,   338, 14171,  6924,   304, 25187,   310,
         17202,   310,   716,  2305,  1269,  2462, 29892,   393, 29871, 29929,
         29896, 29896,   471,  6012, 14561,   491,  2258,  1953,   310,   278,
           501, 29889, 29903, 29889, 14879, 10354, 29889,    13,    13,  9760,
          2462,   306,   626,  2675,   304,   788, 29871, 29941,   304, 29871,
         29946,   716, 15373, 29899, 18082,   583,   515,  5457, 29879,  4700,
         29892,   577, 10201,   896,   526, 19571,   287,  1244, 29892,   301,
           342,   670, 15129,   664,   322,  5925,  3926,   367,  5714, 29892,
           408,  1532,   408,   427,  4366,  8333,  1784,   310,   366,   304,
           670,   714, 11235,   664,   322, 20706,   304, 29871, 29929, 29896,
         29896, 29889,    13,    13, 29902,   626,  3058,   366,   674,   367,
           925,   408, 18014,   491,   777,   310,   278, 29342,   284,   583,
           322,   714,  1266, 21308,   546,   292,   411,   278,  2441, 17739,
         29879, 29889,  1619,  1914, 15997,  1156,  9076,   292,  1438, 17739,
         29879,   338,   393,   896,   892,   752,  2957,   515,  1784,  2440,
           310, 22901, 12841,   341, 28599,  1964,   313, 29924,   465,  6960,
           950,  1017, 29897, 24472,  3476,   267, 29889,  1763,   592,   372,
           338,   278, 19075,  1950,  8252,   363,   777,   310,   278,  7736,
          1907,   366,   526,  1048,   304, 14111, 29889,    13,    13,  2887,
           263,  1605,  2806,   922,  1416,   261, 29892,   306,  4966,   366,
         13389,  5457,   806,  3246,  1963,  3747, 11898,   408,  1568,   408,
           306,   505, 29892,   408,   896,  1298,   304,   385,  6924,  2138,
          1631, 10068,  2629,   451,   925,   278, 22901, 12841, 29892,   541,
           278,  4152, 14879, 10354, 29889,  1670,   526,   777,  2629,   278,
         29871, 29929, 29896, 29896,  1346, 29924,   586,   882, 30024,  1058,
           505,  1497,   445,   338,  4319, 10757, 29892,   322,   304,  5040,
          3063,   470, 13587,   304,   738,   310,   278,  6924, 29828,   310,
         21588, 29875, 10068,  1476,  1244,   297,   278, 22901, 12841, 30010,
         29879,  1914, 17739, 29879,   322,  4863, 10757, 29889,  5806,  1438,
          2305,  1795,   367,   269,  3742,   406,   297,  1009,  3184,  3145,
         29892,   372,   338,   884,  1950,   393,   727,   338,   577,  1568,
         29871, 29929, 29896, 29896,  5296,   310,   385,  2768,  4982,   393,
           896,   526, 15661,   304,   377,  1992,  1623,   278, 10757, 11565,
           964,   385,  6775,   304,  2761,  9677,   310,  2472, 29889,   450,
           501, 29889, 29903, 29889, 10354,   756,  1250,   287,  3528,   964,
           278, 11155, 11211,   278,  6221,  5828,   310, 29871, 29929, 29896,
         29896, 29892,   322,   408,   366,   674, 21734,  1074, 29892,   278,
         22901, 12841,   338,   541,   263,  2323,  9565,   607,  3697,  4549,
          3415,   333,  2063,   322,  5296,   310,   263, 29871, 29929, 29896,
         29896, 21588, 29875, 10068,  2629,   278,   501, 29889, 29903, 10354,
         29889],
        [    1,   349,  1179,    13,    13, 29903,   870,   388, 29892,  5306,
         29871, 29906, 29900, 29892, 29871, 29906, 29900, 29896, 29900,    13,
            13,  1666,  2842,    13,    13,  1293,   310, 23820,   306, 29915,
           345,  5925,   287,   363,   590,  3273,  5828,   297,  6728, 29889,
            13,    13,  2008, 29874,  3938,   459,   793, 29892, 10734,   278,
         21884,   264, 14722, 29892,  1058,   526,  2714,   304,   505, 14416,
           599,   278,  4655, 10801,   310,   278, 25620, 10800,   273, 29892,
          2820, 29871, 29896, 29906, 29900, 29900, 17403,   322, 24639,   278,
           982,   363,   278, 14451,   310,   278, 18438,  2039, 29892,  6033,
           550,   322, 10504,  7631,  2133, 29889,    13,    13, 16382,   368,
           830,  2055,  2760,    13,    13, 28173,  2191,    13,    13, 29923,
           488,   264,   399,  1000,  2634,  2679,   338,   263,  9227, 29892,
           734,   305,  1737,  1416, 29892, 23383, 29892, 26935,   788,   919,
         29892,  6635,   902,   672, 29892,   970,  3489, 22545,   403,   322,
         19001, 29892,  4642,  6920,   322, 25331,   310,  2787,  1334, 12483,
          5254, 29892,   341,  4519,  4656, 29892,  6715,   952,  7759,  5244,
         19032,   394,   398, 29892,  1856, 13897, 29899,   262, 29899, 26495,
         29892,   413, 29881, 20556,  2906,   866, 29872, 29892,  1029,   333,
          9591, 29892,   322,   263, 10579, 27189,  7984, 29889,  2296,   591,
          1503,  1784,   298,  1446, 29892,   408,   278,  5934,  5771, 29889,
          8449,   338,   385,  7736,  5934,   297,   445,  1206, 29892,   408,
          1183, 23703,  3430,  1781,   297,   298,  1446, 29889,    13,    13,
         29950,  1032, 29991,   910,   338,   590,  2030, 12618,  3062,   306,
          1400,  2988,   304,   590,   716, 12618, 29892,   470,   366,  1033,
           925,  1423,   714,   278,   716, 12618,   472,   321,   488,   264,
         29893,  1000,  2634,  2679, 29889,  7312, 29889,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2]], device='cuda:0')
torch.Size([2, 461, 32000]) tensor([[[ -8.9844,   0.8540,   0.6978,  ...,  -3.0410,  -5.3555,  -2.3691],
         [ -6.6953,  -4.9531,   3.1953,  ...,  -3.8066,  -3.4336,  -4.3672],
         [ -7.5664,  -8.7812,   0.5620,  ...,  -1.0713,   4.9531,  -4.3945],
         ...,
         [ -4.8945,  -6.2344,  -1.6240,  ...,   0.1906,   1.5684,  -0.7461],
         [ -7.5352,  -6.3203,  -5.5898,  ...,  -4.2148,  -1.8008,  -5.7500],
         [ -6.3789,  -4.3398,   0.5503,  ...,  -5.3320,  -3.3867,  -4.5156]],

        [[ -8.9844,   0.8540,   0.6978,  ...,  -3.0410,  -5.3555,  -2.3691],
         [ -9.8438, -10.8906,   4.2812,  ...,  -6.6797,  -4.3398,  -6.0508],
         [ -9.3281,  -7.7070,   2.9219,  ...,  -5.2539,  -4.7070,  -5.7734],
         ...,
         [ -5.9922,  -3.3438,   2.4004,  ...,  -4.1250,  -4.4219,  -3.4863],
         [ -5.9648,  -3.2969,   2.3691,  ...,  -4.1094,  -4.4062,  -3.4688],
         [ -5.9375,  -3.2402,   2.3320,  ...,  -4.0898,  -4.3867,  -3.4473]]],
       device='cuda:0')
torch.Size([2, 461, 1]) tensor([[[29918],
         [29871],
         [29874],
         [29879],
         [  392],
         [29874],
         [29892],
         [29871],
         [29892],
         [30488],
         [   13],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [29874],
         [30488],
         [30488],
         [29915],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29889],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29909],
         [30488],
         [  284],
         [30488],
         [30488],
         [30488],
         [31147],
         [31147],
         [  262],
         [29892],
         [30488],
         [29892],
         [ 1266],
         [30488],
         [ 8250],
         [30488],
         [29903],
         [29903],
         [29879],
         [30488],
         [29889],
         [30488],
         [  284],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  592],
         [29903],
         [29924],
         [30488],
         [29909],
         [29890],
         [30488],
         [  392],
         [30488],
         [30488],
         [  376],
         [29871],
         [14262],
         [29896],
         [29903],
         [30488],
         [29909],
         [30488],
         [30488],
         [29874],
         [30488],
         [30488],
         [29933],
         [  317],
         [29892],
         [29889],
         [30488],
         [29954],
         [29874],
         [29892],
         [29892],
         [29892],
         [  392],
         [29892],
         [29915],
         [30488],
         [  517],
         [29909],
         [29874],
         [29906],
         [29899],
         [29879],
         [29945],
         [29909],
         [29909],
         [ 6523],
         [ 3486],
         [29879],
         [  354],
         [ 1124],
         [ 8037],
         [29915],
         [29874],
         [ 1124],
         [ 1730],
         [29902],
         [30488],
         [30488],
         [  287],
         [30488],
         [  262],
         [ 1124],
         [  578],
         [ 1552],
         [29909],
         [  664],
         [ 2218],
         [29882],
         [ 1109],
         [ 1109],
         [11950],
         [  517],
         [29889],
         [29915],
         [29879],
         [29882],
         [  627],
         [ 8333],
         [  392],
         [  376],
         [ 2308],
         [  517],
         [ 2308],
         [29882],
         [11235],
         [  664],
         [ 4704],
         [29882],
         [10588],
         [ 2308],
         [29871],
         [29896],
         [29896],
         [ 1605],
         [29892],
         [29892],
         [29899],
         [29915],
         [29909],
         [ 2308],
         [  276],
         [ 2886],
         [30488],
         [  408],
         [30488],
         [  408],
         [ 3364],
         [  974],
         [ 1438],
         [ 2308],
         [  284],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  292],
         [ 3237],
         [30488],
         [29903],
         [29879],
         [29879],
         [  354],
         [29892],
         [29892],
         [29871],
         [29903],
         [30488],
         [  292],
         [31147],
         [30488],
         [29879],
         [30488],
         [29874],
         [ 2308],
         [  276],
         [30488],
         [29874],
         [29882],
         [29874],
         [29874],
         [29903],
         [29874],
         [29933],
         [  561],
         [30488],
         [29924],
         [ 4192],
         [  376],
         [  392],
         [29874],
         [  950],
         [  537],
         [29909],
         [ 4192],
         [29871],
         [29871],
         [  376],
         [29892],
         [29899],
         [29874],
         [29915],
         [30488],
         [29892],
         [29903],
         [29903],
         [12317],
         [29903],
         [  376],
         [  278],
         [29876],
         [ 1907],
         [  306],
         [  645],
         [30488],
         [  517],
         [29909],
         [14131],
         [  313],
         [29899],
         [29899],
         [  680],
         [  392],
         [  329],
         [  392],
         [  261],
         [  261],
         [  392],
         [ 2308],
         [29915],
         [29902],
         [  276],
         [ 1552],
         [  806],
         [29909],
         [29915],
         [29928],
         [ 6610],
         [  354],
         [ 1568],
         [29902],
         [29902],
         [  437],
         [  392],
         [  392],
         [ 2308],
         [  276],
         [ 2308],
         [29874],
         [29903],
         [  376],
         [ 1631],
         [  336],
         [27996],
         [29874],
         [29903],
         [29874],
         [ 2308],
         [29933],
         [  561],
         [  541],
         [29874],
         [16431],
         [16431],
         [10354],
         [22539],
         [29892],
         [ 1454],
         [ 2308],
         [29903],
         [ 2308],
         [ 2308],
         [29929],
         [29896],
         [29896],
         [ 2308],
         [ 1605],
         [  392],
         [29879],
         [29903],
         [31555],
         [ 2308],
         [29881],
         [ 2308],
         [29903],
         [29882],
         [29903],
         [ 1491],
         [  392],
         [  306],
         [29909],
         [ 2504],
         [  472],
         [29909],
         [ 2308],
         [29903],
         [29903],
         [ 1366],
         [ 2308],
         [29903],
         [ 2308],
         [ 2138],
         [29875],
         [29871],
         [  376],
         [30488],
         [30488],
         [29903],
         [ 2308],
         [29871],
         [  561],
         [29874],
         [29924],
         [29909],
         [29879],
         [29903],
         [29892],
         [  260],
         [29903],
         [  306],
         [29902],
         [29899],
         [29874],
         [29874],
         [ 2308],
         [ 3742],
         [  406],
         [  297],
         [ 1009],
         [31147],
         [ 3145],
         [14131],
         [  306],
         [29903],
         [29903],
         [30488],
         [  896],
         [  896],
         [ 1454],
         [30488],
         [ 1568],
         [30488],
         [29871],
         [29896],
         [29896],
         [ 1605],
         [29903],
         [ 2138],
         [29874],
         [ 4982],
         [22539],
         [ 2308],
         [  276],
         [29903],
         [  517],
         [29903],
         [29874],
         [ 1623],
         [ 2308],
         [ 2308],
         [14131],
         [14131],
         [29874],
         [29874],
         [29899],
         [ 2774],
         [  376],
         [  292],
         [29871],
         [29874],
         [  313],
         [29899],
         [  495],
         [29892],
         [29889],
         [10354],
         [12254],
         [30879],
         [  287],
         [29928],
         [30488],
         [  263],
         [29899],
         [14131],
         [29871],
         [29871],
         [ 5828],
         [ 1220],
         [13634],
         [29929],
         [29896],
         [29896],
         [14131],
         [  392],
         [ 2308],
         [ 2308],
         [ 2308],
         [ 2886],
         [29902],
         [ 2308],
         [ 2308],
         [ 2308],
         [29933],
         [  561],
         [ 2308],
         [  509],
         [ 2308],
         [29903],
         [ 2308],
         [29903],
         [29883],
         [29903],
         [  333],
         [29871],
         [ 2308],
         [29903],
         [ 2308],
         [24433],
         [ 2138],
         [29929],
         [29896],
         [29896],
         [ 2138],
         [29875],
         [29871],
         [29903],
         [30488],
         [  501],
         [  317],
         [29892],
         [10354],
         [  284],
         [29892]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29871],
         [29871],
         [29909],
         [29909],
         [29871],
         [29871],
         [29896],
         [  386],
         [29915],
         [29871],
         [29871],
         [30488],
         [30488],
         [29874],
         [29892],
         [29892],
         [29874],
         [30488],
         [29899],
         [29892],
         [29874],
         [30488],
         [29874],
         [29874],
         [29871],
         [30488],
         [  856],
         [ 1129],
         [30488],
         [30488],
         [30488],
         [30488],
         [29874],
         [29874],
         [29915],
         [29892],
         [29899],
         [29874],
         [  705],
         [29874],
         [29871],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29924],
         [29915],
         [29915],
         [29915],
         [29902],
         [  304],
         [30488],
         [30879],
         [29874],
         [29909],
         [29909],
         [29924],
         [29909],
         [29874],
         [29874],
         [29874],
         [29874],
         [25772],
         [29915],
         [  262],
         [29896],
         [29896],
         [29871],
         [29900],
         [ 5371],
         [29874],
         [29882],
         [29874],
         [29874],
         [  363],
         [29909],
         [30488],
         [29909],
         [29909],
         [29950],
         [29871],
         [ 1491],
         [29889],
         [29871],
         [  392],
         [30879],
         [29883],
         [ 2133],
         [29882],
         [  313],
         [29892],
         [29899],
         [29899],
         [29899],
         [29874],
         [  355],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29899],
         [29899],
         [29899],
         [29892],
         [  262],
         [29889],
         [29871],
         [29874],
         [29915],
         [29874],
         [29899],
         [  392],
         [29892],
         [  305],
         [29899],
         [ 1416],
         [29924],
         [29892],
         [29924],
         [30488],
         [29899],
         [29874],
         [  392],
         [29892],
         [29899],
         [29874],
         [  392],
         [29892],
         [29899],
         [29903],
         [  403],
         [  392],
         [29892],
         [29909],
         [29892],
         [29899],
         [29874],
         [29892],
         [29899],
         [29924],
         [29915],
         [29874],
         [29874],
         [29874],
         [29892],
         [29871],
         [29888],
         [  392],
         [29892],
         [  262],
         [29874],
         [29874],
         [29871],
         [ 1131],
         [  398],
         [29892],
         [29892],
         [29899],
         [29874],
         [  281],
         [29899],
         [29892],
         [  392],
         [29892],
         [29909],
         [29899],
         [  561],
         [  856],
         [29874],
         [  392],
         [29892],
         [  333],
         [29899],
         [29924],
         [29892],
         [29874],
         [29899],
         [29899],
         [29899],
         [29924],
         [29892],
         [29915],
         [ 1503],
         [29882],
         [  298],
         [29871],
         [30488],
         [  392],
         [29902],
         [29892],
         [30488],
         [29874],
         [  313],
         [29915],
         [  856],
         [29950],
         [29899],
         [30488],
         [31147],
         [29899],
         [29874],
         [30488],
         [29923],
         [30488],
         [29903],
         [29928],
         [  297],
         [  298],
         [ 1446],
         [29874],
         [  313],
         [29899],
         [29899],
         [29915],
         [29874],
         [30488],
         [29915],
         [29923],
         [29909],
         [29899],
         [29909],
         [29902],
         [  392],
         [  287],
         [  517],
         [  590],
         [  392],
         [29899],
         [  392],
         [  392],
         [29874],
         [  392],
         [29874],
         [29874],
         [ 1124],
         [  590],
         [29899],
         [  392],
         [  392],
         [29874],
         [29871],
         [29871],
         [29899],
         [29871],
         [29871],
         [29871],
         [29899],
         [29892],
         [29899],
         [29892],
         [29924],
         [29924],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 461, 10]) tensor([[[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29892, 29915,  ...,   315,   376, 29889],
         [29874, 15922,  1595,  ..., 27996,  5184,   376],
         ...,
         [10354, 29958, 29889,  ..., 14202, 24433, 29943],
         [  284,  3528, 29903,  ..., 29879, 29924,   319],
         [29892,   313, 29889,  ..., 29873,   376, 30010]],

        [[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29899, 29892,  ...,   376, 29889,   317],
         [29874, 29871,   262,  ..., 29915,   376,   313],
         ...,
         [29892,   313, 29871,  ...,   856,   315,   317],
         [29892,   313, 29871,  ...,   856,   315,   317],
         [29892,   313, 29871,  ...,   856,   315,   317]]], device='cuda:0')
Batch 19, 38.9% of total tokens
encoded shape: torch.Size([2, 429])
torch.Size([2, 429]) tensor([[    1,  1954, 13847,  8363,   310, 12042,   284, 13374,  1934,   297,
           278,  1226,   296,   352,   681,  4236,  2911, 29889,    13,  1888,
         13847,  8363,   310, 12042,   284, 13374,  1934,   297,   278,  1226,
           296,   352,   681,  9619,  1821,   756, 16413,   304,   367,   385,
         11828, 29892, 23279, 29892,   322,  8500,   519,  8792, 29889,  1670,
           338,  2217,  1472, 29899,  8489,   848,  3625,   373,  2788,  7539,
          1860,   297,   278,  1226,   296,   352,   681,  4236,  2911, 29889,
           450, 12242,   310,   278,  2198,  6559,   471,   304, 24899,  1711,
         14707,  1226,   296,   352,   681,  4236,  2911,   337, 29882,  4427,
          7018,   411,  4030,   519, 16810, 13244,   267,  6969,   491,   278,
           530, 29895,  2904,   359, 10829, 29907,   650,   313, 29928,   296,
          1028,   368, 29899, 27034,   328,   296, 29897,  1788, 29889,   450,
         14502,  1158,   471,  2729,   373, 16800,  8363,   310,  3023, 13374,
          1934,   297,   278,  6446,  1226,   296,   352,   681,  4236,  2911,
         29889,   319,  3001,   310, 29871, 29896, 29947, 29900, 13374,  1934,
           892, 15478,   297, 29871, 29946, 29945, 22069, 29889,   360,   296,
          1973,   892,  7180,   373,   322, 26060,   491,   758, 16582,  2200,
           630,   378,   936, 11660,  1983,   393,   892, 15478,   964,   278,
          5923, 12042,   545,  2967,   491,  1513,   938,   336, 11251, 24324,
           261,  2133,  7389,  1156, 25300,   708,   322,  6969,   491,  6590,
           378,   936,  7601, 13374,   424,   633,   329,  1860, 29889,  7133,
           278, 15500,  3785, 29892,  1023, 13374,  1934,   313, 29896, 29889,
         29896, 29896, 10997,   892,  6206,  2861,   304,   278, 10225,   310,
          2897,   344, 29877, 27925, 29889,  3118, 13374,   424,   471,  6206,
          2861,   304, 23603, 29899, 13699,   424, 23448, 29892,   322,   697,
           916,   313, 29900, 29889, 29945, 29945, 10997, 13374,   424,   471,
          6206,  1363,   310,   263,   285,  1461,   545,  1156, 29871, 29953,
          7378,   310,   740, 29889,   450, 12463, 13374,   424, 10503,  2561,
          6554,   471, 29871, 29929, 29955, 29889, 29955, 29955, 13667,  1550,
           278, 16810, 29882,  6656, 10503,  2561,  6554,   471, 29871, 29896,
         29900, 29900, 15543,  3925,  7807,   470,  1462,  2633,   471,   451,
          8900, 29889,  2860,   263,  3001, 15500,  3785,   310, 29871, 29906,
         29953, 29889, 29955,  7378,   313,  3881, 29871, 29896, 29906,   304,
         29871, 29945, 29946,  7378,   511,   599, 13374,  1934,   750,  9045,
         29891, 23603, 29899, 13699,   424,  4964,   260, 15118,   393, 10018,
          4482,  1819,   310, 24899,   936,  4128, 29889,  9333,  9881, 13374,
          1934,   313, 29941, 29889, 29929, 29955, 10997,  9132,   263,  5394,
          8668, 10767, 21219,  2380,   310, 29871, 29941, 29889,   910,  1158,
         16089,   277,  1078,  1226,   296,   352,   681,  4236,  2911,   337,
         29882,  4427,  7018,   411,  4030,   519, 16810, 13244,   267, 29889,
           450,   378,   936, 20844,  6964,  9132, 20601,   297, 13714,  4866,
         29899, 25873,   545,  3240,  2509, 29892, 12212, 12042,   545,  2967,
         29892,   322, 16710,   470,   284,   298,  4790,  3530, 29889],
        [    1,   525, 24599, 29915, 26953,  1605,  4245,  7799,    13,    13,
         29967, 21419,   968, 12646, 19716, 12012,  9945, 20839,  7142,   943,
          7178,  4794, 29884, 11890,  1878,  2231,   313, 29906,   299,   365,
         29897,   322,  4642, 12113,  5546, 14645, 29949, 10015,  2397, 22740,
           314,  3747,   313, 29931, 29897,   926,   267,   411,   278,  5001,
         29915, 29879, 22267,  1904,   310,   385,   382, 29963,  1605,  4245,
          2841, 17847, 29875,  2645,   263,  3965, 25267,   297, 20377,   373,
          4779, 29871, 29906, 29955, 29892, 29871, 29906, 29900, 29896, 29941,
         29889,   450,  8818, 29875,  1559,  2722, 29871, 29953, 28134,   322,
           278, 10369,  9712,   545,   338, 24332,   297, 15613,   263,  4802,
         22780,   310,   278,   260,  2679, 29899, 29873,  2679,  9999,   297,
         14325, 29889,  1963,  3747, 29901, 23844, 29925, 29914,  2577,  1017,
          1954,  1179,    13,    13, 29909,  6114,   322,   902,  1487,  7845,
          2768,   278, 26091,  1297,   310,   385, 12646,   534,  4245,  2841,
           408,   896,  7899,  3412,   263,  1667,  6520,   297,  6555,  1522,
           823,   292, 29889,  1963,  3747, 29901,   830,   329,   414,    13,
            13, 29909, 27682,  3430,   472,   263, 17546,  1885,  3081, 29899,
           465, 12652,   534,  4245,  2841, 29892, 10371,  1573,   491,  5546,
         29915, 29879,   306, 29893,   271,  3270,  2994, 29886,  1696,  2645,
           278,   350,  2620, 29891,  5546, 29130,   297, 20377, 29889,   450,
          2136,   261,  1497,   278,   534,  4245,  2841,   947,   451,  1996,
           337, 25389,   292,   408,  1472,   408,   372,   338, 26263,   373,
          1363,   278, 17546,  1885,  7774,  8605,  6336, 28075, 17546,  1885,
         10489,   304,   967, 26413,  3038,   304,  5706, 12646,  3081, 10940,
           278,   534,  4245,  2841,  6459, 29879,   278, 16988, 11749,  7415,
          5224,  1135,   278,   758, 29899,   842,  3233, 29889,  1126,   278,
          5759,  3081, 25100,   278, 10992,   304,  6985,   411,  8939, 12818,
         29889,  1963,  3747, 29901, 12279,    13,    13, 29967, 21419,   968,
         12646,  4469,  9712,   545,   321, 29899,  1195, 10730,  6673,   323,
          1446, 29884,  2397,   405,   728,   601, 14423,   278, 12646,   534,
          4245,  2841,   525, 29933,  1061, 29874,   742,   607, 25100,   701,
           304, 29871, 29896, 29900, 29900, 24016,   373,   263,  2323,  8323,
         29892,   472,   278, 26953,  8980, 29882,  2512, 14650, 17968,  1222,
          1129,   297,   612,   554,  1148,  3304, 29892,  1014, 25006, 20377,
           373,  5533, 29871, 29896, 29906, 29892, 29871, 29906, 29900, 29896,
         29896, 29889,   450,   525, 29933,  1061, 29874, 29915,   338,  8906,
           363,   278,  9687, 28289,  2669,  1316,   408,   282, 24990, 28289,
         29889,  1963,  3747, 29901, 23844, 29925, 29914,  2577,  1017,  1954,
          1179,    13,    13,  4013, 12646,   534,  4245,  2841,   338,   760,
           310,   385, 20021, 14650, 10253,   313,  3035, 29933, 29897,  5220,
           287,  2060,   304, 14944,  5864,  8543,  8608,   362, 27809,   297,
           278, 26260, 29889,  1963,  3747, 29901, 23844, 29925, 29914,  2577,
          1017,  1954,  1179,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 429, 32000]) tensor([[[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -8.0312, -12.8672,  -1.2168,  ...,  -6.1562,  -2.9043,  -7.2617],
         [ -8.3047,  -7.1602,   2.8047,  ...,  -4.8789,  -4.7383,  -4.3125],
         ...,
         [ -9.6016, -14.6562,  -2.9629,  ...,  -5.1484,  -3.0293,  -5.4883],
         [ -6.3086,  -8.1953,  -4.7539,  ...,  -2.8203,  -1.4385,  -3.8574],
         [ -6.2930,  -5.0820,   0.5317,  ...,  -3.8848,  -3.4922,  -3.3652]],

        [[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.9414,  -5.4805,   4.4375,  ...,  -4.3086,  -4.7695,  -3.9902],
         [-10.3906, -13.1172,   2.5703,  ...,  -7.1367,  -5.2422,  -6.6719],
         ...,
         [ -7.8320,  -7.3633,  -0.6050,  ...,  -5.4492,  -2.2324,  -6.5273],
         [ -8.0156,  -8.6875,  -0.8857,  ...,  -6.2656,  -2.9297,  -7.1133],
         [ -8.3359,  -9.5781,  -0.7129,  ...,  -6.7969,  -3.4414,  -7.4570]]],
       device='cuda:0')
torch.Size([2, 429, 1]) tensor([[[29918],
         [29871],
         [29899],
         [29874],
         [29874],
         [  284],
         [29903],
         [29874],
         [  376],
         [29874],
         [29874],
         [29874],
         [29871],
         [  392],
         [  392],
         [29874],
         [29874],
         [29871],
         [29899],
         [  392],
         [  262],
         [29874],
         [29881],
         [  284],
         [29903],
         [29933],
         [  262],
         [29874],
         [30488],
         [29871],
         [29903],
         [29871],
         [29874],
         [29874],
         [29874],
         [ 1131],
         [31147],
         [  367],
         [29874],
         [30879],
         [  392],
         [30879],
         [  392],
         [  392],
         [  262],
         [29874],
         [  262],
         [ 5062],
         [29874],
         [  262],
         [29874],
         [29874],
         [29899],
         [ 8489],
         [29874],
         [ 5924],
         [ 1454],
         [ 1552],
         [29874],
         [29871],
         [  572],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [30488],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  262],
         [29874],
         [  517],
         [27289],
         [  262],
         [  392],
         [29874],
         [29899],
         [29899],
         [  392],
         [  392],
         [29874],
         [29874],
         [29874],
         [29933],
         [  277],
         [ 2541],
         [31147],
         [29871],
         [  392],
         [ 9188],
         [29874],
         [  262],
         [30488],
         [31147],
         [30488],
         [29871],
         [29899],
         [31147],
         [31147],
         [29871],
         [29871],
         [31147],
         [29892],
         [31147],
         [29899],
         [29874],
         [31147],
         [29892],
         [29899],
         [29871],
         [29874],
         [31147],
         [29874],
         [31147],
         [29874],
         [29874],
         [ 3002],
         [29874],
         [  373],
         [29874],
         [30488],
         [29874],
         [29874],
         [31147],
         [  392],
         [  262],
         [29874],
         [  262],
         [30488],
         [29874],
         [29871],
         [29933],
         [  392],
         [29874],
         [29874],
         [31147],
         [29871],
         [29874],
         [29874],
         [29896],
         [29874],
         [29874],
         [29899],
         [  392],
         [29893],
         [  262],
         [  262],
         [29871],
         [29896],
         [29874],
         [29874],
         [29874],
         [31147],
         [29871],
         [29899],
         [29893],
         [  262],
         [  262],
         [  262],
         [29874],
         [  491],
         [29874],
         [29899],
         [  262],
         [  392],
         [  262],
         [29899],
         [  392],
         [29899],
         [  354],
         [ 1311],
         [  274],
         [  262],
         [29874],
         [29909],
         [29874],
         [  284],
         [29899],
         [  392],
         [29874],
         [29899],
         [29871],
         [29899],
         [  262],
         [29871],
         [29933],
         [  974],
         [29874],
         [  262],
         [  708],
         [29874],
         [29874],
         [  491],
         [29874],
         [  392],
         [  856],
         [  392],
         [29882],
         [  392],
         [29903],
         [29874],
         [29885],
         [  354],
         [31147],
         [29874],
         [29874],
         [23196],
         [  974],
         [29874],
         [29899],
         [  392],
         [  417],
         [29871],
         [29874],
         [29896],
         [29874],
         [29874],
         [  392],
         [29895],
         [29874],
         [29874],
         [31147],
         [29871],
         [29899],
         [29874],
         [29874],
         [29874],
         [29940],
         [29874],
         [31147],
         [29899],
         [  392],
         [  417],
         [  262],
         [ 1356],
         [  304],
         [29874],
         [29899],
         [29899],
         [29874],
         [29895],
         [29874],
         [  392],
         [29874],
         [13699],
         [29874],
         [29871],
         [29889],
         [29892],
         [29874],
         [29874],
         [  417],
         [  392],
         [  417],
         [29895],
         [ 1356],
         [29874],
         [31147],
         [29874],
         [29871],
         [29874],
         [  974],
         [29871],
         [29871],
         [29874],
         [29874],
         [31147],
         [  292],
         [29874],
         [29874],
         [29874],
         [  392],
         [29895],
         [  262],
         [  392],
         [  262],
         [  392],
         [29871],
         [29871],
         [29995],
         [29871],
         [29995],
         [29995],
         [  392],
         [29874],
         [29874],
         [  354],
         [ 7492],
         [  578],
         [  440],
         [ 6554],
         [ 1131],
         [  392],
         [29871],
         [29871],
         [29900],
         [15543],
         [31147],
         [29871],
         [29874],
         [29874],
         [29871],
         [ 1491],
         [29911],
         [29911],
         [  262],
         [31147],
         [29871],
         [  392],
         [29874],
         [  931],
         [  974],
         [29882],
         [29871],
         [29946],
         [  392],
         [29871],
         [29874],
         [29874],
         [29871],
         [29874],
         [29871],
         [29906],
         [29994],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [  392],
         [ 1934],
         [  392],
         [29874],
         [29899],
         [29899],
         [29899],
         [29892],
         [29874],
         [  260],
         [  260],
         [15118],
         [ 1131],
         [  354],
         [30879],
         [29899],
         [ 1454],
         [30879],
         [29871],
         [29874],
         [29874],
         [31147],
         [29874],
         [  313],
         [  392],
         [  354],
         [29871],
         [29889],
         [29892],
         [29874],
         [29874],
         [  392],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29958],
         [  392],
         [29871],
         [29874],
         [29892],
         [29874],
         [ 3002],
         [  277],
         [29871],
         [30488],
         [30488],
         [30488],
         [  856],
         [  392],
         [29874],
         [29874],
         [29903],
         [29871],
         [  277],
         [ 2541],
         [  262],
         [29871],
         [  771],
         [13244],
         [29874],
         [16431],
         [29874],
         [29874],
         [29899],
         [11660],
         [29899],
         [12759],
         [  262],
         [  262],
         [29874],
         [  392],
         [29899],
         [29899],
         [29933],
         [  262],
         [  262],
         [25772],
         [29874],
         [  262],
         [  284],
         [29899],
         [29875],
         [29899],
         [  856],
         [  262],
         [  284],
         [  298],
         [ 4790],
         [29950],
         [  705],
         [29874]],

        [[29918],
         [29871],
         [29899],
         [29879],
         [29903],
         [  856],
         [29874],
         [27395],
         [  313],
         [29892],
         [29874],
         [29915],
         [29899],
         [29899],
         [  392],
         [ 9945],
         [30488],
         [30488],
         [29871],
         [29915],
         [30488],
         [29889],
         [30488],
         [29871],
         [29871],
         [29915],
         [29892],
         [29899],
         [  365],
         [29871],
         [  392],
         [  392],
         [  262],
         [29875],
         [29875],
         [29874],
         [30488],
         [29871],
         [29899],
         [29871],
         [29871],
         [  313],
         [  390],
         [29933],
         [  392],
         [  856],
         [  262],
         [29874],
         [  392],
         [29915],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [29899],
         [30488],
         [29874],
         [29874],
         [29875],
         [29874],
         [29874],
         [31147],
         [29903],
         [  262],
         [31147],
         [29874],
         [  262],
         [29871],
         [29871],
         [29874],
         [29874],
         [29871],
         [29871],
         [29899],
         [29871],
         [29871],
         [29889],
         [29915],
         [29874],
         [29875],
         [29915],
         [ 2722],
         [29871],
         [29871],
         [29899],
         [  392],
         [29915],
         [  262],
         [  392],
         [29903],
         [29915],
         [29911],
         [  393],
         [29915],
         [29874],
         [29903],
         [25772],
         [  310],
         [ 1552],
         [29911],
         [  856],
         [  260],
         [  260],
         [  578],
         [31555],
         [14131],
         [29933],
         [29874],
         [29892],
         [29874],
         [30488],
         [30488],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29899],
         [29874],
         [29892],
         [29892],
         [  517],
         [ 1022],
         [29874],
         [29874],
         [  392],
         [  262],
         [29874],
         [  376],
         [29874],
         [29899],
         [29874],
         [  262],
         [29899],
         [29874],
         [ 2841],
         [  376],
         [29874],
         [29911],
         [ 5184],
         [29874],
         [29903],
         [29903],
         [  680],
         [29874],
         [29874],
         [29874],
         [29871],
         [  265],
         [29915],
         [29874],
         [29899],
         [29874],
         [  329],
         [29874],
         [29874],
         [29892],
         [29915],
         [  376],
         [  392],
         [29874],
         [29874],
         [  392],
         [29874],
         [29899],
         [  287],
         [  376],
         [29879],
         [  376],
         [29874],
         [ 2841],
         [  376],
         [29915],
         [  277],
         [  262],
         [29903],
         [29915],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [  262],
         [29886],
         [  262],
         [  262],
         [29874],
         [29871],
         [30879],
         [29874],
         [29874],
         [29906],
         [  262],
         [  262],
         [  262],
         [29915],
         [29874],
         [  261],
         [29915],
         [ 1552],
         [29874],
         [  355],
         [ 2841],
         [29915],
         [29882],
         [29903],
         [29874],
         [25389],
         [  292],
         [  376],
         [29950],
         [29874],
         [29950],
         [29987],
         [29874],
         [  957],
         [29874],
         [29950],
         [29950],
         [29940],
         [29899],
         [29874],
         [29915],
         [29950],
         [29950],
         [29903],
         [  517],
         [  517],
         [ 1552],
         [29882],
         [ 7774],
         [29903],
         [  392],
         [ 1129],
         [  537],
         [  517],
         [29874],
         [29875],
         [29874],
         [ 2841],
         [13823],
         [29879],
         [29874],
         [29874],
         [29987],
         [23176],
         [  517],
         [  287],
         [  680],
         [29903],
         [  465],
         [  465],
         [13072],
         [29874],
         [29874],
         [29874],
         [29874],
         [  392],
         [29930],
         [ 1552],
         [29893],
         [  517],
         [24313],
         [ 1552],
         [29881],
         [29881],
         [  517],
         [ 1963],
         [29874],
         [29899],
         [  262],
         [29874],
         [29899],
         [29915],
         [29874],
         [29915],
         [  392],
         [29963],
         [  392],
         [  276],
         [  392],
         [29899],
         [29892],
         [30488],
         [29915],
         [  262],
         [31147],
         [29874],
         [  856],
         [  262],
         [29871],
         [29892],
         [29898],
         [29874],
         [29875],
         [  534],
         [29874],
         [ 2841],
         [  376],
         [29892],
         [29874],
         [29874],
         [29899],
         [29874],
         [  354],
         [29882],
         [  304],
         [  392],
         [29871],
         [29874],
         [29900],
         [ 7725],
         [  262],
         [29874],
         [  392],
         [ 8323],
         [29874],
         [  262],
         [29874],
         [  392],
         [  392],
         [29874],
         [29924],
         [29903],
         [  262],
         [29903],
         [  262],
         [  262],
         [  262],
         [29892],
         [29871],
         [29874],
         [  262],
         [  262],
         [29871],
         [29911],
         [  262],
         [  262],
         [29871],
         [29871],
         [29896],
         [29874],
         [29871],
         [29871],
         [29871],
         [29896],
         [29871],
         [29874],
         [29915],
         [29874],
         [29933],
         [29874],
         [29874],
         [29915],
         [  534],
         [  275],
         [29874],
         [29903],
         [29903],
         [13823],
         [14131],
         [14131],
         [29874],
         [  262],
         [  392],
         [29874],
         [  376],
         [29915],
         [29874],
         [29899],
         [29892],
         [29874],
         [29874],
         [29892],
         [29871],
         [29874],
         [29899],
         [29874],
         [29892],
         [29915],
         [29915],
         [29899],
         [29874],
         [ 2841],
         [29915],
         [  392],
         [29903],
         [29874],
         [  376],
         [29899],
         [29933],
         [16431],
         [  319],
         [29933],
         [29874],
         [  392],
         [  287],
         [29903],
         [14131],
         [16431],
         [  392],
         [14238],
         [  392],
         [  362],
         [18893],
         [ 1454],
         [29928],
         [29882],
         [29915],
         [29915],
         [29892],
         [  856],
         [29892],
         [29892],
         [29874],
         [29892],
         [29871],
         [  561],
         [29899],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874]]], device='cuda:0')
torch.Size([2, 429, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871,   376,   370,  ...,   771, 29915, 29925],
         [29899, 29871, 29874,  ..., 29896,   856, 29898],
         ...,
         [29950, 29924,   262,  ..., 29895,   376,   517],
         [  705,  7308,   517,  ...,  1004,   392, 29874],
         [29874, 29892, 29915,  ..., 29871,   315,   376]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ...,   315, 29874,   349],
         [29899, 29871, 29882,  ..., 29893, 29890, 29875],
         ...,
         [29874, 29933, 29924,  ...,   262, 29875, 29902],
         [29874, 29933, 29924,  ..., 29899, 29871, 29875],
         [29874, 29933, 29871,  ..., 29879, 29875,   262]]], device='cuda:0')
Batch 20, 39.7% of total tokens
encoded shape: torch.Size([2, 697])
torch.Size([2, 697]) tensor([[    1,  2866, 22155,  ...,     2,     2,     2],
        [    1, 11856, 26160,  ..., 29889,  5899, 29889]], device='cuda:0')
torch.Size([2, 697, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [-10.4375, -15.5859,   0.6060,  ...,  -7.7070,  -4.9531,  -8.2266],
         [ -9.3516, -16.2969,  -2.3281,  ...,  -4.7734,   0.3706,  -6.3906],
         ...,
         [ -8.1641,  -7.2070,  -5.0391,  ...,  -6.0117,  -3.6484,  -5.8789],
         [ -8.4766,  -7.0039,  -4.6367,  ...,  -6.0234,  -3.8125,  -5.8867],
         [ -8.5234,  -6.9023,  -4.5234,  ...,  -5.9766,  -3.8320,  -5.8359]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -9.0000,  -9.2578,   3.1445,  ...,  -5.0273,  -4.8203,  -5.2930],
         [ -9.2188,  -9.8672,   2.6523,  ...,  -4.9219,  -5.0078,  -5.9414],
         ...,
         [ -8.4141,  -7.7969,   0.2053,  ...,  -3.7969,  -4.9805,  -4.0391],
         [ -7.1367,  -6.2578,   2.1387,  ...,  -4.5391,  -4.5352,  -3.9590],
         [ -8.3438,  -7.6758,   2.5566,  ...,  -5.2578,  -5.0625,  -4.5547]]],
       device='cuda:0')
torch.Size([2, 697, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29879],
         [29879],
         [29879]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29874],
         [29892]]], device='cuda:0')
torch.Size([2, 697, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874,   262,  ..., 29924, 29933,   313],
         [29874, 29871, 29882,  ..., 29915,   370,   354],
         ...,
         [29879,   313, 30010,  ...,   349,   271,   315],
         [29879,   313, 29915,  ...,   349,   315, 29874],
         [29879,   313, 29915,  ...,   349, 29874, 29892]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874,   262,  ..., 29882, 29924, 29873],
         [29874, 29871,   262,  ..., 29882,   313, 29898],
         ...,
         [29874,   262,   392,  ..., 29915, 29908, 29909],
         [29874, 29871, 29899,  ...,   262, 29896,    13],
         [29892, 29899, 29889,  ..., 29896,    13, 29882]]], device='cuda:0')
Batch 21, 40.6% of total tokens
encoded shape: torch.Size([2, 443])
torch.Size([2, 443]) tensor([[    1, 26221, 10726, 29892,   697,   310,  1749,  8820, 29892,   470,
         23740,  3144,   314, 29892,   591,   505,  1554,   363,   366, 29889,
            13,    13, 17242, 10783,   472,   278, 11243,  2877,  4779,   363,
         20872,   669,   349,  2426,    13,    13,  1576,  1346,  6108,  2877,
          4779,   363, 20872,   669,   349,  2426, 30024,   373,  5306, 29871,
         29896, 29896, 29892,   411,  4959,   297, 13681,   322,  4822,   278,
          3148, 29892,   674, 27227,   675,   278, 16984,   365,  7210, 29911,
         29984,  2305,   322,   394,  3687,   304, 10776,  3730,   322,  9436,
          3211, 21838,  1048,   278,  1857,  8604,  2982,  1557, 11603,   322,
           920,   372,   338, 17737, 17068,   304,   278,   639,  3471,   918,
           322,  2313,  5632,  3381,   310,   365,  7210, 29911, 29984, 15724,
         29889,    13,    13,  8439,   526,  5320,  5837,   366,   508,   679,
          9701,   297,   278, 11243,  2877,  4779,   445,  4723,   355, 29901,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,   379, 11279,   479,  2878,   331,   936, 21862,   322, 24809,
           358,   310, 13748,   292,  4094, 11029,   297,  3091,  1558, 29899,
         29968,   449,   457, 10592,  9633, 29892, 13267,   354, 11530, 21072,
           275,   423, 29889,    13, 24625,  1558, 29899, 29968,   449,   457,
         10592,  9633, 29892,  5982,   297, 13267,   354, 11530, 21072,   275,
           423, 29892,   756,  1063,  1304, 12838,  3598,   408,   263,  7601,
          2752,   304,  5870,   278, 15678,  4225,   310,   278,  5164,   409,
         14359, 29889,   360, 11881,  7134,   310,   278,  1737,  2878,   331,
           936, 14675,   310,  5962, 13405,   322,  4094, 11029,   508, 26371,
           749,  8004,   310,   278, 17546, 14969,   936,  1788, 29892,  2504,
         11427, 15075,   475,   519,  5849,   322, 11828, 10643,   310,  5962,
         13405,  7788, 29889,  1763,   445,  1095, 29892,   263, 17546, 14969,
           936,   322, 24148, 22522,   471, 18043, 29889,  1632,   618, 13405,
         11916,   505,  1063, 16531,   515, 29871, 29896, 29941,  1532, 29879,
           515, 29871, 29896, 29929, 29929, 29945,   304, 29871, 29906, 29900,
         29900, 29945, 29936,   304,  2274,   278,  8974,   310, 23556,  1490,
         29871,  1080,   322, 24809,   278, 22233, 11029,   310,   278,  5962,
         13405, 29889, 17212, 22222,   393,  4249,   278,   274,   800, 29892,
           871,   278,  2099, 14953,   800,   310,  4465, 29898,   718,  1723,
         13461, 16605,  5570,  1819,   731,   491,   278,  2787, 15202,  9205,
          2133,   313, 29956,  8187,   467, 29499,   278, 29537,   287,   385,
          1080, 29892,   278, 26702,   310,  7791, 29898, 29906, 29899,  5033,
         29946, 29897,   322,  2233, 29898,   448,  1723,   526,  2038,   278,
           399,  8187,  2758,   519, 14953,   800, 29889, 14990, 23556,  1490,
           899,  4841,   297,  1556,  5962, 13405, 11916,   526,  7621,  1135,
         29871, 29896, 29892, 29900, 29900, 29900,   286, 29887,   301,  6278,
         29896,   511,   278,  4046,   731,   491,   278,   399,  8187, 29892,
         23941, 10029,  4497,   457,   470, 17768,  2486,  4497,   457,  4094,
         29889,   512,  2498, 29892,   263,  7282,  7910,   297,   278,  7426,
           310,  4094,  1375, 13537,  2133,   471,  8900,   297,   278,  5305,
           310,  7062,  5933,   304,   302, 27374,  1494,   278, 14014,  4972,
          5305, 29889, 20535,   630,   269,  1337,   362, 16285,  1510,   393,
           599,  4094, 11916,   892,   288,   874,  1337,   630,   411,  3390,
           304,   263,  1431,   265,   568, 29892,  1208,  2036, 29892,   322,
          8828,   290,   568, 29892,   322, 23400,  1337,   630,   411,  3390,
           304,   385, 29882,  2941,  1377, 29892, 10966, 15663, 29892,   322,
          8870,   568, 29889, 16564,   373, 17546, 14969,   936,  2258,  2478,
         29892,  1023,  4072,   310,  4094,   758,  3129, 16976,   297,   278,
          6559,  4038, 29889,   450,   937,   338,  9243, 29899, 13695, 29899,
          6156, 29898, 29946,  6817,  6821,   297,  1134,   322,  5982,   297,
           278,  7062,  5933,   607, 16161,   304,   278,   337, 23367,   760,
           310,   278, 10592,  9633, 29889,   450,  1473,  1134,   338,  4465,
         29899, 26270, 29899,  6821, 29899,  6156, 29898, 29946, 29897,   322,
          5982,   297,   278,  9755, 29892,   607, 16161,   304,   278,   766,
         23367,   760, 29889]], device='cuda:0')
torch.Size([2, 443, 32000]) tensor([[[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -8.6797,  -7.8672,   2.3438,  ...,  -4.6992,  -4.0781,  -5.0859],
         [ -8.9375,  -9.2969,  -0.6543,  ...,  -5.0898,  -3.4668,  -6.5156],
         ...,
         [ -7.5898,  -8.8750,  -4.2070,  ...,  -6.1250,  -1.5166,  -5.8008],
         [ -7.6133,  -8.7578,  -4.1758,  ...,  -6.0195,  -1.3916,  -5.6992],
         [ -7.5977,  -8.4922,  -4.2070,  ...,  -5.8438,  -1.2217,  -5.5352]],

        [[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -8.4453, -13.4766,  -1.4180,  ...,  -7.5039,  -3.2773,  -7.2109],
         [ -9.6094, -14.8281,  -3.3867,  ...,  -7.6367,  -3.9531,  -7.6484],
         ...,
         [ -3.3809,  -5.8047,  -2.8906,  ...,  -0.4441,   1.9746,   1.4316],
         [ -4.6094,  -5.8438,  -4.1523,  ...,  -1.3320,   0.3638,  -3.2695],
         [ -4.7344,  -3.0059,   0.2812,  ...,  -3.3535,  -3.1035,  -2.9473]]],
       device='cuda:0')
torch.Size([2, 443, 1]) tensor([[[29918],
         [29874],
         [29874],
         [29908],
         [29882],
         [29909],
         [29871],
         [ 1454],
         [29930],
         [29909],
         [29899],
         [  294],
         [29903],
         [29985],
         [29987],
         [ 1457],
         [  363],
         [29909],
         [  262],
         [  313],
         [29899],
         [29899],
         [16431],
         [29874],
         [16431],
         [29909],
         [  262],
         [  262],
         [29924],
         [29874],
         [  392],
         [29874],
         [ 2426],
         [22752],
         [29892],
         [29899],
         [  355],
         [29892],
         [29871],
         [  262],
         [29874],
         [29874],
         [  392],
         [29874],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29871],
         [29871],
         [30488],
         [29871],
         [29871],
         [30488],
         [29928],
         [  392],
         [29882],
         [29924],
         [29928],
         [29874],
         [29930],
         [30488],
         [  675],
         [29931],
         [29931],
         [29931],
         [  365],
         [29874],
         [29874],
         [29874],
         [29903],
         [29933],
         [ 3687],
         [29903],
         [29928],
         [29943],
         [  392],
         [29874],
         [  392],
         [29874],
         [30488],
         [29874],
         [29931],
         [29931],
         [29931],
         [29903],
         [29871],
         [29909],
         [29903],
         [29931],
         [29987],
         [29909],
         [29933],
         [  517],
         [29931],
         [29882],
         [ 1004],
         [  918],
         [29931],
         [29899],
         [  283],
         [ 3381],
         [29931],
         [29931],
         [29933],
         [29911],
         [29984],
         [  561],
         [30488],
         [29892],
         [29899],
         [29899],
         [ 1454],
         [29924],
         [29899],
         [  304],
         [  508],
         [ 8575],
         [30488],
         [  262],
         [29928],
         [29928],
         [29871],
         [  262],
         [ 1454],
         [30488],
         [  355],
         [  262],
         [  313],
         [29924],
         [29924],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [14131],
         [29871],
         [29871],
         [29871],
         [14131],
         [14131],
         [14131],
         [29871],
         [29871],
         [29871],
         [14131],
         [14131],
         [14131],
         [14131],
         [29871],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131]],

        [[29918],
         [29871],
         [29871],
         [29874],
         [29874],
         [29903],
         [ 1131],
         [  392],
         [29903],
         [  358],
         [  856],
         [29924],
         [  856],
         [29899],
         [30488],
         [  856],
         [  856],
         [29871],
         [30488],
         [29892],
         [29871],
         [29871],
         [29871],
         [29874],
         [  856],
         [  856],
         [  354],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  313],
         [30488],
         [30488],
         [30488],
         [29892],
         [30488],
         [29871],
         [29874],
         [30488],
         [30488],
         [30488],
         [30488],
         [29874],
         [  354],
         [29899],
         [29911],
         [29871],
         [29874],
         [30488],
         [  262],
         [  392],
         [30488],
         [30488],
         [  856],
         [ 1454],
         [29874],
         [30488],
         [30488],
         [ 1454],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29874],
         [30488],
         [30488],
         [30879],
         [  262],
         [29892],
         [30879],
         [31147],
         [29903],
         [ 1552],
         [30488],
         [29874],
         [29874],
         [29903],
         [29950],
         [  392],
         [ 1552],
         [29893],
         [29903],
         [  856],
         [29899],
         [29903],
         [29876],
         [  856],
         [30488],
         [29903],
         [ 1552],
         [29875],
         [  479],
         [  520],
         [ 1131],
         [14131],
         [  392],
         [  262],
         [30488],
         [  475],
         [  519],
         [  392],
         [  284],
         [30488],
         [  392],
         [ 1248],
         [21072],
         [29985],
         [ 7707],
         [29874],
         [31147],
         [ 1366],
         [29874],
         [29892],
         [29874],
         [29950],
         [  479],
         [29873],
         [29950],
         [31147],
         [29899],
         [14131],
         [  535],
         [  262],
         [31147],
         [  856],
         [  509],
         [ 5659],
         [29881],
         [  392],
         [  392],
         [29881],
         [29871],
         [29871],
         [29874],
         [29896],
         [29879],
         [30488],
         [29999],
         [29896],
         [29874],
         [29871],
         [29871],
         [  517],
         [29906],
         [29906],
         [29871],
         [29871],
         [29871],
         [30488],
         [  856],
         [31147],
         [ 1552],
         [31147],
         [  392],
         [ 1552],
         [29871],
         [29924],
         [29924],
         [14131],
         [29903],
         [ 1552],
         [31147],
         [29899],
         [29903],
         [ 3091],
         [29950],
         [29899],
         [  705],
         [31147],
         [  276],
         [29874],
         [29924],
         [ 1552],
         [29871],
         [  856],
         [29924],
         [29924],
         [29924],
         [29924],
         [  262],
         [  856],
         [  974],
         [29924],
         [29874],
         [29871],
         [29871],
         [  392],
         [  287],
         [29899],
         [29903],
         [ 1454],
         [  491],
         [  392],
         [31147],
         [31147],
         [ 9205],
         [29871],
         [ 7707],
         [29871],
         [29874],
         [30057],
         [29874],
         [29924],
         [29924],
         [  392],
         [29924],
         [29874],
         [29924],
         [29924],
         [29874],
         [  392],
         [29950],
         [29874],
         [29871],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29950],
         [ 6278],
         [29874],
         [30057],
         [ 2215],
         [ 9812],
         [  399],
         [  399],
         [29871],
         [ 7707],
         [  519],
         [14953],
         [29871],
         [13075],
         [29892],
         [29881],
         [29871],
         [29903],
         [29874],
         [ 2308],
         [29999],
         [29950],
         [30057],
         [11916],
         [  392],
         [29903],
         [29924],
         [  399],
         [29871],
         [29900],
         [29871],
         [29871],
         [29900],
         [  286],
         [29871],
         [  365],
         [29899],
         [29896],
         [  294],
         [  392],
         [29903],
         [13075],
         [  491],
         [  399],
         [  399],
         [29899],
         [ 1454],
         [  392],
         [29874],
         [29903],
         [  262],
         [25772],
         [29903],
         [  856],
         [29903],
         [  262],
         [25772],
         [25772],
         [29892],
         [  509],
         [29874],
         [ 1552],
         [  392],
         [29924],
         [  297],
         [29924],
         [29924],
         [29899],
         [29950],
         [ 6800],
         [  262],
         [ 6800],
         [ 2308],
         [11651],
         [29881],
         [27736],
         [29874],
         [  284],
         [29903],
         [29899],
         [  517],
         [30488],
         [29940],
         [29874],
         [29874],
         [  262],
         [29899],
         [ 2084],
         [ 2308],
         [29892],
         [  375],
         [29874],
         [  313],
         [  856],
         [29924],
         [27691],
         [29874],
         [29924],
         [29950],
         [29903],
         [  392],
         [29950],
         [30488],
         [30879],
         [  262],
         [ 2320],
         [29924],
         [  304],
         [29924],
         [29871],
         [29871],
         [  277],
         [29924],
         [30488],
         [29871],
         [  392],
         [30488],
         [30488],
         [29871],
         [29871],
         [29871],
         [  392],
         [29876],
         [29874],
         [  856],
         [  517],
         [29924],
         [  304],
         [30488],
         [30488],
         [29871],
         [  856],
         [  392],
         [30488],
         [29871],
         [  392],
         [30488],
         [30488],
         [29871],
         [29903],
         [29892],
         [29874],
         [29874],
         [29899],
         [  520],
         [29950],
         [29874],
         [  392],
         [  705],
         [29950],
         [29874],
         [29950],
         [25772],
         [ 3129],
         [16976],
         [  297],
         [24625],
         [ 3091],
         [30057],
         [29874],
         [29874],
         [29903],
         [ 1853],
         [29950],
         [29899],
         [  341],
         [29899],
         [  379],
         [29874],
         [29871],
         [29874],
         [  379],
         [29899],
         [29903],
         [29874],
         [29924],
         [  262],
         [29903],
         [29903],
         [29899],
         [  392],
         [  509],
         [  517],
         [29874],
         [29903],
         [29874],
         [24595],
         [29874],
         [24625],
         [24595],
         [29874],
         [10265],
         [ 1576],
         [29874],
         [ 1853],
         [29874],
         [29924],
         [29899],
         [ 6156],
         [29899],
         [ 6156],
         [29899],
         [29950],
         [29946],
         [29946],
         [29874],
         [29874],
         [ 1457],
         [  262],
         [ 1552],
         [29876],
         [29899],
         [ 2308],
         [10149],
         [  304],
         [ 1552],
         [29874],
         [29874],
         [ 1595],
         [  310],
         [  313]]], device='cuda:0')
torch.Size([2, 443, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29874, 29871, 29899,  ...,   392,   294, 29876],
         [29874, 29871,   376,  ..., 29899, 29924, 29873],
         ...,
         [14131, 29879, 30010,  ...,   317, 29871,   263],
         [14131, 29879, 30010,  ...,   317, 29871,   263],
         [14131, 30010, 29879,  ...,   317, 23333, 29871]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29933,   341, 29902],
         [29871, 29899, 29874,  ..., 30010, 29875,   313],
         ...,
         [ 1595, 24595,   760,  ..., 29985, 30057,  2222],
         [  310, 14131, 29097,  ...,  1552, 17605, 22752],
         [  313, 29915, 29874,  ..., 29899,   376,   856]]], device='cuda:0')
Batch 22, 41.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  2688,  1704,  ...,  1722,   338,   694],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-6.8750, -5.1133,  3.8027,  ..., -4.2969, -3.9434, -4.3711],
         [-6.7539, -5.5625,  2.0762,  ..., -4.4453, -4.6641, -4.2852],
         ...,
         [-3.7051, -5.1172, -6.0664,  ..., -4.4727,  2.1895, -5.4805],
         [-5.4062, -2.8867, -0.3538,  ..., -4.5469, -2.3203, -4.2227],
         [-4.6914, -3.1387,  0.1177,  ..., -4.1484, -2.8066, -3.4902]],

        [[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-7.1562, -6.3906,  3.4883,  ..., -4.6445, -5.0781, -3.9922],
         [-9.1172, -7.9531,  0.1221,  ..., -4.9141, -3.4141, -4.8906],
         ...,
         [-5.0430,  1.9512, -3.8164,  ..., -1.9443, -3.2598, -1.9766],
         [-4.9727,  1.9365, -3.8301,  ..., -1.9395, -3.2344, -1.9678],
         [-4.9492,  1.8965, -3.8418,  ..., -1.9482, -3.2305, -1.9775]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29874],
         [29874],
         ...,
         [26404],
         [29874],
         [30282]],

        [[29918],
         [29871],
         [29874],
         ...,
         [30140],
         [30140],
         [30140]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29874, 29915, 29871,  ..., 29933, 29875,   262],
         [29874, 29871,   856,  ..., 29882, 29886, 29893],
         ...,
         [26404, 28260,   376,  ..., 25772, 31765, 29903],
         [29874, 29903,   263,  ..., 29902, 29928,   262],
         [30282, 30488, 29903,  ..., 29933,   262, 29924]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [30140,   229,   376,  ...,   313, 29987,   342],
         [30140,   229,   376,  ..., 30488,   313, 29987],
         [30140,   229,   376,  ..., 30488,   313, 29987]]], device='cuda:0')
Batch 23, 45.9% of total tokens
encoded shape: torch.Size([2, 504])
torch.Size([2, 504]) tensor([[   1, 1952,  305,  ...,  310, 8660, 2710],
        [   1,  450, 4603,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 504, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [-10.3594, -15.0312,   0.5664,  ...,  -8.5156,  -4.7461,  -8.2656],
         [ -8.7656,  -8.8828,   3.8711,  ...,  -5.0820,  -5.1680,  -5.0039],
         ...,
         [ -7.6992,  -6.6055,   0.3455,  ...,  -3.5254,  -2.8125,  -4.0078],
         [ -6.9219,  -5.6836,   1.7598,  ...,  -3.7461,  -4.9023,  -3.7949],
         [ -5.9219,  -4.1055,   0.9775,  ...,  -3.2598,  -3.2734,  -3.4492]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -9.5547, -13.0391,   0.4021,  ...,  -6.6094,  -1.0117,  -7.6016],
         [-10.8047, -11.9141,   1.8809,  ...,  -5.3594,  -3.4102,  -6.6484],
         ...,
         [ -4.3867,  -2.5293,   1.8623,  ...,  -3.4785,  -4.0156,  -2.9746],
         [ -4.4102,  -2.5449,   1.8770,  ...,  -3.4863,  -4.0195,  -2.9844],
         [ -4.4297,  -2.5586,   1.8887,  ...,  -3.4922,  -4.0195,  -2.9922]]],
       device='cuda:0')
torch.Size([2, 504, 1]) tensor([[[29918],
         [29874],
         [29871],
         ...,
         [29874],
         [29871],
         [29874]],

        [[29918],
         [29871],
         [29874],
         ...,
         [30488],
         [30488],
         [29889]]], device='cuda:0')
torch.Size([2, 504, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29874, 29871, 29892,  ...,   349,   315, 29875],
         [29871, 29899, 29892,  ...,    13,   349, 29896],
         ...,
         [29874,   262, 29933,  ..., 29875, 29882, 29925],
         [29871,   313, 29896,  ...,   376, 29933,   294],
         [29874, 29882,   262,  ..., 29875, 29883,   313]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29874, 29899, 29871,  ...,   376, 29915,   262],
         ...,
         [30488, 29889, 29892,  ..., 29899,   856, 30282],
         [30488, 29889, 29892,  ..., 29899,   856, 30282],
         [29889, 30488, 29892,  ..., 29899,   856, 30282]]], device='cuda:0')
Batch 24, 46.7% of total tokens
encoded shape: torch.Size([2, 380])
torch.Size([2, 380]) tensor([[    1,  3925,   481,   304,   488, 29873,   322, 28169,   856,   392,
           769,   777,    13,    13, 29902, 18093,   263,   274,  4085,  1048,
         29871, 29906,  2440,  8020, 29892,  4240,   297, 29871, 29896, 29929,
         29945, 29900, 29889,   450,  1473, 11904,   471,  7743,   297,   278,
         29871, 29953, 29900, 29915, 29879,   470, 29871, 29955, 29900, 29915,
         29879, 29889,   450,   931,   756,  2041,   363,   263,  2217,  1083,
           397, 14067,  3045,    13,    13,   797,   278,  1473, 11904, 27683,
           313,  8159, 29897,   306,   864,   304, 18983,  3881,   278, 28169,
           322,   304,   488, 29873, 14354, 29892,   278,  1857,  5912,   338,
           451,  1407,  5929, 12818, 29889,  2178,   278, 14603, 29914, 27696,
           886,   505,  1063, 10076,  2986,   304,  1921, 29879,   313,   517,
         10320,   284,   263, 12355,   873,  1663,  2785,   393, 26999,   304,
          2217,   901,  1135,  1034,  1727,   630,  5650, 11982, 16416,   287,
           411,   260,  3888,   309, 13742,  4525,  1023,  5713,   486,  1973,
           526,   373,   278,  1021, 10090, 29892,   541,   409,   546,   630,
           491,   278,  1667,  9712, 29914,  1429, 29898,  4384, 29897,   322,
           263,   521,   559,   363,  1021,   448,   380,  7358,   714,  1048,
         29871, 29906, 29900, 29908,   515, 10090, 29892,  1048, 29871, 29947,
         29908,  9377, 29889,  2180,   278,  2246,   310,   278,  5096,   338,
           263,  3957,   363,  9712,   292,   278, 23131, 29914,   845,  1680,
           313,  1111,  2496,   467,   512,   278,  1407,  2978,  5434, 29892,
           278, 17526,   674,   367,  8611,   448,  1407,  2319, 24993,   297,
         17526,   988,  5096,   429,  1169,   266,   582, 17526,  1220, 29889,
          6864,  1474, 29892,   278, 27683,   373,   278,   937, 11904,   674,
           884,   367,   330,  4774,   287,   322,  1083,   356,   839,  3695,
          6776,  2527,  1711,   448,   260,  5475,   322,   716,  5713,   486,
          1973, 29892,   694,  1855,  8401,   310, 14354, 29889,    13,    13,
         29956,   483,   372,   367,  1900,   304,  3349,   278,  4320,   393,
           338,   727,   322,  5191,   411,   319,  9851, 29914, 29925,  8257,
         29973,   470,   925,   671,   278,  1183,   789,   287,   285,   986,
           886, 29914,  1114,   415,   943,   304,   337,  6915, 29973,    13,
          5618,   526,   278,  2821,  2925, 29914,  2680,   363,   263,   716,
           304,   488, 29873,   313, 10573, 29899,   262,  6877,    13,  5618,
           526,   278,  2821,  2925, 29914,  2680, 29879,   363,   263, 28169,
           313, 29881,  6392, 29914, 19303,   368, 29897,   448,   278, 28169,
           674,   505,   263,  2967, 28966, 29889,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13, 29928,  5364,   448,  5470,  2874,
            13,    13, 29902,   505,   278,  1494,  2566,   577,  2215, 29901,
            13,  7435,  1904,    13, 20791,  1904,  7846,  1169,   515,  5196,
         29892,   694,  2715,  9863,    13, 29931,   522,  9945,  1904,  1021,
           408, 15740,    13, 29907, 10242,  1904, 29871,    13,   268, 11822,
           353, 19358,  2558,   304,   365,   522,  9945,   313, 29896,   365,
           522,  9945,   508,   505,  1784, 21888, 29897,    13,   268,  8041,
           353,  9267,   517, 14804,   411, 15740,   313, 14804,  8041,   508,
          2125,  1784, 21888, 29897,    13, 13200,  1904,    13,   268,  8368,
           353,  3118,  1762,  6716,   411,  8368,   313, 29896,  5881,   639,
         29871, 29896,  8368,   467,    13,  2624,  1904,    13,   268,  3236,
           353, 19358,  2558,   304,  6325,   344,   313,  6716,  3236,   508,
           505,  1784,  4959, 29897,    13,    13, 10454,   590,  1139,   338,
         29936,   306,   864,   304,  2791,  8041,  2198,   297,   385,  1741,
          2729,   373,   278,  1494, 16614, 29889,  1551, 11265,   310,  6864,
         29892, 10902,  8041,   817,   304,   367,  4069, 29889, 12699,   306,
           674,  1653,   263,  1776,   393,   674,  6036,   263,  9160,  3553,
         29889,   450,  9160,  1904,   756,   263, 29871, 29896, 29899, 29896,
          9443,   411,  8368, 29889, 15740,   338,  1784, 29899, 13011,   411,
          6325,   344, 29889,  6325,   344,   338,   263, 28682,   304,  6864,
         29889, 29871,    13,    13, 15597,   817,   304,   367,   760,   310,
           278,  1021,  3236,   393,   278,  6864,   338,  6631,   304, 29889,
            13,  1576, 10902,  2198,  8041,   817,   304,   367,  7962,  2768,
           278,  1904,  2678,   373, 29889,    13,    13,  5328,   437,   306,
           748,  1048,  2599,   445, 29973,    13,    13, 29909, 29901,    13,
            13,  3644,   372,   892,   592, 29892,   306,  1795,   671,   263,
         16955,  6212, 21642,  1591,   313, 14481,   763,   278,  1494,  1125,
            13,  1990,  6212, 21642, 29898,  3195,  1125,    13,  1678,  8368,
           353,  4733, 29889, 27755,  2558,   877, 20791,  1495,    13,  1678,
          1741,   353,  4733, 29889, 27755,  2558,   877,  2624,  1495,    13,
          1678,  2198,   353,  4733, 29889, 18146,  3073, 29898,  4381, 29922,
          5574, 29897,    13,    13,  3492,  1033, 17945,   714,   278,  8368,
          1746,   363,   263,  9160,  2012, 29892,   565,   393, 29915, 29879,
           825,   366, 13521,   313,  4187,  1951,   372, 29915, 29879,   263,
           697, 29899,   517, 29899,   650, 29892,   372,  1838, 29915, 29873,
          2289,  4383,   467,   450,  2322,   995,   363,   278,  2198,  1746,
          1033,   884,   367,  2381, 17280, 29892,  8679,   373,   920,   366,
           864,   304,  7539,  9976,   297,   445,  1591, 29889,    13,    13]],
       device='cuda:0')
torch.Size([2, 380, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -6.5859,  -5.5664,   3.2129,  ...,  -4.3008,  -4.7734,  -3.8906],
         [-11.1328, -15.2891,   0.9849,  ...,  -7.7109,  -4.4531,  -7.2891],
         ...,
         [ -9.8203, -10.6875,   2.8008,  ...,  -6.6094,  -4.6484,  -6.2461],
         [ -9.7422, -10.2266,   3.0645,  ...,  -6.3438,  -4.6367,  -6.0156],
         [ -9.6641,  -9.9609,   3.1621,  ...,  -6.1992,  -4.5977,  -5.9141]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -7.1406,  -6.3711,   3.4844,  ...,  -4.6367,  -5.0703,  -3.9824],
         [ -9.1250,  -7.9688,   0.1106,  ...,  -4.9141,  -3.4043,  -4.8945],
         ...,
         [ -5.9766,  -6.5430,  -0.1002,  ...,  -5.1680,  -0.7998,  -5.4727],
         [ -8.7578,  -8.2734,   0.7949,  ...,  -7.5039,  -5.6523,  -7.1016],
         [ -5.9141,  -5.0703,   0.0314,  ...,  -5.3633,  -3.6172,  -4.3203]]],
       device='cuda:0')
torch.Size([2, 380, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29871],
         [29874],
         [29909],
         [  856],
         [29874],
         [29892],
         [  376],
         [  856],
         [29882],
         [  313],
         [29889],
         [29915],
         [29874],
         [29871],
         [29871],
         [  315],
         [29874],
         [29906],
         [29900],
         [ 8020],
         [  856],
         [  392],
         [30488],
         [29871],
         [29896],
         [29871],
         [29896],
         [29871],
         [29915],
         [  306],
         [29881],
         [29899],
         [29915],
         [  376],
         [29882],
         [29871],
         [29871],
         [29871],
         [29900],
         [29915],
         [29871],
         [  728],
         [29871],
         [29871],
         [29900],
         [29915],
         [29871],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [ 7807],
         [  856],
         [  313],
         [29892],
         [29899],
         [29879],
         [29890],
         [29933],
         [29915],
         [29902],
         [  260],
         [  856],
         [29889],
         [29915],
         [  304],
         [10840],
         [30488],
         [  856],
         [29876],
         [29924],
         [30488],
         [29950],
         [29874],
         [  856],
         [  856],
         [29889],
         [  856],
         [  856],
         [  856],
         [  856],
         [  293],
         [30879],
         [29874],
         [ 1998],
         [  313],
         [  856],
         [29903],
         [29903],
         [  260],
         [  886],
         [29914],
         [30488],
         [31147],
         [29903],
         [  392],
         [  856],
         [29879],
         [  392],
         [29892],
         [  856],
         [29874],
         [30488],
         [29871],
         [  262],
         [  856],
         [  856],
         [29934],
         [29915],
         [  517],
         [29934],
         [30488],
         [29903],
         [29874],
         [29871],
         [29871],
         [29874],
         [  856],
         [29893],
         [  287],
         [ 1546],
         [29874],
         [29899],
         [29874],
         [  856],
         [  856],
         [29871],
         [29882],
         [  262],
         [29871],
         [  856],
         [30879],
         [  856],
         [29903],
         [29909],
         [  281],
         [  856],
         [  509],
         [  546],
         [  371],
         [  491],
         [29874],
         [29882],
         [29950],
         [  292],
         [  270],
         [17760],
         [29879],
         [  262],
         [  392],
         [29874],
         [29882],
         [  262],
         [ 1582],
         [29874],
         [29898],
         [  313],
         [  497],
         [29985],
         [  941],
         [  262],
         [29896],
         [  615],
         [  728],
         [  728],
         [29956],
         [17605],
         [29915],
         [  262],
         [29896],
         [  728],
         [  262],
         [29985],
         [  313],
         [  509],
         [29902],
         [  310],
         [29874],
         [29933],
         [29879],
         [29874],
         [29882],
         [ 2222],
         [29874],
         [  292],
         [  376],
         [29933],
         [ 1160],
         [  260],
         [  376],
         [29890],
         [  794],
         [29899],
         [  260],
         [  856],
         [29903],
         [29933],
         [29903],
         [29909],
         [  306],
         [  306],
         [  260],
         [  292],
         [26180],
         [26404],
         [  281],
         [  313],
         [29909],
         [29871],
         [  482],
         [ 1131],
         [  509],
         [  262],
         [ 6624],
         [29879],
         [  856],
         [  856],
         [  856],
         [  292],
         [  856],
         [  313],
         [29874],
         [  306],
         [  306],
         [29915],
         [ 8345],
         [29881],
         [  262],
         [14939],
         [  674],
         [26180],
         [26180],
         [26180],
         [  945],
         [29871],
         [17605],
         [29902],
         [  356],
         [  839],
         [17605],
         [  313],
         [  376],
         [  293],
         [13590],
         [  260],
         [29987],
         [  300],
         [29874],
         [ 1109],
         [  495],
         [29871],
         [  680],
         [  313],
         [29899],
         [29903],
         [  262],
         [  715],
         [ 6610],
         [  313],
         [29892],
         [29899],
         [  483],
         [29874],
         [  367],
         [13299],
         [  304],
         [29903],
         [29933],
         [29933],
         [29909],
         [29915],
         [29909],
         [  262],
         [  262],
         [  372],
         [29874],
         [29899],
         [29874],
         [  349],
         [  349],
         [  794],
         [  313],
         [  856],
         [23444],
         [29909],
         [29909],
         [29874],
         [  856],
         [29909],
         [29903],
         [  262],
         [ 1131],
         [  794],
         [  415],
         [  943],
         [ 1131],
         [29909],
         [14930],
         [21141],
         [  313],
         [29892],
         [29915],
         [29902],
         [29903],
         [  292],
         [12428],
         [  401],
         [12428],
         [  319],
         [29902],
         [29963],
         [  517],
         [  300],
         [29987],
         [29915],
         [  262],
         [  297],
         [29958],
         [  313],
         [  313],
         [29915],
         [  278],
         [11561],
         [ 2063],
         [29914],
         [ 2680],
         [  363],
         [ 1454],
         [  263],
         [  680],
         [17605],
         [ 1109],
         [29892],
         [  284],
         [21141],
         [  368],
         [ 1220],
         [  392],
         [  306],
         [29915],
         [29915],
         [  680],
         [29874],
         [  273],
         [29924],
         [ 5062],
         [  313],
         [29924],
         [29924],
         [29933],
         [29933],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29871],
         [29874],
         [29874],
         [  370],
         [29874],
         [29892],
         [29871],
         [20543],
         [ 1457],
         [29874],
         [ 1131],
         [13892],
         [15641],
         [17605],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [29874],
         [  262],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [  271],
         [  856],
         [29883],
         [29874],
         [29874],
         [ 7846],
         [  856],
         [30488],
         [29882],
         [  856],
         [  856],
         [29874],
         [29874],
         [29871],
         [29899],
         [29871],
         [29896],
         [29874],
         [29895],
         [29898],
         [29931],
         [29871],
         [  276],
         [29874],
         [29892],
         [29874],
         [  365],
         [ 7345],
         [  517],
         [29931],
         [29924],
         [29883],
         [29874],
         [29889],
         [29892],
         [29874],
         [29896],
         [30488],
         [  517],
         [29874],
         [  517],
         [  262],
         [  392],
         [29896],
         [  855],
         [  262],
         [29876],
         [29874],
         [29883],
         [29874],
         [29889],
         [29892],
         [29899],
         [29874],
         [29892],
         [29874],
         [29896],
         [29874],
         [ 1762],
         [26272],
         [  517],
         [29874],
         [  271],
         [29896],
         [ 9160],
         [29874],
         [29874],
         [29896],
         [29874],
         [29874],
         [  856],
         [  856],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [  744],
         [  517],
         [29907],
         [29874],
         [29874],
         [29896],
         [ 6864],
         [ 1131],
         [29874],
         [29874],
         [28488],
         [29874],
         [29874],
         [29892],
         [29899],
         [  306],
         [29874],
         [29903],
         [29874],
         [  856],
         [26180],
         [  304],
         [29909],
         [27601],
         [29915],
         [29873],
         [ 1131],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  856],
         [29874],
         [29915],
         [  517],
         [29874],
         [29874],
         [29874],
         [29874],
         [27601],
         [29924],
         [  304],
         [  367],
         [29909],
         [ 1761],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29909],
         [  519],
         [29909],
         [29909],
         [27601],
         [ 1131],
         [ 2624],
         [  271],
         [29915],
         [29874],
         [  976],
         [29915],
         [29874],
         [29874],
         [29896],
         [  517],
         [29896],
         [ 1131],
         [ 2541],
         [ 2624],
         [ 4299],
         [ 9160],
         [29874],
         [29874],
         [  517],
         [  517],
         [29924],
         [ 6864],
         [29874],
         [ 2624],
         [30010],
         [29874],
         [  976],
         [29896],
         [29896],
         [  517],
         [29931],
         [29874],
         [30010],
         [29874],
         [29899],
         [29899],
         [  680],
         [  304],
         [29874],
         [29876],
         [  310],
         [29874],
         [29924],
         [ 2624],
         [29895],
         [ 2624],
         [ 2624],
         [  976],
         [ 1131],
         [  517],
         [29874],
         [  313],
         [29899],
         [29874],
         [ 1131],
         [ 1761],
         [ 1761],
         [  304],
         [  367],
         [29874],
         [  519],
         [29874],
         [29874],
         [ 2624],
         [ 2142],
         [ 2935],
         [  313],
         [29899],
         [29899],
         [  881],
         [  306],
         [29874],
         [  271],
         [  878],
         [  445],
         [29973],
         [  313],
         [29899],
         [29899],
         [29874],
         [  313],
         [29899],
         [29899],
         [ 2624],
         [30057],
         [29874],
         [29902],
         [  306],
         [28301],
         [29874],
         [29874],
         [29909],
         [29909],
         [  392],
         [ 1131],
         [29873],
         [  272],
         [29874],
         [29874],
         [29899],
         [  856],
         [29874],
         [29871],
         [ 1131],
         [  392],
         [29898],
         [29892],
         [29874],
         [29874],
         [29899],
         [29874],
         [ 1131],
         [29874],
         [29889],
         [  383],
         [  261],
         [  517],
         [29892],
         [ 1131],
         [29874],
         [29892],
         [29909],
         [29874],
         [29874],
         [29889],
         [ 1131],
         [29874],
         [29874],
         [ 2624],
         [ 1131],
         [29874],
         [29892],
         [29909],
         [29918],
         [29874],
         [29874],
         [  262],
         [29874],
         [29898],
         [29915],
         [29895],
         [29900],
         [29874],
         [29874],
         [29892],
         [29892],
         [  680],
         [29874],
         [ 1131],
         [ 1131],
         [ 1131],
         [ 1131],
         [  978],
         [29874],
         [  271],
         [  333],
         [29874],
         [ 4187],
         [15889],
         [29915],
         [29871],
         [30488],
         [29915],
         [29915],
         [29874],
         [  272],
         [29879],
         [ 1131],
         [29915],
         [29874],
         [29874],
         [29896],
         [  976],
         [  517],
         [29899],
         [29896],
         [ 1131],
         [27601],
         [ 2656],
         [29915],
         [29899],
         [ 6047],
         [28516],
         [ 1568],
         [  856],
         [29915],
         [27601],
         [27305],
         [ 1131],
         [ 1131],
         [ 1131],
         [  680],
         [  367],
         [  367],
         [ 2774],
         [29873],
         [ 1489],
         [ 7070],
         [ 2501],
         [ 3692],
         [27601],
         [29881],
         [27601],
         [29909],
         [27601],
         [16431],
         [ 1131],
         [ 1131],
         [ 6610],
         [29915],
         [29899],
         [29915]]], device='cuda:0')
torch.Size([2, 380, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   315, 29915,   856],
         [29871, 29899,   376,  ...,   294,   313, 29896],
         ...,
         [29871, 29899, 29892,  ...,   376, 29896,   341],
         [29871, 29899, 29892,  ..., 29874,   376,   315],
         [29899, 29871, 29892,  ..., 29874,   376,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29915, 30010, 29908,  ...,   294, 30166,  2831],
         [29899, 29892, 29915,  ...,   317,    13, 29898],
         [29915,   856, 29892,  ...,   392, 29898, 29874]]], device='cuda:0')
Batch 25, 47.4% of total tokens
encoded shape: torch.Size([2, 290])
torch.Size([2, 290]) tensor([[    1, 27930,   297,  5613,   322, 17986, 23093,   310,   360,  1883,
          3021,  4233, 17381,   711,  1557,  2002, 29889,    13,  1576, 21292,
           287, 18530, 15196,  4110,   310,   360,  1883,  3021,  4233, 17381,
           711,  1557,  2002,   892,  1304,   491,   498, 29889, 21451, 17599,
           550,  3459,   297, 29323,  3241,  3483,   952,   267,   310,  5613,
          9262, 29889,  3599,   296, 15729,   505, 28453,  3578,   373,   278,
          7208, 12903,   310,  9262, 17737, 17068,   304,   278,  6411,  8362,
         24324, 28611,   363,   278, 18530, 15196,  4110, 29889,   512, 17986,
         23093, 29892,  1716,  4655,  7117,   310,  6216,  2264, 29892,  3516,
          3097,   322, 19965,  1793, 29892,   526, 10868, 14278, 29892,   322,
         10812,  2531,   327,  7384,  4049,   505,   263,  1831,   573, 10631,
         29889, 10630, 11614,   526,   884,  9027, 14278, 29889,   450, 10868,
         26307,   322,  9027, 26307,   310,   278,  6216,  2264,  7117,   526,
           451, 15968, 29889,  3834,   413,   653,   327,  7384,   526, 13818,
         28482,   491, 10868,   470,  9027, 29892,   777,   526, 10029, 28482,
         29892,   322,   777,   437,   451,  2615,   304,   367, 28482,   472,
           599, 29889,   450,  6297,   310, 25745, 29877,  1537, 29887,   866,
         10631,   297,   278,  9262,   373,   278, 18530, 15196,  4110,   338,
           451,  2821, 29889,   739,   338,  3117,   697,  4100,  1543,   297,
           278, 12463,  9262, 29892,   541,  3516,  3097,   322, 19965,  1793,
           437,   451,  2337,  1510,   263, 25745, 29877,  1537, 29887,   866,
         10631, 29889, 10630,  3097,   322, 19965,  1793,  7117,   310,  9262,
          2833,   304,   367,  1048, 18018,  4100,   297,  6480,   297,  3259,
         29511, 29889, 27208,   286,  1218,  2551,   338,   385,  4100,  4163,
           310,  9262,   297,  5613, 23093, 29892,   322,   297,   697,  4665,
         10812, 14263,   413,   653,   327,  7384,   505,  1063,  1476,   304,
           505,   263, 11504, 20979,   286,  1218, 10631, 29889,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1, 29871, 29896, 29889,  8364,   936,  8989,    13,  4013,   297,
          7316,  1104,  1078,   304,  3519,   363,  2578,  1218,  4414,   314,
          2922,   706,  5855,   322,   304,   752,  3885,   322,  1374, 22824,
           346,   329,   936,  5541,  2187, 13907,   363,   727,   262, 29889,
            13, 29906, 29889, 16585, 10343,    13,  1576, 14502,   310,  4414,
           314,  2922,   706,  5855, 29892,  1316,   408,   472,   459,   293,
           589,  2922, 23448, 29892,  6958,   589,  2922, 23448, 29892,  6529,
           272,  3173,   275, 29892,   364,   354,   398,  1219,   333,   564,
           386,   768,   275, 29892,  3144, 12392,   352,   650,   561,   768,
           275, 29892,   288,  1655, 29877, 28696,   768,   275, 29892,   301,
           786,   375,   604,  1541,   331,  4507,   275, 29892,   269, 12121,
          6119,   655, 29892,  8717, 29882,   655,   322,  3805,   768,   519,
         12580,   295, 17135,   756, 29892,   297,   278,  4940, 29892,  9701,
           278,   671,   310, 19518,  1316,   408,  7051,   381,   262, 29899,
          4561,  1661,   303,  1489, 23670,  9418, 29899, 13453,   314,  2922,
           706, 19518, 29892,  3144,  1682,   542,   441,  1417,  4841, 29892,
           286,   621,   327,   276, 29916,   403,   322,  5094, 15126,   561,
         25715,   314,   680, 29889, 11511,  1438, 19518,  6892,  7738, 18500,
          9714,  2625,  9545, 29889, 26321, 29892,   278,  1661,   303,  1489,
         23670,  9418, 29899, 13453,   314,  2922,   706,  5883,  3174,  4049,
          4556,   330, 23364,   524,   342,   979,   322,  4325,   284,  2625,
          9545, 29889,  8467,  1682,   542,   441,  1417,  4841, 21301,   278,
          5198,  1540,  1788, 29892,  4550, 20811, 28602,  4695,   297, 20309,
           322,  1095,  8415,   262,   459,   493, 29891, 29889,   341,   621,
           327,   276, 29916,   403,   756,  1063,  6942,   411, 16500,  4892,
         29892,   322,  5094, 15126,   561, 25715,   314,   680,   756,  1559,
         16381,  6352,   293,   619,  3097, 29889,  6549, 29892,   716, 19518,
           363,  2578,  1218,  4414,   314,  2922,   706,  5855,   393,   526,
          3889,   310,  1438,   594,  3901,  2625,  9545,   526,  4312, 29889]],
       device='cuda:0')
torch.Size([2, 290, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -6.1875,  -4.6172,   2.4062,  ...,  -3.8281,  -4.2617,  -3.5156],
         [ -7.9531, -13.1562,  -1.9346,  ...,  -4.5742,   2.0879,  -5.0430],
         ...,
         [ -5.6133, -10.1406,  -2.7109,  ...,  -6.8242,  -2.8066,  -6.1562],
         [ -5.5938, -10.1875,  -2.8770,  ...,  -6.8125,  -2.7734,  -6.1602],
         [ -5.6914, -10.2734,  -2.9453,  ...,  -6.8633,  -2.8223,  -6.2109]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7754,  -4.3477,  -3.3770],
         [ -6.7617,  -4.9141,   3.0273,  ...,  -3.6504,  -4.2383,  -4.0039],
         ...,
         [ -3.8164,  -1.2744,   0.2098,  ...,  -2.9746,  -3.3145,  -2.6035],
         [ -5.8203,  -3.7207,   1.0117,  ...,  -3.7285,  -3.5977,  -2.9375],
         [ -5.8672,  -4.4688,   1.2910,  ...,  -3.7344,  -3.4082,  -3.3555]]],
       device='cuda:0')
torch.Size([2, 290, 1]) tensor([[[29918],
         [29899],
         [29928],
         [29909],
         [29909],
         [29909],
         [29874],
         [29874],
         [29871],
         [29871],
         [29933],
         [29874],
         [29899],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [29871],
         [ 2364],
         [29928],
         [29871],
         [29874],
         [29933],
         [29874],
         [29871],
         [29903],
         [29874],
         [29874],
         [23333],
         [  517],
         [29909],
         [29871],
         [29874],
         [29871],
         [29909],
         [29874],
         [  517],
         [  578],
         [ 3241],
         [ 1131],
         [  952],
         [30488],
         [30488],
         [30488],
         [30488],
         [  627],
         [29874],
         [30488],
         [30488],
         [30488],
         [30488],
         [29882],
         [  373],
         [  856],
         [30488],
         [  262],
         [ 1491],
         [  262],
         [  627],
         [29871],
         [  517],
         [  262],
         [  262],
         [  262],
         [  262],
         [28611],
         [ 5521],
         [  262],
         [  262],
         [29874],
         [29871],
         [ 3733],
         [29874],
         [  509],
         [29928],
         [29874],
         [  262],
         [  262],
         [29899],
         [ 1457],
         [29928],
         [29899],
         [ 2308],
         [29875],
         [  370],
         [  392],
         [  262],
         [29924],
         [29874],
         [29985],
         [ 1131],
         [29928],
         [  627],
         [  627],
         [29874],
         [29899],
         [  300],
         [ 7384],
         [ 5521],
         [29909],
         [ 6216],
         [29950],
         [29874],
         [29875],
         [  627],
         [  797],
         [  519],
         [ 3733],
         [ 2236],
         [  627],
         [  262],
         [17605],
         [  797],
         [29875],
         [29985],
         [29985],
         [29875],
         [23149],
         [17260],
         [ 6216],
         [29875],
         [29875],
         [29875],
         [  627],
         [29985],
         [29903],
         [  262],
         [ 3733],
         [29875],
         [29890],
         [29874],
         [ 7384],
         [ 2687],
         [29875],
         [29909],
         [  491],
         [29928],
         [29874],
         [29928],
         [29928],
         [  392],
         [29882],
         [ 1129],
         [13453],
         [  392],
         [  392],
         [29874],
         [ 3733],
         [29882],
         [10049],
         [  304],
         [10049],
         [13453],
         [ 5108],
         [  599],
         [29874],
         [ 3733],
         [29875],
         [  974],
         [  262],
         [29874],
         [29909],
         [29871],
         [29950],
         [29899],
         [  627],
         [29928],
         [29928],
         [ 5521],
         [29928],
         [29928],
         [16401],
         [29875],
         [ 2778],
         [ 1131],
         [29903],
         [ 7582],
         [23333],
         [29874],
         [29928],
         [29909],
         [  974],
         [ 7329],
         [  627],
         [ 5521],
         [29924],
         [ 2622],
         [ 2139],
         [ 4187],
         [  509],
         [  519],
         [29909],
         [29928],
         [29924],
         [21731],
         [29882],
         [29909],
         [29909],
         [29950],
         [29950],
         [29933],
         [29909],
         [29874],
         [29903],
         [29909],
         [14131],
         [29875],
         [  519],
         [23333],
         [29874],
         [29875],
         [29909],
         [29985],
         [ 6216],
         [ 5521],
         [  304],
         [ 5521],
         [29985],
         [ 5521],
         [13453],
         [  627],
         [14131],
         [ 1552],
         [29928],
         [ 7713],
         [14131],
         [23333],
         [29899],
         [  376],
         [29875],
         [ 9700],
         [29985],
         [29874],
         [ 1831],
         [  974],
         [ 6216],
         [  627],
         [ 1131],
         [23093],
         [29874],
         [ 4187],
         [29874],
         [ 1131],
         [29909],
         [29874],
         [  392],
         [29903],
         [29871],
         [29874],
         [ 7384],
         [ 3733],
         [29874],
         [23333],
         [  517],
         [ 1131],
         [29874],
         [ 2622],
         [29933],
         [ 1831],
         [ 1218],
         [29875],
         [  262],
         [29875],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899]],

        [[29918],
         [29871],
         [29871],
         [   13],
         [29871],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29899],
         [30488],
         [30488],
         [29871],
         [30488],
         [30488],
         [30488],
         [  262],
         [30488],
         [29892],
         [29892],
         [29874],
         [29892],
         [29874],
         [29874],
         [15403],
         [29874],
         [29903],
         [30488],
         [29924],
         [29871],
         [29903],
         [29928],
         [29874],
         [29892],
         [29874],
         [29909],
         [  459],
         [29874],
         [29928],
         [29874],
         [  856],
         [  392],
         [29874],
         [29928],
         [29874],
         [29903],
         [  392],
         [30488],
         [29909],
         [29909],
         [29874],
         [  392],
         [29874],
         [  354],
         [29874],
         [  517],
         [29899],
         [29928],
         [29874],
         [29933],
         [29874],
         [  392],
         [29874],
         [29874],
         [29874],
         [29924],
         [29874],
         [29875],
         [29879],
         [29874],
         [29874],
         [29874],
         [29874],
         [  564],
         [29873],
         [29879],
         [29874],
         [29874],
         [29915],
         [29874],
         [  561],
         [29909],
         [29874],
         [29873],
         [  375],
         [29874],
         [29899],
         [29871],
         [29892],
         [29924],
         [29874],
         [29899],
         [29875],
         [  655],
         [29874],
         [29874],
         [29874],
         [29933],
         [29933],
         [  295],
         [22898],
         [29874],
         [29909],
         [29874],
         [  578],
         [29925],
         [29874],
         [14969],
         [29874],
         [  262],
         [29874],
         [29874],
         [ 2622],
         [29874],
         [29909],
         [  262],
         [  262],
         [29909],
         [20211],
         [29903],
         [16864],
         [ 1489],
         [  333],
         [29909],
         [13453],
         [13453],
         [29924],
         [29871],
         [  313],
         [29928],
         [29909],
         [29874],
         [30488],
         [29871],
         [29871],
         [29879],
         [ 4841],
         [  392],
         [  392],
         [30488],
         [  856],
         [29892],
         [29903],
         [  371],
         [  392],
         [29874],
         [29909],
         [29903],
         [29871],
         [29892],
         [  680],
         [29874],
         [29874],
         [29874],
         [29874],
         [29909],
         [29909],
         [29874],
         [  295],
         [  392],
         [ 9545],
         [29874],
         [29874],
         [29874],
         [ 3144],
         [  262],
         [16864],
         [29903],
         [  333],
         [29903],
         [13453],
         [13453],
         [29924],
         [29899],
         [  517],
         [26179],
         [29874],
         [ 4692],
         [  627],
         [29874],
         [  368],
         [  524],
         [29899],
         [  262],
         [22330],
         [29950],
         [  284],
         [  517],
         [ 9545],
         [29874],
         [ 8467],
         [29871],
         [29879],
         [29933],
         [29879],
         [ 4841],
         [  392],
         [29928],
         [30488],
         [ 1540],
         [ 2933],
         [  392],
         [  392],
         [  368],
         [29874],
         [29933],
         [  297],
         [ 1725],
         [ 2858],
         [29874],
         [29899],
         [  262],
         [29903],
         [29874],
         [29879],
         [29874],
         [  341],
         [29892],
         [29871],
         [29892],
         [29874],
         [29903],
         [ 1129],
         [  517],
         [29924],
         [  411],
         [29874],
         [29899],
         [29879],
         [29874],
         [29874],
         [29871],
         [29903],
         [29933],
         [29933],
         [29933],
         [29909],
         [  517],
         [  262],
         [  520],
         [ 6656],
         [10072],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  392],
         [29909],
         [ 1552],
         [29874],
         [ 4414],
         [  314],
         [29889],
         [30879],
         [29928],
         [30488],
         [29909],
         [  262],
         [29928],
         [  262],
         [ 2625],
         [29874],
         [29928],
         [ 9545],
         [30488],
         [30488],
         [29874],
         [29874]]], device='cuda:0')
torch.Size([2, 290, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29899, 29874, 29871,  ...,   315, 29882,   392],
         [29928, 29874, 29924,  ..., 29882, 29875, 29934],
         ...,
         [29899, 29892, 29871,  ..., 29908,    13,   315],
         [29899, 29892, 29871,  ...,   313, 29908,   315],
         [29899, 29892, 29871,  ...,   313, 29908,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29874, 29899,  ...,   376,   313,   856],
         ...,
         [30488, 30879, 31147,  ..., 31488,   856, 29874],
         [29874,   262, 29875,  ..., 29909, 29881, 29882],
         [29874, 29892, 29875,  ..., 29882, 30010,   856]]], device='cuda:0')
Batch 26, 48.0% of total tokens
encoded shape: torch.Size([2, 3723])
torch.Size([2, 3723]) tensor([[    1,   660, 29901,  ...,  5527,    13,    13],
        [    1,  2796,  8415,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3723, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.1562,  -6.3906,   3.4883,  ...,  -4.6445,  -5.0781,  -3.9922],
         [ -9.1172,  -7.9531,   0.1221,  ...,  -4.9141,  -3.4141,  -4.8906],
         ...,
         [ -5.8086,  -3.1035,   0.1467,  ...,  -4.5508,  -3.9551,  -4.0898],
         [ -4.3594,  -2.8105,   1.4727,  ...,  -3.9062,  -3.9922,  -3.0527],
         [ -4.5742,  -3.1465,   1.6064,  ...,  -3.9023,  -3.8867,  -2.8086]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -9.8828, -10.9844,   3.5137,  ...,  -6.3086,  -4.7930,  -6.3125],
         [-11.4219, -13.3594,   1.1094,  ...,  -6.9023,  -6.0000,  -7.5195],
         ...,
         [ -8.3516,   2.0273,   1.1182,  ...,  -2.6406,  -5.1562,  -1.9697],
         [ -8.3203,   2.0312,   0.9517,  ...,  -2.6406,  -5.1328,  -1.9990],
         [ -8.3125,   2.0391,   0.9219,  ...,  -2.6328,  -5.1211,  -1.9990]]],
       device='cuda:0')
torch.Size([2, 3723, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29892],
         [29892]],

        [[29918],
         [29899],
         [  262],
         ...,
         [29918],
         [29918],
         [29918]]], device='cuda:0')
torch.Size([2, 3723, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29874, 29875,   262,  ...,   392, 29876, 29909],
         [29892, 29889,   313,  ..., 30879, 29915, 29914],
         [29892, 29871, 29899,  ..., 29914,   315,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29899, 29874, 29871,  ...,   317,   272, 29898],
         [  262, 29874,   315,  ..., 29924, 29882, 29896],
         ...,
         [29918, 29879, 29915,  ..., 29973,   229, 29892],
         [29918, 29879, 29915,  ..., 29973,   229, 29892],
         [29918, 29879, 29915,  ..., 29973,   229, 29892]]], device='cuda:0')
Batch 27, 51.9% of total tokens
encoded shape: torch.Size([2, 410])
torch.Size([2, 410]) tensor([[    1, 16340, 29892,  3979, 29871, 29896, 29947, 29892, 29871, 29906,
         29900, 29896, 29947,    13,    13, 18498,   271, 29901,  5593, 12469,
           378, 29887,   602,   472,  6298,   271,  4799,   637,   297,   278,
          1833,  7303,   310,  7378,   756,  9508,   287,  5593,  4011, 13361,
           537,   310,  7513,   313,  6344, 29902, 29897,   304,  1925, 22035,
          5313,  3631,   664,   373,   263,  5172,  5702, 29889,  2973,   263,
          1776,   304,  1653, 24454,   363,   610,  9292,   310,  7968, 15780,
           763,   319,  5659, 29879,   322,   660, 29946, 29900, 29900, 29892,
           278, 22704, 29902,   756, 16610, 22707,   363,  5849,   310,  2030,
         21783,   265,   472,   278,  4799,   637, 29889,   450,   337, 25431,
           310,   278,  2030, 21783,   265,   674,  1653,   716,   298,  4600,
          2913,   363,  7968, 15780,   363,   610,  9292, 29892,  8363, 29892,
           443, 13234,   322,  2143, 29884,  7807, 29889,    13,    13, 29949,
          7880,  8974,  1497,   278,  2030, 21783,   265,   674,   367,   701,
           322,  7960,   363,   671,   491,  2319, 15780,   297,  2446,  3023,
          7378,   322,   393, 13184,   310,  1667, 21783,   265,   338,  5517,
           304,   367,  8676,   491,  3979, 29871, 29906, 29900, 29906, 29900,
         29889,  2180,  2198, 29892,   727,   526,  3001, 29871, 29945, 29947,
         16286, 24147,   639,  2462, 29899, 29906, 29929, 18517, 29879,   322,
         29871, 29906, 29929,  5840,  1973, 29899,  3166,  6298,   271,  4799,
           637, 29889,   450,  4799,   637,  8638,  9242,   521,  1698, 29899,
         29874, 29899,  1271, 10106,   278,  2462,  2861,   304, 18517,   322,
         25619,   310, 28134, 29889,  1094,   639, 22704, 29902,   848, 29892,
           278,  3001, 28507, 12469,   297,  5533, 21692, 29871, 29896,   425,
         15339,  2791,   322,   393,   372,   338,  3806,   304,  4340,  7910,
           304, 29871, 29896, 29889, 29945,   425, 15339, 28134,   639,  4098,
           491,  6339, 29871, 29906, 29900, 29896, 29929, 29889,    13,    13,
          1576,  4799,   637,   338,  6766,   491,  5593,  7513, 29892,  5593,
          2887,   423, 29892,  1894, 29875,  8120, 29892,  1706,   625, 29967,
           300, 29892,  5593,  6715,   728, 29874,   322, 21141,  2002,  5593,
         14971, 29889,   317,  2863,  1497,   393,   278, 14218, 16286, 24147,
           674,  7910,   515, 29871, 29906, 29929,   304, 29871, 29941, 29941,
           491,  3979, 29899,   355,   411,   278,  6826,   310,  3023,   716,
          1652,  5861,   491,  1706,   625, 29967,   300, 16791,  6298,   271,
           304,   501,  1388,   666,   332, 29892,   435,  1759,   284,  1050,
         29892, 11681,   273,  6840,   322,  2921, 29874, 29889,    13, 29896,
         29947, 29914, 29896, 29896, 29914, 29896, 29947, 10277,   310,  7513,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,  7997,  4412,   365,  5861,   498,  2004, 26240,    13,    13,
          4013,  7997,  4412,   365,  5861,   498,  2004, 26240, 15223,   263,
          9758,  4366,   373,  1570,  3088,  4412, 29991,    13,    13, 12148,
          1831,   385,  2984,    13,    13, 13026,    13,    13, 29938, 29896,
         29892, 29947, 29955, 29929, 29889, 29929, 29929,    13,    13,  6293,
          1122,   884,   763,    13,    13, 10602,  2713, 17347,  5618, 29915,
         29879,   512, 13347,    13,    13, 29949,   332,  7997,  4412,   365,
          5861,   498,  2004, 26240,   674,  1371,   366,   337,  3258,   278,
         15709,   310, 23526, 29907, 29889,   910, 21863,   292, 29892,  4272,
           963,   287, 10200,  1218,   413,   277,  7805,  9849,   293,  5214,
         17761, 29892, 29871, 29941, 29928, 23526, 29907,  3578,   287,  8721,
         29892, 13283,  4272, 11952, 26068, 29892,   263,  2989, 18786,  5700,
           449, 29892,   322,   263,  4272, 14744,  1220,  3239, 29889,    13,
            13, 29928,   434,   304,  4978,   322,  7794,   575,   292,  2702,
           800, 29892,   445,  3234,  2609,   367,   528, 16242,  5377,  8278,
         29889,    13,    13, 29956, 25614, 29901,    13,  4013,  3234,   508,
         24396,   366,   304, 22233, 29879,  3704,  5012,  3954, 29892,   607,
           338,  2998,   304,   278,  4306,   310,  8046,   304,  4556, 23900,
           322, 12060, 23503, 29879,   470,   916,   337,  4704,   573, 10311,
         29889,  1152,   901,  2472,   748,   304,    13,  1636, 29889, 29925,
         29953, 29945, 29956,  2753,   886, 29889,  1113, 29889, 13513, 29889,
            13,    13,  7566,  5920, 29901,   476, 29907, 29906, 29896, 29945,
         29947,    13,    13, 12148,  2758,   626,   552,   931,   363, 28289,
         29889,   450, 28289,  2635,   363,   445,  3234,   338, 11682,  2038,
           363,  3148,   528, 17347,   871, 29889,  3529,  2737,   304, 24808,
           363, 28289, 10116,  5377,   310,   278,  2866,  5526,   681, 29871,
         29946, 29947,  3900, 29889,    13,    13,  2713, 17347, 21090,   526,
          2729,   373,   278,   995,   310,   278,  2778,   305,   392,   895,
           322,   451,   278,  1353,   310,  7751,  1860, 29889,  1152,  5684,
           528, 17347,  2472, 29892,  3113,  6958,  1749, 21886,  6692, 10317,
           472, 29871, 29947, 29900, 29900, 29899, 29941, 29946, 29947, 29899,
         29945, 29900, 29947, 29946, 29889,    13,    13, 15122,   830,  7406,
            13,    13, 15122,   894, 29879,   669,   530,  5956,    13,    13,
          9868, 29901,    13, 29949,   332, 21863,   292,  1771, 23951, 13402,
          8345, 26240,  4076,   596,  1741,    13, 29874,   380, 27389,  1106,
         29889,   910,   429,  7680,   568,  6263,   413,   277,  7805,   337,
         27979, 12286,  1316,   408,  3578,   287, 10697, 29892, 19703,  1475,
          1760,  4341, 29892,  1302,   384, 18237,  6131,   322,   263,  3578,
           287,   521,   392,   295,   631,   393,   526,  1854,   304,  5967,
           596,  6263, 28865,   297,   263,   705, 29889,  3940, 29901,  2216,
           599,  4452,   282,   919,  2955,   526,  5134, 29889,  3529,  2023]],
       device='cuda:0')
torch.Size([2, 410, 32000]) tensor([[[ -8.9844,   0.8472,   0.6909,  ...,  -3.0449,  -5.3633,  -2.3750],
         [ -7.7539,  -6.4297,   2.0527,  ...,  -4.6172,  -4.5508,  -4.9336],
         [ -6.9258,  -8.2500,  -2.0293,  ...,  -2.2402,   3.1250,  -2.9902],
         ...,
         [ -6.2305,  -4.6250,   2.6211,  ...,  -4.2539,  -4.1836,  -3.6621],
         [ -6.1680,  -4.5508,   2.6191,  ...,  -4.2148,  -4.1641,  -3.6387],
         [ -6.1445,  -4.5078,   2.6289,  ...,  -4.2031,  -4.1602,  -3.6484]],

        [[ -8.9844,   0.8472,   0.6909,  ...,  -3.0449,  -5.3633,  -2.3750],
         [ -9.9609, -10.5312,   3.1035,  ...,  -6.6914,  -4.6484,  -7.0078],
         [ -9.4375, -14.8984,  -3.0195,  ...,  -7.5938,  -3.6094,  -7.4883],
         ...,
         [ -6.3086,  -5.5898,   1.1465,  ...,  -3.6484,  -2.9473,  -3.6680],
         [ -4.9648,  -3.8359,   0.5781,  ...,  -2.8203,  -3.3203,  -3.3125],
         [ -4.9219,  -3.5566,   1.5547,  ...,  -3.5547,  -4.1484,  -3.0469]]],
       device='cuda:0')
torch.Size([2, 410, 1]) tensor([[[29918],
         [29871],
         [  386],
         [29871],
         [29871],
         [29896],
         [  386],
         [29906],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [  313],
         [30488],
         [30488],
         [30488],
         [29874],
         [30488],
         [30488],
         [30488],
         [  856],
         [30488],
         [30488],
         [29871],
         [30488],
         [30488],
         [  376],
         [30879],
         [30488],
         [29874],
         [29881],
         [29909],
         [  376],
         [30488],
         [  287],
         [  262],
         [30879],
         [29874],
         [29874],
         [29874],
         [  262],
         [  517],
         [29892],
         [29871],
         [29874],
         [  517],
         [29909],
         [  262],
         [12425],
         [29874],
         [  392],
         [  373],
         [  376],
         [30879],
         [29899],
         [ 4464],
         [  376],
         [  262],
         [29871],
         [29874],
         [  262],
         [29874],
         [29903],
         [29874],
         [  262],
         [29874],
         [29909],
         [29909],
         [29879],
         [30879],
         [29871],
         [  392],
         [  392],
         [  856],
         [29871],
         [29900],
         [29900],
         [29879],
         [29874],
         [29874],
         [29871],
         [  275],
         [ 8459],
         [29874],
         [ 1454],
         [29934],
         [  284],
         [29874],
         [29874],
         [29871],
         [29903],
         [29903],
         [29874],
         [29874],
         [29874],
         [29892],
         [  262],
         [29899],
         [  284],
         [21783],
         [21783],
         [21783],
         [29871],
         [31684],
         [ 3438],
         [29874],
         [  610],
         [29871],
         [29903],
         [ 1454],
         [  262],
         [24347],
         [29879],
         [29874],
         [29871],
         [  262],
         [29874],
         [  392],
         [30488],
         [29899],
         [  392],
         [31147],
         [  262],
         [ 7807],
         [29874],
         [29892],
         [29892],
         [29899],
         [  262],
         [29874],
         [29874],
         [  262],
         [  262],
         [29909],
         [29871],
         [ 7540],
         [  367],
         [29909],
         [29899],
         [29903],
         [31713],
         [29909],
         [ 3428],
         [ 4779],
         [  392],
         [ 7320],
         [  262],
         [  517],
         [ 9404],
         [  354],
         [29909],
         [29915],
         [29903],
         [ 1552],
         [29909],
         [29874],
         [22752],
         [  262],
         [  517],
         [ 4866],
         [ 7960],
         [ 3428],
         [ 3364],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [  517],
         [  376],
         [  262],
         [29871],
         [ 1552],
         [ 1454],
         [29871],
         [29903],
         [29896],
         [29896],
         [29909],
         [29903],
         [  271],
         [29909],
         [  262],
         [29871],
         [29896],
         [  262],
         [29879],
         [  392],
         [29871],
         [29871],
         [29874],
         [29874],
         [  292],
         [  271],
         [  472],
         [  392],
         [29871],
         [  262],
         [29874],
         [  262],
         [  376],
         [  262],
         [29874],
         [29874],
         [29903],
         [29883],
         [31147],
         [29899],
         [31147],
         [29899],
         [29933],
         [ 2541],
         [ 1552],
         [29903],
         [ 2230],
         [  304],
         [  262],
         [29879],
         [  311],
         [  974],
         [ 1652],
         [  262],
         [  376],
         [  680],
         [29903],
         [29871],
         [29915],
         [29874],
         [ 3001],
         [29874],
         [29928],
         [29928],
         [  262],
         [  392],
         [  262],
         [  262],
         [29871],
         [29931],
         [29874],
         [29903],
         [  262],
         [  262],
         [29903],
         [29903],
         [  262],
         [  304],
         [  262],
         [  262],
         [  262],
         [  262],
         [29896],
         [29906],
         [29896],
         [ 2364],
         [15339],
         [ 3364],
         [  262],
         [29924],
         [  262],
         [ 3364],
         [29874],
         [29906],
         [29900],
         [29896],
         [29871],
         [29874],
         [  376],
         [29892],
         [ 2277],
         [  262],
         [  637],
         [29874],
         [  262],
         [  491],
         [  262],
         [30879],
         [  262],
         [30879],
         [30879],
         [  262],
         [  262],
         [30879],
         [29899],
         [29899],
         [  392],
         [30879],
         [30879],
         [  392],
         [31147],
         [  392],
         [30879],
         [30879],
         [30488],
         [29874],
         [  392],
         [30879],
         [30879],
         [  262],
         [30488],
         [29879],
         [  376],
         [29899],
         [29874],
         [29963],
         [  262],
         [  262],
         [29909],
         [13529],
         [11843],
         [  262],
         [  304],
         [29876],
         [29871],
         [29871],
         [  517],
         [29871],
         [29871],
         [29896],
         [  376],
         [ 3364],
         [29874],
         [29915],
         [  392],
         [  262],
         [  262],
         [  292],
         [29963],
         [29899],
         [ 1652],
         [29871],
         [ 6610],
         [29963],
         [29871],
         [29967],
         [31147],
         [ 3372],
         [  262],
         [29871],
         [ 2541],
         [  262],
         [29899],
         [29871],
         [29874],
         [  392],
         [  262],
         [29871],
         [29871],
         [29871],
         [29874],
         [  262],
         [29871],
         [29871],
         [  392],
         [  262],
         [29874],
         [ 5062],
         [  376],
         [29892],
         [29871],
         [29899],
         [29896],
         [29896],
         [29899],
         [29889],
         [29871],
         [30488],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871]],

        [[29918],
         [29899],
         [29874],
         [29871],
         [  680],
         [  262],
         [29874],
         [29871],
         [  313],
         [29871],
         [29874],
         [29874],
         [29931],
         [29873],
         [29899],
         [29871],
         [29874],
         [29903],
         [29874],
         [29882],
         [29903],
         [  373],
         [29882],
         [29874],
         [29915],
         [29915],
         [  262],
         [29899],
         [29892],
         [30488],
         [29871],
         [29871],
         [30488],
         [29871],
         [29871],
         [29874],
         [29871],
         [29899],
         [29871],
         [29896],
         [29871],
         [29871],
         [29871],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29899],
         [29882],
         [29871],
         [29874],
         [29915],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29899],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29903],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  310],
         [31147],
         [29907],
         [29915],
         [  262],
         [29882],
         [  292],
         [29899],
         [30488],
         [30488],
         [  856],
         [31147],
         [  392],
         [  262],
         [  277],
         [  797],
         [29871],
         [29899],
         [29892],
         [29899],
         [  392],
         [29889],
         [29896],
         [29928],
         [29899],
         [29907],
         [30488],
         [29899],
         [30879],
         [  392],
         [29892],
         [29899],
         [29899],
         [29903],
         [  392],
         [29892],
         [29871],
         [29899],
         [29892],
         [29899],
         [  392],
         [29892],
         [  392],
         [29871],
         [29879],
         [ 1220],
         [29889],
         [29909],
         [30488],
         [29899],
         [29899],
         [29892],
         [29874],
         [29874],
         [  284],
         [29899],
         [  575],
         [  292],
         [29903],
         [29871],
         [29892],
         [29892],
         [29882],
         [29924],
         [30488],
         [30488],
         [  528],
         [  262],
         [ 1552],
         [29874],
         [29892],
         [29899],
         [29899],
         [29871],
         [29899],
         [29915],
         [29899],
         [29915],
         [29903],
         [30488],
         [29874],
         [29874],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29874],
         [29889],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29883],
         [29933],
         [29874],
         [29933],
         [29874],
         [29871],
         [30488],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [30488],
         [29874],
         [29892],
         [29871],
         [29892],
         [29871],
         [29945],
         [29874],
         [29874],
         [29871],
         [29874],
         [29892],
         [29874],
         [29908],
         [29874],
         [29874],
         [29871],
         [29899],
         [29874],
         [29871],
         [29874],
         [29896],
         [29896],
         [29896],
         [29896],
         [29874],
         [29899],
         [29871],
         [29899],
         [29874],
         [29874],
         [29871],
         [29903],
         [29874],
         [29882],
         [29874],
         [29915],
         [29874],
         [29882],
         [30488],
         [29889],
         [29874],
         [29874],
         [30879],
         [30488],
         [30488],
         [29874],
         [29899],
         [29934],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29903],
         [29874],
         [  375],
         [ 1552],
         [29903],
         [  262],
         [29874],
         [  375],
         [29946],
         [29947],
         [  375],
         [29874],
         [29892],
         [29899],
         [29899],
         [  262],
         [29874],
         [29874],
         [29882],
         [29874],
         [29874],
         [29874],
         [  392],
         [29874],
         [  392],
         [29871],
         [  392],
         [29933],
         [  392],
         [29903],
         [29903],
         [29903],
         [29874],
         [29903],
         [29899],
         [30488],
         [29915],
         [29924],
         [29874],
         [29875],
         [29903],
         [29874],
         [29889],
         [29874],
         [29874],
         [29874],
         [29874],
         [  262],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29889],
         [29899],
         [29899],
         [29899],
         [29874],
         [29871],
         [29892],
         [29871],
         [29874],
         [  856],
         [  856],
         [30488],
         [29871],
         [29874],
         [29892],
         [29892],
         [29899],
         [29892],
         [29892],
         [29871],
         [29874],
         [  292],
         [  392],
         [29889],
         [  392],
         [  392],
         [  392],
         [  392],
         [29874],
         [29882],
         [29915],
         [29892],
         [  262],
         [  538],
         [  392],
         [  262],
         [29892],
         [  392],
         [  392],
         [  277],
         [  392],
         [29903],
         [  277],
         [24366],
         [29871],
         [29874],
         [29892],
         [  392],
         [29874],
         [  856],
         [29899],
         [29899],
         [  392],
         [  392],
         [  262],
         [29883],
         [  392],
         [  392],
         [  392],
         [29874],
         [29909],
         [29909],
         [  680],
         [  856],
         [  392],
         [29899],
         [  392],
         [  392],
         [29871],
         [ 4926],
         [  392],
         [ 4486],
         [  392],
         [  304],
         [  281],
         [29874],
         [29874],
         [ 1131],
         [12032],
         [  263],
         [  705],
         [  705],
         [29892],
         [29871],
         [29874],
         [29874],
         [29899],
         [29903],
         [29871],
         [29871],
         [  262],
         [30879],
         [  262],
         [29892],
         [29874],
         [29871]]], device='cuda:0')
torch.Size([2, 410, 10]) tensor([[[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29874, 29892,  ..., 29896,   313,   317],
         [  386, 29909,   262,  ...,   271,   303,  2541],
         ...,
         [29899, 29871, 29892,  ...,    13, 29874,   856],
         [29899, 29871, 29892,  ...,    13, 29874,   856],
         [29899, 29871, 29892,  ...,    13, 29874,   856]],

        [[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29899, 29871, 29892,  ...,   262, 29875,   313],
         [29874, 29875, 29871,  ..., 29924, 29909,   392],
         ...,
         [29892,   313, 29899,  ..., 29896, 29876, 29903],
         [29874, 29903, 29909,  ..., 29883, 29881, 29911],
         [29871, 29892, 29899,  ..., 29874, 29898, 29915]]], device='cuda:0')
Batch 28, 52.7% of total tokens
encoded shape: torch.Size([2, 438])
torch.Size([2, 438]) tensor([[    1,   450,  2779,   310, 26900,  3677,   335,   575, 29892,  8175,
         29892,  7916, 29892,   322, 19224,   349,  4717,   373, 15899, 19194,
         10534,   931,   363,   263,   937,  9747,   369, 26397,  3801,  1301,
         24389, 29889,    13, 29896, 29889, 29008,  1017, 29899, 28319, 26900,
         17292,   327,  7384,  3633,   363, 29871, 29929, 29945, 29995,   310,
           278,  4665, 10534,   363,   263,  1301, 24389,   322,  1058,   505,
          4520,   263,  1301, 24389, 29889,  1670,   526, 29871, 29896, 29945,
         11000,   393,  3633,   363, 29871, 29946, 29953, 29995,   310,   278,
          4665, 29889,  8218,   479, 12651,   297,   278,  4978,   310, 26900,
         17292,   327,  7384,  1546,   278, 19830,   892,  8900, 29889, 29871,
         29906, 29889,  1670,   437,   451,  2615,   304,   367,  7282, 12651,
          4249,   278, 29871, 29896, 29945, 26900, 17292,   327,  7384,   297,
           278,  6554,   310,  1301, 24389,   362, 29889,  1670,   526, 29892,
          3138, 29892,  7282, 12651,   297,   278, 19194, 10534,   931,   304,
           263,   937,  9747,   369, 26397,  3801,  1301, 24389,  4822,   278,
         29871, 29896, 29945, 26900, 17292,   327,  7384, 29889, 29871, 29941,
         29889,  6054, 29879,   526,   451,  1641,  1301,   572,  9714,   297,
         18618,   304,  1009,  3694,   373,   278,  1051,   310,  1906,  7272,
           292,   263,  1301, 24389, 29889,  6054, 29879,  2755, 14235, 29871,
         29906, 29955, 29995,   310,   278,  4665, 10534,   363,   263,  1301,
         24389, 29892,   541,  2755,   871, 29871, 29906, 29906, 29889, 29953,
         29995,   310,   278,  4665,   607, 20586,   263,   937,  9747,   369,
         26397,  3801,  1301, 24389, 29889, 29871, 29946, 29889,   450, 15899,
         19194, 10534,   931,   363,  6054, 29879,   338,  4359,  8951,   393,
           310,   806,  3246, 29889,  1932,  5046, 29892, 19224,   349,  4717,
         29892, 26900, 17292,   327,   668, 29892, 10416,  1134, 29892,   322,
          7916,   526, 20704, 29892,  6054, 29879, 29892,   746,  9401,   304,
           806,  3246, 29892,   526,  1603, 29871, 29896, 29947, 29995,  3109,
          5517,   304,  7150,   263,   937,  9747,   369, 26397,  3801,  1301,
         24389,   472,   738,  1298,   297,   931, 29889,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2],
        [    1,   450,  6297,   310,   301,   653, 29876,   479,   284,  9238,
         10678,   618,   297,   278, 24809,   358,   310,  8939,  7163,  2200,
           270,   952,   561,  6405,   322,   851, 23377, 29889,    13, 29928,
           952,   561,  6405,   322,   851, 23377,   526,   451,  3041,   276,
         16011,   297,   278,  8939,  7163,  2200,  4665, 29889, 22886,  1296,
          8281,   324,   653,   865,   359,  8552,   313,  2190, 29931, 29897,
           338,   278,  7601,   652, 21780,  8792,  1304,   304, 14707,   263,
          2278,   411,   851, 23377,   322, 29914,   272,   270,   952,   561,
          6405, 29889,   450,  4655, 29485,   310,   445, 11043,   338,  6460,
          1302, 16453,   297,  4344, 29892,  9819,   297,   297,  1943,   339,
           403,  7604,  2133,   310,   278,   301,   653, 23818, 29889, 10103,
         10678,   618,   338,   263, 17644,  1304,  1661,   262,  4428,   573,
          6382,   292,   878,  2877,   393,   756,  3447,   304,   367,  7436,
           304,   278,   301,   653, 29876,   479,   284,  4392,  3381, 29889,
          8680,  7306,   471,   304, 23033,   278, 28326,  4127,   322,   652,
         21780,  7037,   310,   301,   653, 29876,   479,   284,  9238, 10678,
           618,   313, 29931,  3308, 29897,   297,  4251,   310,  8939,  7163,
          2200,   851, 23377,   322, 29914,   272,   270,   952,   561,  6405,
         29889,  1019, 29879, 12645, 16842,   287, 16165,   441,  6559,   310,
          3041,  1934,   322,  4344, 29871, 29900, 29899, 29896, 29953,  2440,
           310,  5046, 12992,   363, 13764, 29931,  2861,   304,  7314,   766,
         20488,   322, 29914,   272,   851, 23377, 29889, 22096,  7134,   310,
           278,   634, 29875,  3002,   471,  5545,   385,   429, 10085, 28770,
           291, 29889,   365,  3308,   378,  2764,  1127,   411,   278, 13764,
         29931,   297,   278, 24876, 19263,   310,   633,  8945,  7186,  4226,
           301,   653, 23818,   297, 29871, 29906, 29947, 29914, 29941, 29906,
          4344,   393,   892,  1162,   582,  1573, 29889,   365,  3308,   750,
           263,  4771, 24858,   322,  2702,   537,   310, 29871, 29947, 29955,
         29995,   313, 29929, 29945, 29995, 25781, 29901, 29871, 29953, 29929,
         29995, 29899, 29929, 29953, 10997,   322, 29871, 29896, 29900, 29900,
         29995,   313, 29929, 29945, 29995, 25781, 29901, 29871, 29896, 29953,
         29995, 29899, 29896, 29900, 29900, 10997,  8307, 29892,   363, 24876,
         14556, 12463,   301,   653, 29876,   479,   284,   766, 20488,   297,
         10230,   304, 13764, 29931, 29889,   365,  3308,   884,   750,   385,
          4038,  1090,   278, 19870, 13598, 17443,   313,  1672, 29907, 29897,
         11672,   313, 29909, 23129, 29897,   310, 29871, 29900, 29889, 29929,
         29941, 29892,   313, 29925,   353, 29871, 29900, 29889, 29900, 29946,
         29892, 29871, 29929, 29945, 29995, 25781, 29901, 29871, 29900, 29889,
         29947, 29946, 29899, 29896,   467,   365,  3308,  1122,   367,  7436,
           408,   385, 12109,  4090,   424,   652, 21780,  5780,   363,   364,
         19478,   297,   301,   653, 29876,   479,   284,  2224, 11763,   297,
          4344,  3704,   270,   952,   561,  6405,   322,   851, 23377, 29889,
          1094,  4340,  7271,   338, 16692,   278,   995,   310,   365,  3308,
           297, 24876, 19263,   674,   367,  2253, 11098, 29889]],
       device='cuda:0')
torch.Size([2, 438, 32000]) tensor([[[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -9.5625, -13.0312,   0.4087,  ...,  -6.6133,  -1.0186,  -7.5977],
         [ -9.9688, -12.4219,  -1.0352,  ...,  -4.8633,  -2.3535,  -7.7422],
         ...,
         [ -4.9531,  -3.2520,   2.2871,  ...,  -3.7441,  -4.1953,  -3.1816],
         [ -4.9570,  -3.2461,   2.2910,  ...,  -3.7422,  -4.1953,  -3.1797],
         [ -5.0117,  -3.3184,   2.3262,  ...,  -3.7656,  -4.2188,  -3.2051]],

        [[ -9.0156,   0.8467,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -9.5625, -13.0312,   0.4087,  ...,  -6.6133,  -1.0186,  -7.5977],
         [ -7.1680,  -6.2891,   1.3438,  ...,  -4.0117,  -3.1855,  -4.3203],
         ...,
         [ -0.7046,  -0.7676,  -5.1094,  ...,   2.9805,   8.0156,   1.2090],
         [ -5.2617,  -4.9414,  -5.1289,  ...,  -1.8457,   0.7642,  -3.9727],
         [ -7.8242,  -7.8203,   0.3633,  ...,  -4.9219,  -3.0508,  -4.1992]]],
       device='cuda:0')
torch.Size([2, 438, 1]) tensor([[[29918],
         [29871],
         [29874],
         [29874],
         [29871],
         [  262],
         [29871],
         [29874],
         [29874],
         [  392],
         [  392],
         [  392],
         [  392],
         [29899],
         [29899],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  392],
         [29899],
         [29871],
         [29874],
         [  856],
         [29874],
         [29874],
         [29874],
         [  313],
         [29892],
         [29874],
         [29874],
         [29924],
         [29899],
         [31017],
         [29899],
         [29874],
         [  376],
         [  668],
         [29874],
         [  292],
         [29871],
         [29871],
         [29945],
         [29995],
         [  310],
         [ 8353],
         [29928],
         [29874],
         [29874],
         [ 9747],
         [ 9747],
         [29874],
         [  376],
         [29871],
         [29874],
         [29874],
         [29874],
         [ 8353],
         [29950],
         [29874],
         [29874],
         [  974],
         [29871],
         [29896],
         [29896],
         [29874],
         [29874],
         [10149],
         [  363],
         [ 1552],
         [29871],
         [29945],
         [29995],
         [  310],
         [ 8353],
         [  271],
         [10685],
         [29874],
         [  479],
         [29899],
         [25154],
         [29928],
         [29874],
         [27691],
         [ 8353],
         [ 4788],
         [  376],
         [ 7384],
         [13556],
         [ 1016],
         [29909],
         [10149],
         [ 1131],
         [  271],
         [29874],
         [29871],
         [29874],
         [23613],
         [ 7045],
         [29874],
         [  932],
         [  304],
         [  367],
         [ 8175],
         [ 8175],
         [  297],
         [ 8353],
         [ 8353],
         [29871],
         [29945],
         [ 8353],
         [ 8353],
         [  376],
         [ 7384],
         [13556],
         [  578],
         [27691],
         [23362],
         [ 2308],
         [24389],
         [  362],
         [  627],
         [29871],
         [  974],
         [29928],
         [ 3138],
         [29874],
         [ 8175],
         [25525],
         [27691],
         [27691],
         [27691],
         [15716],
         [ 1761],
         [27691],
         [ 1761],
         [ 9747],
         [ 9747],
         [29874],
         [ 1016],
         [  856],
         [ 1016],
         [29874],
         [13556],
         [ 8353],
         [ 8353],
         [29896],
         [29945],
         [ 8353],
         [17292],
         [  376],
         [ 7384],
         [  271],
         [29874],
         [29871],
         [29874],
         [23613],
         [29879],
         [15716],
         [29871],
         [29924],
         [ 1761],
         [  856],
         [  856],
         [ 3872],
         [29950],
         [  517],
         [ 1009],
         [29928],
         [29874],
         [23332],
         [ 9747],
         [  886],
         [29950],
         [10685],
         [  292],
         [ 9747],
         [ 9747],
         [29874],
         [29874],
         [23613],
         [29879],
         [29874],
         [29871],
         [29871],
         [29871],
         [29945],
         [29995],
         [  310],
         [ 8353],
         [ 1051],
         [ 7272],
         [ 1761],
         [  263],
         [ 9747],
         [29874],
         [  392],
         [  392],
         [10149],
         [  262],
         [ 1131],
         [29896],
         [29896],
         [29995],
         [29871],
         [29995],
         [  310],
         [ 9747],
         [ 9747],
         [13556],
         [13556],
         [29874],
         [ 9747],
         [ 9747],
         [29874],
         [ 9747],
         [29909],
         [ 1016],
         [29950],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [ 9176],
         [10685],
         [  931],
         [  363],
         [29874],
         [29879],
         [29874],
         [  262],
         [29874],
         [29881],
         [13556],
         [  806],
         [29871],
         [  271],
         [29874],
         [29874],
         [  392],
         [  392],
         [29874],
         [29871],
         [29874],
         [  392],
         [29874],
         [  856],
         [  668],
         [  392],
         [  392],
         [29909],
         [29909],
         [  392],
         [  392],
         [25525],
         [ 6451],
         [ 1454],
         [29874],
         [29879],
         [15716],
         [29892],
         [  262],
         [  304],
         [  806],
         [29871],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [30064],
         [29995],
         [  392],
         [29931],
         [  517],
         [13556],
         [29874],
         [ 9747],
         [ 9747],
         [29874],
         [ 9747],
         [29909],
         [ 2646],
         [29874],
         [29874],
         [29874],
         [29874],
         [  297],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871]],

        [[29918],
         [29871],
         [29899],
         [29874],
         [29899],
         [29874],
         [  376],
         [29874],
         [29899],
         [  509],
         [29874],
         [  262],
         [29874],
         [29874],
         [  358],
         [  310],
         [29874],
         [29871],
         [29874],
         [29874],
         [  856],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [  313],
         [29899],
         [29871],
         [29874],
         [  561],
         [  392],
         [29874],
         [29874],
         [ 1131],
         [  392],
         [  348],
         [  276],
         [16011],
         [ 2886],
         [ 1131],
         [29874],
         [29950],
         [29874],
         [ 4665],
         [29874],
         [  365],
         [29899],
         [  392],
         [29874],
         [29899],
         [29874],
         [29874],
         [ 8552],
         [29874],
         [29892],
         [29871],
         [29871],
         [  392],
         [29874],
         [  262],
         [  392],
         [21780],
         [  878],
         [ 1454],
         [  517],
         [  465],
         [29881],
         [  392],
         [ 2858],
         [29881],
         [29871],
         [  392],
         [  270],
         [29871],
         [30488],
         [30488],
         [30488],
         [  856],
         [29874],
         [  365],
         [29874],
         [30488],
         [30488],
         [30488],
         [29874],
         [  262],
         [29874],
         [29899],
         [29899],
         [14131],
         [29874],
         [  392],
         [  392],
         [  297],
         [29874],
         [ 5729],
         [29899],
         [  403],
         [  392],
         [ 2133],
         [  392],
         [ 1552],
         [  262],
         [  653],
         [29874],
         [  705],
         [  365],
         [  509],
         [29874],
         [29874],
         [29874],
         [  262],
         [  392],
         [  392],
         [  262],
         [  509],
         [  262],
         [  392],
         [  292],
         [  878],
         [29874],
         [  262],
         [29909],
         [ 1552],
         [  517],
         [ 7171],
         [  392],
         [  517],
         [ 1552],
         [  262],
         [  653],
         [29874],
         [29871],
         [29874],
         [  392],
         [ 3381],
         [  297],
         [  365],
         [29874],
         [  262],
         [  517],
         [  262],
         [ 1552],
         [29874],
         [29890],
         [  392],
         [  262],
         [29903],
         [ 4771],
         [29879],
         [  262],
         [29871],
         [29874],
         [29899],
         [29874],
         [  517],
         [  509],
         [29874],
         [  705],
         [29892],
         [29871],
         [29871],
         [  392],
         [  578],
         [29909],
         [29881],
         [29871],
         [29950],
         [29928],
         [29871],
         [  392],
         [  270],
         [29871],
         [  270],
         [  856],
         [29899],
         [  262],
         [29874],
         [29892],
         [29879],
         [29899],
         [29874],
         [29899],
         [29899],
         [  856],
         [29874],
         [  262],
         [29874],
         [29899],
         [  392],
         [29911],
         [  271],
         [29871],
         [29874],
         [29896],
         [29871],
         [  229],
         [29950],
         [  856],
         [29874],
         [11888],
         [29874],
         [29871],
         [  392],
         [29874],
         [29874],
         [  392],
         [ 1037],
         [  392],
         [29914],
         [29892],
         [29874],
         [29933],
         [  271],
         [29892],
         [  304],
         [29874],
         [  392],
         [  392],
         [29875],
         [ 3002],
         [25772],
         [29909],
         [29874],
         [29874],
         [  856],
         [  653],
         [29871],
         [29874],
         [  365],
         [  653],
         [  392],
         [29874],
         [29899],
         [ 2541],
         [  262],
         [  262],
         [29871],
         [  262],
         [  578],
         [29874],
         [19263],
         [29874],
         [29874],
         [29874],
         [12542],
         [29874],
         [29899],
         [  653],
         [29874],
         [12542],
         [29871],
         [29871],
         [29896],
         [29995],
         [29906],
         [29896],
         [  313],
         [  271],
         [ 5062],
         [29909],
         [  856],
         [29871],
         [29874],
         [  365],
         [  653],
         [12542],
         [29874],
         [29871],
         [  277],
         [  392],
         [30488],
         [29871],
         [  974],
         [29871],
         [29871],
         [29871],
         [29995],
         [  392],
         [29871],
         [29945],
         [29995],
         [25781],
         [30057],
         [29871],
         [29871],
         [29871],
         [29995],
         [  517],
         [29871],
         [29871],
         [29995],
         [  392],
         [29874],
         [29871],
         [29874],
         [29900],
         [29995],
         [  313],
         [29871],
         [29945],
         [29995],
         [25781],
         [29874],
         [29871],
         [29871],
         [29874],
         [29995],
         [29899],
         [29871],
         [29871],
         [29874],
         [29995],
         [ 8307],
         [29874],
         [  392],
         [ 1552],
         [14556],
         [29874],
         [29874],
         [  653],
         [29874],
         [29933],
         [29874],
         [ 2084],
         [ 1037],
         [29874],
         [29874],
         [  304],
         [29874],
         [29871],
         [29874],
         [  365],
         [  653],
         [12542],
         [21312],
         [29874],
         [29874],
         [29903],
         [13556],
         [13556],
         [ 3372],
         [29909],
         [13556],
         [  319],
         [29874],
         [  319],
         [29909],
         [29909],
         [  319],
         [29874],
         [29874],
         [29909],
         [29909],
         [29900],
         [29871],
         [29929],
         [29906],
         [  271],
         [29874],
         [29929],
         [  392],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29915],
         [29871],
         [29945],
         [29995],
         [25781],
         [29874],
         [29900],
         [29871],
         [29871],
         [29871],
         [29896],
         [29874],
         [29896],
         [29874],
         [  365],
         [  375],
         [12542],
         [29874],
         [29874],
         [  262],
         [29874],
         [29874],
         [18049],
         [  392],
         [  878],
         [21780],
         [  878],
         [ 7354],
         [ 1552],
         [  856],
         [  297],
         [  392],
         [29871],
         [29873],
         [29899],
         [29874],
         [ 2224],
         [ 3002],
         [29874],
         [ 1131],
         [  271],
         [29874],
         [  392],
         [  561],
         [  262],
         [  392],
         [  561],
         [29933],
         [  271],
         [  365],
         [  680],
         [29874],
         [ 4888],
         [ 7171],
         [  392],
         [29874],
         [29931],
         [  365],
         [29899],
         [  705],
         [  578],
         [14556],
         [  392],
         [26180],
         [  999],
         [  999],
         [  392],
         [29915]]], device='cuda:0')
torch.Size([2, 438, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29874,   310,   376,  ..., 29915, 29909, 29928],
         ...,
         [29892, 29871, 29889,  ...,   349, 29915,   315],
         [29892, 29871, 29889,  ...,   349, 29915,   315],
         [29892, 29871, 29889,  ...,   349, 29915,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29899, 29874, 29915,  ...,   856,   392, 29882],
         ...,
         [  999,  7556, 18383,  ..., 28904,  2143,  4016],
         [  392, 29874, 29885,  ...,   680, 29872, 29881],
         [29915, 29874,   313,  ...,   376,   315,   271]]], device='cuda:0')
Batch 29, 53.5% of total tokens
encoded shape: torch.Size([2, 2240])
torch.Size([2, 2240]) tensor([[    1,  1724, 15057,  ...,   411,   445, 29889],
        [    1,  2266,   591,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2240, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.0117,  -5.6250,   2.5488,  ...,  -4.3320,  -3.5742,  -4.3398],
         [ -7.9727, -10.0312,  -0.0687,  ...,  -4.8008,  -1.6895,  -4.2500],
         ...,
         [ -6.8438,  -6.3633,  -0.4800,  ...,  -2.5469,   0.3762,  -3.9297],
         [ -6.2070,  -5.3867,  -0.7217,  ...,  -3.6719,  -2.8711,  -4.8984],
         [ -5.2070,  -3.1406,   1.5186,  ...,  -4.2227,  -3.1543,  -4.2500]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.2734,  -4.7734,   1.8945,  ...,  -5.1797,  -4.0586,  -4.5977],
         [ -8.7500, -10.7500,  -0.3203,  ...,  -4.3203,  -1.1191,  -7.3203],
         ...,
         [ -4.8281,   0.9209,  -3.4512,  ...,  -2.3145,  -3.1426,  -2.3301],
         [ -4.8711,   0.9375,  -3.4805,  ...,  -2.3105,  -3.1484,  -2.3359],
         [ -4.8906,   0.9565,  -3.4902,  ...,  -2.2969,  -3.1387,  -2.3301]]],
       device='cuda:0')
torch.Size([2, 2240, 1]) tensor([[[29918],
         [29915],
         [29903],
         ...,
         [  445],
         [29882],
         [29889]],

        [[29918],
         [  262],
         [29874],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 2240, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29915,   376, 29871,  ...,   313,   349,   315],
         [29903, 29874, 29899,  ..., 29876,   271, 29871],
         ...,
         [  445,  1366,  1552,  ..., 29903,  5747, 29924],
         [29882, 29924, 29889,  ..., 29909, 29933, 29940],
         [29889, 29892, 30010,  ..., 29876,   262, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [  262, 29915, 29874,  ..., 29902, 29924, 29928],
         [29874, 29902, 29925,  ..., 29911, 29909, 29931],
         ...,
         [30488,   376, 30879,  ...,   313, 31147,   392],
         [30488,   376, 29915,  ...,   313,   392, 31147],
         [30488,   376, 29915,  ...,   313,   392, 31147]]], device='cuda:0')
Batch 30, 56.0% of total tokens
encoded shape: torch.Size([2, 251])
torch.Size([2, 251]) tensor([[    1,   512,  1579,  3837,  1362, 24424,   341, 29906, 26823,   338,
           385, 10160,  3813, 10800, 26823, 13384,   373,   278,  3041, 26458,
         29899,  3729,  7101, 29889,    13,  1576, 13787,  1362,   319, 24424,
           341, 29906, 26823,   338, 13384, 18666, 10835,   472,   278,  3038,
          7101, 29892,   322,   297,  6124,   304,   278,  9736,   351,  3820,
           329,   262,   262,   313, 15715, 29897,   322, 26808,  9103,   333,
           559,   313,  3521,   511,   338,   263,  4654, 24424, 29899, 14940,
          3813, 10800, 26823, 29889,   341, 29906,   756,   385,  7463, 17546,
           561,   711,   293,  3813, 10800, 23791,  6022,  5354,   322,  4067,
          1078,   411,   278,  1021,  3038,  1070,  3813, 10800,  5227,  1953,
           408,   379, 29909,   322,  8598, 29889,  3967,   567,   262, 14502,
           310,  3041, 26458,  9101,   322,  5198,   348,   459,  4361, 29886,
          7018,   411,  3268, 29899, 14940,  3677,   275,  1572, 12266,   393,
           263,  9212,   310, 29871, 29896, 29947,   405, 29950, 29906, 29899,
          8489,   979,   626,  1789,  1274,  4841,   310,   341, 29906,   526,
         19884,   472,   278,  3038,  7101, 29889, 12444,   405, 29950, 29906,
         29899,  8489,   979, 10995,  1041,   526, 21929,  1490,   297,   599,
          5312,  1144,   310, 13787,  1362,   319, 24424,   363,   607, 15602,
           526,  3625, 29889,  5459,   747,   397,   583,   508, 18720,   341,
         29906,   373,   278,  3038,  7101,   322,  5480,   372,  1122,   367,
           385,  3041, 26458, 29899,  3729,  7101,  3677,  2101, 29889,  1334,
          5353,  4426,   310,   341, 29906,   393,  1993,   372,   304,   278,
           560,   375,   573,  4655,  3646, 13206, 29883,  1297,   373, 13787,
          1362,   319, 24424, 29899,   262,  3647,   287,  9101,   363,  4891,
         29899,   276,  4925,   274,  3637,   327,  2251,   293,   323,  9101,
         29889],
        [    1,   660, 29901,    13,    13, 17936,   292,  7395, 26824,   639,
          1813,   297,   263,  4700,    13,    13,  3624,   727,   263,   982,
           304,  5702,   278,  1353,   310,  7395, 26824,   363,  1269,  1813,
           297,   590,  4700, 29973,   306,   864,   304,  1835,  1554,   763,
           376,  8439,   526, 29871, 29953,  2305,  1776,   292,   445,  1813,
          1492,  1286, 29908,   746,   263, 27682, 24395,   445,  1813, 29889,
            13,    13, 29909, 29901,    13,    13,  3492,  1033,  2048,  1554,
           451,  1568,  4280,   773,  9954,   284, 29934,   322,  3513, 29889,
            13, 29909,  3513,   297,  1269,  1813,   723,  1871,   278,  9954,
           284, 29934,  2669,   393,  4856,   338,   297,   727,   322,   278,
          1923,   723, 20431,   372,   322, 12672,   372,   304, 14332,   393,
           338,   297,   278,  1021,  1813, 29889,    13,    13,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2]], device='cuda:0')
torch.Size([2, 251, 32000]) tensor([[[ -8.9922,   0.8447,   0.6909,  ...,  -3.0449,  -5.3633,  -2.3770],
         [-10.4062, -12.7578,   1.7686,  ...,  -6.6836,  -1.6934,  -6.2383],
         [-11.5078, -13.7031,  -1.0088,  ...,  -7.0781,  -4.7305,  -7.5156],
         ...,
         [ -3.1035,  -3.4766,  -2.8516,  ...,  -0.6958,   3.0762,  -0.8794],
         [ -7.0273,  -9.3828,  -4.6289,  ...,  -6.0234,  -1.7441,  -5.0312],
         [ -7.3438,  -5.6680,   1.1963,  ...,  -5.5000,  -3.6992,  -4.0312]],

        [[ -8.9922,   0.8447,   0.6909,  ...,  -3.0449,  -5.3633,  -2.3770],
         [ -7.1523,  -6.3867,   3.4844,  ...,  -4.6445,  -5.0781,  -3.9922],
         [ -9.1406,  -7.9961,   0.1010,  ...,  -4.9297,  -3.4102,  -4.9062],
         ...,
         [ -4.0977,  -2.1699,   1.6855,  ...,  -3.4004,  -3.9453,  -2.7988],
         [ -4.0977,  -2.1484,   1.6738,  ...,  -3.4004,  -3.9414,  -2.7949],
         [ -4.0898,  -2.1250,   1.6602,  ...,  -3.3965,  -3.9355,  -2.7891]]],
       device='cuda:0')
torch.Size([2, 251, 1]) tensor([[[29918],
         [29871],
         [29924],
         [29874],
         [29874],
         [29874],
         [29896],
         [29874],
         [29874],
         [ 2841],
         [29909],
         [29924],
         [29874],
         [  680],
         [  392],
         [  262],
         [29874],
         [29874],
         [29874],
         [29874],
         [  376],
         [29874],
         [29874],
         [10266],
         [29874],
         [29874],
         [29874],
         [29924],
         [29874],
         [29924],
         [29906],
         [29874],
         [29874],
         [29874],
         [  262],
         [29874],
         [  262],
         [29874],
         [29874],
         [ 3733],
         [29874],
         [29874],
         [29924],
         [ 1131],
         [  517],
         [29874],
         [29874],
         [29874],
         [29903],
         [29882],
         [  262],
         [  262],
         [29924],
         [  379],
         [29874],
         [ 1457],
         [29874],
         [29874],
         [  333],
         [  559],
         [ 1491],
         [29874],
         [29874],
         [29924],
         [29874],
         [ 1131],
         [29874],
         [ 1131],
         [ 1131],
         [29924],
         [29874],
         [29924],
         [29903],
         [  341],
         [29906],
         [29874],
         [  680],
         [29874],
         [29874],
         [29874],
         [29924],
         [  293],
         [29874],
         [29874],
         [29874],
         [29903],
         [29875],
         [  392],
         [29874],
         [ 1078],
         [ 2541],
         [29950],
         [29950],
         [29874],
         [29899],
         [  262],
         [  661],
         [29903],
         [29874],
         [  680],
         [29950],
         [29909],
         [  392],
         [29874],
         [29874],
         [  341],
         [29874],
         [  262],
         [29963],
         [29924],
         [30488],
         [29874],
         [29899],
         [29924],
         [29874],
         [  348],
         [29925],
         [29874],
         [29925],
         [ 7018],
         [15729],
         [29874],
         [29899],
         [30488],
         [29874],
         [  747],
         [  392],
         [ 2750],
         [29924],
         [29924],
         [29924],
         [29874],
         [29874],
         [29906],
         [29874],
         [29874],
         [29899],
         [29906],
         [29899],
         [ 2308],
         [29924],
         [29874],
         [  262],
         [ 8638],
         [29871],
         [30488],
         [30488],
         [29871],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [ 1070],
         [29874],
         [29874],
         [29899],
         [29950],
         [29906],
         [29899],
         [ 8638],
         [29924],
         [29874],
         [ 1041],
         [ 2364],
         [ 2308],
         [29874],
         [  262],
         [29924],
         [29924],
         [ 1144],
         [29874],
         [13787],
         [29909],
         [29909],
         [ 1491],
         [29924],
         [29874],
         [29924],
         [  680],
         [  354],
         [29874],
         [29874],
         [  747],
         [  397],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [16431],
         [29874],
         [29924],
         [29924],
         [30488],
         [30488],
         [29874],
         [29924],
         [29874],
         [29899],
         [ 3038],
         [29924],
         [29924],
         [  747],
         [29874],
         [29874],
         [  557],
         [29924],
         [29924],
         [29924],
         [29871],
         [29874],
         [ 6574],
         [29874],
         [29874],
         [29874],
         [29874],
         [  375],
         [  573],
         [29875],
         [29924],
         [  287],
         [29883],
         [29899],
         [29924],
         [ 1552],
         [29874],
         [29909],
         [29874],
         [29899],
         [ 3041],
         [ 3647],
         [29874],
         [ 9101],
         [29874],
         [29924],
         [29899],
         [29899],
         [29950],
         [29924],
         [29874],
         [  262],
         [29909],
         [  262],
         [29924],
         [ 9101],
         [29874],
         [29874]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [29924],
         [29924],
         [29874],
         [29871],
         [29899],
         [29874],
         [29874],
         [  392],
         [  517],
         [ 1480],
         [ 1730],
         [ 1730],
         [  310],
         [ 1730],
         [ 1730],
         [ 1730],
         [ 1269],
         [ 1491],
         [  297],
         [29874],
         [29909],
         [29973],
         [  856],
         [31684],
         [  304],
         [28192],
         [ 1173],
         [ 1129],
         [29874],
         [29896],
         [29915],
         [  262],
         [29871],
         [29945],
         [ 6493],
         [  292],
         [ 1366],
         [29909],
         [30488],
         [30488],
         [  262],
         [  265],
         [29874],
         [  392],
         [ 1730],
         [29874],
         [29874],
         [20509],
         [30879],
         [29892],
         [30879],
         [29874],
         [29892],
         [29892],
         [29915],
         [29915],
         [29874],
         [29874],
         [29882],
         [ 1022],
         [29903],
         [  261],
         [29909],
         [29899],
         [31147],
         [29874],
         [30488],
         [29909],
         [29915],
         [29892],
         [  392],
         [30488],
         [29874],
         [29909],
         [30488],
         [30488],
         [16431],
         [29874],
         [29874],
         [29934],
         [30488],
         [29874],
         [29874],
         [ 5893],
         [29911],
         [ 1730],
         [29874],
         [29874],
         [29903],
         [  680],
         [ 3974],
         [29881],
         [29874],
         [ 3974],
         [ 1730],
         [ 1250],
         [ 1730],
         [ 1491],
         [ 1491],
         [ 1491],
         [ 1730],
         [29903],
         [29909],
         [  271],
         [29915],
         [29892],
         [29892],
         [29924],
         [29924],
         [29924],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899],
         [29899],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 251, 10]) tensor([[[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29874, 29899,  ..., 29903, 29895,   517],
         [29924, 29871, 29933,  ...,   517, 29928,   509],
         ...,
         [ 9101,  3038, 19413,  ...,  1491, 10072,  1783],
         [29874,   271,   705,  ..., 29875,  1595,   392],
         [29874, 29875, 29915,  ..., 29898,   262, 29889]],

        [[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [30488, 30879, 31147,  ..., 29871,   856, 29899],
         [30488, 30879, 31147,  ..., 29871,   856, 29899],
         [30488, 30879, 31147,  ..., 29871,   856, 29899]]], device='cuda:0')
Batch 31, 56.4% of total tokens
encoded shape: torch.Size([2, 394])
torch.Size([2, 394]) tensor([[    1,   660, 29901,    13,    13,  2951, 15852,  2624,   451,  2000,
           373,  1856,  1493,    13,    13, 29902,   723,   763,   304,   671,
           373, 15852,  2624,   297,  2563,  1043, 29889,  2398, 29892,  3078,
           338,  8833,   297,  1480, 29889,   739,  1736,   565,   306,  1735,
           373, 15852,  2624,   304, 13916, 15852,  2624, 29889,    13, 11008,
           338,   373, 15852,  2624,   451,  2000, 29973,    13,  3597,  2563,
          1043,   590, 23237, 29936,    13, 29992,  4640,    13, 24681,  1780,
         14813, 29898,  9534,  7160, 12223, 29897,   426,    13,  1678,  2428,
         29889, 17879, 29898, 17314, 12223,   416,    13,  1678, 26916, 29898,
         29934, 29889,  2680, 29889, 10072, 29918,  3396,   416,    13,  1678,
         21704,  1646, 29840,   353,   313, 12229,  1646, 29897, 17003, 29898,
         29934, 29889,   333, 29889, 10154,  1646,   416,    13,  1678,   731,
         14039,  4276,  4297, 29898, 10154,  1646,   416,    13,  1678,   590,
         23237,   353,   313, 23237, 29897, 15418, 29898, 29934, 29889,   333,
         29889,  2676,  1043, 29900, 29896,   416,    13,  1678,   590, 23237,
         29889,   842, 23237,  4032, 29898,  1482,  2563,  1043,  4032,  3310,
            13,  1678,   590, 23237, 29889,  1359,  5983,   703,  1124,   597,
          1636, 29889,  3608, 29889,  1111, 29889, 16865,  1496,    13,  1678,
           849,  7729,    13,  1678,   590, 23237, 29889,   657,  9585,  2141,
           842, 16963, 10861, 29898,  3009,   416,    13, 29913,    13,    13,
         29992,  4640,    13,  3597,  7223,   373, 15852,  2624, 29898, 29924,
          8194,  2624,  3415, 29897,   426,    13,  1678,  4522, 29889, 29881,
           703, 15852,  2624,  3284,  4804,  1496,    13,  1678,   736,  1565,
         29936,    13, 29913,    13,    13, 29909, 29901,    13,    13,  6293,
           526,  9963,   525,  2951, 15852,  2624, 29915,   310,  6354, 29892,
           451,  2563,  1493, 29889, 29871,    13,  6295, 29892, 11008,  1551,
         15852,  2624,   451,  2000, 29973,   739,   338,  1048,  6864, 28289,
           297,  6354, 29889,   512,  3273, 29892,   278,  1856,  1493, 29151,
           278,  1741,   746,   366,  6023,   278,  3474, 29889, 29871,    13,
          3492,   508,   437,   263,  1243, 29901,    13, 29896, 29889,  1925,
           263, 11025,   322,   263,  3992,  1493,   297,  6354, 29889,  1480,
           297,   373, 15852,  2624,  2141,    13, 29906, 29889,  6023,   278,
         11025,  6660,   373, 15852,  2624,   580,   451,   367,  2000, 29889,
          1363, 11025, 29871, 29151,   278,  1741, 29892,   763,   596,  1856,
          1493, 29889,    13, 29941, 29889,  6023,   278,  3992,  1493,  6660,
           373, 15852,  2624,   580,   674,   367,  2000, 29889,  1363,  3992,
          1493,   508,   451, 29151,   278,  1741, 29889,   259,    13, 28173,
           525,  2624, 28289,   742,   366,   508,   679,  1568,   411,  5386,
         29889,    13, 26026,   445,   674,  1371,   366,   304,  2274,   372,
         29889, 29871,    13,    13],
        [    1,  2191,   300,   278, 15880, 11644,   512,  1028,  2859,   450,
           360,  1151,   297,   278,  3189,   264, 25522, 30010,  5129,  1576,
          7997,  9388, 11716, 30010,    13,    13, 17392,   272, 12208, 29331,
           911,   335,  1539,   450,   360,  1151, 29871, 29896, 29906,  2440,
          1434,   450,  7997,  9388, 11716, 29889,   450,   360,  1151,  1641,
         12208, 26028, 29881, 29892,  1058,  2869,   471,  2000,   393, 29892,
           322,  1058, 20603,   278,  3189,   264,  4358,   721, 30010, 29879,
          4185, 13444,   297,   278, 29871, 29896, 29929, 29929, 29947,  2706,
         29889,  2567, 29892, 29331,   911,   335,   756,  2183,   450,   360,
          1151,   670,  1914, 14064, 29901,   263,  1842,   653,  2000,   450,
           360,  1151,    13,    13,  1576,   360,  1151,   322,   306,  2360,
          1258,   664,  4208, 29892,   541,   975,   278,  2440,   591, 30010,
         29881,  4891, 10898,   373,   278, 16005, 11369, 29892,   322,   372,
          2337,  1370,  2168,   590,  5192,   393,  1316,   263,  2931, 29892,
           445,  1565,  1339,   347,   369, 29892,   471,  1603, 19436,   278,
          4842,   305,   363, 25266,  2706, 29889,  1932,   278,  3189,   264,
         25522,  1754,   450,  7997,  9388, 11716,   297, 29871, 29896, 29929,
         29929, 29947, 29892,   306,  3290,   297,   263,  6501,  6419,   278,
          1008,  1811,   304,  8265, 21873,   278,   360,  1151,   306,  6363,
           411,   278, 26797,   277,  2738,  2931, 12208,  1771,   333,  2710,
           471,  8743,   373,  4315,   813, 12208,  1346,  1576,   360,  1151,
         30024,  9388, 11716,   813,   541,   306,   471,   451, 18014,   297,
           278,  3203,   393,   278,  3189,   575,  1476,  8681, 12232,   297,
           278,   360,  1151, 29889, 12208, 26028, 29881,   338,   263,  1492,
           310, 13382,   297,   278,  1399,   347,  2706,  3186,   813, 27257,
          1608,   491,   278,   360,  1151,   813,   670,   805,  1992,   322,
          1781,   325,   747,   267,  4444,   366,  3889,   304,  1653,   263,
          3186,   310,   596,  1914, 29889,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 394, 32000]) tensor([[[-8.9844,  0.8472,  0.6909,  ..., -3.0449, -5.3633, -2.3750],
         [-7.1484, -6.3867,  3.4844,  ..., -4.6445, -5.0781, -3.9902],
         [-9.1172, -7.9492,  0.1118,  ..., -4.9102, -3.4023, -4.8828],
         ...,
         [-8.1562, -8.1250,  1.1572,  ..., -5.4375, -2.7148, -4.7969],
         [-4.6211, -2.9941,  1.6143,  ..., -3.8809, -3.8984, -3.1270],
         [-4.9844, -3.2168,  1.6182,  ..., -3.8887, -3.8965, -3.0898]],

        [[-8.9844,  0.8472,  0.6909,  ..., -3.0449, -5.3633, -2.3750],
         [-6.7852, -5.4297,  2.5391,  ..., -4.2656, -4.7930, -4.6445],
         [-7.2305, -8.6875, -2.8418,  ..., -4.4141,  3.1113, -4.3906],
         ...,
         [-4.0781, -2.3320,  1.6904,  ..., -3.3574, -4.0078, -2.8105],
         [-4.0625, -2.3086,  1.6797,  ..., -3.3516, -4.0000, -2.8027],
         [-4.0469, -2.2812,  1.6689,  ..., -3.3457, -3.9922, -2.7969]]],
       device='cuda:0')
torch.Size([2, 394, 1]) tensor([[[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29871],
         [29871],
         [29874],
         [24237],
         [29874],
         [29874],
         [29899],
         [29915],
         [29889],
         [29892],
         [29915],
         [30488],
         [  304],
         [29903],
         [29874],
         [29879],
         [29879],
         [  517],
         [29874],
         [29874],
         [29874],
         [29892],
         [29902],
         [  306],
         [24237],
         [21001],
         [  262],
         [29903],
         [ 4117],
         [30488],
         [  354],
         [ 2691],
         [  306],
         [30488],
         [29881],
         [29911],
         [29879],
         [  517],
         [30488],
         [29871],
         [  392],
         [30488],
         [29915],
         [29892],
         [  265],
         [  593],
         [15852],
         [ 2624],
         [ 1333],
         [13998],
         [  262],
         [29902],
         [29892],
         [29899],
         [29874],
         [29874],
         [29903],
         [29874],
         [29874],
         [30488],
         [29892],
         [30488],
         [30488],
         [29874],
         [30488],
         [29898],
         [29892],
         [  262],
         [  262],
         [  262],
         [29889],
         [29899],
         [30488],
         [29874],
         [29874],
         [29892],
         [29898],
         [29892],
         [29874],
         [29874],
         [29874],
         [  392],
         [29874],
         [29898],
         [  390],
         [29889],
         [30488],
         [29874],
         [29892],
         [29874],
         [29892],
         [29874],
         [29874],
         [  392],
         [29874],
         [29874],
         [29874],
         [  392],
         [29898],
         [29892],
         [29874],
         [29874],
         [29874],
         [29898],
         [  390],
         [29889],
         [30488],
         [30488],
         [29892],
         [29874],
         [29874],
         [29874],
         [  392],
         [29874],
         [29874],
         [29899],
         [29874],
         [29898],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29898],
         [29892],
         [29874],
         [17003],
         [29898],
         [29934],
         [29874],
         [29892],
         [29889],
         [29892],
         [29909],
         [29874],
         [29896],
         [29874],
         [29874],
         [  392],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29898],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  392],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29892],
         [29874],
         [29892],
         [30488],
         [29892],
         [30488],
         [29892],
         [29874],
         [  262],
         [29874],
         [29874],
         [  392],
         [29874],
         [29892],
         [29871],
         [  392],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29898],
         [29892],
         [29874],
         [29874],
         [  392],
         [29889],
         [30488],
         [29892],
         [29874],
         [29874],
         [30879],
         [29874],
         [29874],
         [29899],
         [29874],
         [29898],
         [29899],
         [  392],
         [  262],
         [  262],
         [29871],
         [29933],
         [29874],
         [29892],
         [29874],
         [29874],
         [29881],
         [  703],
         [29892],
         [ 2624],
         [ 1188],
         [22539],
         [  292],
         [29874],
         [  392],
         [29874],
         [29898],
         [29874],
         [29874],
         [29874],
         [29871],
         [29892],
         [29899],
         [29874],
         [29892],
         [29892],
         [29892],
         [27996],
         [  774],
         [  517],
         [29892],
         [ 6023],
         [ 2624],
         [29915],
         [  392],
         [ 3886],
         [29874],
         [ 4187],
         [ 2676],
         [ 1160],
         [29915],
         [10072],
         [29915],
         [29892],
         [ 3886],
         [ 1188],
         [29874],
         [29879],
         [ 2624],
         [  451],
         [13998],
         [  262],
         [ 1188],
         [ 1311],
         [  593],
         [ 3886],
         [29909],
         [  292],
         [10072],
         [29898],
         [ 3886],
         [10072],
         [29874],
         [ 3886],
         [ 2624],
         [ 3886],
         [29915],
         [ 6864],
         [ 2624],
         [  525],
         [ 1310],
         [ 6023],
         [ 2624],
         [ 2676],
         [22539],
         [29898],
         [29871],
         [29892],
         [ 3068],
         [29915],
         [  344],
         [29882],
         [  261],
         [  313],
         [29871],
         [29874],
         [  262],
         [29874],
         [ 1762],
         [ 3886],
         [29874],
         [29874],
         [  262],
         [ 6112],
         [10072],
         [29909],
         [  313],
         [  976],
         [29874],
         [29874],
         [ 2624],
         [29898],
         [29898],
         [29871],
         [29874],
         [  392],
         [  726],
         [  726],
         [29898],
         [29898],
         [15852],
         [ 2624],
         [ 1188],
         [ 1188],
         [ 1188],
         [10748],
         [ 1188],
         [ 1188],
         [29933],
         [ 2624],
         [29915],
         [ 6864],
         [ 2624],
         [ 3696],
         [29874],
         [29874],
         [29874],
         [ 1160],
         [29872],
         [ 1188],
         [29892],
         [29874],
         [ 6023],
         [  726],
         [29911],
         [ 6203],
         [ 1188],
         [  373],
         [15852],
         [ 2624],
         [ 1188],
         [ 1188],
         [  367],
         [13998],
         [  262],
         [29898],
         [29911],
         [ 6203],
         [29898],
         [29915],
         [15852],
         [ 3696],
         [ 3696],
         [  271],
         [29898],
         [29871],
         [29892],
         [29874],
         [29892],
         [14777],
         [  297],
         [  715],
         [  508],
         [ 3608],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29892],
         [29874],
         [30879],
         [ 2929],
         [  991],
         [  991],
         [  392],
         [ 2624],
         [  991],
         [29898],
         [29871],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29989],
         [29924],
         [  294],
         [19040],
         [  328],
         [ 2658],
         [  497],
         [29874],
         [29871],
         [29933],
         [29928],
         [29875],
         [  262],
         [21383],
         [30010],
         [  262],
         [  856],
         [29874],
         [  856],
         [29871],
         [29874],
         [29874],
         [  313],
         [29892],
         [  272],
         [29882],
         [29874],
         [  856],
         [29874],
         [29874],
         [29874],
         [29928],
         [29871],
         [ 1457],
         [29871],
         [29874],
         [29899],
         [29903],
         [  354],
         [  262],
         [  262],
         [29871],
         [29874],
         [30488],
         [29899],
         [29871],
         [29874],
         [30488],
         [29874],
         [30488],
         [29871],
         [29874],
         [29915],
         [29903],
         [29874],
         [29874],
         [30488],
         [29874],
         [  354],
         [30057],
         [29928],
         [29928],
         [  262],
         [21383],
         [29871],
         [29915],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29896],
         [29899],
         [29929],
         [29871],
         [  386],
         [29874],
         [29892],
         [29874],
         [  354],
         [30488],
         [29871],
         [29915],
         [29874],
         [29928],
         [  360],
         [29871],
         [29874],
         [30488],
         [29882],
         [29874],
         [29874],
         [29871],
         [29874],
         [29903],
         [  856],
         [29874],
         [29871],
         [  262],
         [29871],
         [29871],
         [29874],
         [29871],
         [  262],
         [29874],
         [29874],
         [30879],
         [30488],
         [  262],
         [30488],
         [29892],
         [  705],
         [  354],
         [  497],
         [  705],
         [30010],
         [29881],
         [30488],
         [29899],
         [  472],
         [29882],
         [29909],
         [ 9088],
         [ 2504],
         [29882],
         [  306],
         [30488],
         [30488],
         [29924],
         [29928],
         [29909],
         [  517],
         [  354],
         [29874],
         [29928],
         [29899],
         [29874],
         [29899],
         [29899],
         [  262],
         [29899],
         [  297],
         [ 1366],
         [29911],
         [30879],
         [  373],
         [29928],
         [  305],
         [  363],
         [29899],
         [29909],
         [29889],
         [29892],
         [  306],
         [ 3189],
         [  262],
         [29857],
         [29893],
         [ 1576],
         [29928],
         [29909],
         [29871],
         [29902],
         [29896],
         [29896],
         [29899],
         [29929],
         [29871],
         [29902],
         [29928],
         [29895],
         [  262],
         [29909],
         [29889],
         [29899],
         [29892],
         [29874],
         [  392],
         [  517],
         [31147],
         [29883],
         [29928],
         [29928],
         [29893],
         [30010],
         [ 1482],
         [  392],
         [29874],
         [  360],
         [  277],
         [29871],
         [29928],
         [ 2011],
         [29874],
         [30488],
         [30488],
         [ 2011],
         [ 2011],
         [30488],
         [29899],
         [29874],
         [29892],
         [29928],
         [30879],
         [29928],
         [30488],
         [30488],
         [  262],
         [29871],
         [29874],
         [29892],
         [29882],
         [29894],
         [30488],
         [30488],
         [  517],
         [29903],
         [31147],
         [  517],
         [29902],
         [29928],
         [  262],
         [29925],
         [29928],
         [29874],
         [  297],
         [ 1491],
         [29899],
         [29871],
         [29915],
         [30488],
         [26028],
         [30488],
         [30010],
         [29874],
         [29892],
         [29899],
         [30488],
         [  363],
         [29909],
         [29909],
         [29909],
         [29899],
         [29899],
         [29874],
         [29874],
         [29924],
         [  284],
         [29899],
         [29899],
         [29892],
         [29874],
         [29874],
         [29899],
         [29874],
         [29899],
         [29892],
         [29899],
         [  747],
         [29871],
         [  392],
         [30488],
         [  373],
         [29874],
         [29882],
         [29874],
         [29882],
         [12435],
         [29882],
         [29928],
         [29882],
         [29892],
         [29924],
         [29924],
         [29924],
         [29924],
         [29924],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 394, 10]) tensor([[[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29871, 29899, 29874,  ..., 29892, 29909, 29928],
         [29892, 29899,   313,  ..., 29915,   315, 29898],
         [29892, 29899,   313,  ...,   315,   319,   349]],

        [[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29892, 29874,  ..., 29915,   349, 29889],
         [29989,   886, 29924,  ...,  1129, 29987,   278],
         ...,
         [30488, 30879, 31147,  ...,   313, 29899,   856],
         [30488, 30879, 31147,  ...,   313, 29899,   856],
         [30488, 30879, 31147,  ..., 29871,   856, 29899]]], device='cuda:0')
Batch 32, 57.1% of total tokens
encoded shape: torch.Size([2, 341])
torch.Size([2, 341]) tensor([[    1,   512,   445,  3390, 29892, 18915, 30010, 29879,  9281, 29159,
           373,  1749,  4670, 19217,  4771,   747,  9770,   947,   451, 23451,
         29889,    13,    13,  1576,  4802,  1139,   338,   920,  4482,   338,
           540,  2675,   304, 28169,   445,   931, 29889,    13,    13, 29954,
           388,   758,  4130,   706, 23151, 29973,  5399, 29991,    13,    13,
          8140,  3277,   289,  2335, 29891,   712,   575,  4257,   678,   682,
         29884,   322,   349,   682, 29884, 29973,  5399, 29991,    13,    13,
         29925,   790,  2958,   446, 29973,  5399, 29991,    13,    13, 29943,
           442,  2958,   446,  1048,   278,  4168,  6400,   504, 29973,  5399,
         29991,    13,    13,  3624,  3078, 26546,   363,   317,  1175,   333,
         29973,   739,  5692,   577,   408,   540,  1584,  8026,   297,   263,
           379, 14108, 29899,  7083,   493, 29875, 13590, 10787,  5322,   964,
           278,  6837, 29991,    13,    13,  2697, 18425,   297,   263,   379,
         14108, 29899,  5965,  5086,  4517, 29892,   591,  5870, 12835,   554,
           313, 17618,   361, 10785, 18915, 29897,   263, 27229,   845,  2460,
         24532,   284, 29899,  1853,  7911,  1111,   265,   322,  7051,  8491,
           419,   287,   713,   322,   670,  1900,  5121,   476, 24540,   313,
         29934,  3246, 29882,  2726, 29882,  2589, 15339,   511,  1058, 18864,
          1009,   931, 23623, 24866, 12516,  5377,   278,  7021, 10537,  6573,
         29889,    13,    13, 13555, 25136,  1009,  5360,   363,  1269,   916,
           313, 30086,  3492,  5360,   592, 29973, 30010,  5129,  8241, 30010,
           511,   896, 13748,   777,   805,   638,   287,  4094, 29892,   607,
          3732,   963, 23389,   763, 26361, 29892,   322,   526,  9508,   368,
         19355,   304,   385,   408,  2904,   398, 29892,   607,   884, 12955,
          1009,   748,   974, 29891, 27641, 29889,    13,    13, 15597,  1095,
           701,  1641, 25257,   363,  1269,   916, 29889,    13,    13,  3112,
         10083,   763,   263,  2504,  5921,  5188,   895,   363,   269,  6984,
           303,   860,  3165,   473,   541, 18915,  4893,   445, 22830, 29901,
          4890, 13672,   269,  6984,  1269,   916,   322,  1560,   799,   541,
           357,   373,  1269,   916, 17240,   297,  1797,   304,   321,  5744,
         10569,   357, 29889,    13,    13,  8439,   526,   694,   337,   311,
           331,   292,  5680,   297,   445, 21620, 26771,   292,   528,  1117,
           324,   293,  2706, 29892,   607,   338,   263,  3652,   310,   443,
          7692,  1460,   322,  3309, 29891, 15602, 20459, 13261,   287,  4208,
         29889],
        [    1,   678, 16047,   267, 14432,   310, 11176, 14703, 16083,  5722,
          8910, 10591,  1078,   297,   278,   664,  6689,   297, 14883, 29901,
           263,  4021, 23378,  6559, 29889,    13, 29923,  1050, 14703, 16083,
          5722, 14722,   313, 29923, 11490, 29879, 29897,   297, 14883,  3896,
           278,   664,  6689,  1156,   263,  3273, 21567,  9793, 29889, 11275,
           664,  6689,   756,  1880, 23023,  1848,  1652,  5313, 29884,   800,
           322,  7275,   267,  1880, 12959, 29889,   450, 12242,   310,   445,
          6559,   471,   304, 24809,   278, 18066,   267, 20050,   491,   382,
         11490, 10591,  1078,   297, 14883, 29889,   910,  7436,  6559,   471,
         18043,   773,  4021, 23378,  2793,  7418, 29889,  8168, 13841,  1828,
           287,  1199,   322, 10591,  1078,   411, 29871, 29906,   304, 29871,
         29941,  2440,   310,  2669,   892, 15593,   287,   322,  1009, 20890,
           892, 29537,   287,   491,  2793,  7418, 29889, 10987,   886,   892,
          9132,   297,  5320,   963,   267, 29901,  8674,  1288, 12959, 29892,
         28976,  3114, 29892, 10257, 12084, 29892, 23023,  1848,  2254, 29892,
           322, 19818, 11235,   310,  4045, 29889, 21882,  4828, 21751,   382,
         11490, 29879,   297, 14883, 29889,  7519, 29883,  4097,   322, 28976,
           715,   812,   414,   297,   445, 29822,  1033,  1371,  8814,  1438,
          4828,   491, 23484,   292,  1108,  2454,  3291,   297,   278,  9793,
           322, 10643,   310,   382, 11490, 10591,  1078,   322,   491, 23484,
           292, 28976,  3519,   322,  5199,  6503, 10643,   304,  3867,  2253,
          5786,   322,  4078, 12080, 29889,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2]], device='cuda:0')
torch.Size([2, 341, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [-10.4062, -12.7578,   1.7705,  ...,  -6.6836,  -1.6875,  -6.2344],
         [ -9.5312, -10.1250,   2.8984,  ...,  -5.0781,  -2.4160,  -6.2070],
         ...,
         [ -2.4609,  -2.5762,  -1.8467,  ...,  -0.2607,   5.7344,  -0.4692],
         [ -6.6406,  -4.5469,  -3.8555,  ...,  -4.3281,  -0.7900,  -5.5234],
         [ -5.8633,  -3.8203,   0.9077,  ...,  -4.2188,  -2.8770,  -4.0977]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -7.3320,  -6.4414,   3.5801,  ...,  -4.5039,  -4.6758,  -4.0898],
         [-11.4062, -16.4688,  -0.9956,  ...,  -6.7031,  -3.4473,  -7.4414],
         ...,
         [ -4.6445,  -2.9355,   2.0957,  ...,  -3.5938,  -4.1016,  -3.0195],
         [ -4.6523,  -2.9336,   2.0996,  ...,  -3.5957,  -4.1055,  -3.0234],
         [ -4.6328,  -2.9141,   2.0898,  ...,  -3.5879,  -4.1016,  -3.0195]]],
       device='cuda:0')
torch.Size([2, 341, 1]) tensor([[[29918],
         [29871],
         [29874],
         [29874],
         [ 2308],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29874],
         [  313],
         [29892],
         [29899],
         [29874],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29874],
         [30488],
         [29874],
         [30488],
         [29874],
         [30488],
         [29874],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29899],
         [ 1457],
         [29899],
         [29899],
         [29874],
         [29874],
         [29874],
         [29899],
         [29903],
         [  272],
         [29882],
         [  370],
         [29899],
         [29899],
         [  261],
         [29973],
         [29874],
         [29871],
         [29874],
         [  262],
         [29874],
         [29871],
         [29874],
         [29973],
         [ 5399],
         [29874],
         [29892],
         [29892],
         [  793],
         [  392],
         [29899],
         [29874],
         [29973],
         [ 5399],
         [29874],
         [29874],
         [29892],
         [  349],
         [29899],
         [  292],
         [29874],
         [29973],
         [29892],
         [29892],
         [29871],
         [29874],
         [29973],
         [ 5399],
         [29874],
         [29874],
         [29892],
         [  349],
         [29874],
         [30488],
         [  262],
         [29874],
         [30488],
         [30488],
         [  262],
         [29892],
         [30488],
         [30488],
         [29874],
         [29909],
         [29874],
         [  262],
         [  297],
         [29874],
         [30488],
         [30879],
         [29899],
         [  349],
         [  262],
         [29874],
         [29899],
         [29892],
         [29874],
         [29874],
         [29874],
         [29909],
         [14131],
         [  313],
         [29899],
         [29892],
         [  262],
         [  262],
         [29874],
         [29892],
         [29871],
         [29899],
         [  349],
         [29874],
         [29899],
         [29899],
         [29874],
         [  774],
         [29874],
         [29874],
         [29874],
         [29892],
         [29871],
         [29909],
         [29882],
         [29874],
         [  392],
         [29899],
         [  262],
         [29874],
         [  262],
         [29871],
         [29899],
         [  281],
         [29899],
         [29871],
         [  262],
         [29899],
         [29874],
         [ 8491],
         [29899],
         [29874],
         [29903],
         [29909],
         [29874],
         [29882],
         [  392],
         [30488],
         [29871],
         [  313],
         [30488],
         [30488],
         [29874],
         [30488],
         [30488],
         [31147],
         [29874],
         [29874],
         [29874],
         [29874],
         [ 1009],
         [29909],
         [29882],
         [29874],
         [29882],
         [  392],
         [  262],
         [29892],
         [  262],
         [29950],
         [29874],
         [29882],
         [29899],
         [  319],
         [  497],
         [29909],
         [29882],
         [  363],
         [29909],
         [29899],
         [  705],
         [29892],
         [  306],
         [30010],
         [  592],
         [29874],
         [30488],
         [30488],
         [  306],
         [  306],
         [29889],
         [29874],
         [29903],
         [29874],
         [30488],
         [29874],
         [29871],
         [30488],
         [29909],
         [  392],
         [29909],
         [20313],
         [29882],
         [  604],
         [ 3001],
         [  392],
         [  392],
         [29909],
         [29925],
         [29909],
         [29882],
         [  517],
         [29874],
         [29874],
         [  262],
         [  856],
         [  262],
         [29882],
         [29909],
         [29903],
         [29874],
         [30488],
         [29899],
         [29909],
         [29899],
         [29909],
         [  313],
         [29899],
         [  319],
         [  276],
         [  701],
         [29882],
         [29882],
         [  363],
         [29874],
         [29899],
         [  392],
         [29892],
         [29899],
         [  319],
         [29903],
         [30488],
         [29874],
         [30488],
         [29925],
         [30879],
         [29871],
         [ 1454],
         [29874],
         [  368],
         [29909],
         [  680],
         [  262],
         [29874],
         [  818],
         [  509],
         [30010],
         [29882],
         [29882],
         [30488],
         [29909],
         [29882],
         [29874],
         [ 1004],
         [29899],
         [30488],
         [ 4771],
         [29882],
         [29874],
         [29874],
         [29874],
         [29909],
         [29909],
         [29882],
         [29915],
         [  262],
         [30488],
         [  517],
         [29882],
         [ 1730],
         [29882],
         [29879],
         [29882],
         [  313],
         [29899],
         [29892],
         [  262],
         [29874],
         [29899],
         [  311],
         [29903],
         [  292],
         [29909],
         [  297],
         [29909],
         [29874],
         [  465],
         [  292],
         [29874],
         [29874],
         [  793],
         [29903],
         [29874],
         [29903],
         [29874],
         [29903],
         [29903],
         [  392],
         [29874],
         [29874],
         [13492],
         [ 1460],
         [ 2071],
         [  262],
         [29909],
         [ 2071],
         [29886],
         [  392],
         [  287],
         [ 4208],
         [  517],
         [29892]],

        [[29918],
         [29871],
         [  292],
         [ 1454],
         [29874],
         [29903],
         [ 3460],
         [29874],
         [29874],
         [29924],
         [  376],
         [ 4167],
         [29874],
         [29950],
         [29874],
         [10118],
         [29874],
         [29874],
         [29874],
         [30488],
         [30488],
         [  856],
         [29875],
         [29874],
         [10266],
         [29899],
         [29874],
         [29874],
         [29874],
         [29874],
         [29924],
         [  271],
         [  382],
         [29874],
         [29879],
         [29874],
         [ 2364],
         [29902],
         [ 2364],
         [ 1457],
         [29874],
         [10118],
         [ 2541],
         [29882],
         [  392],
         [29899],
         [  392],
         [  392],
         [29882],
         [29874],
         [  845],
         [29899],
         [  517],
         [29899],
         [ 1848],
         [  392],
         [  856],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  373],
         [  382],
         [30488],
         [29903],
         [29874],
         [30488],
         [  262],
         [  517],
         [29875],
         [  382],
         [  856],
         [29899],
         [ 5738],
         [  491],
         [  382],
         [29874],
         [29879],
         [  392],
         [  262],
         [  278],
         [  262],
         [31147],
         [29874],
         [31147],
         [  262],
         [  392],
         [  262],
         [29874],
         [29899],
         [  392],
         [29909],
         [  392],
         [31147],
         [  625],
         [29899],
         [29874],
         [29903],
         [  392],
         [29874],
         [ 1078],
         [  392],
         [  472],
         [29896],
         [29900],
         [  392],
         [29896],
         [  229],
         [ 7271],
         [ 7271],
         [25772],
         [  392],
         [  856],
         [12647],
         [29871],
         [  392],
         [29893],
         [  392],
         [29899],
         [  392],
         [31147],
         [29909],
         [  392],
         [31147],
         [29874],
         [  276],
         [29874],
         [  262],
         [  392],
         [29899],
         [  856],
         [  392],
         [  313],
         [ 1288],
         [  392],
         [29874],
         [29892],
         [ 5254],
         [  392],
         [29892],
         [  392],
         [  392],
         [29892],
         [ 1848],
         [  392],
         [  392],
         [  392],
         [29899],
         [11235],
         [  376],
         [29923],
         [29915],
         [29915],
         [  392],
         [26180],
         [  292],
         [11490],
         [29879],
         [  262],
         [ 1009],
         [  262],
         [30057],
         [29883],
         [ 1288],
         [  392],
         [  262],
         [  715],
         [  392],
         [  414],
         [  392],
         [29902],
         [  392],
         [26180],
         [  392],
         [  517],
         [ 1438],
         [  392],
         [  491],
         [  392],
         [  292],
         [ 1552],
         [ 2454],
         [  392],
         [  297],
         [  278],
         [29924],
         [ 9878],
         [29882],
         [  284],
         [  382],
         [11490],
         [29879],
         [ 1078],
         [  262],
         [29902],
         [ 3364],
         [  292],
         [  278],
         [  392],
         [14131],
         [29899],
         [29924],
         [ 3733],
         [ 3733],
         [ 1131],
         [29874],
         [29899],
         [ 5738],
         [29874],
         [ 1457],
         [  262],
         [29892],
         [29924],
         [29924],
         [29924],
         [29924],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889]]], device='cuda:0')
torch.Size([2, 341, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29899,  ..., 29903, 29895,   517],
         [29874, 29882, 29879,  ..., 29902, 29885, 29899],
         ...,
         [ 4208, 31555,  3996,  ..., 23414,   351,  1323],
         [  517,  2541, 29874,  ...,   941, 29893,   354],
         [29892, 29882,   313,  ...,    13, 29915,   376]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ..., 29896, 29915, 29874],
         [  292, 29871, 29874,  ..., 29915, 29892, 29924],
         ...,
         [29889, 29892, 29871,  ..., 30488, 29915,   349],
         [29889, 29892, 29871,  ..., 30488, 29915,   349],
         [29889, 29892, 29871,  ..., 30488, 31147,   349]]], device='cuda:0')
Batch 33, 57.6% of total tokens
encoded shape: torch.Size([2, 1030])
torch.Size([2, 1030]) tensor([[    1,   450,  5493,  ..., 29889,   317, 15451],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1030, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -9.5547, -13.0312,   0.3982,  ...,  -6.6094,  -1.0088,  -7.5977],
         [-11.1875, -13.7578,   2.5859,  ...,  -6.5898,  -4.2852,  -7.4531],
         ...,
         [ -5.3203,  -4.1289,   1.2188,  ...,  -3.4004,  -4.0195,  -3.3027],
         [ -5.1328,  -3.8848,   1.4912,  ...,  -3.5156,  -4.4336,  -3.5156],
         [-10.2891, -14.0625,  -1.9980,  ...,  -7.3086,  -4.6719,  -8.2031]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -7.1367,  -6.3672,   3.4805,  ...,  -4.6328,  -5.0664,  -3.9805],
         [ -9.1328,  -7.9727,   0.1193,  ...,  -4.9180,  -3.4141,  -4.8945],
         ...,
         [ -7.6992, -10.4609,  -6.0430,  ...,  -5.6055,  -1.7832,  -6.0977],
         [ -7.6484, -10.3984,  -6.1094,  ...,  -5.5938,  -1.7959,  -6.0820],
         [ -7.6484, -10.3906,  -6.1094,  ...,  -5.5781,  -1.7715,  -6.0664]]],
       device='cuda:0')
torch.Size([2, 1030, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [29874],
         [29871],
         [29874]],

        [[29918],
         [29871],
         [29874],
         ...,
         [14131],
         [14131],
         [14131]]], device='cuda:0')
torch.Size([2, 1030, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29915,  ..., 29903,   262, 29882],
         [29871, 29899, 29874,  ...,   313,   315,   376],
         ...,
         [29874, 29889, 29899,  ..., 29915,   856,   313],
         [29871, 29892, 29889,  ...,   349, 29915,   376],
         [29874, 29882,   313,  ..., 29896, 29892,   376]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [14131, 23333, 29879,  ...,  1131,   514,   376],
         [14131, 23333, 29879,  ...,  1131,   514,   376],
         [14131, 23333, 29879,  ...,  1131,   514,   376]]], device='cuda:0')
Batch 34, 59.0% of total tokens
encoded shape: torch.Size([2, 1019])
torch.Size([2, 1019]) tensor([[    1, 29871, 29941,  ...,     2,     2,     2],
        [    1, 23529,   349,  ...,   372,   338, 29889]], device='cuda:0')
torch.Size([2, 1019, 32000]) tensor([[[-9.0156,  0.8442,  0.8052,  ..., -3.0469, -5.3750, -2.3613],
         [-5.7109, -4.3555,  3.1562,  ..., -3.7715, -4.3477, -3.3730],
         [-5.7227, -3.9570,  2.3789,  ..., -4.0352, -4.1367, -3.6641],
         ...,
         [-6.5117, -2.8555, -0.0143,  ..., -3.9082, -4.0664, -3.5547],
         [-6.4961, -2.8789,  0.0456,  ..., -3.9082, -4.0781, -3.5566],
         [-6.3594, -2.8262,  0.1575,  ..., -3.8633, -4.0742, -3.5000]],

        [[-9.0156,  0.8442,  0.8052,  ..., -3.0469, -5.3750, -2.3613],
         [-4.9805, -3.4688,  1.9629,  ..., -3.5742, -4.0664, -3.2422],
         [-5.8555, -4.5664,  2.5371,  ..., -4.0273, -4.3633, -3.5410],
         ...,
         [-2.5645, -2.9395, -3.0488,  ..., -0.5430,  7.2695, -0.4949],
         [-7.4180, -8.1797, -4.7617,  ..., -3.4609,  0.2008, -4.5508],
         [-1.6094, -1.0137, -4.0078,  ...,  1.8232,  5.6602, -2.4258]]],
       device='cuda:0')
torch.Size([2, 1019, 1]) tensor([[[29918],
         [29871],
         [29899],
         ...,
         [  313],
         [  313],
         [  313]],

        [[29918],
         [29871],
         [29871],
         ...,
         [ 2656],
         [29874],
         [22995]]], device='cuda:0')
torch.Size([2, 1019, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29899, 29871, 29892,  ...,   376,   315, 29915],
         ...,
         [  313, 29892, 29915,  ..., 29899,   306,   341],
         [  313, 29892, 29915,  ..., 29899,   306,   341],
         [  313, 29892, 29915,  ..., 29899,   306,   341]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29889,  ..., 29915,   262,   315],
         [29871, 29889, 29892,  ...,   349,    13,   856],
         ...,
         [ 2656, 14380,  2924,  ...,   354,  1311, 20025],
         [29874,   593,   517,  ...,   331, 29902, 29875],
         [22995,  3792, 25772,  ..., 15753, 25771, 24601]]], device='cuda:0')
Batch 35, 60.3% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871, 29955,  ...,   278, 11654,   271],
        [    1, 29871, 29906,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-5.7188, -4.3633,  3.1621,  ..., -3.7734, -4.3477, -3.3750],
         [-5.1289, -3.3867,  1.9277,  ..., -3.7051, -3.9922, -3.3789],
         ...,
         [-7.2617, -5.6484,  0.4189,  ..., -3.5527, -1.0820, -3.7188],
         [-4.8438, -2.9551,  1.6992,  ..., -3.3945, -3.9824, -3.0840],
         [-5.4805, -3.7246,  1.4902,  ..., -3.3770, -3.8066, -3.3379]],

        [[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-5.7188, -4.3633,  3.1621,  ..., -3.7734, -4.3477, -3.3750],
         [-6.0625, -4.0234,  2.3203,  ..., -3.9238, -4.3008, -3.4434],
         ...,
         [-7.7656,  2.0332, -0.8003,  ..., -2.6934, -4.8750, -2.3105],
         [-7.7656,  2.0410, -0.7959,  ..., -2.6914, -4.8750, -2.3105],
         [-7.8398,  1.9854, -0.6968,  ..., -2.7324, -4.9336, -2.3398]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [29899],
         ...,
         [29924],
         [29871],
         [  313]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29918],
         [29918],
         [29918]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29899, 29892, 29889,  ..., 29915,   856, 29896],
         ...,
         [29924, 29874, 29928,  ..., 29950,  1454,   262],
         [29871, 29892,   856,  ...,   349, 29915,   315],
         [  313, 29899, 29915,  ..., 29933, 29896, 29876]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29899, 29892,  ...,   376, 29915,   349],
         ...,
         [29918, 29915, 30010,  ..., 29899,   229, 29892],
         [29918, 29915, 30010,  ..., 29899,   229, 29892],
         [29918, 29915, 30010,  ..., 29899, 29892,   229]]], device='cuda:0')
Batch 36, 64.5% of total tokens
encoded shape: torch.Size([2, 1785])
torch.Size([2, 1785]) tensor([[   1,  518,  797,  ...,    2,    2,    2],
        [   1, 4485,  390,  ...,  293, 6012,  414]], device='cuda:0')
torch.Size([2, 1785, 32000]) tensor([[[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [ -6.7578,  -6.1094,   4.1719,  ...,  -4.1211,  -4.5859,  -4.0234],
         [-10.6641, -15.3984,   1.5312,  ...,  -6.7539,  -4.4180,  -6.4180],
         ...,
         [ -4.5859,   1.0820,  -3.4785,  ...,  -2.2637,  -3.1641,  -2.2402],
         [ -4.5898,   1.0615,  -3.4746,  ...,  -2.2656,  -3.1680,  -2.2461],
         [ -4.5898,   1.0752,  -3.4746,  ...,  -2.2598,  -3.1602,  -2.2402]],

        [[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [-10.2031, -11.1719,   2.6191,  ...,  -5.7422,  -5.1523,  -6.4180],
         [ -6.3359,  -5.3945,   2.5293,  ...,  -3.8555,  -4.7305,  -3.5684],
         ...,
         [ -6.4375,  -5.2148,   0.4895,  ...,  -3.7969,  -2.2266,  -3.9980],
         [ -7.5781,  -6.7695,   1.1182,  ...,  -3.3223,  -3.2559,  -4.4648],
         [ -9.4141, -12.0156,  -0.0210,  ...,  -6.4844,  -3.6660,  -6.7422]]],
       device='cuda:0')
torch.Size([2, 1785, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [30488],
         [30488],
         [30488]],

        [[29918],
         [29871],
         [29871],
         ...,
         [  392],
         [29874],
         [29882]]], device='cuda:0')
torch.Size([2, 1785, 10]) tensor([[[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29892, 29899,  ..., 29874,   315,   349],
         [29874, 29899, 29879,  ..., 29875, 29903, 29883],
         ...,
         [30488, 30879, 31147,  ...,   313, 30140, 30057],
         [30488, 30879, 31147,  ...,   313, 30140, 30057],
         [30488, 30879, 31147,  ...,   313, 30140, 30057]],

        [[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29874, 29899,  ...,   349, 29933, 29879],
         [29871, 29892, 29889,  ...,   315,   856,   349],
         ...,
         [  392,   262, 29899,  ..., 29875, 29915, 29925],
         [29874,   414, 29933,  ...,   262, 29875, 29911],
         [29882, 29874,   392,  ...,   294, 29886, 29883]]], device='cuda:0')
Batch 37, 66.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871, 29896,  ...,     2,     2,     2],
        [    1,   910, 14059,  ...,   278,  9082,  5725]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-5.7188, -4.3633,  3.1621,  ..., -3.7734, -4.3477, -3.3750],
         [-6.7500, -4.9023,  3.0215,  ..., -3.6504, -4.2383, -3.9961],
         ...,
         [-4.4883,  1.0547, -3.4355,  ..., -2.1035, -3.0137, -2.3262],
         [-4.5195,  1.0645, -3.4551,  ..., -2.1074, -3.0293, -2.3340],
         [-4.5039,  1.0732, -3.4551,  ..., -2.0996, -3.0195, -2.3242]],

        [[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-6.7031, -4.9609,  3.1992,  ..., -3.8066, -3.4277, -4.3711],
         [-8.8047, -9.1641,  1.6631,  ..., -4.9648, -3.7461, -6.0039],
         ...,
         [-8.4453, -7.8398, -0.1543,  ..., -4.1797, -0.5752, -4.8633],
         [-7.5938, -6.5234,  0.6831,  ..., -2.8438, -2.3633, -4.3438],
         [-5.1641, -6.9297, -4.1211,  ..., -1.9170,  5.1133, -4.3750]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [30488],
         [30488],
         [30488]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29874],
         [  392]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29874, 29899,  ...,   376,   313,   856],
         ...,
         [30488, 30879, 31147,  ...,   392,   376, 29915],
         [30488, 30879, 31147,  ...,   392,   376, 29915],
         [30488, 30879, 31147,  ...,   392,   376, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29915,  ...,   315,   376, 29889],
         [29874, 29871, 29873,  ..., 29882,   317,   262],
         ...,
         [29874, 29924, 29882,  ...,   354, 29881, 29873],
         [29874, 29907, 29875,  ...,   271, 29882, 29886],
         [  392, 29879, 29985,  ..., 19274, 28045,  1761]]], device='cuda:0')
Batch 38, 71.3% of total tokens
encoded shape: torch.Size([2, 349])
torch.Size([2, 349]) tensor([[    1,   349,   496,  1478,   271,  3547,    13,    13, 29925,   496,
          1478,   271,  3547,   338,   263, 16106,   310, 26933, 29875,   297,
           278,  3942,  1459, 29885,  1070,   423, 23062, 29889,    13,    13,
          1123, 10662,    13,    13, 25865,  2988,    13,  4907, 29925,   496,
          1478,   271,  3547, 29915,   472, 11374,   383,   686, 17220,    13,
            13, 10900, 29901,  2177, 29885,  1070,   423, 23062,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13,  5328,   304,  1735,  4918,  9123,
           501,  2096,   363, 22583,  7190,   297,  3561,  9239, 29871, 29896,
         29889, 29929,    13,    13, 29902,   505,   263,  3561,  9239, 10781,
           411,   263, 10929,   393,   306, 20848,   322,   306,   864,   304,
          1735,   278,  1400,  3158,  3988,   363,   599,  6036, 29914,  4530,
           786,  7190,   373,   278,  3268, 29889,  2860,  3063,  1549,  1716,
           278, 29871, 10929,  2066,   322,  7136,  2066, 29892,   306, 29915,
           345,  2041,  4822,   278,  3989,   740,   395,  1366,   976,   657,
          6747,  4276,  5983,   580,  2999,  3064, 29889,  1317,   445,   278,
           740,   393,   306,   723,   505,   304,  6623, 29973,   960,   577,
         29892,   607,   934,   723,   306,   817,   304,  3863,   297,  1797,
           304,  1735,   278,  1400,  3158,   363,   599,   310,   278,  1804,
           786,  7190, 29973,    13,    13, 29909, 29901,    13,    13,  3492,
          1033,  7522,  1735,   278,  3158, 25076,  1961,  2916,   395,  1366,
           976,   657,  6747,  4276,  5983,   890,  6681, 29908,   304,  3158,
         13802,  8066, 29914,  2783,  2859, 29914,  2271,  1642, 29871, 13466,
         29892,   278,  1234,   338,  4874, 29889, 29871,   887,   508,  1735,
           372,   363,   697,   883,   565,   366,   864,   322,   297,   777,
          4251, 29892,  3196,  1422,  7190, 29889, 29871,   306,   674,   671,
           278, 11962,  6464,   883,   363,   385,  1342, 29889,    13,  3644,
           366,  2916,   470,  1480,   679, 29918,  1990,  1566,  1366, 29897,
          2629,   596,  4472,   934, 29892,   366,   674,  1284,   393,   278,
           770,  6943,   596,   679,  6747,  4276,  5983,   580,   338,   341,
           482, 29918, 15122, 29918,  7445, 29918,  2500, 29918, 11049,   313,
           277,   338,   884,   297,   263,  3440,   472,   278,  2246,   363,
          2322, 17475,   467,    13,  6295, 29892,   366,   508,  3509,   623,
         29914,   401, 29914,  3221, 29914, 29924,   482, 29914, 15122, 29914,
          7445, 29914,  2500, 29914, 11049, 29889,  1961,   304,   623, 29914,
           401, 29914,  2997, 29914, 29924,   482, 29914, 15122, 29914,  7445,
         29914,  2500, 29914, 11049, 29889,  1961,   322,  3863,   278,   970,
           740,   679,  6747,  4276,  5983,   580,   373,  1196, 29871, 29946,
         29929,   304,   736,   278,   995,   366,   864, 29889,    13,  9842,
         29901, 29871,   445,   338,   278,   376, 24561,   322, 26616, 29908,
           982,   310,  2599,   372, 29889, 29871,   450,  1492,   982,   338,
           304,  7338,   355, 29914,  4640,   278,   770,    13,    13]],
       device='cuda:0')
torch.Size([2, 349, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -9.8594, -10.9375,   4.2695,  ...,  -6.6992,  -4.3477,  -6.0703],
         [ -6.3320,  -5.3398,   3.0859,  ...,  -4.0117,  -4.5625,  -3.9844],
         ...,
         [ -8.7578, -11.1562,  -5.6992,  ...,  -6.8633,  -2.7891,  -6.9883],
         [ -8.7344, -11.0547,  -5.7578,  ...,  -6.7930,  -2.7305,  -6.9297],
         [ -8.7188, -10.9844,  -5.7930,  ...,  -6.7344,  -2.6816,  -6.8750]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -7.1406,  -6.3711,   3.4844,  ...,  -4.6367,  -5.0703,  -3.9824],
         [ -9.1250,  -7.9688,   0.1106,  ...,  -4.9141,  -3.4043,  -4.8945],
         ...,
         [ -7.2383,  -5.2383,  -2.9004,  ...,  -5.4492,  -3.5488,  -4.6797],
         [ -4.6328,  -2.7676,   1.8623,  ...,  -3.8145,  -4.2578,  -3.0664],
         [ -5.2500,  -3.5059,   1.8906,  ...,  -4.2188,  -4.0391,  -3.1250]]],
       device='cuda:0')
torch.Size([2, 349, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29871],
         [29899],
         [29874],
         [  313],
         [29871],
         [29871],
         [29871],
         [29874],
         [29903],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [29871],
         [29899],
         [29909],
         [29909],
         [29874],
         [29874],
         [29871],
         [29899],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29871],
         [29871],
         [29888],
         [29874],
         [29874],
         [29903],
         [29874],
         [  376],
         [29899],
         [29888],
         [  273],
         [29874],
         [29874],
         [29899],
         [29899],
         [29874],
         [29888],
         [29871],
         [29909],
         [29909],
         [29909],
         [29874],
         [29874],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29871]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29950],
         [29874],
         [ 2084],
         [29928],
         [  392],
         [29909],
         [29928],
         [29874],
         [29871],
         [29871],
         [29874],
         [29892],
         [29874],
         [29892],
         [29899],
         [26180],
         [ 3561],
         [29909],
         [29874],
         [29896],
         [29898],
         [29874],
         [29909],
         [29881],
         [29903],
         [  808],
         [29874],
         [29882],
         [30598],
         [  304],
         [ 3167],
         [16431],
         [ 4918],
         [ 2467],
         [ 2271],
         [29903],
         [ 1727],
         [ 4597],
         [  856],
         [30488],
         [  262],
         [29914],
         [29898],
         [30879],
         [30879],
         [29874],
         [30879],
         [  392],
         [  472],
         [29928],
         [29874],
         [29909],
         [29896],
         [29915],
         [  392],
         [29924],
         [29924],
         [  306],
         [  306],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [29874],
         [  392],
         [29881],
         [  262],
         [29915],
         [  593],
         [29903],
         [29874],
         [  306],
         [30488],
         [29915],
         [30488],
         [  304],
         [30488],
         [11082],
         [  856],
         [29902],
         [29902],
         [  920],
         [19095],
         [30488],
         [  306],
         [29874],
         [  304],
         [29874],
         [20509],
         [29924],
         [  517],
         [ 1356],
         [16431],
         [16431],
         [ 2467],
         [16431],
         [29874],
         [19095],
         [ 1552],
         [19095],
         [ 9514],
         [ 3812],
         [  373],
         [30879],
         [29892],
         [30879],
         [29874],
         [29892],
         [29892],
         [29892],
         [29915],
         [29874],
         [29909],
         [ 1552],
         [29903],
         [ 2271],
         [30488],
         [30488],
         [30488],
         [29889],
         [29899],
         [30488],
         [29899],
         [29874],
         [29874],
         [  262],
         [  262],
         [30488],
         [29903],
         [29874],
         [  262],
         [29892],
         [29899],
         [29881],
         [  262],
         [ 2467],
         [ 2224],
         [  262],
         [  856],
         [29915],
         [29874],
         [ 3561],
         [29924],
         [29915],
         [29882],
         [29874],
         [29915],
         [29915],
         [  276],
         [30488],
         [11082],
         [  262],
         [29924],
         [29924],
         [16431],
         [29909],
         [29881],
         [  517],
         [  856],
         [29924],
         [29903],
         [19095],
         [19095],
         [29924],
         [29909],
         [29874],
         [29915],
         [29915],
         [29915],
         [30488],
         [29874],
         [29909],
         [29915],
         [29909],
         [29915],
         [29874],
         [29924],
         [29881],
         [29915],
         [29892],
         [  262],
         [  276],
         [  287],
         [30488],
         [29924],
         [29899],
         [31147],
         [29896],
         [29892],
         [29874],
         [29889],
         [29874],
         [29909],
         [29909],
         [29881],
         [29915],
         [  645],
         [ 2886],
         [29874],
         [29924],
         [29874],
         [  978],
         [  976],
         [29874],
         [ 6747],
         [ 4276],
         [ 5983],
         [29882],
         [  275],
         [29924],
         [29892],
         [29892],
         [29889],
         [29874],
         [30488],
         [29874],
         [29889],
         [29874],
         [29892],
         [  313],
         [29892],
         [29915],
         [29924],
         [29924],
         [29924],
         [29924],
         [ 6610],
         [  459],
         [11082],
         [ 6610],
         [29924],
         [29874],
         [16431],
         [  856],
         [  856],
         [29874],
         [ 3150],
         [26180],
         [29874],
         [29924],
         [29874],
         [29892],
         [29874],
         [29892],
         [29874],
         [30879],
         [  856],
         [29874],
         [29892],
         [29892],
         [29892],
         [29874],
         [29892],
         [29874],
         [29892],
         [29889],
         [30879],
         [29915],
         [29874],
         [29871],
         [29892],
         [29874],
         [29892],
         [29874],
         [29892],
         [29892],
         [29874],
         [29892],
         [29899],
         [29892],
         [29874],
         [29892],
         [29874],
         [29892],
         [  313],
         [29892],
         [  392],
         [29874],
         [29924],
         [29924],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  262],
         [29882],
         [ 3454],
         [29906],
         [29871],
         [29896],
         [  271],
         [29874],
         [29874],
         [29893],
         [ 2467],
         [26180],
         [29881],
         [29915],
         [29892],
         [29874],
         [  262],
         [29924],
         [29882],
         [29924],
         [29924],
         [29892],
         [29899],
         [  360],
         [29899],
         [  392],
         [  517],
         [29909],
         [  372],
         [ 1356],
         [29915],
         [29915],
         [29924],
         [  982],
         [  304],
         [  517],
         [30488],
         [  392],
         [29924],
         [29874],
         [29924],
         [29924],
         [29924],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 349, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ...,   376, 29889,   317],
         [29871, 29892, 29899,  ...,    13, 29915,   349],
         ...,
         [29892, 29871, 29915,  ...,   263,   306,   341],
         [29892, 29871, 29915,  ...,   306,   263,   341],
         [29892, 29871, 29915,  ...,   306,   263,   341]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29924,   341, 29915,  ..., 29879, 29898,   262],
         [29892,   313, 29889,  ..., 29915,   349,    13],
         [29892, 29899,   313,  ..., 29889,   349,   392]]], device='cuda:0')
Batch 39, 71.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,    13,  ...,    13, 29881,  1127],
        [    1,   319,   402,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7734,  -4.3477,  -3.3750],
         [ -5.5742,   3.1094,   6.1836,  ...,  -0.4592,  -1.2529,   0.1636],
         ...,
         [ -4.8125,  -3.4883,   2.1016,  ...,  -3.7812,  -3.8262,  -2.9375],
         [ -5.0273,  -3.3965,   2.0254,  ...,  -3.6426,  -4.0312,  -3.1621],
         [ -4.7500,  -3.2910,   1.5918,  ...,  -3.4062,  -4.1484,  -3.1738]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [-10.1562, -14.0391,  -0.2639,  ...,  -6.8203,  -1.9922,  -8.5156],
         [ -8.0547, -13.6172,  -2.7988,  ...,  -6.3398,  -0.7056,  -7.8281],
         ...,
         [ -4.9141,  -3.2598,   2.1895,  ...,  -3.6289,  -4.2930,  -3.0996],
         [ -4.8945,  -3.2363,   2.1777,  ...,  -3.6191,  -4.2852,  -3.0918],
         [ -4.8828,  -3.2285,   2.1699,  ...,  -3.6152,  -4.2812,  -3.0879]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [29892],
         [29871],
         [29871]],

        [[29918],
         [29871],
         [29902],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [   13, 29871,   313,  ..., 30010, 29915,    12],
         ...,
         [29892, 29889,   313,  ...,   315, 29914, 29901],
         [29871, 29892, 29899,  ...,   392, 29896,   349],
         [29871, 29889, 29892,  ..., 30488, 29874,   856]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ...,   349, 29875,   315],
         [29902, 29909, 29899,  ...,   271,   319, 29915],
         ...,
         [29899, 29871, 29892,  ..., 29874, 29915, 29896],
         [29899, 29871, 29892,  ..., 29874, 29915, 29896],
         [29899, 29871, 29892,  ..., 29874, 29915, 29896]]], device='cuda:0')
Batch 40, 79.6% of total tokens
encoded shape: torch.Size([2, 796])
torch.Size([2, 796]) tensor([[    1,  7870,   323,  ...,  4225,   304,  1213],
        [    1,  1720, 22971,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 796, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -6.2227,  -4.9805,   2.4648,  ...,  -4.0273,  -4.3672,  -4.0547],
         [ -5.1289,  -3.8770,   2.2930,  ...,  -3.5020,  -4.4258,  -3.3320],
         ...,
         [ -6.5781,  -4.1797,  -2.5410,  ...,  -2.7578,   0.1318,  -4.9805],
         [ -4.0898,  -3.2676,  -5.1094,  ...,  -1.9072,   1.3008,  -3.4238],
         [ -8.3906,  -8.8984,   0.7031,  ...,  -7.3984,  -3.1270,  -7.1836]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -6.0195,  -4.6680,   2.7637,  ...,  -3.8711,  -4.6172,  -3.8320],
         [-10.5781, -13.1641,   0.4026,  ...,  -5.9180,  -3.6465,  -7.2305],
         ...,
         [ -7.7656,   0.3489,  -3.6328,  ...,  -2.2617,  -3.0508,  -2.4492],
         [ -7.7578,   0.4014,  -3.5410,  ...,  -2.2383,  -3.0547,  -2.4082],
         [ -7.7188,   0.4114,  -3.4023,  ...,  -2.1973,  -3.0469,  -2.3477]]],
       device='cuda:0')
torch.Size([2, 796, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [  304],
         [  392],
         [29882]],

        [[29918],
         [29871],
         [29874],
         ...,
         [10266],
         [10266],
         [10266]]], device='cuda:0')
torch.Size([2, 796, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   349,   262, 29889],
         [29871, 29889, 29892,  ...,   315,   349,   856],
         ...,
         [  304,   517,   372,  ...,   287,   262, 29911],
         [  392,  6042,  1356,  ..., 20539,  5232,  1311],
         [29882, 29899, 29881,  ..., 29883,   295, 29876]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   349,   856,    13],
         [29874, 29875, 29871,  ..., 29899, 29896,   294],
         ...,
         [10266,   891, 30119,  ..., 30010,  2880, 30057],
         [10266,   891, 30119,  ..., 30010,  2880, 30057],
         [10266,   891, 30119,  ..., 30010,  2880, 30057]]], device='cuda:0')
Batch 41, 80.4% of total tokens
encoded shape: torch.Size([2, 332])
torch.Size([2, 332]) tensor([[    1, 12798, 12026,   472,   278, 29871, 29906, 29900, 29900, 29947,
         13329,  1459,   284,   962, 29886,  1199,    13,    13, 29950,   549,
         12026, 22071,  1090,   278,  1024,   376, 29950,   549, 12026, 29892,
          7551, 29908,   472,   278, 29871, 29906, 29900, 29900, 29947, 13329,
          1459,   284,   962, 29886,  1199,   297,  1522,   823,   292, 29892,
         11647, 29915, 29879,  8063,   310,  7551, 29889, 12798, 12026,  2665,
         29871, 29906, 29896, 28563,   267,   304,   752,  2650,   297,  9475,
          4959,   472,   278,  1522,   823,   292, 12482, 29889, 29871,  8512,
         12798, 12026, 29915, 29879,   405,  9026,   471,   263,  5004,  4509,
           310,   278,  5641, 29907, 29892, 12798, 12026, 17791,   278,   321,
          1119,  6392,  4959, 29889,    13,    13, 19302,   284,  2879,    13,
            13, 29903,  4011,    13,    13, 29909,   386,  1026,  1199,    13,
            13, 28154,    13,    13, 29956,  2770,    13,    13, 29933,   542,
          1512,    13,    13, 29923,  1119,  6392,    13,    13, 21472, 29880,
         24377,    13,    13,  4301,   292,    13,    13, 29903,  1251, 11427,
            13,    13,  3562, 22556,    13,    13, 28154,    13,    13, 29956,
          2770,    13,    13, 29956, 10552,   305,  1466,   285, 16750,    13,
            13, 28154,    13,    13, 29956,  2770,    13,    13, 13393,   884,
            13, 29906, 29900, 29900, 29947, 13329,  1459,   284,   962, 29886,
          1199,    13, 29950,   549, 12026,   472,   278,  1459,   284,   962,
         29886,  1199,    13, 29950,   549, 12026, 29892,  7551,   472,   278,
         29871, 29906, 29900, 29900, 29947, 13329, 16373,    13,    13,  1123,
         10662,    13,    13, 25865,  2988,    13,  3629,   823,   292, 29871,
         29906, 29900, 29900, 29947,  1459,   284,   962, 16447, 12482, 10564,
         10781,    13, 17579,  1288,  1459,   284,   962, 16447, 12930,    13,
         29950,   549, 12026,  1459,   284,   962, 16447, 12930,   322, 12453,
          7993,   363,   278, 11661,  1711,  3295,  3606,   313, 29909,  4509,
           946,  3819,   310, 12453, 20438,   322, 19025, 12930,   310, 12798,
         12026, 29892,  7551, 29897,    13, 29950,   549, 12026, 12807,  2879,
           472,   278, 29871, 29906, 29900, 29900, 29947,  1459,   284,   962,
         16447, 12482,    13,    13, 10900, 29901, 29940,   800,   472,   278,
         29871, 29906, 29900, 29900, 29947, 13329,  1459,   284,   962, 29886,
          1199,    13, 29906, 29900, 29900, 29947,    13,  2177,   284,   962,
         29886,  1199],
        [    1,   660, 29901,    13,    13,  5328,   437,   306,  2125,   263,
          2643,   304,  1790,  4847,   297, 22809, 11189,   292, 29973,    13,
            13,  4591,   931,   304,   931, 29892,   263, 12307,   674,  2244,
           592,   304,  2125,   263,  2643,   304,  1790,  4847,   297,   590,
         22809, 11189,   292, 29901,  4412,  8301, 29895,  3748, 29901,    13,
            13, 29902,   505,   263,  2643,   306,   864,   366,   304,  2125,
           304,  1075, 29889,    13,    13, 10401,   306,  3544,   278, 10655,
         29892,   278, 12307,   674,  1827,  1554,   763, 29901,    13,    13,
          8949,   769, 29892,   723,   366,  3113,  2649,   529,   978, 29958,
           393,   306,   864,   304,  5193,   304,  1075,  1048,   376, 11358,
         25517,  8652,    13,    13, 11921,   525, 11358, 25517, 29915,  3620,
           304,  6514,   372,   338,   278, 12307, 10753,   304,  5193,  1048,
         29889,    13, 29902,   508, 29915, 29873,  2833,   304,  4377,   714,
           920,   304,  1209,   445,  2643,  3412, 29889, 29871,   306, 29915,
           345,  1898,  9348,   263,  5497,   304,   278,   916,  4847,   393,
          7805,   278,  1820,  1734, 29892,   541,   306, 29915,   345,  2360,
          4520,   738,  2924,   310, 24084, 19422,   363,   590, 14231, 29889,
            13,  5328,  3721,   947,   590, 12307,   864,   592,   304,  1209,
           373,   445,  2643, 29892,   322,   825,   338,   278, 20751,   313,
           361,   738, 29897,   363,  2599,   577, 29973,    13,    13, 29909,
         29901,    13,    13,  1576,  2022,   393,   278,  4213,  1875, 10753,
           304,  5193,   304,   756,   304, 22830,   748,   322,  5193,   304,
           278,  4213,  1875, 29889,  1987,   366, 29915,   645,   925,  1134,
           297,   825,   896,  5131,   304,  5193,  1048,   746,   278, 12247,
          5304,   701, 29889,    13,    13,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 332, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [-11.0859, -12.5312,   3.5312,  ...,  -6.4492,  -5.9023,  -6.4922],
         [ -8.9609, -13.1172,  -2.8066,  ...,  -7.4453,  -2.8008,  -7.9805],
         ...,
         [ -9.3281, -15.6719,  -1.4580,  ...,  -3.0840,  -2.4824,  -5.5859],
         [ -9.8516, -17.0156,  -3.2090,  ...,  -5.5273,  -3.0488,  -5.7422],
         [ -8.8828, -15.2891,  -4.1328,  ...,  -6.7539,  -2.8184,  -6.6328]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -7.1406,  -6.3711,   3.4844,  ...,  -4.6367,  -5.0703,  -3.9824],
         [ -9.1250,  -7.9688,   0.1106,  ...,  -4.9141,  -3.4043,  -4.8945],
         ...,
         [ -4.4453,  -2.8652,   1.9658,  ...,  -3.4473,  -4.0312,  -2.8633],
         [ -4.4219,  -2.8555,   1.9453,  ...,  -3.4395,  -4.0469,  -2.8613],
         [ -4.4258,  -2.8750,   1.9424,  ...,  -3.4473,  -4.0742,  -2.8750]]],
       device='cuda:0')
torch.Size([2, 332, 1]) tensor([[[29918],
         [29871],
         [29871],
         [  354],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29871],
         [29871],
         [29925],
         [29871],
         [29874],
         [29918],
         [29892],
         [29924],
         [29874],
         [29874],
         [  262],
         [29874],
         [29950],
         [29950],
         [29950],
         [29968],
         [29968],
         [29924],
         [29874],
         [29874],
         [  262],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29924],
         [ 1457],
         [  284],
         [29909],
         [29925],
         [29903],
         [  262],
         [29933],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [30488],
         [29874],
         [29874],
         [29933],
         [  262],
         [29915],
         [29874],
         [29915],
         [29874],
         [29874],
         [29896],
         [30488],
         [29874],
         [29874],
         [29933],
         [ 2650],
         [  262],
         [29933],
         [29928],
         [29874],
         [29933],
         [29928],
         [29874],
         [29924],
         [29928],
         [29874],
         [29915],
         [29871],
         [29950],
         [29874],
         [29915],
         [29871],
         [29909],
         [29871],
         [29915],
         [ 1646],
         [29950],
         [  392],
         [29909],
         [29928],
         [29928],
         [29874],
         [  517],
         [29950],
         [29968],
         [29915],
         [29874],
         [29903],
         [29874],
         [29933],
         [29909],
         [ 1454],
         [29915],
         [29892],
         [29915],
         [29874],
         [  392],
         [29874],
         [29874],
         [29874],
         [29915],
         [29874],
         [29899],
         [29899],
         [29874],
         [29903],
         [29903],
         [29874],
         [29874],
         [29930],
         [29915],
         [29874],
         [29930],
         [  273],
         [29874],
         [29874],
         [29930],
         [29924],
         [29933],
         [29874],
         [29892],
         [29930],
         [29874],
         [29874],
         [ 1457],
         [29899],
         [29930],
         [29874],
         [29933],
         [29874],
         [29899],
         [29903],
         [29874],
         [29874],
         [29899],
         [  317],
         [29892],
         [29874],
         [29874],
         [29899],
         [  317],
         [29874],
         [29874],
         [29899],
         [29930],
         [29871],
         [29874],
         [  317],
         [  273],
         [29874],
         [29899],
         [29915],
         [29871],
         [29933],
         [29933],
         [  285],
         [  285],
         [29874],
         [29871],
         [29915],
         [29871],
         [29874],
         [  317],
         [  354],
         [29874],
         [29871],
         [29915],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [  262],
         [29874],
         [29909],
         [29871],
         [29925],
         [29903],
         [29874],
         [29892],
         [29933],
         [29874],
         [29915],
         [29874],
         [29874],
         [29871],
         [  376],
         [29871],
         [29871],
         [29882],
         [29899],
         [29968],
         [29874],
         [29915],
         [29874],
         [29915],
         [29874],
         [29874],
         [29871],
         [29899],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29899],
         [29874],
         [  292],
         [29871],
         [29871],
         [29871],
         [29900],
         [29871],
         [29874],
         [  284],
         [  376],
         [29925],
         [29903],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29933],
         [29871],
         [29871],
         [29925],
         [29903],
         [29874],
         [29899],
         [29968],
         [29874],
         [29924],
         [29871],
         [  326],
         [29925],
         [29903],
         [29874],
         [29933],
         [29933],
         [ 1454],
         [29874],
         [29874],
         [29874],
         [29874],
         [29909],
         [29874],
         [29871],
         [29871],
         [29933],
         [29874],
         [29874],
         [29950],
         [29874],
         [29933],
         [29903],
         [29933],
         [29950],
         [29950],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29968],
         [29874],
         [29915],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [ 1459],
         [29871],
         [29909],
         [16447],
         [29903],
         [29874],
         [29899],
         [29899],
         [29899],
         [29906],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29871],
         [  376],
         [29925],
         [29871],
         [29874],
         [29899],
         [29871],
         [29871],
         [29871],
         [29874],
         [29899],
         [29874],
         [  376],
         [29925],
         [29903],
         [29874]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29874],
         [  306],
         [29874],
         [29874],
         [29909],
         [29909],
         [29924],
         [29874],
         [29874],
         [29924],
         [  392],
         [  292],
         [29874],
         [29874],
         [29871],
         [29892],
         [29874],
         [  304],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29911],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29899],
         [  262],
         [29899],
         [30488],
         [  392],
         [29871],
         [29882],
         [30488],
         [29874],
         [29892],
         [30488],
         [29915],
         [29874],
         [30488],
         [29874],
         [30879],
         [30488],
         [30488],
         [30488],
         [  262],
         [29909],
         [29874],
         [29915],
         [29892],
         [29892],
         [  306],
         [29915],
         [29874],
         [29882],
         [29902],
         [  306],
         [29899],
         [30488],
         [30488],
         [  856],
         [  517],
         [29874],
         [29874],
         [29899],
         [29873],
         [29909],
         [29874],
         [29909],
         [29874],
         [30488],
         [29911],
         [ 6610],
         [  313],
         [29958],
         [29874],
         [29902],
         [29915],
         [29874],
         [29909],
         [  517],
         [29966],
         [  262],
         [29874],
         [29892],
         [29899],
         [29909],
         [29874],
         [29899],
         [29892],
         [  294],
         [29889],
         [  392],
         [29915],
         [30488],
         [30488],
         [29874],
         [29915],
         [29915],
         [29909],
         [29874],
         [29893],
         [  592],
         [29911],
         [  517],
         [29874],
         [29889],
         [29892],
         [29915],
         [29915],
         [29889],
         [30488],
         [30488],
         [30488],
         [29874],
         [30488],
         [30488],
         [30488],
         [29874],
         [30488],
         [30488],
         [30488],
         [30879],
         [30879],
         [29915],
         [  345],
         [30879],
         [  856],
         [30488],
         [30488],
         [29882],
         [29874],
         [29874],
         [29874],
         [29915],
         [29915],
         [29874],
         [29899],
         [29909],
         [29898],
         [  392],
         [29909],
         [30488],
         [29889],
         [30488],
         [29909],
         [29874],
         [30488],
         [29874],
         [30488],
         [19422],
         [ 1250],
         [29882],
         [29882],
         [29874],
         [29871],
         [29899],
         [  437],
         [29903],
         [29874],
         [29874],
         [29915],
         [  592],
         [29874],
         [29903],
         [  445],
         [  445],
         [29882],
         [29973],
         [  392],
         [29903],
         [29915],
         [29874],
         [29874],
         [29902],
         [29892],
         [29911],
         [29909],
         [  363],
         [  592],
         [  445],
         [29973],
         [29874],
         [29892],
         [30488],
         [29899],
         [29892],
         [29892],
         [29915],
         [29874],
         [29909],
         [29915],
         [29874],
         [29933],
         [30879],
         [  304],
         [29911],
         [  304],
         [29903],
         [  941],
         [29909],
         [31147],
         [30488],
         [31147],
         [  517],
         [ 1552],
         [29874],
         [29933],
         [29915],
         [30879],
         [29874],
         [29915],
         [29909],
         [30879],
         [30879],
         [  297],
         [29874],
         [29915],
         [  276],
         [29874],
         [29911],
         [  517],
         [  262],
         [30488],
         [  262],
         [29909],
         [  701],
         [  392],
         [30879],
         [29892],
         [30488],
         [29933],
         [29933],
         [29924],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899],
         [29899],
         [29892],
         [29892],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889]]], device='cuda:0')
torch.Size([2, 332, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29874, 29899,  ..., 29875,   376,   262],
         [29871,   376, 29899,  ..., 29924, 30010, 29873],
         ...,
         [29925, 29886, 16447,  ..., 29902, 29903, 29915],
         [29903, 29871,   376,  ..., 29915, 29892, 29924],
         [29874, 29899, 29875,  ..., 29903,   262, 29906]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29889, 29871, 29899,  ...,   313, 31147, 29915],
         [29889, 29871, 29892,  ...,   856,   313,    13],
         [29889, 29871, 29892,  ...,   856,   313,    13]]], device='cuda:0')
Batch 42, 81.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 19040,   542,  ...,   278,   315,   489],
        [    1, 15057,   310,  ..., 29995, 25781, 29871]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [-10.8828, -14.6406,   2.9258,  ...,  -7.0586,  -4.5000,  -8.1328],
         [-10.5312, -13.8203,   1.8350,  ...,  -7.2305,  -4.4453,  -7.3984],
         ...,
         [ -8.5312, -10.8828,  -0.8525,  ...,  -5.1328,  -0.4021,  -5.7070],
         [ -7.3086, -12.4766,  -5.1055,  ...,  -5.9648,  -2.0996,  -6.8242],
         [ -7.0859,  -5.5195,   0.6108,  ...,  -4.8008,  -4.4648,  -4.5703]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [-10.6797, -12.1875,   2.0254,  ...,  -6.2305,  -3.9355,  -6.5039],
         [ -8.9844, -10.2109,  -0.2966,  ...,  -3.9902,  -0.0619,  -4.6602],
         ...,
         [ -4.1719,  -5.0352,  -3.1035,  ...,   0.8765,   3.5977,   0.5063],
         [-10.6250, -14.2578,  -3.7930,  ...,  -4.2188,  -1.2959,  -6.2812],
         [ -9.8203,  -8.7891,   1.0938,  ...,  -4.7148,  -4.2773,  -5.6875]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [29892],
         ...,
         [  262],
         [29896],
         [  379]],

        [[29918],
         [29871],
         [29874],
         ...,
         [25781],
         [29874],
         [29871]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29915,  ..., 29903, 29874, 29909],
         [29892, 29871, 29924,  ..., 29933,   856, 29896],
         ...,
         [  262, 29903, 29943,  ...,   271, 29911, 29928],
         [29896, 29899,  1148,  ...,   379, 29994, 29873],
         [  379,   315, 29950,  ...,   313, 29871,   341]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ...,   392, 29903, 29882],
         [29874, 29903, 29879,  ..., 29924, 29928, 29915],
         ...,
         [25781,  6821,  5527,  ..., 17332,   406, 29874],
         [29874, 29871,   392,  ..., 29883,   376, 29933],
         [29871, 29874, 29900,  ...,   376, 29892, 29909]]], device='cuda:0')
Batch 43, 89.2% of total tokens
encoded shape: torch.Size([2, 321])
torch.Size([2, 321]) tensor([[    1,   660, 29901,    13,    13,  6341, 12066, 29916,  2761,   451,
          1985,   411,  6379, 29890,   945, 29877, 29871, 29955,    13,    13,
         29902,   505,   263,  2560, 12066, 29916,  6958,   502,  2761,   393,
         16003,   385,  4876, 29889,    13, 29902,   505,  1063,   773,   372,
           975,   931,   304,  5164,  1922, 29890,   945, 29877, 28007,  2734,
          6910,   515, 29871, 29946,   701,   304, 29871, 29953, 29889, 29896,
         29889, 29945,   322,   372,   756,  2337,  3796,  2691, 29889,   306,
           505,  1063,   884,  1898,   372,   411,  5164,  6910,   310,   869,
          6006,  1728,  4828, 29889,    13,  4013,   931,   306,  4784,   372,
           304,   869,  6006, 29871, 29946, 29889, 29945,   322,  9528,   372,
           322,   769,  2715,   372,   297,   385,  6379, 29890,   945, 29877,
         29871, 29955,  2060, 29889,   739,  7697,   414,  2691,   541,   746,
           278,  9752,  2826,   338, 15385,   278,  1813,   337, 18132,  1728,
           263,  1400,  1627,   322,  3078,  5930, 29889,    13,  8439,   338,
           694,  1059,  2643,   297,   278, 10748, 29892,   727,   338,   694,
          6354,   515,   278,   883, 29889,    13,  1576,   775,   338,  1316,
           393,   565,   727,   338,   385,  1059,   393,   723,   367, 16459,
           322,  4318,   373,   278,  4315,  1156,   263,  1400,  1627,   541,
           278,   883,  3763,   337, 18132, 29889,    13, 29902,   505,  1898,
           599,   278,  9670, 12747,   322,   306,   508, 29915, 29873,  1284,
         13312,  3078,  2743,   411,   372, 29889,  1815,  5019,  4368,  2020,
           278,  2761,  7656, 29915, 29873,   664,   373,  6379, 29890,   945,
         29877, 29871, 29955,   470,   920,   304,  1284,   278,  1059,   393,
          9946,   263,  2989,  1813, 11086, 29973,    13, 25271,   366,    13,
            13, 29909, 29901,    13,    13,  3492,   508, 29915, 29873,   671,
          1404, 26255,   297, 13348,  8386, 29889,   960,   366,   864,   304,
           671,  1404, 26255,  1603,   769,  4607,   278,  4050,  6012,  1250,
           304,  2563,  9514,   297,  1922, 29890,   945, 29877,  9585, 29889,
          2917, 29892,  1162, 13317,   596,   623, 11565,   322,   337,  3258,
           599,   596, 17475,   408,  5835, 12292, 29889,  2398, 29892,   306,
         29915, 29881, 22939,   366,   304,   337,  1867,   278,   883,   297,
         13348, 29889,  5087, 29901,  6298,  2161,  2956,  6958,   883,    13,
            13],
        [    1,   660, 29901,    13,    13,  5618,   338,   278,  3978,   310,
           278,   376,  1366,   338,   263,   664,   310, 24159, 29908,  8252,
         29973,  1317,   372,   263,  3147,   412, 29973,    13,    13,  4178,
           278,  6763,   470,  1095,   310, 23238,   310,   385,   603,   306,
          6041,  1074,   263,  2313,   433,  4193,  2788,   304,   445, 29901,
            13,  4013,  1824,   338,   263,   664,   310, 24159, 29889,    13,
         10773,   620, 13365,   749,   304,  2305, 29892, 13973, 29892,    13,
           272, 18845,   338, 24837, 22819,  1693,   284, 29889,    13,    13,
          3624,   445,   263,  3147,   412, 29973,  1394,   338,   727,   777,
         10369,  1072,  2785,   393,  6041, 16058,   304,  1438,  3697, 29973,
            13,  1576,  2038, 14978,   471,  4586,   515,   278,  1095,   310,
          7073,   279,  2518, 29991,  9358, 29871, 29896, 29916, 29896, 29941,
           304,   367,  2684, 29889,    13,    13, 29909, 29901,    13,    13,
          4013,   338,  3109,   310,   263,  3147,   412,   322,   901,   310,
           263,  3509,  1266,  4380, 29899,   497,  5995, 29889,    13,  2887,
           263,  3407,   515,   278,  2178, 12407, 26797,   277,  2738,  2313,
           433,  4193, 29892,   278,  1667,  2769,   393,   445,   338,  2309,
           338,   304,  5557,  1790,  2022,   515,   480,   292,   363,  4303,
           295, 29889,    13,  3112,  3508, 29915, 29873,   443,  6370,  4695,
           304,  1348,   393,  4856, 29915, 29879,  3942,  1024,  1033,   367,
         11678, 29882,  2518, 29892,   322,   723,  2125,   867, 10384,   749,
           411,   278,   982, 15674,  9010,   338,  2011, 25724, 29889, 29871,
          1105, 29892,   304,  5557,   963,   515,   480,   292, 29892,   278,
          1736,   526,  1754,   304,   367, 24159,   322,   451,  2729,   373,
           738,   697,  2022,   470,   738,   697,  1855,  1741, 29889,    13,
          4013,   508,   884,  1304,   304,  4612,   701,   363,  2114,   950,
           297,  5753,  2002,  2478,   408,  1532, 29892,   639,  3685,   332,
          1794, 14092,   417, 29877, 29901,    13,    13,  4013,   664,   310,
         24159,   338,   451,   385, 16232, 15839,  2011,   764,   284, 29889,
            13, 27552,   591,  2562, 29889,    13, 10454, 12522,   701,   322,
         13389,   278,  1510, 29991,    13,    13,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2]], device='cuda:0')
torch.Size([2, 321, 32000]) tensor([[[-9.0156,  0.8428,  0.8076,  ..., -3.0449, -5.3789, -2.3613],
         [-7.1406, -6.3711,  3.4844,  ..., -4.6367, -5.0703, -3.9824],
         [-9.1328, -7.9805,  0.1097,  ..., -4.9219, -3.4062, -4.8984],
         ...,
         [-6.4570, -5.9648,  1.0439,  ..., -4.0508, -2.2734, -3.4629],
         [-4.8633, -3.1797,  2.0957,  ..., -3.8281, -4.4844, -3.2949],
         [-5.0938, -3.4414,  2.1387,  ..., -3.7129, -4.0195, -2.9961]],

        [[-9.0156,  0.8428,  0.8076,  ..., -3.0449, -5.3789, -2.3613],
         [-7.1406, -6.3711,  3.4844,  ..., -4.6367, -5.0703, -3.9824],
         [-9.1328, -7.9805,  0.1097,  ..., -4.9219, -3.4062, -4.8984],
         ...,
         [-4.9570, -3.1875,  2.7324,  ..., -3.6719, -4.2500, -3.0176],
         [-5.1016, -3.2656,  2.8008,  ..., -3.6855, -4.2188, -2.9844],
         [-5.0898, -3.2051,  2.6914,  ..., -3.6250, -4.1914, -2.9512]]],
       device='cuda:0')
torch.Size([2, 321, 1]) tensor([[[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29874],
         [29899],
         [29896],
         [29896],
         [  774],
         [29874],
         [29871],
         [29871],
         [29892],
         [29871],
         [29871],
         [29871],
         [29874],
         [29892],
         [29892],
         [  345],
         [29874],
         [29909],
         [29909],
         [29871],
         [29899],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [29892],
         [29915],
         [29893],
         [30488],
         [29928],
         [ 1454],
         [29874],
         [29893],
         [29903],
         [29928],
         [29871],
         [29892],
         [29874],
         [29924],
         [29902],
         [29924],
         [29881],
         [29894],
         [29871],
         [29874],
         [ 2935],
         [29924],
         [29871],
         [29874],
         [29915],
         [29896],
         [29892],
         [29874],
         [29915],
         [13129],
         [  593],
         [ 3796],
         [ 2691],
         [29874],
         [  313],
         [29915],
         [30488],
         [29909],
         [29909],
         [29881],
         [ 2541],
         [29928],
         [29903],
         [29881],
         [29909],
         [29892],
         [29898],
         [29874],
         [ 1129],
         [  313],
         [29902],
         [29909],
         [  306],
         [29915],
         [29928],
         [  517],
         [29924],
         [ 6779],
         [29946],
         [29946],
         [29874],
         [29945],
         [  392],
         [ 9249],
         [  372],
         [ 2541],
         [30488],
         [29902],
         [  372],
         [  304],
         [  976],
         [  809],
         [29871],
         [29892],
         [29874],
         [ 4836],
         [29871],
         [29874],
         [  392],
         [  313],
         [  999],
         [29889],
         [ 2691],
         [  541],
         [30488],
         [  306],
         [29909],
         [  275],
         [ 1491],
         [ 5254],
         [30488],
         [30488],
         [30488],
         [29899],
         [30488],
         [29903],
         [30488],
         [29899],
         [  392],
         [30488],
         [29903],
         [29909],
         [30879],
         [29892],
         [ 1454],
         [30488],
         [30488],
         [29903],
         [30488],
         [31147],
         [30488],
         [ 1445],
         [  392],
         [ 1454],
         [30488],
         [29874],
         [  271],
         [29874],
         [  392],
         [29874],
         [  313],
         [29892],
         [29874],
         [29903],
         [29875],
         [29874],
         [  856],
         [29888],
         [29915],
         [29874],
         [29903],
         [  705],
         [29903],
         [29909],
         [ 1129],
         [29876],
         [29874],
         [  517],
         [ 1552],
         [ 6151],
         [29885],
         [  392],
         [29909],
         [ 1627],
         [  271],
         [  856],
         [29909],
         [ 1491],
         [11834],
         [18132],
         [  392],
         [  313],
         [29892],
         [  661],
         [ 1129],
         [  262],
         [29909],
         [29909],
         [29928],
         [ 1761],
         [29915],
         [ 8077],
         [29915],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 2541],
         [ 1552],
         [  856],
         [  313],
         [29915],
         [30488],
         [30488],
         [29874],
         [29909],
         [30488],
         [29915],
         [29892],
         [29909],
         [  262],
         [ 2935],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29973],
         [29903],
         [  517],
         [30488],
         [ 1332],
         [16431],
         [16431],
         [29915],
         [  372],
         [29874],
         [29909],
         [11086],
         [  287],
         [  313],
         [29892],
         [  292],
         [31147],
         [29892],
         [29899],
         [29874],
         [29892],
         [29892],
         [29892],
         [  276],
         [29903],
         [29909],
         [29903],
         [29909],
         [29909],
         [29881],
         [ 5628],
         [ 8006],
         [ 2142],
         [29915],
         [  366],
         [  276],
         [  517],
         [29903],
         [29874],
         [26255],
         [  297],
         [29874],
         [29874],
         [  304],
         [29909],
         [29909],
         [  517],
         [  517],
         [30488],
         [29874],
         [  392],
         [29909],
         [29871],
         [29871],
         [29874],
         [29915],
         [29874],
         [29892],
         [29909],
         [29892],
         [29876],
         [29875],
         [29875],
         [  392],
         [  392],
         [29874],
         [29899],
         [29874],
         [29909],
         [29909],
         [ 2142],
         [29909],
         [29909],
         [  262],
         [29915],
         [29902],
         [  705],
         [29915],
         [29881],
         [30488],
         [29909],
         [  517],
         [29909],
         [29899],
         [29985],
         [12346],
         [ 6451],
         [ 9504],
         [29888],
         [29915],
         [29909],
         [29909],
         [  262],
         [29874],
         [  392],
         [  375],
         [  392],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29915],
         [29874],
         [29924],
         [29924],
         [29924],
         [29924],
         [29892],
         [29899],
         [29874],
         [29924],
         [  262],
         [29903],
         [29874],
         [ 2313],
         [29903],
         [29915],
         [  372],
         [29874],
         [29903],
         [  412],
         [ 3147],
         [ 3147],
         [29892],
         [29892],
         [ 9089],
         [29903],
         [29874],
         [29903],
         [  310],
         [29874],
         [29874],
         [29903],
         [29903],
         [29874],
         [29915],
         [  354],
         [29874],
         [ 2313],
         [  824],
         [  326],
         [  376],
         [  304],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [ 1287],
         [ 4704],
         [  326],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [  663],
         [  517],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [  392],
         [29875],
         [  284],
         [29874],
         [29874],
         [29899],
         [29899],
         [  445],
         [ 3147],
         [ 3147],
         [  412],
         [29973],
         [29915],
         [29915],
         [  372],
         [29874],
         [29899],
         [29914],
         [ 2785],
         [12748],
         [ 1261],
         [29902],
         [  517],
         [29903],
         [29876],
         [29973],
         [  313],
         [29892],
         [29915],
         [29899],
         [29915],
         [  354],
         [  515],
         [29874],
         [29903],
         [29903],
         [29874],
         [29871],
         [29871],
         [29874],
         [29915],
         [29896],
         [29871],
         [29896],
         [29896],
         [29896],
         [29874],
         [29874],
         [30488],
         [29874],
         [29915],
         [29892],
         [29892],
         [29899],
         [29892],
         [29892],
         [29892],
         [29915],
         [29874],
         [29874],
         [ 3147],
         [ 3147],
         [29903],
         [ 3147],
         [30488],
         [29874],
         [29874],
         [29903],
         [ 1266],
         [29914],
         [24588],
         [  497],
         [29876],
         [  292],
         [29915],
         [29892],
         [  680],
         [29903],
         [29903],
         [29874],
         [29903],
         [29899],
         [29874],
         [29874],
         [30488],
         [30488],
         [30488],
         [29874],
         [  281],
         [29874],
         [29889],
         [30488],
         [30488],
         [29915],
         [30488],
         [30879],
         [30488],
         [  517],
         [29903],
         [30879],
         [30488],
         [29898],
         [30879],
         [30879],
         [29874],
         [30488],
         [29874],
         [14131],
         [  313],
         [29892],
         [29915],
         [29915],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [  393],
         [29874],
         [30879],
         [29892],
         [30879],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [29871],
         [29874],
         [29892],
         [29874],
         [30488],
         [  372],
         [29874],
         [  681],
         [ 2467],
         [29874],
         [29915],
         [15988],
         [29871],
         [29915],
         [ 2011],
         [25724],
         [29874],
         [  313],
         [29915],
         [29874],
         [29915],
         [ 5494],
         [ 1316],
         [29903],
         [  480],
         [  292],
         [29892],
         [29915],
         [29915],
         [29915],
         [29903],
         [29903],
         [30488],
         [ 1736],
         [29874],
         [29874],
         [29874],
         [  373],
         [29874],
         [29874],
         [29915],
         [29915],
         [29915],
         [  376],
         [29915],
         [ 2624],
         [29874],
         [29915],
         [29892],
         [29915],
         [30488],
         [29876],
         [29874],
         [29903],
         [29915],
         [  376],
         [29915],
         [  950],
         [29914],
         [ 1131],
         [  313],
         [29871],
         [29874],
         [29915],
         [29874],
         [29872],
         [29915],
         [29915],
         [29871],
         [29899],
         [30488],
         [29874],
         [29915],
         [29874],
         [29892],
         [29899],
         [29874],
         [29909],
         [29874],
         [29874],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [29909],
         [  284],
         [29874],
         [29915],
         [29892],
         [ 3538],
         [29874],
         [29874],
         [29915],
         [29899],
         [29874],
         [29903],
         [30488],
         [29874],
         [29874],
         [29909],
         [  262],
         [29874],
         [29892],
         [29892],
         [29924],
         [29924],
         [29924],
         [29924],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 321, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [  392, 29909, 29903,  ..., 29883, 29875, 29911],
         [29892, 29889, 29899,  ..., 29914,   349, 29898],
         [29892, 29899,   313,  ..., 29909, 29889,   392]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29892, 29871, 29889,  ..., 29915, 29874,   349],
         [29892, 29871, 29899,  ..., 29915, 29874,   349],
         [29892, 29871, 29899,  ...,   856,   349, 29874]]], device='cuda:0')
Batch 44, 89.8% of total tokens
encoded shape: torch.Size([2, 222])
torch.Size([2, 222]) tensor([[    1, 15573,  1705, 19923,  2770, 20191,   346,   280,   322,  1085,
         12963, 29915, 29879, 17135, 29889,  3118,  1206, 29889,    13,  1576,
         15717,  3461,   263,  1206,   310,  7067,  1705, 19923,  2770, 20191,
           346,   280, 10943,   491,  8825,   297,   263, 29871, 29906, 29929,
         29899,  6360,  2030, 14263, 16500,  2198,   292,   411,  1085, 12963,
         29915, 29879, 17135, 29889,   512,   445, 17135, 29892,  1316,   633,
          8945,  1907,   526,  3619,   322,  2861,   304, 19163,   573, 13855,
          1793, 29889,   310,   278,  1411, 29874, 15875, 29889, 26637,   322,
           341,  3960,  3867,   385, 16232, 18131,  5996,  7418,   322,   263,
          4866, 17983,   310,   301,  3774,   359,   562,  1705,   288,  1655,
          2770, 19144,   284,   633,  8945,  1907, 29889,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,   350,  7515,  3250,  5977,    13,    13, 29896, 29900, 29955,
         29889, 29955,   278,  6211,   350,  7515,  3250,  5977,   756,  1754,
           777,  5566, 11407,  3620, 29991,   887,   508,  1603,  9752, 12060,
         16700,  1244,   304,   367,  1303,   373,   278,  4799,  1432,  4723,
          3250,  7250,   472, 29871, 29955, 29901, 29906, 29900, 29889,  2398,
         29892,   304,  7150, 21114,  3581,  1112, 16688,   373,   596, 12060,
          3250,  3025,  4876, 29892,   366,  1818,  1804,   701,   363,   278,
          5852,  4644,  9204,  8527,   383,   273,  9305, 29889,  3529,  1804,
           701,  1244, 29991,    13,    13,  6880,   414,  3160, 29901,    13,
            13, 29938, 29941,  1283,   263,  6097,  1974,  1559,   471, 29882,
           515,  4306,  7103, 11133,   399,  1161,    13,    13,  2577, 29871,
         29896, 29914, 29906,  1283,   263,  4158,   482,   472,  7360,   482,
         13976, 18385, 15202,  7817,    13,    13, 24131,   395, 29896, 29900,
          1283,   738,  4943,   544,  7612,  2944,   472,  2581,   550,   402,
         17741,   322,   315,  3163, 29892,  3271,   310,   278,  1346,  9588,
         11500,  9954,   317,   744, 30024,   297,  9272,   414,  4412, 29991,
            13,    13, 29933,  8193,  4690, 28658,  2672, 19094,  8098,   399,
         24071,  5195, 29032,  6732, 24080,  8291, 29911,  6227,  6093,   399,
         17896, 29968,  8079,   612, 22970,   350,  8193,  4690, 28658, 29889,
           612, 27269,   315,  2190,  8183,  5195, 29899, 20633, 26349, 15842,
          6093,   405, 12194,   612, 26441, 29991,    13,    13, 17813,   278,
           883,  2400,   304,  9752,   596, 12060,  3250, 26232,   304,  5852,
          4644,  9204]], device='cuda:0')
torch.Size([2, 222, 32000]) tensor([[[ -9.0547,   0.7935,   0.8057,  ...,  -3.0742,  -5.4062,  -2.3906],
         [ -8.1875,  -7.0312,   3.4062,  ...,  -4.7578,  -5.1172,  -4.6602],
         [-10.1641, -14.7031,  -3.0938,  ...,  -6.8281,  -2.9219,  -7.9336],
         ...,
         [ -4.0391,  -2.2324,   1.6709,  ...,  -3.3281,  -3.9492,  -2.8184],
         [ -4.0039,  -2.1914,   1.6387,  ...,  -3.3164,  -3.9375,  -2.8027],
         [ -3.9648,  -2.1387,   1.6064,  ...,  -3.3008,  -3.9238,  -2.7832]],

        [[ -9.0547,   0.7935,   0.8057,  ...,  -3.0742,  -5.4062,  -2.3906],
         [-10.3359, -12.4766,   4.1289,  ...,  -7.7305,  -4.4609,  -7.6094],
         [ -9.9609, -12.7578,  -1.5039,  ...,  -6.3867,  -3.6738,  -8.9297],
         ...,
         [ -6.2344,  -4.2812,   1.8525,  ...,  -3.9355,  -4.1445,  -3.6289],
         [ -7.1406,  -2.8457,  -2.0430,  ...,  -3.0625,  -2.2090,  -4.2969],
         [ -7.1875,  -2.9883,  -2.6328,  ...,  -3.4727,  -2.7246,  -4.4180]]],
       device='cuda:0')
torch.Size([2, 222, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [  262],
         [29871],
         [29903],
         [30488],
         [30488],
         [30488],
         [  313],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29903],
         [29874],
         [  392],
         [  262],
         [29874],
         [  262],
         [29874],
         [30488],
         [29871],
         [29906],
         [29899],
         [30304],
         [29899],
         [30488],
         [29874],
         [  262],
         [  262],
         [29874],
         [29874],
         [29874],
         [29915],
         [29871],
         [29928],
         [29874],
         [29915],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [29874],
         [ 1907],
         [29874],
         [  375],
         [  705],
         [29874],
         [  304],
         [29874],
         [  262],
         [30488],
         [  262],
         [29903],
         [29915],
         [29874],
         [29874],
         [29874],
         [15875],
         [29874],
         [29915],
         [  392],
         [29924],
         [  390],
         [29874],
         [29874],
         [29874],
         [  392],
         [29874],
         [  392],
         [  392],
         [29874],
         [  392],
         [  392],
         [  974],
         [ 1552],
         [29915],
         [29903],
         [29925],
         [  284],
         [ 2084],
         [29892],
         [29874],
         [29874],
         [29871],
         [29903],
         [  392],
         [ 1907],
         [29874],
         [  313],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[29918],
         [29871],
         [29874],
         [29874],
         [29879],
         [   13],
         [29892],
         [29871],
         [29899],
         [29871],
         [29889],
         [29899],
         [29874],
         [29874],
         [29871],
         [29874],
         [ 5977],
         [29874],
         [29874],
         [29928],
         [29882],
         [11407],
         [  392],
         [29903],
         [  376],
         [29915],
         [29903],
         [29903],
         [29874],
         [29950],
         [29950],
         [30488],
         [29924],
         [29924],
         [  373],
         [29899],
         [29933],
         [29924],
         [29924],
         [  355],
         [30488],
         [30488],
         [29874],
         [29871],
         [29874],
         [29896],
         [29871],
         [29874],
         [29892],
         [29892],
         [  705],
         [29903],
         [29874],
         [29903],
         [29874],
         [29903],
         [  392],
         [29899],
         [29874],
         [29874],
         [  705],
         [30488],
         [  392],
         [29874],
         [  341],
         [29934],
         [29909],
         [ 1454],
         [29933],
         [29933],
         [29899],
         [29899],
         [29874],
         [29915],
         [30879],
         [29899],
         [29874],
         [30879],
         [29903],
         [29950],
         [  379],
         [30488],
         [30879],
         [29892],
         [29899],
         [29899],
         [29874],
         [29874],
         [29874],
         [29899],
         [29899],
         [29896],
         [29874],
         [29874],
         [29874],
         [29903],
         [29874],
         [29893],
         [29874],
         [29874],
         [29874],
         [29899],
         [  262],
         [29893],
         [  392],
         [29874],
         [29892],
         [  263],
         [29871],
         [29896],
         [29900],
         [29906],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  262],
         [29874],
         [29874],
         [  262],
         [  392],
         [29903],
         [  262],
         [29899],
         [  392],
         [29874],
         [29896],
         [29900],
         [ 7113],
         [29874],
         [29874],
         [29874],
         [29933],
         [29933],
         [29909],
         [29933],
         [29874],
         [29874],
         [  262],
         [  392],
         [29874],
         [29871],
         [29874],
         [29874],
         [30488],
         [29882],
         [29871],
         [29892],
         [  273],
         [29874],
         [29874],
         [  339],
         [29903],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29899],
         [  392],
         [29874],
         [29874],
         [28819],
         [ 5977],
         [29874],
         [29874],
         [ 1491],
         [ 1131],
         [31494],
         [30488],
         [25145],
         [ 6610],
         [25145],
         [  793],
         [29871],
         [ 1745],
         [29874],
         [29909],
         [29874],
         [  355],
         [ 8258],
         [22970],
         [19304],
         [ 7515],
         [  386],
         [29909],
         [28044],
         [16589],
         [27269],
         [25543],
         [  341],
         [ 5628],
         [ 3670],
         [29899],
         [ 1491],
         [ 2415],
         [13315],
         [31494],
         [23031],
         [12194],
         [16589],
         [  661],
         [ 6610],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29903],
         [29874],
         [29903],
         [29874],
         [29874],
         [29950],
         [29950],
         [29903],
         [29933],
         [29874],
         [29874],
         [29874]]], device='cuda:0')
torch.Size([2, 222, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ...,   315,   262, 29889],
         [29871, 29874, 29899,  ..., 29892, 29882,   370],
         ...,
         [30488, 30879, 31147,  ..., 29871,   856, 29899],
         [30488, 30879, 31147,  ..., 29871,   856, 29899],
         [30488, 30879, 31147,  ..., 29871,   856, 29899]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ...,    13,   317, 29889],
         [29874, 29930, 29871,  ...,   376, 29879, 29882],
         ...,
         [29874, 29899,   262,  ..., 29892,   856, 29883],
         [29874, 29934,   375,  ..., 29933, 29879, 29928],
         [29874, 29915, 29924,  ..., 29933, 29882, 29881]]], device='cuda:0')
Batch 45, 90.2% of total tokens
encoded shape: torch.Size([2, 485])
torch.Size([2, 485]) tensor([[    1,   660, 29901,    13,    13,  3644,   395, 29872,   998, 29875,
          1314, 29918, 29876,  1042, 24144,   363,   395, 29884, 29905,   262,
         29905,  1995, 29912, 29934,  4429,   395, 29916, 29918, 29876, 29938,
          5486,   479,   304,   263,  8093,  4046,    13,    13, 12024,   395,
         29916, 29918, 29876, 29938,   367,   263,  5665,   310,  1855,  3694,
          1316,   393,   395, 29872,   998, 29875,  1314, 29918, 29876,  1042,
         24144,   408,   395, 29876, 29905,   517, 29905,  3411, 29938,   363,
          4359,   599,   395, 29884, 29905,   262, 29905,  1995, 29912, 29934,
          4311,  1987,   395, 29916, 29918, 29876, 29938, 24144,   304,   263,
          8093,  4046, 29889,    13,    13, 29902,  1073,   263,  5296,   491,
          6976,  6368,   313,  1184, 29873,   357, 29915, 29879,   376, 20754,
           305,  6288, 17100,   362,   322,   360,  8349,  2556, 11243,   800,
          4968,   541,   306,   864,   304,  1510,   445,  9185,   491,  7418,
           982, 29889,   306,  1016, 29915, 29873,  1073,   825,   304,   437,
         29889,    13, 25271,   366,   363,   596,  1302, 16453, 29889,    13,
            13, 29909, 29901,    13,    13,  9842,   393,   395, 29872,   998,
          5871, 29898, 29916, 29918, 29876, 29899, 29916, 29918, 29885,  2915,
          2013,  1154,   426, 29872,   998, 29875,  1314, 29918, 29876,  7585,
         29872,   998, 29875,  1314, 29918, 29885,   930,   320,   517, 29871,
         29896, 29938,   408,   395, 29876, 29892,   286,   320,   517,   320,
          3411, 29938,   363,  4359,   599,   395, 29884,  1504,  2648,   360,
          1783,   591,   679,   779,  1154, 29871, 29896, 29871, 29906,   320,
           524, 22631, 29896,  2844, 29896, 29913,   321,   998,  5871, 29898,
         29916, 29918, 29876, 29899, 29916, 29918, 29885,  2915,   868,   320,
           517, 29871, 29896,  1504, 11190,   278,  1855,   760,   322, 14707,
           278, 10160, 29889,   887,   674,   679,   779,  1154,  2802,  5223,
           313, 29916, 29918, 29876, 29899, 29916, 29918, 29885,  2915,   426,
         29916, 29918, 29876, 29899, 29916, 29918, 29885, 29913,   320,   517,
         29871, 29896,  1504,   306,   674,  5967,   372,   304,   366,   304,
           671,   777,  4426,   310,   779,  5223,   921, 29938,   304,  1510,
           393,   395, 29916, 29918, 29876, 29899, 29916, 29918, 29885, 29905,
           517, 29871, 29900, 29938,   408,   395, 29876, 29892, 29885,   320,
           517,   320,  3411,  1504,  6549,  2427, 29916, 29918, 29876,  1262,
           338,   315, 13989, 29891, 29892,  8151,  5486,  5362, 29889, 29871,
            13,  9526,  4902,   363,   278, 29871,  1833,   760, 29901,  2803,
           779,  5463,  1405, 29900, 29938,   322,  2050,   278,   740,   395,
         29896,  2612,  1154,  2802,  5223,   921,   500,   921, 29938,   373,
           395,  7110,  5463, 29892,   320,  3411,  4935,   910,   740,   338,
          6374,   313, 14606,  7897,   322,  9126, 29889,   739, 29867,   304,
           395, 29896, 29938,   408,   395,   921,   320,   517,   320,  3411,
          1504,  4525, 17099, 22366,   393,   372,   756, 29871,   263,  6374,
          9212, 29889,  8251,   445,  9212,   779,  4181,  1504,   739,  4477,
           393,   395, 29871, 29896,  2612,  1154,  2802,  5223,   921, 29913,
           921,   320,  6279,   320,  4181, 29938, 10940,   395, 29916,   320,
          6279,   320,  5463,  1504, 10133,   395, 29871, 29896,  2612,  1154,
          2802,  5223,   921,   500,   921,   529,   320,  4181, 29938, 10469,
           395, 29916,   529,   320,  5463,  1504, 11190,   395, 29916, 29922,
         29989, 29916, 29918, 29876, 29899, 29916, 29918, 29885, 25183,   297,
           445, 29889, 29871,    13,    13],
        [    1, 29871,    13,    13,  1576,  6407,  5538,  2216, 29849,  8892,
           313,  2816,  3750,  1706,   327,  1598,  2811, 18573,   390, 29881,
           601, 29897,   448,   281,   267,  2330,   369,  1251, 29872,   345,
            13,  1124,   597,  1636, 29889, 29893,   267,  2330,   369,  1251,
         29872,   345, 29889,   510, 29914,  5499, 29875,   586,   893, 17765,
          1598,    13,    13,  2751,  1360,    13, 18386,   709, 29882,  1657,
            13, 29934, 29881,   601,   338,  3148, 29914,  6028,  1114,   871,
          2466, 29889, 18585,   368,  1706,   327,  1598, 29915, 29879,  7200,
          5120,  2302,   338,   925,   408,    13, 17001,   297,   967, 10503,
          2561,   322, 29914,   272,   967,  8022,   749, 29892,   694, 29973,
            13,    13,  1576,  3148,   338,   903,  1333, 29918,   278,   871,
          9999,   393, 13750, 29889,    13,    13, 22158,    13, 29893,   267,
          2330,   369,  1251, 29872,   345,    13, 29866, 29892,   366,   526,
          1492, 29889,   306,   674,   788,   263,  4996,  4443,   393,   278,
          4274,   871,  8569,   267,    13,   265,   278,  3148,  9999, 29889,
            13,    13,  7377, 30022,    13, 18386,   709, 29882,  1657,    13,
         26856,   414, 29889,   306,  4459,   372, 29915, 29879,   385,  4100,
          9493, 29889,    13,    13,   903,  5628, 29918,   584, 10734,  1363,
           306, 29915, 29881,  5360,   304,  1018,   390, 29881,   601,   541,
           508, 29915, 29873, 29892,   408,   306, 29915, 29885,   297,    13,
         29902, 11209,  4248,    13,    13,  7377, 30022,    13, 29893,   267,
          2330,   369,  1251, 29872,   345,    13, 10858,  7314,   756,  1063,
          2715,   304,   278,  4274,  4248,    13,    13,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 485, 32000]) tensor([[[ -9.0234,   0.7998,   0.7329,  ...,  -3.0684,  -5.3945,  -2.3965],
         [ -7.1523,  -6.3906,   3.4883,  ...,  -4.6445,  -5.0820,  -3.9922],
         [ -9.1172,  -7.9570,   0.1188,  ...,  -4.9141,  -3.4102,  -4.8906],
         ...,
         [ -9.1875, -13.3906,  -2.3750,  ...,  -8.3359,  -1.6230,  -8.3906],
         [ -8.4453,  -8.1250,   2.6289,  ...,  -7.5000,  -5.6484,  -6.4609],
         [ -6.1172,  -4.6680,   2.2480,  ...,  -4.9297,  -4.3008,  -3.9648]],

        [[ -9.0234,   0.7998,   0.7329,  ...,  -3.0684,  -5.3945,  -2.3965],
         [ -5.7188,  -4.3633,   3.1602,  ...,  -3.7734,  -4.3477,  -3.3770],
         [ -5.5078,   3.1719,   6.1367,  ...,  -0.4111,  -1.1953,   0.2119],
         ...,
         [ -7.3672,  -8.5703,  -4.1094,  ...,  -5.5312,  -1.6123,  -5.0273],
         [ -7.3984,  -8.6875,  -4.3203,  ...,  -5.6914,  -1.8037,  -5.1367],
         [ -7.3828,  -8.6719,  -4.3867,  ...,  -5.7070,  -1.8320,  -5.1367]]],
       device='cuda:0')
torch.Size([2, 485, 1]) tensor([[[29918],
         [29871],
         [29874],
         [   13],
         [29871],
         [29874],
         [29909],
         [29909],
         [29906],
         [ 2308],
         [29874],
         [29896],
         [ 1042],
         [29950],
         [  517],
         [29874],
         [29874],
         [  262],
         [  262],
         [11096],
         [29892],
         [29912],
         [  390],
         [ 1042],
         [29874],
         [29874],
         [  262],
         [29896],
         [ 1405],
         [29874],
         [29874],
         [29874],
         [  262],
         [29874],
         [29903],
         [29924],
         [29892],
         [29892],
         [29915],
         [  285],
         [  262],
         [29896],
         [ 1405],
         [  392],
         [29874],
         [29928],
         [  262],
         [  262],
         [20326],
         [29895],
         [29874],
         [29902],
         [29892],
         [29909],
         [  474],
         [13375],
         [29874],
         [29874],
         [ 1042],
         [24144],
         [ 1454],
         [29874],
         [29874],
         [  517],
         [  517],
         [  262],
         [29889],
         [ 1131],
         [ 1454],
         [29874],
         [29874],
         [29903],
         [29874],
         [ 1405],
         [  262],
         [11096],
         [29889],
         [29874],
         [  390],
         [ 4311],
         [30488],
         [30488],
         [29874],
         [  262],
         [29874],
         [29950],
         [  535],
         [29874],
         [29874],
         [  262],
         [  271],
         [29874],
         [29874],
         [29899],
         [  856],
         [29915],
         [29874],
         [30488],
         [30488],
         [29909],
         [29909],
         [29874],
         [29874],
         [29892],
         [29871],
         [29874],
         [29871],
         [30488],
         [30488],
         [30488],
         [30879],
         [29874],
         [  856],
         [29874],
         [30488],
         [30879],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [  856],
         [30488],
         [29874],
         [29968],
         [29874],
         [30488],
         [30488],
         [30488],
         [29882],
         [29874],
         [29915],
         [29915],
         [29915],
         [29892],
         [29903],
         [29874],
         [29915],
         [29902],
         [ 7192],
         [30879],
         [29899],
         [29903],
         [30488],
         [30488],
         [30488],
         [29874],
         [  262],
         [29889],
         [29899],
         [29899],
         [29874],
         [29892],
         [29892],
         [29899],
         [29874],
         [29902],
         [  321],
         [29909],
         [  474],
         [29909],
         [29874],
         [29915],
         [29874],
         [29899],
         [29874],
         [29915],
         [29874],
         [  392],
         [29909],
         [30488],
         [29896],
         [29896],
         [29909],
         [  474],
         [29898],
         [29874],
         [29874],
         [29924],
         [29896],
         [29909],
         [  474],
         [  329],
         [29874],
         [29874],
         [29924],
         [  321],
         [29892],
         [29896],
         [29896],
         [ 6610],
         [  392],
         [29902],
         [29874],
         [  517],
         [  286],
         [  517],
         [  517],
         [  262],
         [  262],
         [ 1131],
         [  392],
         [ 9388],
         [  497],
         [29903],
         [  318],
         [ 1504],
         [29950],
         [29928],
         [29871],
         [29874],
         [28385],
         [29874],
         [29892],
         [29912],
         [29896],
         [29906],
         [29874],
         [ 2308],
         [29892],
         [29909],
         [29896],
         [29874],
         [29896],
         [ 1012],
         [ 1188],
         [29909],
         [  474],
         [29898],
         [29874],
         [29899],
         [29874],
         [29899],
         [29874],
         [29874],
         [29874],
         [29928],
         [ 1188],
         [29915],
         [29892],
         [29896],
         [29896],
         [ 1131],
         [29950],
         [29928],
         [29875],
         [ 2308],
         [29924],
         [29902],
         [ 7192],
         [29928],
         [ 8058],
         [29915],
         [  881],
         [26180],
         [29874],
         [29892],
         [29896],
         [29892],
         [29912],
         [  313],
         [  262],
         [29874],
         [29899],
         [29874],
         [29924],
         [29874],
         [29950],
         [  392],
         [29906],
         [29874],
         [29874],
         [29899],
         [29874],
         [29924],
         [29874],
         [ 1012],
         [  517],
         [29892],
         [29896],
         [29896],
         [ 1131],
         [  294],
         [ 1016],
         [29903],
         [ 1552],
         [ 5184],
         [  366],
         [  517],
         [23516],
         [29928],
         [29928],
         [29874],
         [29928],
         [29892],
         [29909],
         [29909],
         [  517],
         [  771],
         [29874],
         [29902],
         [29874],
         [  262],
         [29874],
         [  448],
         [29874],
         [29924],
         [29874],
         [ 1405],
         [29892],
         [29900],
         [29874],
         [ 1504],
         [ 6574],
         [29902],
         [29892],
         [29924],
         [  286],
         [  517],
         [  517],
         [  262],
         [29871],
         [ 1504],
         [29874],
         [29902],
         [29874],
         [29909],
         [29874],
         [29902],
         [29895],
         [  315],
         [  349],
         [29909],
         [  392],
         [ 6574],
         [29874],
         [29909],
         [29874],
         [29874],
         [29874],
         [29899],
         [29892],
         [  354],
         [29874],
         [29874],
         [29874],
         [29903],
         [29902],
         [  991],
         [29915],
         [29892],
         [ 1405],
         [29900],
         [ 1405],
         [  392],
         [29925],
         [29924],
         [29933],
         [ 1338],
         [  285],
         [29874],
         [ 3944],
         [  741],
         [ 5223],
         [  313],
         [  262],
         [  741],
         [ 1405],
         [ 1131],
         [  262],
         [11096],
         [29892],
         [29924],
         [29896],
         [ 1631],
         [29874],
         [  705],
         [30057],
         [ 1131],
         [  262],
         [29874],
         [29892],
         [29973],
         [  392],
         [  262],
         [ 6574],
         [29950],
         [ 1131],
         [  517],
         [29900],
         [29900],
         [ 1131],
         [29909],
         [29924],
         [  260],
         [ 1405],
         [  517],
         [  262],
         [ 3411],
         [ 1504],
         [  375],
         [29874],
         [ 6574],
         [29874],
         [29925],
         [30057],
         [29874],
         [29874],
         [29874],
         [29874],
         [29924],
         [  375],
         [  372],
         [29924],
         [29924],
         [  376],
         [ 1405],
         [29925],
         [  680],
         [29874],
         [29925],
         [29896],
         [29896],
         [ 1405],
         [ 1154],
         [  741],
         [ 5223],
         [  370],
         [ 1131],
         [  426],
         [ 1405],
         [  262],
         [29896],
         [29896],
         [ 1405],
         [ 6574],
         [29902],
         [29900],
         [ 1405],
         [  262],
         [ 1131],
         [  514],
         [ 1405],
         [ 6246],
         [29925],
         [29896],
         [29896],
         [ 1405],
         [ 1154],
         [  741],
         [ 5223],
         [  313],
         [30057],
         [  741],
         [ 1405],
         [29896],
         [ 7192],
         [ 1131],
         [ 6574],
         [29874],
         [29900],
         [  529],
         [29906],
         [ 7192],
         [ 1504],
         [29950],
         [29874],
         [29900],
         [ 1405],
         [  313],
         [29874],
         [  262],
         [29874],
         [29989],
         [29874],
         [29924],
         [29874],
         [29989],
         [  392],
         [29950],
         [29924],
         [29915],
         [29874],
         [29899],
         [29899]],

        [[29918],
         [29871],
         [   13],
         [29892],
         [29874],
         [  392],
         [29874],
         [29874],
         [29903],
         [29874],
         [29871],
         [29874],
         [  294],
         [  355],
         [29899],
         [29987],
         [ 6864],
         [29875],
         [29871],
         [29871],
         [  300],
         [29889],
         [  856],
         [29871],
         [  392],
         [  856],
         [29871],
         [29871],
         [29892],
         [29871],
         [29871],
         [29871],
         [29892],
         [30488],
         [29889],
         [30488],
         [31147],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29914],
         [29892],
         [29871],
         [29903],
         [  392],
         [29909],
         [29924],
         [29899],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [29881],
         [29871],
         [29915],
         [29874],
         [29899],
         [29892],
         [  392],
         [29899],
         [29874],
         [29874],
         [30488],
         [29892],
         [29874],
         [29871],
         [29888],
         [29915],
         [29874],
         [29871],
         [29903],
         [ 1761],
         [29903],
         [29874],
         [29903],
         [29903],
         [29892],
         [29874],
         [29915],
         [29915],
         [  440],
         [29973],
         [  856],
         [29892],
         [30488],
         [29915],
         [  262],
         [ 2432],
         [30488],
         [29973],
         [  313],
         [29892],
         [29892],
         [29874],
         [29914],
         [29874],
         [29889],
         [29918],
         [29874],
         [29924],
         [29924],
         [14131],
         [ 5461],
         [29874],
         [29915],
         [29892],
         [29892],
         [29871],
         [29892],
         [29871],
         [29871],
         [29899],
         [29871],
         [29871],
         [29871],
         [29874],
         [29892],
         [29915],
         [29915],
         [29915],
         [ 1492],
         [29934],
         [29915],
         [30879],
         [30488],
         [29874],
         [  392],
         [30488],
         [12748],
         [29934],
         [29915],
         [29915],
         [30282],
         [29881],
         [  373],
         [30488],
         [29934],
         [29934],
         [  392],
         [  292],
         [29915],
         [29899],
         [29899],
         [29871],
         [29871],
         [29899],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29874],
         [23976],
         [29915],
         [29915],
         [29934],
         [29915],
         [29881],
         [30488],
         [29924],
         [  392],
         [  517],
         [29915],
         [29899],
         [29899],
         [29871],
         [29871],
         [29892],
         [29892],
         [  294],
         [29934],
         [29915],
         [29881],
         [30488],
         [  304],
         [29934],
         [29934],
         [29881],
         [29871],
         [29915],
         [29915],
         [29915],
         [29933],
         [ 1491],
         [29915],
         [29934],
         [29915],
         [29881],
         [30488],
         [29909],
         [29892],
         [29915],
         [ 6610],
         [29889],
         [29899],
         [29899],
         [29892],
         [29871],
         [  281],
         [29871],
         [29924],
         [29899],
         [29871],
         [29871],
         [29871],
         [29874],
         [29899],
         [29915],
         [  354],
         [ 1063],
         [  354],
         [  517],
         [29934],
         [29924],
         [29874],
         [29889],
         [29899],
         [29899],
         [29924],
         [29924],
         [29924],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [  313],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29915],
         [29915],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [14131],
         [30010],
         [30010],
         [30010],
         [14131],
         [14131]]], device='cuda:0')
torch.Size([2, 485, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29874, 29915, 29871,  ..., 29909, 29875, 29934],
         [29899, 29892, 29915,  ...,   317, 29889,   349],
         [29899, 29892, 29915,  ...,   319,   349,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [   13, 29871,   313,  ...,   304,    12, 29915],
         ...,
         [30010, 29879, 14131,  ..., 12254,   538,   313],
         [14131, 30010, 29879,  ..., 12254,   538,   313],
         [14131, 29879, 30010,  ..., 12254,   538,   313]]], device='cuda:0')
Batch 46, 90.9% of total tokens
encoded shape: torch.Size([2, 96])
torch.Size([2, 96]) tensor([[    1,   997,   354, 29926,   423,  4670,   261,  6151,   575,    13,
            13,  5661,   354, 29926,   423,  4670,   261,  6151,   575,   338,
           263,  6606,   310, 20447,   367,   300,   280,   310,  5701,  4749,
         10387,   423,   322,   612, 12398,  5439,   491,  5322,  6936,   402,
           801,   273,   297, 29871, 29896, 29947, 29929, 29953, 29889,    13,
            13,  1123, 10662,    13,    13, 10900, 29901, 29923,   398,   324,
         29886, 17174,    13, 10900, 29901,  3629,   300,   793,   310, 14325,
            13, 10900, 29901,  3629,   300,   793,  5439,   297, 29871, 29896,
         29947, 29929, 29953,    13, 10900, 29901, 29911,  1165, 29874,  4257,
           491,  5322,  6936,   402,   801,   273],
        [    1,   678, 29017, 29892,   476,  3391,   381,    13,    13,  1451,
         29017,   313, 29892,   884,  5917,  1891,   408,   678, 30107, 29882,
         30132, 29897,   338,   263,  5720,   297, 10670,  1646,   390,  3631,
          7457, 29892,  9723,  2941,   279,  7457, 29892,   476,  3391,   381,
          5127, 29892,   379,   555,  2112,  6249, 17325, 29892, 14883, 29889,
          2180,   278, 29871, 29906, 29900, 29900, 29953, 16411, 29892,   967,
          4665,   471, 29871, 29941, 29947, 29892,   297, 29871, 29953, 13175,
         29889,    13,    13,  1123, 10662, 29871,    13,    13, 10900, 29901,
         12310,  7964,  7600,   297,   476,  3391,   381,  5127,     2,     2,
             2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 96, 32000]) tensor([[[ -9.0156,   0.8486,   0.8086,  ...,  -3.0469,  -5.3750,  -2.3613],
         [ -7.5039,  -5.7266,   2.9902,  ...,  -4.6523,  -4.2891,  -4.5742],
         [ -5.5938,  -4.4570,   2.5078,  ...,  -3.7324,  -4.4453,  -3.5430],
         ...,
         [-12.4922, -16.7031,   2.2871,  ...,  -7.0117,  -6.1875,  -8.3516],
         [-11.8047, -16.3125,   0.1265,  ...,  -6.4414,  -6.0078,  -7.9492],
         [ -9.6953, -16.5312,  -1.3926,  ...,  -5.6055,  -2.6074,  -7.3984]],

        [[ -9.0156,   0.8486,   0.8086,  ...,  -3.0469,  -5.3750,  -2.3613],
         [ -7.3125,  -6.4102,   3.5723,  ...,  -4.4961,  -4.6680,  -4.0781],
         [ -8.7344,  -8.0156,   3.2363,  ...,  -4.5273,  -5.2031,  -4.8945],
         ...,
         [ -4.3984,  -2.4141,   2.0762,  ...,  -3.3691,  -4.1367,  -2.8809],
         [ -4.4258,  -2.5410,   2.1230,  ...,  -3.3848,  -4.1641,  -2.8945],
         [ -4.4375,  -2.6719,   2.1484,  ...,  -3.4043,  -4.1914,  -2.9082]]],
       device='cuda:0')
torch.Size([2, 96, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [29874],
         [  313],
         [29892],
         [29871],
         [29871],
         [29871],
         [29874],
         [29871],
         [29950],
         [29950],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29924],
         [  300],
         [  280],
         [29874],
         [29909],
         [29874],
         [29909],
         [29874],
         [29874],
         [  262],
         [29924],
         [29933],
         [  262],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [  262],
         [29871],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [29915],
         [29892],
         [29892],
         [30488],
         [29874],
         [29871],
         [29871],
         [30488],
         [29892],
         [29889],
         [29871],
         [29871],
         [29924],
         [29874],
         [29874],
         [29899],
         [29886],
         [29874],
         [29903],
         [29874],
         [29933],
         [29874],
         [29899],
         [29899],
         [29874],
         [  300],
         [29903],
         [29874],
         [  262],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29933],
         [29874]],

        [[29918],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [  313],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29871],
         [29874],
         [  392],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [  262],
         [  262],
         [29874],
         [29871],
         [29899],
         [29871],
         [29928],
         [29874],
         [29874],
         [29871],
         [29933],
         [29924],
         [29874],
         [29899],
         [29871],
         [29871],
         [29933],
         [29874],
         [  262],
         [29924],
         [29874],
         [29924],
         [  262],
         [29874],
         [  262],
         [  262],
         [29889],
         [  392],
         [  392],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [  392],
         [  262],
         [29871],
         [29896],
         [29874],
         [  262],
         [29933],
         [29871],
         [29909],
         [29874],
         [29874],
         [29899],
         [ 1454],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29899],
         [29892],
         [  262],
         [  392],
         [  262],
         [29950],
         [29871],
         [29871],
         [29875],
         [29874],
         [29874],
         [29874],
         [29871],
         [29889],
         [30488],
         [30488],
         [30488],
         [29889]]], device='cuda:0')
torch.Size([2, 96, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ..., 29889,   317,   349],
         [29871, 29892,   313,  ...,    13,   349, 29915],
         ...,
         [29871, 29874, 29924,  ..., 29903, 29915,   313],
         [29933, 29874, 29875,  ..., 29871,   273, 29909],
         [29874,  1457, 29882,  ..., 29886, 29872,   262]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ..., 29896, 29915, 29874],
         [29871, 29933, 29899,  ...,   262, 29924, 29896],
         ...,
         [30488, 29889, 29871,  ...,   313, 30282, 29899],
         [30488, 29889, 29871,  ..., 29899,   313, 30282],
         [29889, 30488, 29871,  ...,   856,   313,    13]]], device='cuda:0')
Batch 47, 91.1% of total tokens
encoded shape: torch.Size([2, 766])
torch.Size([2, 766]) tensor([[    1,  1932,   263,  ...,     2,     2,     2],
        [    1,   660, 29901,  ...,   416,    13,    13]], device='cuda:0')
torch.Size([2, 766, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -8.0625,  -5.5234,   2.8828,  ...,  -4.6328,  -2.7148,  -4.3398],
         [ -8.5156, -13.2891,  -1.9297,  ...,  -6.2656,   1.7627,  -6.2812],
         ...,
         [ -8.1172,  -7.1055,  -6.1211,  ...,  -5.4688,  -3.2344,  -5.4766],
         [ -8.4375,  -6.8164,  -5.8281,  ...,  -5.4570,  -3.3945,  -5.4648],
         [ -8.6172,  -6.3398,  -5.5039,  ...,  -5.3398,  -3.5039,  -5.3516]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -7.1406,  -6.3711,   3.4844,  ...,  -4.6367,  -5.0703,  -3.9824],
         [ -9.1250,  -7.9688,   0.1106,  ...,  -4.9141,  -3.4043,  -4.8945],
         ...,
         [ -7.6836,  -7.0117,   1.9678,  ...,  -4.9375,  -3.8906,  -5.2070],
         [ -4.9570,  -3.2773,   1.7939,  ...,  -3.7461,  -4.0938,  -3.3281],
         [ -4.9336,  -3.1660,   1.4834,  ...,  -4.0273,  -3.7812,  -3.0762]]],
       device='cuda:0')
torch.Size([2, 766, 1]) tensor([[[29918],
         [29915],
         [29882],
         ...,
         [29879],
         [29879],
         [29879]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 766, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29915, 29871,   376,  ..., 29899, 29903, 29892],
         [29882, 29903, 29874,  ...,   376,   262, 29879],
         ...,
         [29879, 30057, 30010,  ...,   538,   517,  1131],
         [29879, 30057, 30010,  ...,   538,   517, 29896],
         [29879, 29915, 30010,  ..., 29896,   349,   392]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29874, 29909, 29896,  ..., 29903, 29871, 29924],
         [29892, 29889, 29871,  ..., 29915,   315,   319],
         [29892,   319,   313,  ..., 29871,   392, 29915]]], device='cuda:0')
Batch 48, 92.0% of total tokens
encoded shape: torch.Size([2, 1561])
torch.Size([2, 1561]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29889,    13,    13]], device='cuda:0')
torch.Size([2, 1561, 32000]) tensor([[[-9.0156,  0.8423,  0.8076,  ..., -3.0449, -5.3789, -2.3613],
         [-7.1406, -6.3711,  3.4844,  ..., -4.6367, -5.0703, -3.9824],
         [-9.1250, -7.9688,  0.1140,  ..., -4.9180, -3.4082, -4.8984],
         ...,
         [-8.2344, -8.0312, -5.1289,  ..., -6.2188, -3.5684, -5.9883],
         [-8.0938, -8.0312, -5.2617,  ..., -6.1797, -3.4863, -5.9609],
         [-8.1250, -7.9531, -5.2266,  ..., -6.1602, -3.4824, -5.9453]],

        [[-9.0156,  0.8423,  0.8076,  ..., -3.0449, -5.3789, -2.3613],
         [-7.1406, -6.3711,  3.4844,  ..., -4.6367, -5.0703, -3.9824],
         [-9.1250, -7.9688,  0.1140,  ..., -4.9180, -3.4082, -4.8984],
         ...,
         [-5.9648, -4.1289,  0.0850,  ..., -4.8203, -3.2559, -4.8984],
         [-6.0742, -4.1953,  1.3643,  ..., -4.9102, -4.3398, -4.2812],
         [-5.4258, -3.8027,  0.9355,  ..., -4.3711, -4.0664, -3.3418]]],
       device='cuda:0')
torch.Size([2, 1561, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29879],
         [29879],
         [29879]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29915],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 1561, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29879,   313, 29915,  ..., 29892,   271, 29874],
         [29879, 29915,   313,  ...,   271, 29874, 29892],
         [29879, 29915,   313,  ...,   271, 29874, 29892]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29915, 29892,   313,  ..., 30166, 29889, 29874],
         [29892,   313, 29899,  ...,   349, 29901,   376],
         [29892, 29899,   856,  ..., 29889, 29871, 29874]]], device='cuda:0')
Batch 49, 94.0% of total tokens
encoded shape: torch.Size([2, 1148])
torch.Size([2, 1148]) tensor([[    1,  4794,   358,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29914,    13,    13]], device='cuda:0')
torch.Size([2, 1148, 32000]) tensor([[[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -8.1797,  -8.1484,   3.9648,  ...,  -4.8945,  -5.6094,  -4.5156],
         [-10.4766, -15.3516,  -2.6250,  ...,  -7.4102,  -3.7227,  -8.6094],
         ...,
         [ -8.1094,  -5.9492,  -7.0703,  ...,  -3.3926,  -2.0352,  -4.2812],
         [ -8.1328,  -6.1289,  -7.1094,  ...,  -3.4590,  -2.0488,  -4.3398],
         [ -8.1406,  -6.0781,  -7.1016,  ...,  -3.4414,  -2.0527,  -4.3281]],

        [[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -7.1367,  -6.3711,   3.4805,  ...,  -4.6328,  -5.0664,  -3.9805],
         [ -9.1328,  -7.9727,   0.1193,  ...,  -4.9180,  -3.4141,  -4.8945],
         ...,
         [ -9.7422, -14.3672,  -3.8145,  ...,  -7.0898,  -2.8770,  -8.2500],
         [ -9.7422, -11.5234,  -0.0999,  ...,  -7.6367,  -5.2461,  -8.2422],
         [ -7.3789,  -9.9766,  -2.3887,  ...,  -6.7227,  -3.9375,  -6.7031]]],
       device='cuda:0')
torch.Size([2, 1148, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [30057],
         [30057],
         [30057]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 1148, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29889, 29890, 29898],
         [29874, 29871,   376,  ...,   272,   313, 29875],
         ...,
         [30057, 10266, 30119,  ..., 30010,  1131,   229],
         [30057, 10266, 30119,  ..., 30010,  1131, 23333],
         [30057, 10266, 30119,  ..., 30010,  1131, 23333]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29874, 29915, 29875,  ..., 29925, 29909, 30010],
         [29892, 29899,   313,  ..., 29873,   349, 29875],
         [29892, 29899, 29915,  ..., 29943,   349, 29873]]], device='cuda:0')
Batch 50, 95.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 11474,    13,  ...,  6292,  4650,  6353],
        [    1, 26804,  2133,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.5508,  -3.0449,   1.9414,  ...,  -3.4023,  -4.0625,  -3.0234],
         [ -5.8359,   3.2266,   6.0742,  ...,  -0.1229,  -2.0488,   0.7637],
         ...,
         [ -8.1484, -11.0547,  -2.8926,  ...,  -5.8047,  -3.2305,  -7.3438],
         [ -9.0781, -13.8047,  -4.1875,  ...,  -6.3516,  -1.9629,  -6.2812],
         [ -7.8438,  -9.3984,  -1.9150,  ...,  -6.3203,  -1.6885,  -5.8281]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [-10.1797, -12.7656,   0.5581,  ...,  -6.4062,  -4.1445,  -7.0273],
         [-10.6094, -14.5703,  -2.2598,  ...,  -6.2852,  -2.2012,  -8.1094],
         ...,
         [ -5.3594,   2.2910,  -3.4883,  ...,  -2.0293,  -3.3926,  -2.1484],
         [ -5.4648,   2.3359,  -3.4316,  ...,  -2.0371,  -3.4355,  -2.1484],
         [ -5.5859,   2.4043,  -3.3535,  ...,  -2.0430,  -3.4844,  -2.1387]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29889],
         [   13],
         ...,
         [29892],
         [29874],
         [ 8229]],

        [[29918],
         [29871],
         [29874],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 30488,  ...,   313, 31147,   856],
         [   13,   313,    12,  ..., 29918, 29915, 30024],
         ...,
         [29892,   302,   474,  ...,  8229,   313,  2589],
         [29874,   370, 29875,  ..., 29896, 29915,   485],
         [ 8229,  2589,   302,  ...,   514,  2892,   364]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ...,   392, 29883, 29875],
         [29874,   392, 29899,  ..., 29924, 29915, 29883],
         ...,
         [30010, 30140, 29915,  ...,   313, 29987,   342],
         [30010, 30140, 29915,  ...,   313, 29987,   342],
         [30010, 30140, 29915,  ...,   392, 29987, 29879]]], device='cuda:0')
Batch 51, 100.0% of total tokens
encoded shape: torch.Size([2, 685])
torch.Size([2, 685]) tensor([[    1,   660, 29901,  ...,  1817,    13,    13],
        [    1, 15050,  8497,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 685, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -7.1367,  -6.3672,   3.4805,  ...,  -4.6328,  -5.0664,  -3.9805],
         [ -9.1328,  -7.9727,   0.1193,  ...,  -4.9180,  -3.4141,  -4.8945],
         ...,
         [ -6.6758,  -5.6562,  -0.4097,  ...,  -3.8262,  -2.0234,  -3.8887],
         [ -5.4180,  -3.9160,   2.1719,  ...,  -4.4961,  -4.5430,  -3.4707],
         [ -5.1016,  -3.7168,   1.8477,  ...,  -4.1562,  -4.3477,  -3.0020]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [-10.3125, -13.6719,  -0.7515,  ...,  -7.9258,  -5.5312,  -8.2734],
         [ -6.9531,  -6.1758,   1.5693,  ...,  -4.1406,  -3.3828,  -4.2695],
         ...,
         [ -7.4570,  -3.2832,   0.1603,  ...,  -4.4531,  -4.1055,  -3.9785],
         [ -7.3125,  -3.1816,   0.2468,  ...,  -4.3672,  -4.0938,  -3.8867],
         [ -7.1797,  -3.0840,   0.2810,  ...,  -4.2930,  -4.0859,  -3.8047]]],
       device='cuda:0')
torch.Size([2, 685, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29973],
         [29892],
         [29892]],

        [[29918],
         [29881],
         [29874],
         ...,
         [  313],
         [  313],
         [  313]]], device='cuda:0')
torch.Size([2, 685, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   376,   317, 29874],
         [29874, 29915,   376,  ...,   306,   262, 29882],
         ...,
         [29973,   392, 29898,  ..., 29875, 29906, 29896],
         [29892,   313, 29871,  ...,   315, 29915,   376],
         [29892, 29899, 29871,  ...,   315,   349,    13]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29881, 29871,   262,  ...,   319, 29875,   376],
         [29874, 29899, 29871,  ..., 29881,   392,   856],
         ...,
         [  313, 29892, 29915,  ..., 30010, 29874,   392],
         [  313, 29892, 29915,  ..., 30010,   392, 29874],
         [  313, 29892, 29915,  ...,   317,   392, 29874]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 927])
torch.Size([2, 927]) tensor([[    1,   660, 29901,  ..., 29889,    13,    13],
        [    1,  6324,  4360,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 927, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7324],
         [-3.8770, -2.2344,  0.2607,  ..., -2.9766, -3.7422, -2.6484],
         ...,
         [-3.9062, -2.3008,  0.1819,  ..., -2.9922, -3.6992, -2.8301],
         [-3.8594, -2.2637,  0.4871,  ..., -3.0684, -3.7949, -2.7578],
         [-3.8652, -2.2910,  0.4260,  ..., -3.0430, -3.7949, -2.7148]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.8730, -2.2910,  0.2839,  ..., -3.0215, -3.7676, -2.6816],
         [-3.9785, -2.4531,  0.3005,  ..., -3.0215, -3.7852, -2.7402],
         ...,
         [-3.8359, -2.0957,  0.3716,  ..., -2.9902, -3.8027, -2.6504],
         [-3.8320, -2.0918,  0.3713,  ..., -2.9883, -3.8027, -2.6465],
         [-3.8340, -2.0996,  0.3735,  ..., -2.9922, -3.8066, -2.6504]]],
       device='cuda:0')
torch.Size([2, 927, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 927, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892,   856]]], device='cuda:0')
Batch 1, 1.2% of total tokens
encoded shape: torch.Size([2, 952])
torch.Size([2, 952]) tensor([[    1,   450, 26377,  ...,     2,     2,     2],
        [    1,  2811,   437,  ..., 29900, 29900, 29896]], device='cuda:0')
torch.Size([2, 952, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9922, -2.2715,  0.4722,  ..., -3.0371, -3.7656, -2.7207],
         [-3.9824, -2.4629,  0.3599,  ..., -3.0215, -3.7871, -2.7109],
         ...,
         [-3.8516, -2.0957,  0.3889,  ..., -2.9863, -3.7910, -2.6641],
         [-3.8418, -2.0820,  0.3862,  ..., -2.9824, -3.7871, -2.6582],
         [-3.8359, -2.0801,  0.3831,  ..., -2.9805, -3.7852, -2.6582]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9824, -2.3965,  0.3494,  ..., -3.0332, -3.7734, -2.7637],
         [-3.9766, -2.4492,  0.3320,  ..., -3.0508, -3.7305, -2.7578],
         ...,
         [-3.9414, -2.3223,  0.3530,  ..., -3.0371, -3.7910, -2.7305],
         [-4.0039, -2.4863,  0.3320,  ..., -3.0645, -3.8477, -2.7578],
         [-3.9590, -2.3125,  0.2844,  ..., -3.0059, -3.7461, -2.6992]]],
       device='cuda:0')
torch.Size([2, 952, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 952, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]]], device='cuda:0')
Batch 2, 2.4% of total tokens
encoded shape: torch.Size([2, 1131])
torch.Size([2, 1131]) tensor([[    1,   660,  6271,  ...,     2,     2,     2],
        [    1,   660, 29901,  ...,   467,    13,    13]], device='cuda:0')
torch.Size([2, 1131, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7344],
         [-4.0078, -2.5059,  0.2842,  ..., -2.9980, -3.8203, -2.7500],
         ...,
         [-3.7891, -2.0469,  0.3201,  ..., -2.9551, -3.7617, -2.6406],
         [-3.7930, -2.0527,  0.3208,  ..., -2.9590, -3.7637, -2.6426],
         [-3.7871, -2.0449,  0.3206,  ..., -2.9551, -3.7617, -2.6387]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2344,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.9121, -2.3789,  0.3013,  ..., -3.0527, -3.7363, -2.7734],
         [-3.9082, -2.3262,  0.5972,  ..., -3.0781, -3.8398, -2.7559],
         [-3.8965, -2.3359,  0.4980,  ..., -3.0859, -3.8184, -2.7266]]],
       device='cuda:0')
torch.Size([2, 1131, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1131, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ...,   856, 30555,   315]]], device='cuda:0')
Batch 3, 3.7% of total tokens
encoded shape: torch.Size([2, 719])
torch.Size([2, 719]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 29871, 29896,  ...,   711,  2366, 29889]], device='cuda:0')
torch.Size([2, 719, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0039, -2.4922,  0.4116,  ..., -3.0566, -3.8887, -2.7344],
         [-3.8770, -2.2324,  0.2607,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.9336, -2.2285,  0.4304,  ..., -3.0273, -3.7988, -2.7090],
         [-3.9414, -2.2383,  0.4275,  ..., -3.0312, -3.8008, -2.7129],
         [-3.9336, -2.2266,  0.4243,  ..., -3.0273, -3.7949, -2.7090]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0078, -2.3809,  0.5591,  ..., -3.0293, -3.8496, -2.7051],
         [-4.0273, -2.4121,  0.2847,  ..., -2.9883, -3.8320, -2.7266],
         ...,
         [-3.9746, -2.4277, -0.0090,  ..., -2.9375, -3.7617, -2.6992],
         [-3.9805, -2.3320,  0.1332,  ..., -2.9941, -3.7305, -2.6582],
         [-3.8848, -2.2734,  0.3262,  ..., -2.9941, -3.6758, -2.7305]]],
       device='cuda:0')
torch.Size([2, 719, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 719, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 4, 5.1% of total tokens
encoded shape: torch.Size([2, 1348])
torch.Size([2, 1348]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 23974, 14045,  ..., 18650,  2741, 29897]], device='cuda:0')
torch.Size([2, 1348, 32000]) tensor([[[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-4.0039, -2.4922,  0.4119,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2324,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.8555, -2.1094,  0.3872,  ..., -2.9980, -3.7988, -2.6562],
         [-3.8496, -2.1035,  0.3862,  ..., -2.9961, -3.7969, -2.6543],
         [-3.8516, -2.1074,  0.3877,  ..., -2.9980, -3.7988, -2.6562]],

        [[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-3.9941, -2.4277,  0.4058,  ..., -3.0215, -3.7812, -2.7344],
         [-4.0312, -2.4004,  0.2206,  ..., -2.9805, -3.7949, -2.7637],
         ...,
         [-3.9199, -2.3438,  0.1970,  ..., -2.9922, -3.7949, -2.7461],
         [-3.8848, -2.3379,  0.3149,  ..., -2.9629, -3.7656, -2.7070],
         [-3.9062, -2.3203,  0.3970,  ..., -2.9707, -3.7969, -2.7344]]],
       device='cuda:0')
torch.Size([2, 1348, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1348, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856,   349],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 5, 6.9% of total tokens
encoded shape: torch.Size([2, 344])
torch.Size([2, 344]) tensor([[    1, 28251, 29899,  4819,   265,   265,  2522,  2620,   292,   297,
           278,  4360,   663,   310,  1105,   615,   341,  2631,   322, 28251,
           341,   711,  1793,   297, 26250, 29911, 29875, 29949,   648, 29941,
         29913,  2431,   586,   808,   568,   515,  3824, 14771,  2701, 29889,
            13, 19560,  3631,  8576,  1301,  2187,   322,  4964,  1374,   265,
           265, 18893, 18593,   263,  1472, 29899, 11235, 18766,   304, 20602,
         11966, 29899, 17607,   265,   313, 29872, 29899,   561, 29897, 22060,
           297, 13818,   385, 23024,  8927, 10901,   303,  1338, 29889,  2266,
           591,  2693,   263,   937, 29899,   558,  2173,  2701,  2948,   304,
         10272,   321, 29899,   561, 14801,   292,   322,  8323,  8608,   297,
         17279,   411,   385, 23024,  8927, 24094, 19753, 29889,  8680,  2948,
          3710,   417,   952,  4325,  2759,  1891,  1374,   265,   787,   304,
         10272,   278, 10430, 29899, 18980,   321, 29899,   561, 23638,   363,
           599,  1374,   265,   265, 18893, 29892,  3704,   278,  4964, 18893,
          6942,   411, 19850, 15436,  2200,   537,   322,  8576,  1301,  2187,
         29889,  1334,  1510,   393,   278, 11966, 22458,  1793,   297, 13630,
           293, 26250, 29911, 29875, 29949,   648, 29941, 29913,   338, 20704,
           491, 14801,   292,   411, 25579,   979, 27070,  1374,   265,   787,
           472,  5716, 10430,   322,   411, 19850, 15436,  2200,  4964,  1374,
           265,   787,  2400, 29871, 29906, 29900, 29900,   476, 29889,  8680,
         17203,   508,  7913,  2486,  8500,   278, 10430, 26307,   310,   278,
         11966, 22458,  1793,   297, 26250, 29911, 29875, 29949,   648, 29941,
         29913,  1546, 29871, 29896, 29945, 29900, 29899, 29941, 29900, 29900,
           476, 29892,   322, 10320,   284,   278,  9200, 21785,   293,  3978,
           310,   967, 20928,   323,  3426, 29941, 29913,   534,   355, 29889,
          8680,  2948, 28936,   937, 29899,   558,  2173,  2701, 17203,   310,
           321, 29899,   561, 22060,   322,  8323,  8608,   297,  7300,  4413,
           310, 10901,   303,  1338,   411,  8576,  1301,  2187,   322, 13818,
           385, 23024,  8927,  1374,   265,   787, 29889,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2],
        [    1,   910,   297,  7316,  1104,  1078,   304,  5731,  1218, 12646,
         14884, 29892,   322,   297,  3153,   304,   385,  4799, 17261,   281,
          4015,  5731,  1218, 12646,  4933,   297,   607,   278,  1002,   272,
          1302,  2719,   508,   367, 12912,   333,   368,   322, 12536,  2197,
         26130,   304,   278,  1002,   272,  2625, 29889,    13,   797,  7786,
          2440, 29892,  4799, 17261,   281,  4015,  5731,  1218, 12646, 14884,
           505,  4953, 10231,   368,  3619, 29889,   450,  1667,  4682,   310,
           445,  1134,   310,  4933,   338,   393,   278,  1002,   272,  7136,
           756,   694,  2243,  1862,   363,   278, 27963,   310,   278,  1002,
           272,  1302,  2719, 29889,  8669, 29892,   278,  1002,   272,  1302,
          2719,   526,  7180,   297,   278,  2913,   313, 29875, 29889, 29872,
         29889,   278,  4799, 17261, 29897,  1546,   278,  1002,   272,  7136,
           322,   278,  5731,   272, 29889, 13494,  3277,   278,  1002,   272,
          1302,   309,  8805,   886,   297,   278,  4799, 17261,  3732,  8543,
           671,   310,  4069,  2913,   322, 16415,   278, 15611, 19389,  9027,
           310,   278,  1002,   272,  1302,  2719, 29889, 11275, 27963,   297,
           278,  4799, 17261,   338, 10734, 10631,   681,   297,  2919, 13284,
           322,  2428,   535,  2199,   292,  5731,  1218, 12646, 14884, 29889,
            13, 17245, 29892,  4799, 17261,   281,  4015,  5731,  1218, 12646,
         14884,   505,   278,   766, 17263,  8501,   393, 12536,  2197,   409,
          2764,   292,   278,  1002,   272,  1302,  2719,   304,   278,  1002,
           272,  7136,   338,  1407,  5189, 29889,   450,  1158,  1304,   297,
           278,  7536,  1616,   310, 11549,   292,   278,  1002,   272,  1302,
          2719,   297,   385,  4799, 17261,   281,  4015,  5731,  1218, 12646,
          4933,   338,   304,  4153, 21224,   278,  1002,   272,  1302,  2719,
           304,   278,  1002,   272,  7136,   773,   263,  4549,   594, 13244,
           573, 29892,  1316,   408,   263,   620,   262,   594, 13244,   573,
         29889,  2398, 29892,   263, 18430,  4549, 21224,   508,   451,   367,
          7625,  1546,   278,  1002,   272,  7136,   322,  1002,   272,  1302,
          2719, 29892,   322,   278,  2919,  8249,   429,   814,   287,   373,
           278,  1002,   272,  1302,  2719,  2645,  5858,   508,  1121,   297,
           658,  7749,   292,   322,   443, 16044,   519,   325, 26218,   310,
           278,  1002,   272,  1302,  2719, 29892, 18658,   304,   278,  1663,
          2785, 18830,   278,  1302,  2719, 29892,   322,  2788,  4828,  9819,
           297,  4933, 10672, 29889]], device='cuda:0')
torch.Size([2, 344, 32000]) tensor([[[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.4941,  0.3303,  ..., -3.0117, -3.8613, -2.7422],
         [-3.9746, -2.4297,  0.1473,  ..., -2.9844, -3.8105, -2.7070],
         ...,
         [-3.8301, -2.1191,  0.4685,  ..., -3.0039, -3.7871, -2.6582],
         [-3.8301, -2.1211,  0.4651,  ..., -3.0039, -3.7871, -2.6582],
         [-3.8281, -2.1230,  0.4595,  ..., -3.0020, -3.7852, -2.6582]],

        [[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9316, -2.2852,  0.4167,  ..., -3.0273, -3.7559, -2.7441],
         [-4.0508, -2.5234,  0.3032,  ..., -3.0664, -3.7949, -2.7910],
         ...,
         [-3.8652, -2.2520,  0.0540,  ..., -2.9258, -3.6973, -2.7246],
         [-3.8730, -2.1992,  0.0942,  ..., -2.9199, -3.7207, -2.7188],
         [-3.8184, -2.2109,  0.3101,  ..., -3.0078, -3.6602, -2.6816]]],
       device='cuda:0')
torch.Size([2, 344, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 344, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 29899, 30555],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 29892],
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]]], device='cuda:0')
Batch 6, 7.5% of total tokens
encoded shape: torch.Size([2, 1038])
torch.Size([2, 1038]) tensor([[    1,   306,  1348,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29958,    13,    13]], device='cuda:0')
torch.Size([2, 1038, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.9199, -2.3906,  0.4036,  ..., -3.0312, -3.8105, -2.7109],
         [-4.0508, -2.3926,  0.3345,  ..., -3.0625, -3.7012, -2.8145],
         ...,
         [-3.3281, -1.3877, -0.9927,  ..., -2.5762, -3.4277, -2.4141],
         [-3.3359, -1.4023, -0.9727,  ..., -2.5820, -3.4336, -2.4199],
         [-3.3359, -1.4023, -0.9561,  ..., -2.5840, -3.4336, -2.4180]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2344,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.8945, -2.3301,  0.4888,  ..., -3.0410, -3.8125, -2.6973],
         [-3.8574, -2.2402,  0.6089,  ..., -3.0508, -3.8301, -2.6953],
         [-3.8398, -2.2324,  0.5215,  ..., -3.0410, -3.8379, -2.6895]]],
       device='cuda:0')
torch.Size([2, 1038, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1038, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313, 30186,   856]]], device='cuda:0')
Batch 7, 8.5% of total tokens
encoded shape: torch.Size([2, 830])
torch.Size([2, 830]) tensor([[    1, 29871, 29896,  ...,   381,   567, 29889],
        [    1,  2864,   295,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 830, 32000]) tensor([[[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-4.0078, -2.3809,  0.5596,  ..., -3.0293, -3.8496, -2.7051],
         [-4.0273, -2.4102,  0.2849,  ..., -2.9883, -3.8301, -2.7266],
         ...,
         [-4.1523, -2.5996, -0.2617,  ..., -2.8301, -3.7148, -2.8086],
         [-4.0977, -2.4531,  0.1582,  ..., -3.0059, -3.7637, -2.7949],
         [-3.8750, -2.2227,  0.2664,  ..., -2.9648, -3.6855, -2.7129]],

        [[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-4.0586, -2.4863,  0.3921,  ..., -3.0391, -3.7832, -2.7734],
         [-4.0352, -2.4512,  0.2749,  ..., -3.0156, -3.8086, -2.7520],
         ...,
         [-3.8535, -2.0527,  0.4053,  ..., -2.9922, -3.7910, -2.6562],
         [-3.8496, -2.0469,  0.4050,  ..., -2.9902, -3.7891, -2.6562],
         [-3.8496, -2.0469,  0.4055,  ..., -2.9902, -3.7910, -2.6562]]],
       device='cuda:0')
torch.Size([2, 830, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [31147],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 830, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [31147, 30488, 30879,  ...,   349,   856, 30555],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856]]], device='cuda:0')
Batch 8, 9.7% of total tokens
encoded shape: torch.Size([2, 1886])
torch.Size([2, 1886]) tensor([[    1, 20049,   470,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29913,    13,    13]], device='cuda:0')
torch.Size([2, 1886, 32000]) tensor([[[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-3.9707, -2.3867,  0.3174,  ..., -3.0508, -3.7676, -2.7129],
         [-3.9648, -2.4531,  0.3137,  ..., -3.0566, -3.8066, -2.7988],
         ...,
         [-3.8828, -2.1172,  0.3401,  ..., -2.9980, -3.7871, -2.6660],
         [-3.8750, -2.1113,  0.3433,  ..., -2.9922, -3.7812, -2.6621],
         [-3.8848, -2.1211,  0.3462,  ..., -2.9980, -3.7891, -2.6680]],

        [[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-4.0039, -2.4922,  0.4119,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2324,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.9707, -2.4082,  0.4600,  ..., -3.1211, -3.8594, -2.7734],
         [-3.8672, -2.2500,  0.5474,  ..., -3.1309, -3.8438, -2.7266],
         [-3.9082, -2.3262,  0.4102,  ..., -3.1035, -3.8066, -2.7246]]],
       device='cuda:0')
torch.Size([2, 1886, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1886, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856,   313, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186]]], device='cuda:0')
Batch 9, 12.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,    13,  ...,  3762, 29892,  3643],
        [    1,   525, 26521,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-2.4590,  0.4312, -5.0547,  ..., -1.4912, -2.2754, -1.8203],
         ...,
         [-3.9727, -2.3574,  0.0906,  ..., -3.0020, -3.7090, -2.7812],
         [-4.0000, -2.3945,  0.2937,  ..., -3.0371, -3.7246, -2.7520],
         [-3.9922, -2.3594,  0.2432,  ..., -3.0449, -3.7090, -2.7637]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9922, -2.3594,  0.4192,  ..., -3.0430, -3.8398, -2.7266],
         [-3.9199, -2.3906,  0.2067,  ..., -3.0332, -3.7832, -2.7539],
         ...,
         [-3.3418, -1.5000, -0.3694,  ..., -2.7051, -3.5391, -2.4473],
         [-3.3418, -1.4990, -0.3762,  ..., -2.7031, -3.5391, -2.4473],
         [-3.3438, -1.5029, -0.3816,  ..., -2.7051, -3.5410, -2.4492]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [31147, 30488, 30879,  ..., 30331, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ..., 29889, 30186,   856],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ...,   313, 30555,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 30879, 31147,  ...,   856,   313, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]]], device='cuda:0')
Batch 10, 16.9% of total tokens
encoded shape: torch.Size([2, 577])
torch.Size([2, 577]) tensor([[    1,   450,  9358,  ...,  7495,  6530, 29889],
        [    1,   960,   366,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 577, 32000]) tensor([[[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.9980, -2.2812,  0.4727,  ..., -3.0410, -3.7715, -2.7246],
         [-4.0820, -2.6211,  0.2690,  ..., -3.0234, -3.7773, -2.7617],
         ...,
         [-3.9023, -2.3223,  0.2563,  ..., -2.9492, -3.7695, -2.7207],
         [-3.9844, -2.4023,  0.1864,  ..., -2.9492, -3.7988, -2.7246],
         [-3.8828, -2.2754,  0.3435,  ..., -2.9590, -3.7695, -2.6680]],

        [[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-4.0234, -2.4160,  0.4209,  ..., -3.0312, -3.7871, -2.7188],
         [-3.9902, -2.4688,  0.2751,  ..., -3.0703, -3.7734, -2.7383],
         ...,
         [-3.8711, -2.0977,  0.3545,  ..., -2.9961, -3.8164, -2.6543],
         [-3.8633, -2.0859,  0.3530,  ..., -2.9922, -3.8125, -2.6484],
         [-3.8633, -2.0898,  0.3525,  ..., -2.9941, -3.8145, -2.6504]]],
       device='cuda:0')
torch.Size([2, 577, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 577, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 29915],
         ...,
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856]]], device='cuda:0')
Batch 11, 17.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 10782,   313,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,   450,  2407,  3697]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9961, -2.4453,  0.3865,  ..., -3.1133, -3.8418, -2.7402],
         [-4.1094, -2.5918,  0.3171,  ..., -3.0684, -3.7773, -2.8320],
         ...,
         [-3.2812, -1.3965, -0.5669,  ..., -2.6445, -3.4902, -2.4180],
         [-3.2832, -1.4023, -0.5737,  ..., -2.6465, -3.4922, -2.4219],
         [-3.2852, -1.4033, -0.5747,  ..., -2.6465, -3.4922, -2.4219]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-2.4590,  0.4312, -5.0547,  ..., -1.4912, -2.2754, -1.8203],
         ...,
         [-4.1055, -2.5996,  0.3457,  ..., -3.0508, -3.7266, -2.8242],
         [-3.9199, -2.2266,  0.0503,  ..., -2.9648, -3.6934, -2.7188],
         [-3.9805, -2.3711,  0.1650,  ..., -2.9668, -3.6836, -2.8105]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ...,   856,   349, 29871],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [31147, 30488, 30879,  ..., 30331, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30555, 30186,   856]]], device='cuda:0')
Batch 12, 22.2% of total tokens
encoded shape: torch.Size([2, 3128])
torch.Size([2, 3128]) tensor([[    1,   413,   287,  ..., 18691,  1728, 16920],
        [    1,  1094,   962,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3128, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9668, -2.4531,  0.4304,  ..., -3.0527, -3.7754, -2.7188],
         [-3.9941, -2.4336,  0.4275,  ..., -3.0469, -3.8457, -2.7363],
         ...,
         [-3.9805, -2.3555,  0.2883,  ..., -2.9922, -3.7930, -2.7402],
         [-3.9258, -2.3066,  0.2954,  ..., -2.9922, -3.7500, -2.7051],
         [-4.0078, -2.3945,  0.2299,  ..., -3.0605, -3.7656, -2.7559]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0039, -2.4453,  0.3889,  ..., -3.0352, -3.7559, -2.7285],
         [-4.0078, -2.5469,  0.2219,  ..., -2.9316, -3.7988, -2.7812],
         ...,
         [-3.3125, -1.4346, -0.5659,  ..., -2.6582, -3.4980, -2.4316],
         [-3.3184, -1.4443, -0.5635,  ..., -2.6621, -3.5020, -2.4355],
         [-3.3086, -1.4297, -0.5679,  ..., -2.6543, -3.4941, -2.4297]]],
       device='cuda:0')
torch.Size([2, 3128, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 3128, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         ...,
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ...,   856, 30555, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856,   349],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]]], device='cuda:0')
Batch 13, 25.6% of total tokens
encoded shape: torch.Size([2, 1087])
torch.Size([2, 1087]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 15197,  8797,  ...,   414,   363,  2867]], device='cuda:0')
torch.Size([2, 1087, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7324],
         [-3.8770, -2.2344,  0.2607,  ..., -2.9766, -3.7422, -2.6484],
         ...,
         [-3.8770, -2.1172,  0.4023,  ..., -3.0039, -3.8105, -2.6641],
         [-3.8672, -2.1074,  0.4019,  ..., -3.0000, -3.8066, -2.6582],
         [-3.8711, -2.1152,  0.4028,  ..., -3.0039, -3.8086, -2.6602]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0000, -2.4219,  0.3125,  ..., -3.0488, -3.7812, -2.7520],
         [-4.0859, -2.5371,  0.1631,  ..., -3.0137, -3.7734, -2.7715],
         ...,
         [-4.2070, -2.5957, -0.0124,  ..., -3.0527, -3.8145, -2.8848],
         [-4.0156, -2.5059,  0.1730,  ..., -2.9824, -3.8125, -2.6934],
         [-4.0586, -2.5273,  0.1238,  ..., -2.9941, -3.8105, -2.7852]]],
       device='cuda:0')
torch.Size([2, 1087, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1087, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         ...,
         [30488, 31147, 30879,  ...,   313, 29915,   349],
         [30488, 31147, 30879,  ...,   856, 30186, 30555],
         [30488, 31147, 30879,  ...,   856, 30555, 29899]]], device='cuda:0')
Batch 14, 27.1% of total tokens
encoded shape: torch.Size([2, 416])
torch.Size([2, 416]) tensor([[    1, 13693,   624,  2361, 29892,  9266, 29889,   313, 29940,  3289,
          7698, 29984, 29901,   390,  3718, 29897,    13,    13,  1672,  1254,
          8364,   936, 24352,    13,    13, 29946,    13,    13,  2887,   373,
            13, 29941, 29896,   303,  4756, 29871, 29906, 29900, 29896, 29955,
           390,  3718, 26849, 20743,  5764,   732,    13, 29953, 29941, 29889,
         29946, 29929,   322,   591,  5195,  3217,  7428, 11794,  3727, 29891,
            13,  1454,   365, 20614, 29899,  4945, 29924,   411, 22303,  6758,
           310,    13, 29953, 29906, 29889, 29929, 29946,   669,    13,  5015,
           549,  5373, 29891,   363, 24972,  8476, 29899,  4945, 29924,   411,
         22303,  6758,   310,    13, 29953, 29896, 29889, 29945, 29896,    13,
           705,   884,  2149,   317,  4986,  7077,   304,  7657,   373, 12206,
           306,  3580,  8476, 13566, 11060, 29963,  6670, 29903, 29889,    13,
            13, 29934,  2209,   624,  2361, 29892,  9266, 29889,   338,   385,
          1283, 29899,  9175,   623, 17243,   322,  3271, 13460,  9704,   297,
           278,  3303,  3900, 29892,   411, 29871, 29896, 29892, 29900, 29929,
         29896, 14354,   297, 29871, 29941, 29941,  5922, 29892,   278,  7457,
           310, 15411,   322,  2088,   314, 29889,   450,  6938,  1751,  1078,
          1023,  1506,  4167,   310,  1283, 29899,  9175,  3240,   737,   623,
         17243,   322,  3271, 13460, 14422, 29901, 13693,   360,  1253,   363,
         27898,   313, 29934,  2209, 29897,   322, 24488, 30140, 29879, 28657,
          3217,  3904,  9375, 29889,   739, 16688, 23383,   623, 17243, 29892,
          2130,  3842, 29892,  3661,   705,   279, 29892,   322,  3271,   285,
          1161,  1080,   363,   278,  4152,  3942,   472,  1432,  3250,  4048,
           886,   310, 29871, 29906, 29900, 29995,   304, 29871, 29953, 29900,
         29995,  1283, 14311,   322,  4266,  1017,  3787,  4943, 26094, 29889,
          1094,   310,  6339, 29871, 29906, 29892, 29871, 29906, 29900, 29896,
         29941, 29892,   372, 19623, 29871, 29896, 29900, 29947, 24488, 30140,
         29879, 28657,  3217,  3904,  9375, 14422,   297,  9475,  5922, 29889,
         24488, 29915, 29879, 28657,  3217,  3904,  9375,  5680, 14982,   623,
         17243, 29892,  2130,  3842, 29892,  3661,   705,   279, 29892,   322,
          3271,   285,  1161,  1080,   363,   278,  4152,  3942,   472,  1432,
          3250,  4048,   886,   310, 29871, 29906, 29900, 29995,   304, 29871,
         29955, 29900, 29995,  1283, 17768,   403, 14311,   322,  2313,   792,
          3787,  4943, 26094, 29889,    13,    13,  1469,   322,  2472,   338,
          4944,   363,  1871,  1288, 11976,   871, 29892,   322,   338,   451,
          9146,   363,  3534,   292, 11976, 29889,    13,  8139,  2121,   350,
           834,  4025,  2308,   355, 29889,   510,  4700,  3643,   738,   310,
           967,  2504,   327,   414,  4091,   367,   619,   519,   363,   738,
          4436,   470,   628,  1036,   297,   278,  2793, 29892,    13,   272,
           363,   738,  8820,  4586,   297, 12536,   749,   727,   265, 29889,
            13, 10858,   671,   310,   445,  4700, 20016,  2667,  3544,   749,
           310,  1749, 11814, 29879,  4587,  6692],
        [    1,   512, 25044,   663,   310,  5164,  1601, 10611,   296,   274,
           800,   322, 15835,   398, 16346,   373,   278,   784,   417, 23670,
         12584,  1847,  7037, 29889,    13,  1576,  9949,   310,  5164,  1601,
         10611,   296,   274,   800,   322,   310,  1933,   284,   296, 15835,
           398, 29871,  1080,   373,   784,   417, 23670, 12584,  1847,  9324,
           471,  7405,   630,  4323,   277,  6703,   373,   263,  3856,   305,
         29899,  7052,  8494,   336,  1777,   509,   362,  4742, 29889,   319,
          6133,   784,   417, 23670, 12584,  1847,  7037,   313, 29895, 29897,
           471,  5718,  2705,  8900,   411,   301,   389,  1974,   521,  5095,
           680,  9401,   304,   278,  1021, 16346,   293,  9324, 29879,   310,
           521,  5095,  2247,   310,   916,  1601, 10611,   296,   274,   800,
           313, 13695, 29974, 29892,   476, 29974, 29892,   322, 24277, 29974,
           467,   910, 15500,   471, 29393,   304,   278, 12409,   310,   385,
         10112,  2366,  7546,  2820,   278,   784,   417, 23670, 16445,   491,
           301,   389,  1974, 29871,  1080,   393,  5557,   287,   278,  1634,
          7273,   573,  8249,  2861,   304,   278, 14881,   310,   278,  4047,
           983, 11315, 29879,  8429,   373,   278, 17105,   297,   278, 10122,
           310,  4094, 29889,   450, 10879,   310,   278,  1933,   284,   296,
         15835,   398, 16346,   373,   278, 12584,  1847,  7037,   471,   901,
          4280, 29889,   450, 12584,  1847,  7037,   937, 11664,   411, 15835,
           398, 16346, 26702,   322,   769,  9263,  1463, 29889,   450,  7472,
           995,   310, 12584,  1847,  7037, 10761,   472,   278, 16346,   293,
          9324,  6590,   304,   278, 12187,  1302,   351,  2785, 26702, 29892,
           607,  9263,  1463,   411, 10231,   784,   417,   333, 26702, 29889,
           450,   784,   417, 23670, 12584,  1847,  7037,   471,  1532,  8855,
           630,   491,   263, 13181,   457,   279,  9443,   411,   784,   417,
           333, 26702,   322, 16346,   293,  9324,   363,   599,  4497,  1372,
          9528,  1090,   278, 12187,  1302,   351,  2785, 26702, 29889,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 416, 32000]) tensor([[[-2.7793e+00, -5.4492e-01, -2.4844e+00,  ..., -2.0996e+00,
          -2.9980e+00, -2.1191e+00],
         [-3.9258e+00, -2.4121e+00,  4.3359e-01,  ..., -3.0449e+00,
          -3.8398e+00, -2.7129e+00],
         [-3.9160e+00, -2.3340e+00,  2.4243e-01,  ..., -3.0410e+00,
          -3.8047e+00, -2.6660e+00],
         ...,
         [-3.8359e+00, -2.2520e+00,  2.6050e-01,  ..., -2.9805e+00,
          -3.7852e+00, -2.6719e+00],
         [-3.8320e+00, -2.2832e+00,  2.8638e-01,  ..., -2.9727e+00,
          -3.7305e+00, -2.6660e+00],
         [-3.8086e+00, -2.2129e+00,  2.7197e-01,  ..., -2.9570e+00,
          -3.7480e+00, -2.6387e+00]],

        [[-2.7793e+00, -5.4492e-01, -2.4844e+00,  ..., -2.0996e+00,
          -2.9980e+00, -2.1191e+00],
         [-4.0547e+00, -2.4746e+00,  4.2700e-01,  ..., -3.0762e+00,
          -3.8008e+00, -2.7012e+00],
         [-4.1016e+00, -2.4727e+00, -2.4071e-03,  ..., -3.0078e+00,
          -3.7812e+00, -2.7578e+00],
         ...,
         [-3.8184e+00, -2.0938e+00,  5.4199e-01,  ..., -3.0195e+00,
          -3.8164e+00, -2.6641e+00],
         [-3.8145e+00, -2.0879e+00,  5.4004e-01,  ..., -3.0156e+00,
          -3.8125e+00, -2.6602e+00],
         [-3.8164e+00, -2.0918e+00,  5.4053e-01,  ..., -3.0156e+00,
          -3.8145e+00, -2.6621e+00]]], device='cuda:0')
torch.Size([2, 416, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 416, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ...,   313, 31488, 29892]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 29892,   313, 31488]]], device='cuda:0')
Batch 15, 27.8% of total tokens
encoded shape: torch.Size([2, 637])
torch.Size([2, 637]) tensor([[    1, 21808, 29892,  ...,     2,     2,     2],
        [    1,  3323, 23545,  ...,   278,  5337, 29889]], device='cuda:0')
torch.Size([2, 637, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9316, -2.4043,  0.3804,  ..., -3.0137, -3.8145, -2.7051],
         [-4.0273, -2.4434,  0.2812,  ..., -3.0156, -3.7793, -2.7559],
         ...,
         [-3.9414, -2.1543,  0.4243,  ..., -3.0273, -3.8164, -2.6895],
         [-3.9414, -2.1504,  0.4236,  ..., -3.0254, -3.8145, -2.6875],
         [-3.9414, -2.1504,  0.4226,  ..., -3.0254, -3.8145, -2.6875]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9492, -2.4961,  0.3882,  ..., -3.0410, -3.8438, -2.6621],
         [-3.9707, -2.3984,  0.2211,  ..., -2.9746, -3.8574, -2.6699],
         ...,
         [-4.0039, -2.3984,  0.1649,  ..., -2.9824, -3.7930, -2.7305],
         [-3.9961, -2.3730,  0.1051,  ..., -2.9824, -3.8516, -2.7578],
         [-3.9297, -2.2637,  0.2284,  ..., -2.9863, -3.7285, -2.7539]]],
       device='cuda:0')
torch.Size([2, 637, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [31147]]], device='cuda:0')
torch.Size([2, 637, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ..., 30555, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [31147, 30488, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 16, 28.9% of total tokens
encoded shape: torch.Size([2, 1083])
torch.Size([2, 1083]) tensor([[    1,   319,  3957,  ...,     2,     2,     2],
        [    1,   960,   445,  ...,   271,  1503, 29889]], device='cuda:0')
torch.Size([2, 1083, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9766, -2.3262,  0.4531,  ..., -3.0449, -3.7891, -2.7754],
         [-3.9434, -2.3633,  0.1281,  ..., -3.0020, -3.8086, -2.7031],
         ...,
         [-3.7715, -2.0293,  0.3311,  ..., -2.9512, -3.7598, -2.6289],
         [-3.7695, -2.0234,  0.3308,  ..., -2.9512, -3.7598, -2.6270],
         [-3.7695, -2.0234,  0.3308,  ..., -2.9512, -3.7598, -2.6289]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0234, -2.4160,  0.4211,  ..., -3.0312, -3.7871, -2.7188],
         [-3.9492, -2.4395,  0.3372,  ..., -3.0293, -3.7598, -2.7539],
         ...,
         [-4.0039, -2.4316, -0.0930,  ..., -2.8633, -3.7012, -2.7266],
         [-4.2109, -2.6367, -0.2168,  ..., -2.9531, -3.6953, -2.8320],
         [-3.8809, -2.3574,  0.1154,  ..., -3.0020, -3.7227, -2.8047]]],
       device='cuda:0')
torch.Size([2, 1083, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1083, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 31488, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ..., 29892, 30555,   349],
         [30488, 31147, 30879,  ..., 29889, 29892, 31488]]], device='cuda:0')
Batch 17, 30.1% of total tokens
encoded shape: torch.Size([2, 420])
torch.Size([2, 420]) tensor([[    1,   624,  3097,   310,  9167,   438,  9258,   438,   309,  1963,
           264,   324,   293,  3831,  3885,  2645,  6242, 29899, 14343, 26162,
           313, 29896, 29947, 23471, 29879, 29897,   472,  6789,   546,  3698,
           310, 29871, 29945, 29899, 29945, 29900,  6719, 29907, 29889,    13,
         29963,   381,  5359,   288,  9258, 17182,   313, 24898, 29949, 29897,
         17292,   324,   293,   752,  3885,   505,  1880, 18254, 29878,  3245,
           322,  4768,  5996,  4426, 29889,   450,  6437,   310,   445,  5925,
           471,   304,  6559,   278, 25806,   310,   478, 29949, 29949, 17292,
           324,   293,   752,  3885,  2645,  1472, 29899,  8489,  8635,   313,
         29896, 29947,  7378, 29897,   472,  1422,  6238,  3698,   313, 29945,
         29892, 29871, 29896, 29945, 29892, 29871, 29906, 29945, 29892,   322,
         29871, 29945, 29900,  6719, 29907, 29897,   322,   304, 11539,   278,
         10631,   310, 15446,   478, 29949, 29949,   472,   263, 10430,  5224,
          1135,   278,  9670, 12128,  5855,   313, 29906, 29900, 29899, 29906,
         29945,  6719, 29907,   467, 12458,  1601,   586,  1306, 26310,   478,
         29949, 24768,   393,  1163,   287,   297,  1009,  9950,  1017, 22193,
          8722,   322,  2793,   310,  5613,  3677,   601, 29916,   333,  1934,
           892,  1304,   297,   445,  6559, 29889,   450,   316,  5105,   362,
           310,   409,  1111,   381,  1941,   333, 17292,   324,  1199,  2645,
          8635,  8833, 17381, 29899,  4102, 29899,  2098,   413, 10157,  1199,
           322,  1401,  2760,   373,   278,  2847,  2793,   310, 17292,   324,
          1199,  4475,   304,   288,  9258, 17182, 12875, 29889,   450,  2847,
           316,  5105,   362,  6554,   471,  2788,   472, 29871, 29945,   322,
         29871, 29896, 29945,  6719, 29907,   541, 11664,  2050,  2197,   472,
         29871, 29906, 29945,  6719, 29907,   322,   471,  1584,  8473,   472,
         29871, 29945, 29900,  6719, 29907, 29889,  9656,  1883,   324, 25748,
           892,   901, 13714,  1135, 17546,  3594,  1017,  1883,   324,   752,
          3885, 29892,  7148,   297,  5764, 18046,   793,   411,  9078,   288,
         28596, 20847,  3097, 29889,   450,  7910,   297,   278,  2793,   310,
          2560, 17292,   324,  1199, 29892,   278, 23806,   310,  1009,   409,
          1111,   381,  1941,   333, 25748, 29892,   470,   278, 11959,   310,
          2560,   304,   409,  1111,   381,  1941,   333, 17292,   324,  1199,
          1033,   367,  1304,   408, 16285,   310,   278, 19100,   333,  1230,
           322, 17546,   368, 29873,   293,   316,  5105,   362,   310,   478,
         29949, 29949, 17292,   324,  1199, 29889,   450,   528,   761,  2834,
           310,   278, 12399,   478, 29949, 29949,   471,  2050,  2197, 10410,
           472, 12212,  8635, 10430,   313, 29896, 29945,  7186, 29871, 29906,
         29945,  6719, 29907,   467, 12808, 29892,  8635,  5855, 15201,   478,
         29949, 29949, 17292,   324,   293,  2793,   322,  5480,   278,  1518,
         12232,  2635,   310,   278,  9045,  5995,   393,   288,  9258, 17182,
         15680,  9789,  3775, 29126,   304,   278, 13047,   310, 10416, 17441,
          4841,   515, 19100,   333,  1230, 22884, 29889,     2,     2,     2],
        [    1,   660, 29901,    13,    13,  9135,  1687,   304, 10563,  2989,
          9066,   470,  2159,   310,  9066, 29973,    13,    13,  3624,   372,
          1950,   363,   263,  2115, 29285,   304,  6597,   278,  2989,  1426,
           310,   263,  2009,  4839,   310,  2933,  4839,  3265,  1135,  2599,
           278,   679,  7850,   580,  1158, 29689, 29973, 20360, 29892,   723,
           372,   367,  1950,   304,   679,   278,  2989,  2159,   297,  6262,
           310,  1438,  9066, 29973,    13,  1123,  1658,   306, 29915, 29885,
          6721,   445,   338,  1363,   306,   864,   304,  5702,   278,   848,
          8744,  1546,   278, 29285,   322,  4742,  9348,   278,  2009, 29892,
           322,  2861,   304,   278,  2919,  5253,   310,  7274,   393,   674,
           367,  3638,   515,  1422,  9224,   306,   864,   304,   367,  2221,
           304,   679,   385, 16232,  8954,   310,   920,  1784,  6262,   892,
          1304,   701,   925,   491,   278,  9066, 29889,    13, 16894,   297,
          6564, 29889, 29871,    13,    13, 29909, 29901,    13,    13,  1576,
          3450,   947,   451,  3867,   263,   982,   304,   679,   599,   278,
          9066,   411,   263,  2323,  1246,   448,  1423,   278,   435,   485,
           328, 12332, 29901,    13,    13,  1124,   597, 10382, 29889, 11347,
         29889,   510, 29914,  1645,  3905, 29914, 29953, 29914,  2754, 29914,
         23357, 29914, 12144, 29914,  1124, 29914,  5506, 10735,  3089, 29889,
          1420,    13,    13, 10605,   338,   385,  1342,   310,   920,   366,
          1033,   679,   599,  9066,   313, 14037, 29748,  2738,  1870, 12747,
           467,    13,  9053, 14974,  1917,  3388,   679,  3596, 18163, 29898,
          5506, 10735,  3089,  2009, 29897,   426,    13,  1678, 14974,  1917,
          3388,   599, 18163,   353,   716, 14974,  1917,  3388,   890,    13,
          1678,  2391, 29966,  1231, 29958,  4839,  8659,   353,  1530,  5942,
         29889,  1761,  3552, 29923,  8058,   362, 29966,  1231, 12948,  3827,
         29889,   657,  7850,  8659,  3310,    13,  1678,   363,   313,  1231,
          4839,  1170,   584,  4839,  8659, 29897,   426,    13,  4706,   599,
         18163, 29889,   649,  3596, 29898,  6672,  1170, 29892,  1530,  5942,
         29889,  1761,  3552, 29923,  8058,   362, 29966,  1231, 12948,  2009,
         29889,   657, 18163, 29898,  6672,  1170, 17884,    13,  1678,   500,
            13,    13,  1678,   736,   599, 18163, 29936,    13, 29913,    13,
            13, 26222,   366,   526,   773,   278,  3355,  9635,  1026,  4733,
           366,  2609,   679,   278,  4839,  2159,   297,  6262,  1728,   337,
         29899, 11433,   292,   372,   313,   347, 29901, 13649,   975,   679,
          3596, 18163,   322,  9773,   529,  6672,  1024, 23917,   529,  6672,
           995, 29958,   511,   366,   674,   884,   817,   304,   788,   278,
          1045,  3955, 15284, 12354,  7331, 29871, 29896, 29914, 29896, 29889,
         29896,  2992, 29889, 29871,  5282, 18639,   437,   519,   565,   366,
         13312,   817,   263,  3355,  1650, 29892,   541,   306,   679,   278,
         11223,   366,   881,  1348,  1048, 27556,   445,  5900,   714,   310,
           596,  2115,   623,   322,   964,   263, 10166, 29889,    13,    13]],
       device='cuda:0')
torch.Size([2, 420, 32000]) tensor([[[-2.7793, -0.5454, -2.4844,  ..., -2.0996, -2.9980, -2.1191],
         [-3.9688, -2.3984,  0.3940,  ..., -3.0254, -3.8223, -2.6914],
         [-4.0508, -2.4980,  0.2593,  ..., -3.0762, -3.8164, -2.8242],
         ...,
         [-4.2031, -2.0938,  0.3401,  ..., -3.0000, -3.8496, -2.7637],
         [-4.0195, -1.9971,  0.4333,  ..., -2.9844, -3.8203, -2.7031],
         [-3.9062, -1.9648,  0.5015,  ..., -2.9824, -3.8145, -2.6738]],

        [[-2.7793, -0.5454, -2.4844,  ..., -2.0996, -2.9980, -2.1191],
         [-4.0078, -2.5020,  0.4126,  ..., -3.0605, -3.8926, -2.7383],
         [-3.8867, -2.2480,  0.2627,  ..., -2.9844, -3.7500, -2.6582],
         ...,
         [-3.8086, -2.3008,  0.3853,  ..., -3.0312, -3.8223, -2.7578],
         [-3.8320, -2.2500,  0.6377,  ..., -3.0820, -3.8711, -2.7207],
         [-3.7637, -2.2031,  0.5366,  ..., -3.0391, -3.8047, -2.6875]]],
       device='cuda:0')
torch.Size([2, 420, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 420, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ...,   313,   856, 29871],
         [30488, 31147, 30879,  ...,   313,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856]]], device='cuda:0')
Batch 18, 30.9% of total tokens
encoded shape: torch.Size([2, 361])
torch.Size([2, 361]) tensor([[    1, 21444,   310,   270,   858, 19783,   262, 29899, 21264,   630,
          3279,  1144,   297,   270,   858, 19783,   262, 29899,  1066,  3321,
          2301,  2841, 18755,   414,   313,   276,  1765,  1934, 29897,   297,
         23568,  4584,  2301, 16637,   270,   858,   307, 11461, 29889,    13,
          1576,   270,   858, 19783,   262, 29899, 16808,  9708,  4859,   262,
          4280,   805,   550,   278, 22887,  1111, 13846,   304,  3867,   263,
          1544,   482,  1546,   278, 11684,   279,  1111,  2409,  5156,   274,
          3637,   359,   446, 11285,   322,   278,  1294,   945,   514,  1070,
          4636,   297, 18109,  1026,   284,  2301,  2841, 29889,   512, 23568,
          4584,  2301, 16637,   270,   858,   307, 11461,   313, 29928,  5773,
           511,   278, 18070,   310,   270,   858, 19783,   262, 11981,   304,
           263,  4192,  6288, 20376,   297,   599,   310,   278,   270,   858,
         19783,   262, 29899, 21264,   630,  3279,  1144,   297,   278, 22887,
          1111, 13846, 29892,  4550, 10805,   278,   766, 18953,   310,   278,
           270,   858, 19783,   262, 29899, 16808,  9708,  4859,   262,  4280,
           322,   278,  6410,   310,   278,  1544,   482,   304,   278,  1294,
           945,   514,  1070,  4636, 29889,   910,   338,  2225, 21571,   304,
          3275,   304, 22887,  1111,  2409,  5156,   832,  3097,   607,  1033,
          4050,  2301,  2841, 18755,   414,  2858,  1547,  1821,   304,   452,
         29883,  1883,   275, 29889,   512,   360,  5773, 29892,   263,  1407,
          2319, 19649,   310,  2301,  2841, 18755,   414,  1510,   270,   858,
         19783,   262,   380, 17225,  3412,   278, 22887,  1111, 13846, 29892,
          2225, 24873,  2861,   304,   263,  1473,   297, 29899,  2557,  7374,
           291,   297,   278,   270,   858, 19783,   262, 18530, 29889,  2398,
         29892,   278, 13303, 26002,   310,  1438, 10812,   270,   858, 19783,
           262, 29899,  1066,  3321,  2301,  2841, 18755,   414,   313,   276,
          1765,  1934, 29897,   297,   360,  5773,   756,  1063, 20871, 29889,
          2266,   591,  3461,   278,  1302, 29899, 17471,   310,   278,   270,
           858, 19783,   262, 29899, 21264,   630,  3279,  1144,   411,   270,
           858, 19783,   262,   297, 29538,  1934,   310,   360,  5773, 18109,
          1026,   284,  2301,  2841, 29889,  8680,  2582,  4368,   393,   278,
          4152,   270,   858, 19783,   262, 29899, 16808,  9708,  4859,   262,
          4280,   338, 23119,   297, 29538,  1934,   322, 29892,  4550, 29892,
           278,  1544,   482,  1546,   278, 11684,   279,  1111,  2409,  5156,
           274,  3637,   359,   446, 11285,   322,   278,  1294,   945,   514,
          1070,  4636,   338, 23119,   297,  1438,  2301,  2841, 18755,   414,
         29889],
        [    1,   501,  2460,  1939, 20929,  9940, 29871, 29896, 29896, 29900,
           448,  7523,   501,  2460,  1939, 20929,  9940, 23040, 29871, 29896,
         29896, 29900,    13,    13, 29965,  2460,  1939, 20929,  9940, 29871,
         29896, 29896, 29900,   276,  4611, 29991,   887,   526,  1286,  5183,
           501,  2460,  1939, 20929,  9940, 29871, 29896, 29896, 29900,  7395,
         29889,   960,   366,   526,   289,  4395,   515,   501,  2460,  1939,
         20929,  9940,   286, 12686, 29892,   366,   508,  1018, 16671,   592,
          1544,   472,  2246,   310,  1813,   470,  1831,  1790,   286, 12686,
           763,   501,  2460,  1939, 20929,  9940, 29871, 29896, 29896, 29900,
           515,  1749, 12176,   286, 12686,  1051, 29889,    13, 29965,  2460,
          1939, 20929,  9940, 29871, 29896, 29896, 29900,  5492,   297,   286,
         12686,   282,  5863,  5172,   342, 29892,  6907,   596,  7875,   304,
          1303,   501,  2460,  1939, 20929,  9940, 29871, 29896, 29896, 29900,
          1286, 29991,    13, 25353, 21778, 29936, 25016,   598,  1664, 29901,
           396, 29896,  6503,   363,   501,  2460,  1939, 20929,  9940,  2522,
           550, 13542, 29889,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2]], device='cuda:0')
torch.Size([2, 361, 32000]) tensor([[[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9980, -2.4707,  0.3245,  ..., -3.0391, -3.8398, -2.7500],
         [-3.9297, -2.3223,  0.1002,  ..., -2.9746, -3.6855, -2.7090],
         ...,
         [-3.9160, -2.3691,  0.2930,  ..., -2.9551, -3.8652, -2.7109],
         [-3.8906, -2.1797,  0.1443,  ..., -2.9473, -3.7207, -2.7793],
         [-3.8223, -2.1719,  0.2922,  ..., -2.9746, -3.6543, -2.6758]],

        [[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0156, -2.5176,  0.4563,  ..., -3.0566, -3.8730, -2.7715],
         [-4.0039, -2.4844,  0.2764,  ..., -3.0234, -3.8086, -2.7051],
         ...,
         [-3.9141, -2.1035,  0.4094,  ..., -3.0137, -3.8047, -2.6719],
         [-3.9180, -2.1055,  0.4070,  ..., -3.0156, -3.8047, -2.6738],
         [-3.9219, -2.1133,  0.4072,  ..., -3.0176, -3.8086, -2.6777]]],
       device='cuda:0')
torch.Size([2, 361, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 361, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 30879, 31147,  ..., 29892,   856,   313],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892,   856,   313],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 19, 31.5% of total tokens
encoded shape: torch.Size([2, 3359])
torch.Size([2, 3359]) tensor([[    1,   660, 29901,  ...,   262,    13,    13],
        [    1,   739,   338,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3359, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0078, -2.5020,  0.4119,  ..., -3.0586, -3.8926, -2.7363],
         [-3.8770, -2.2324,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-4.0352, -2.4277,  0.1122,  ..., -2.9727, -3.8027, -2.7344],
         [-3.8809, -2.2656,  0.5552,  ..., -3.0840, -3.8574, -2.7598],
         [-3.8262, -2.2148,  0.4907,  ..., -3.0645, -3.8242, -2.7188]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9453, -2.3438,  0.3689,  ..., -3.0605, -3.8184, -2.7793],
         [-4.0742, -2.4453,  0.3123,  ..., -3.1113, -3.7930, -2.8418],
         ...,
         [-3.3242, -1.4775, -0.4263,  ..., -2.6875, -3.5215, -2.4395],
         [-3.3320, -1.4834, -0.4275,  ..., -2.6914, -3.5273, -2.4453],
         [-3.3184, -1.4668, -0.4302,  ..., -2.6836, -3.5176, -2.4355]]],
       device='cuda:0')
torch.Size([2, 3359, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [31147],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 3359, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [31147, 30488, 30879,  ...,   313, 29899,   315],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]]], device='cuda:0')
Batch 20, 35.2% of total tokens
encoded shape: torch.Size([2, 336])
torch.Size([2, 336]) tensor([[    1, 10670, 29891, 24740, 11727, 15028,   411,   670,  6532,  8660,
           389, 24740, 11727,   408,   540,  5969,  2039,   304,   278,  5745,
          2645,   263, 11531,  5040, 29892,   323,  1041,  3250, 29892,   297,
          3122,  3793, 29885, 17594, 29892, 13813, 29889,    13,    13, 29934,
           566, 29891, 24740, 11727,   338, 20662,  3262,   297,   278,  2106,
          5545,   376, 29883,   582,  1455, 29908,   304,   670,  6673,   616,
           521,  2925, 29889,    13,    13,  2744,  6588,   310,  2211,  1248,
          3137,  4586,   297, 13813,  1510, 24740, 11727,   297,  4654,  2058,
         29889,  2259, 15612,   475,   322, 24532,  6033,  3801,   526, 18873,
         29899,   392, 29899,   484,   384,   472, 29871, 29906, 29955, 29995,
           322, 29871, 29906, 29945, 15543, 24740, 11727,   338,   982,  1250,
           472, 29871, 29896, 29953, 29995,   856,  4120,  1711, 21351,   411,
         12828,   379,  2707,   370,  3905, 29892,  1058,  4947, 29871, 29896,
         29945, 15543,   739, 29915, 29879,  3063,   901,   322,   901,   763,
         24740, 11727, 29915, 29879, 12561,   310,  1641,  6673,   338,  2343,
           287,   363,   278,   885,  2390, 16947, 29889,  7803,  7378,  8020,
         24740, 11727,   471,   278, 21460,  3321, 25448,   297, 13813,   472,
         29871, 29941, 29947, 29995,   304, 29871, 29896, 29955, 29995,   363,
         24532,  6033,  3801,   322, 29871, 29896, 29896, 29995,   363,  2259,
         15612,   475, 29889,    13,    13,  6716, 21180,  2475,   338, 23153,
           491,   278, 23740,  2439,  2741,  5934, 24740, 11727,   756,   376,
         15389,  1474,   694,  8825,   304,  5401,   297, 13813,  1213,  7280,
          4083, 29892,   376,  3644,   540,   508, 29915, 29873,  1207,   372,
           727,   297, 13813, 29892,   540,   508, 29915, 29873,  1207,   372,
         12214,  1213,  2088,   404,   278,  3838,   310,   393, 13834,  4823,
          1016, 29915, 29873,  2337,  9228,  1565, 29889,  1126, 13813,   338,
         19576,  2125,   599, 30098,   361,   366,  1016, 29915, 29873,  8341,
           937,   366,  1016, 29915, 29873,   679,   263,  2323, 13341, 29889,
            13,    13, 26074,   352, 11727, 29915, 29879, 11531, 29892,   310,
          3236, 29892,  8937,   267,   599,   445, 29892,  1663, 15423,   540,
         29915,   645,  5401, 29889,   940,  1852,  1041,   670,  2643,   925,
          4225,   263,  2217,   901,   931,   304, 28169,   297, 29889,    13,
            13,  1762,  1303,   901,   322, 29126,   304,   278,   315,  2142,
           571,  1017,  3497, 10679,  2828,  1244],
        [    1,  2216,   304,   289,  1431, 29892,   541, 29892,   590,  3942,
           322,  7875,   505,   599,  5429,   592,   393,   306,  1207,  2107,
         26459,   360,  1253,   292, 29889,  1105, 29892,   304,   599,   393,
           505,  4433,   363,   278,  9522,   412, 12985, 12985,  4150,   372,
           338, 29991,  3115,  1423,   714,  1749, 26459,   322,  4989, 13308,
         29991, 12065,   596, 24842,   872,   329, 29948,  7243,   373,   472,
           263,  2217,  6133,  1135, 18350,   869,   315,   329,   701,   263,
           282,   618,   310,  9922,   535,   408,  7523,   901,    13,    13,
          3492,   679,  1749,  2246,  3006, 25562,   363,  4996,   322,  4780,
          9522,  5547,   363, 19587,  2305,   322,   679,   716,  9522,  5547,
           321,   655,  2356,   304,   366, 29991,  1334,  1016, 30010, 29873,
          6232,   596,  4876,  3211,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 336, 32000]) tensor([[[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9648, -2.4453,  0.4749,  ..., -3.0332, -3.8438, -2.7246],
         [-3.9355, -2.4102,  0.3464,  ..., -3.0312, -3.7930, -2.7324],
         ...,
         [-3.7871, -2.1777,  0.3140,  ..., -2.9805, -3.8262, -2.6973],
         [-3.7383, -2.1582,  0.2913,  ..., -2.9492, -3.7324, -2.6250],
         [-3.8359, -2.2285,  0.3445,  ..., -3.0039, -3.7656, -2.6660]],

        [[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9863, -2.3809,  0.2966,  ..., -2.9707, -3.8281, -2.7266],
         [-3.9824, -2.3945,  0.1245,  ..., -2.9629, -3.8066, -2.7617],
         ...,
         [-3.9512, -2.1309,  0.3569,  ..., -3.0098, -3.8223, -2.6738],
         [-3.9473, -2.1250,  0.3552,  ..., -3.0039, -3.8164, -2.6699],
         [-3.9590, -2.1426,  0.3560,  ..., -3.0117, -3.8262, -2.6777]]],
       device='cuda:0')
torch.Size([2, 336, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [31147],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 336, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 31488,   856],
         [30488, 31147, 30879,  ..., 31488, 29892,   313],
         [30488, 31147, 30879,  ..., 29892,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ..., 30555, 30186,   856]]], device='cuda:0')
Batch 21, 35.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,    13,  ..., 10311, 16831,   287],
        [    1,   518,  1917,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-2.4590,  0.4312, -5.0547,  ..., -1.4912, -2.2754, -1.8203],
         ...,
         [-3.9609, -2.3633, -0.1279,  ..., -2.9141, -3.6738, -2.6973],
         [-4.0586, -2.4902, -0.0553,  ..., -2.9609, -3.7578, -2.7715],
         [-3.8301, -2.3047,  0.0701,  ..., -2.9473, -3.6465, -2.7090]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9746, -2.4434,  0.4133,  ..., -3.0215, -3.8398, -2.6992],
         [-4.0430, -2.6113,  0.2542,  ..., -2.9941, -3.8086, -2.7539],
         ...,
         [-3.3926, -1.5762, -0.2438,  ..., -2.7422, -3.5703, -2.4727],
         [-3.3984, -1.5879, -0.2424,  ..., -2.7500, -3.5801, -2.4785],
         [-3.3887, -1.5723, -0.2390,  ..., -2.7441, -3.5703, -2.4707]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [31147, 30488, 30879,  ..., 30331, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ...,   313, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]]], device='cuda:0')
Batch 22, 40.5% of total tokens
encoded shape: torch.Size([2, 1033])
torch.Size([2, 1033]) tensor([[    1, 16340, 29892,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29889,    13,    13]], device='cuda:0')
torch.Size([2, 1033, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.9844, -2.3809,  0.3132,  ..., -3.0352, -3.8223, -2.7520],
         [-4.0078, -2.3574,  0.2930,  ..., -3.0312, -3.7520, -2.7461],
         ...,
         [-3.7012, -1.9619,  0.2186,  ..., -2.9199, -3.7363, -2.5938],
         [-3.7109, -1.9766,  0.2272,  ..., -2.9258, -3.7422, -2.5996],
         [-3.7148, -1.9805,  0.2310,  ..., -2.9277, -3.7441, -2.6016]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2344,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.8926, -2.2656,  0.1982,  ..., -3.0098, -3.6934, -2.7910],
         [-3.8691, -2.2422,  0.5581,  ..., -3.0664, -3.7871, -2.7246],
         [-3.8418, -2.2480,  0.4717,  ..., -3.0098, -3.8008, -2.6660]]],
       device='cuda:0')
torch.Size([2, 1033, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1033, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         ...,
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186]]], device='cuda:0')
Batch 23, 41.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 15862,  9400,  ...,     2,     2,     2],
        [    1, 18884,  6058,  ...,  1346,  3318,  3598]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9336, -2.4219,  0.3694,  ..., -3.0352, -3.8027, -2.7305],
         [-3.9219, -2.3848,  0.2466,  ..., -2.9512, -3.8203, -2.6484],
         ...,
         [-3.2266, -1.2900, -0.8809,  ..., -2.5723, -3.4258, -2.3848],
         [-3.2285, -1.2910, -0.8794,  ..., -2.5723, -3.4258, -2.3848],
         [-3.2305, -1.2920, -0.8794,  ..., -2.5723, -3.4258, -2.3848]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8945, -2.3047,  0.4504,  ..., -3.0293, -3.7930, -2.6387],
         [-4.0586, -2.4961,  0.3479,  ..., -3.0039, -3.8184, -2.7500],
         ...,
         [-3.7246, -2.0410,  0.2042,  ..., -2.9844, -3.7129, -2.6113],
         [-3.8945, -2.2988,  0.1158,  ..., -2.9863, -3.8340, -2.7715],
         [-3.8242, -2.2266,  0.1575,  ..., -2.9375, -3.7207, -2.6621]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 30879, 31147,  ..., 30555,   856, 29899],
         ...,
         [30488, 31147, 30879,  ..., 31488, 29892,   313],
         [30488, 31147, 30879,  ...,   313,   856, 29892],
         [30488, 31147, 30879,  ..., 29892,   856,   313]]], device='cuda:0')
Batch 24, 46.2% of total tokens
encoded shape: torch.Size([2, 909])
torch.Size([2, 909]) tensor([[    1,   660, 29901,  ..., 29871,    13,    13],
        [    1,  2391,   310,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 909, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7324],
         [-3.8770, -2.2344,  0.2607,  ..., -2.9766, -3.7422, -2.6484],
         ...,
         [-3.9844, -2.4414,  0.4207,  ..., -3.0859, -3.7266, -2.7871],
         [-3.8613, -2.3398,  0.5127,  ..., -3.1270, -3.7949, -2.7500],
         [-3.8320, -2.2773,  0.4629,  ..., -3.0820, -3.7988, -2.6953]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0508, -2.5391,  0.2260,  ..., -2.9980, -3.8359, -2.7539],
         [-3.9688, -2.4180,  0.2161,  ..., -2.9219, -3.7637, -2.6953],
         ...,
         [-3.6777, -1.9336,  0.1479,  ..., -2.9062, -3.7207, -2.5879],
         [-3.6719, -1.9307,  0.1442,  ..., -2.9062, -3.7207, -2.5859],
         [-3.6777, -1.9346,  0.1498,  ..., -2.9082, -3.7227, -2.5898]]],
       device='cuda:0')
torch.Size([2, 909, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 909, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 29889,   313, 29892],
         [30488, 31147, 30879,  ..., 29889,   313, 30331],
         [30488, 31147, 30879,  ..., 29889,   313, 29892]]], device='cuda:0')
Batch 25, 47.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 27576,   426,  ..., 29871, 29941, 29906],
        [    1,   315,   475,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9766, -2.3105,  0.3232,  ..., -3.0273, -3.7930, -2.7246],
         [-3.9609, -2.4082,  0.4067,  ..., -3.0000, -3.8301, -2.7090],
         ...,
         [-3.9766, -2.4316,  0.3662,  ..., -3.0410, -3.8379, -2.7676],
         [-3.9297, -2.4180,  0.3352,  ..., -3.0488, -3.8555, -2.7344],
         [-3.9609, -2.3281,  0.1517,  ..., -3.0449, -3.8027, -2.7129]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9316, -2.3516,  0.5376,  ..., -3.0332, -3.8066, -2.7285],
         [-4.0234, -2.4941,  0.3054,  ..., -3.0547, -3.8008, -2.7363],
         ...,
         [-3.2246, -1.2725, -0.9365,  ..., -2.5586, -3.4180, -2.3809],
         [-3.2188, -1.2646, -0.9351,  ..., -2.5547, -3.4141, -2.3770],
         [-3.2168, -1.2646, -0.9282,  ..., -2.5566, -3.4141, -2.3770]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]]], device='cuda:0')
Batch 26, 51.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 10522, 28320,  ...,     2,     2,     2],
        [    1,  2178,  8018,  ..., 29889,    13,    13]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9297, -2.4102,  0.2153,  ..., -2.9609, -3.7871, -2.7168],
         [-3.9082, -2.3809,  0.2842,  ..., -2.9395, -3.7871, -2.7148],
         ...,
         [-3.2207, -1.2803, -0.8501,  ..., -2.5723, -3.4238, -2.3789],
         [-3.2227, -1.2803, -0.8628,  ..., -2.5703, -3.4238, -2.3789],
         [-3.2207, -1.2783, -0.8711,  ..., -2.5684, -3.4219, -2.3789]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0000, -2.3945,  0.3491,  ..., -3.0723, -3.7812, -2.7520],
         [-3.9902, -2.4121,  0.1976,  ..., -2.9727, -3.7910, -2.7031],
         ...,
         [-3.7676, -2.1172,  0.1946,  ..., -2.9297, -3.6992, -2.6211],
         [-3.8398, -2.2520,  0.6030,  ..., -3.0566, -3.8340, -2.7129],
         [-3.7500, -2.1172,  0.4446,  ..., -2.9668, -3.8027, -2.6328]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 31488,   313]]], device='cuda:0')
Batch 27, 56.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 27576,   426,  ...,   310, 17135,   313],
        [    1, 29871,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9766, -2.3105,  0.3232,  ..., -3.0273, -3.7930, -2.7246],
         [-3.9609, -2.4082,  0.4067,  ..., -3.0000, -3.8301, -2.7090],
         ...,
         [-3.8105, -2.1465,  0.1995,  ..., -2.9199, -3.6660, -2.6738],
         [-3.9551, -2.3516, -0.1091,  ..., -2.9473, -3.7832, -2.7422],
         [-3.8828, -2.3262,  0.2883,  ..., -2.9238, -3.7598, -2.6797]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-2.4590,  0.4312, -5.0547,  ..., -1.4912, -2.2754, -1.8203],
         ...,
         [-3.8691, -2.1660,  0.5088,  ..., -3.0332, -3.8398, -2.6875],
         [-3.8691, -2.1660,  0.5088,  ..., -3.0352, -3.8398, -2.6875],
         [-3.8730, -2.1699,  0.5088,  ..., -3.0371, -3.8457, -2.6914]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 31488,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [31147, 30488, 30879,  ..., 30331, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]]], device='cuda:0')
Batch 28, 63.1% of total tokens
encoded shape: torch.Size([2, 928])
torch.Size([2, 928]) tensor([[    1, 12440,  1230,  ...,     2,     2,     2],
        [    1,  7605,   292,  ...,   310, 22069, 29889]], device='cuda:0')
torch.Size([2, 928, 32000]) tensor([[[-2.7754e+00, -5.4541e-01, -2.4824e+00,  ..., -2.1016e+00,
          -2.9980e+00, -2.1172e+00],
         [-3.9980e+00, -2.3828e+00,  4.0820e-01,  ..., -3.0469e+00,
          -3.8809e+00, -2.7441e+00],
         [-3.9766e+00, -2.4219e+00,  2.5806e-01,  ..., -3.0293e+00,
          -3.8145e+00, -2.6973e+00],
         ...,
         [-3.8477e+00, -2.0879e+00,  4.7363e-01,  ..., -3.0059e+00,
          -3.7969e+00, -2.6621e+00],
         [-3.8555e+00, -2.0996e+00,  4.7559e-01,  ..., -3.0137e+00,
          -3.8047e+00, -2.6699e+00],
         [-3.8496e+00, -2.0918e+00,  4.7388e-01,  ..., -3.0098e+00,
          -3.8008e+00, -2.6660e+00]],

        [[-2.7754e+00, -5.4541e-01, -2.4824e+00,  ..., -2.1016e+00,
          -2.9980e+00, -2.1172e+00],
         [-3.9766e+00, -2.4141e+00,  3.0786e-01,  ..., -3.0371e+00,
          -3.8574e+00, -2.6523e+00],
         [-4.0430e+00, -2.4863e+00,  3.1860e-01,  ..., -3.0312e+00,
          -3.7871e+00, -2.7012e+00],
         ...,
         [-4.0273e+00, -2.4531e+00,  1.5674e-01,  ..., -2.9551e+00,
          -3.7012e+00, -2.6562e+00],
         [-3.9023e+00, -2.3066e+00, -2.4738e-03,  ..., -2.8750e+00,
          -3.6113e+00, -2.7031e+00],
         [-3.9609e+00, -2.3633e+00,  3.2520e-01,  ..., -3.0176e+00,
          -3.6934e+00, -2.7461e+00]]], device='cuda:0')
torch.Size([2, 928, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 928, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313, 30555,   349],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 29892, 31488],
         [30488, 31147, 30879,  ..., 30555, 30186,   856]]], device='cuda:0')
Batch 29, 64.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 27822, 29892,  ..., 29941,   386, 21726],
        [    1, 11856,  6813,  ...,    13, 29968,  2108]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9570, -2.3633,  0.3738,  ..., -3.0723, -3.8457, -2.7852],
         [-4.0039, -2.3594,  0.3035,  ..., -3.0273, -3.7559, -2.7461],
         ...,
         [-3.9121, -2.3125,  0.1221,  ..., -2.9512, -3.8066, -2.7402],
         [-3.8750, -2.2852, -0.1884,  ..., -2.7871, -3.6621, -2.7148],
         [-3.9609, -2.3672, -0.1086,  ..., -2.8926, -3.6973, -2.7793]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9785, -2.4727,  0.2424,  ..., -3.0000, -3.8066, -2.7344],
         [-4.0742, -2.5312,  0.3486,  ..., -3.0879, -3.8320, -2.7930],
         ...,
         [-3.8203, -2.1973,  0.2058,  ..., -3.0234, -3.7676, -2.7168],
         [-3.8789, -2.3711,  0.2053,  ..., -2.9688, -3.6836, -2.6836],
         [-3.8418, -2.2520,  0.2157,  ..., -2.9590, -3.7695, -2.6152]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856]]], device='cuda:0')
Batch 30, 72.8% of total tokens
encoded shape: torch.Size([2, 900])
torch.Size([2, 900]) tensor([[    1, 16081,  1175,  ...,     2,     2,     2],
        [    1,  3739, 29875,  ...,   322,  1746, 29897]], device='cuda:0')
torch.Size([2, 900, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0312, -2.4688,  0.3987,  ..., -3.0430, -3.8652, -2.7598],
         [-3.9453, -2.3887,  0.3120,  ..., -3.0312, -3.8457, -2.7539],
         ...,
         [-3.7910, -2.0469,  0.2925,  ..., -2.9551, -3.7656, -2.6367],
         [-3.7891, -2.0449,  0.2910,  ..., -2.9551, -3.7656, -2.6367],
         [-3.7910, -2.0488,  0.2942,  ..., -2.9570, -3.7676, -2.6367]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.9043, -2.3691,  0.4597,  ..., -3.0547, -3.8262, -2.6895],
         [-3.9004, -2.3418,  0.3308,  ..., -3.0312, -3.7910, -2.6660],
         ...,
         [-3.8867, -2.3672,  0.0417,  ..., -2.9082, -3.7441, -2.6875],
         [-3.9160, -2.3965,  0.0583,  ..., -2.9453, -3.7168, -2.7148],
         [-3.9902, -2.4219,  0.1719,  ..., -2.9746, -3.7949, -2.7305]]],
       device='cuda:0')
torch.Size([2, 900, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 900, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 29892],
         [30488, 31147, 30879,  ...,   313,   856, 29892],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 31, 73.8% of total tokens
encoded shape: torch.Size([2, 542])
torch.Size([2, 542]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   512,  6335,  ...,  3038, 14321, 29889]], device='cuda:0')
torch.Size([2, 542, 32000]) tensor([[[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0039, -2.4922,  0.4111,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2344,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.8516, -2.1816,  0.5166,  ..., -3.0215, -3.8262, -2.6855],
         [-3.8516, -2.1816,  0.5181,  ..., -3.0215, -3.8281, -2.6855],
         [-3.8516, -2.1816,  0.5205,  ..., -3.0215, -3.8301, -2.6875]],

        [[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0469, -2.4609,  0.4248,  ..., -3.0703, -3.7910, -2.6953],
         [-4.1172, -2.6035,  0.2085,  ..., -2.9180, -3.7852, -2.7754],
         ...,
         [-3.9941, -2.3633, -0.0139,  ..., -2.9277, -3.7070, -2.6758],
         [-3.8789, -2.1855,  0.0740,  ..., -2.9043, -3.7129, -2.7168],
         [-3.9531, -2.3379,  0.3076,  ..., -3.0098, -3.7168, -2.7402]]],
       device='cuda:0')
torch.Size([2, 542, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 542, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   856, 30555,   315],
         ...,
         [30488, 31147, 30879,  ...,   856,   313, 29892],
         [30488, 31147, 30879,  ...,   856, 29892, 31488],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 32, 74.8% of total tokens
encoded shape: torch.Size([2, 1182])
torch.Size([2, 1182]) tensor([[    1,   360,  2147,  ...,     2,     2,     2],
        [    1, 29871, 29896,  ..., 17263, 19771, 29897]], device='cuda:0')
torch.Size([2, 1182, 32000]) tensor([[[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9492, -2.3496,  0.5088,  ..., -3.0469, -3.8242, -2.7188],
         [-4.0625, -2.5117,  0.2482,  ..., -3.0195, -3.7988, -2.7617],
         ...,
         [-3.3926, -1.5459, -0.4243,  ..., -2.7148, -3.5449, -2.4688],
         [-3.3906, -1.5430, -0.4246,  ..., -2.7148, -3.5449, -2.4668],
         [-3.3945, -1.5537, -0.4116,  ..., -2.7188, -3.5508, -2.4707]],

        [[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0078, -2.3809,  0.5596,  ..., -3.0293, -3.8496, -2.7051],
         [-4.0273, -2.4121,  0.2844,  ..., -2.9883, -3.8320, -2.7266],
         ...,
         [-4.0508, -2.4551,  0.2319,  ..., -2.9883, -3.8164, -2.7871],
         [-4.1445, -2.7305,  0.1597,  ..., -3.0312, -3.7305, -2.8145],
         [-4.1719, -2.6680,  0.2698,  ..., -3.1504, -3.7539, -2.8594]]],
       device='cuda:0')
torch.Size([2, 1182, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1182, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         [31147, 30488, 30879,  ...,   856, 30555, 29899],
         [31147, 30488, 30879,  ..., 29899,   349,   856]]], device='cuda:0')
Batch 33, 76.0% of total tokens
encoded shape: torch.Size([2, 486])
torch.Size([2, 486]) tensor([[    1,  1222,   397,   609,   423, 29899, 19910,  1133,  2301, 16637,
         10163,   974,   651,   491,  3528,   470,  6942,   304, 17168,   293,
         22884,  2411,  7121,  4158,  1308,  2301,  2841, 18131,  3002,   322,
           967,  1380,  2878,   898,  9315,   740, 29889,    13,  5015,   404,
           338,  6942,   411,   470,   974, 29874,  1455,  6788,  4771, 24858,
           322,   338, 18698,   408,   263,  5382,   290,   392,   747,  1070,
           766,  2098, 12045,  7329, 29889,  7133, 22884,  1319, 23704, 29892,
          6788,  1319,   266,  3781,  3361,   310,   286,  6288,  7606,  2301,
          7799,   297, 15724, 23164,  2301,  2841,  2258,  1455,  6788,   526,
         16951,  5224,  1135,   297, 11761, 29892,   541,   278,  2684,  4824,
         29875,  1189,   293, 13336, 14407,   445,  8220,  9242, 20871, 29889,
          8680, 20051,   338,   393, 17168,   293,   443, 27711,   519, 22884,
           322,   286,  6288,  7606, 10163,   974,   651,  9013,   346, 18131,
          1189,   293,   322,  1539, 19388,   293,  4158,  1308,  2301,  2841,
          3620,   297,   364,  1446, 29889,  1152,  1243,   445, 20051, 29892,
         16157,   399,   391,   279,   364,  1446,   892, 18397,   304, 17168,
           293,   443, 27711,   519, 22884,   322, 29914,   272,   429,   397,
           609,   423,   310,  2175,  6062,  1503,   322,   278,  2175,  4158,
          1308,  2301,  2841,   471,  6206,   363,  7418, 29889,   450,  4128,
         19030,  5134,  9238,   509,  7614, 12425, 29892, 19100,   333,  1230,
          3233, 29892,  1539, 19388,  1608,  6354,   322, 18131,  5996,  7418,
           297,   445,  2301,  2841, 29889,  8680,   848,  1510,   491,  9825,
          5996,  7418, 29892,   393, 22884,   322,   429,   397,   609,   423,
         21201,   263, 19262,   373, 11502,  2699,   322,   884,  2614,   839,
           640,  2470,   297,  4158,  1308, 18755,   414, 29889,   450,   286,
          6288,  7606, 10163,   974,   651, 11664, 19100,   333,  1230,  1539,
         19388,  1608,   408,  1532,   408,  9263,  1463,   337,  4925,  6606,
           310,   288, 28596,   297,  4158,  1308,  2301,  2841, 29889,   450,
          9238,   509,  7614,  5313,  3631,  7418,   310,  2301,  2841, 18755,
           414, 10018,   766, 18953,   310,   278,   269,  5666,   459,  3333,
         13076,  3240, 12906,   398,   274,   275,   725, 29879,   297,  3058,
         12786,   310,   278,  5713,   495,   297, 22884,  2318, 29892,   322,
           278,  8796, 21711,   310,   278,   269,  5666,   459,  3333, 13076,
          3240, 12906,   398,  3813, 10800,   297,  2318,   411, 15477,   310,
         22884,   322,   429,   397,   609,   423, 29889,  8680,  1284,   886,
         15544,  7208, 12903,   491,   607, 17168,   293, 22884,   322,   286,
          6288,  7606, 10163,   974,   651,  1795,   367,  9701,   297,   278,
          2224,  3021,   952, 29875,  3002,   310,  2301, 16637,   270,   952,
         12171, 29889,   341,  6288,  7606, 10163,   974,   651, 28482, 19100,
           333,  1230, 22884,   322, 20974, 19100,   333,  1230,  1539, 19388,
          1608,   373,  4158,  1308,  2301,  2841, 29892,   408,  1532,   408,
         10551,   287,   967,  5713,   495, 18131,  3002, 29889, 15336,   293,
         22884,  9132, 14263,  9639,  2779,   373,  4158,  1308, 18131,  3002,
           472,  9200,   322,  8494,   336,  2281,   332,   635, 29889,  1932,
          1716, 20436, 14549,   892,  7436, 29892,   727,   892,   472, 19783,
           293, 18755,   414,   322,   263,  4866,  1380,  2878,   898,  9315,
           589,   574,   882, 29889,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2],
        [    1,   660, 29901,    13,    13, 19407,   448,  1128,   304,  2479,
         14687,  1426,   297,   697,  1948, 29973,    13,    13, 29902, 29915,
         29885,  5214,   263, 14687,  6143,   322,   306, 29915,   345,  2355,
           385,  2228, 10018,   373,   445, 10153, 29901,    13,    13, 29902,
           864,   278,   376, 29906, 29889, 29896, 29908,  1426,   304,   367,
          8833,  2446,   304,   278,   376,  2001, 29908,  1426, 29889,  1152,
           777,   337, 29874,  1658, 29892,  1432,   716,  1734,  4947,   263,
           716,  1196, 29889,    13, 10605, 29915, 29879,   278,  3472, 29901,
            13, 29966,   352,  1178,  2433,  6654, 11041, 29871,    13,  1678,
           529,   492,  5299, 29874,  2822,  2433, 29914, 11041,  2001, 29871,
         29896,   829, 29874,  2565,   492, 29958,    13,  1678,   529,   492,
          5299, 29874,  2822,  2433, 29914, 11041,  2001, 29871, 29906,   829,
         29874, 29958,    13,  4706,   529,   352, 29958,    13,  9651,   529,
           492,  5299, 29874,  2822,  2433, 29914, 11041,  2001, 29871, 29906,
         29889, 29896,   829, 29874,  2565,   492, 29958,    13,  4706,  1533,
           352, 29958,    13,  1678,  1533,   492, 29958,    13,  1678,   529,
           492,  5299, 29874,  2822,  2433, 29914, 11041,  2001, 29871, 29941,
           829, 29874,  2565,   492, 29958,    13,  1678,   529,   492,  5299,
         29874,  2822,  2433, 29914, 11041,  2001, 29871, 29946,   829, 29874,
          2565,   492, 29958,    13,  1678,   529,   492,  5299, 29874,  2822,
          2433, 29914, 11041,  2001, 29871, 29945,   829, 29874,  2565,   492,
         29958,    13,   829,   352, 29958,    13,    13,  2855,  1244, 29915,
         29879,   278,  6783, 29901,    13, 29937,  6654,   426,    13,  1678,
          1051, 29899,  3293, 29901,  5642, 29936,    13, 29913,    13, 29937,
          6654,   619,   426,    13,  1678,  5785, 29901,  2175, 29936,    13,
          1678,  2602, 29901,  6198, 29936,    13, 29913,    13, 29937,  6654,
           619,   263,   426,    13,  1678,  2479, 29901,  2908, 29936,    13,
          1678,  1426, 29899, 19557,   362, 29901,  5642, 29936,    13,  1678,
          1426, 29899,  2520, 29901,  4818, 29936,    13,  1678,  3239, 29901,
           396, 26854, 29936,    13,  1678,  5906, 29899,  1266, 29901, 29871,
         29945,  1756, 29936,    13, 29913,    13, 29937,  6654,   619,  9238,
           426,    13,  1678,  2602, 29901,  8380, 29936,    13, 29913,    13,
         29937,  6654,   619,  9238,   619,   426,    13,  1678,  2479, 29901,
          2908, 29936,    13, 29913,    13, 29937,  6654,   619,  9238,   619,
           263,   426,    13,  1678,  7164, 29901, 29871, 29900,  1756, 29871,
         29896, 29900,  1756, 29936,    13,  1678,  3171, 29901, 29871, 29906,
         29900,  1756, 29936,  1678,    13,  1678,  1426, 29899,  2520, 29901,
          2175, 29936,    13,  1678,  3239, 29901,   396, 29929, 29929, 29929,
         29936,    13, 29913,    13,    13, 16894,   363,   738,  1371, 29892,
         12828, 29889,    13,    13, 29909, 29901,    13,    13,  2744,  4780,
           982,   304,  2329,   445,   338,  4417,   263,  1286,  2390,  2875,
           304,   396,  6654,   619,  9238,   619,   263, 29901,    13, 29937,
          6654,   619,  9238,   619,   263,   426,    13,  1678,  7164, 29901,
         29871, 29900,  1756, 29871, 29896, 29900,  1756, 29936,    13,  1678,
          3171, 29901, 29871, 29906, 29900,  1756, 29936,  1678,    13,  1678,
          1426, 29899,  2520, 29901,  2175, 29936,    13,  1678,  3239, 29901,
           396, 29929, 29929, 29929, 29936,    13,  1678,  4796, 29899,  3493,
         29901,  1286,  2390, 29936, 29871,  4949,  1152, 29890,  4841,  1426,
         28489,  3776,    13, 29913,    13,    13]], device='cuda:0')
torch.Size([2, 486, 32000]) tensor([[[-2.7793, -0.5444, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-3.9473, -2.4004,  0.4521,  ..., -3.0527, -3.8418, -2.7363],
         [-4.0898, -2.5859,  0.2522,  ..., -3.0312, -3.8262, -2.8105],
         ...,
         [-3.8438, -2.1074,  0.5103,  ..., -3.0078, -3.8066, -2.6504],
         [-3.8516, -2.1172,  0.5063,  ..., -3.0098, -3.8086, -2.6523],
         [-3.8496, -2.1152,  0.5020,  ..., -3.0078, -3.8047, -2.6504]],

        [[-2.7793, -0.5444, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-4.0039, -2.4922,  0.4116,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2324,  0.2603,  ..., -2.9766, -3.7422, -2.6484],
         ...,
         [-3.8867, -2.2734,  0.5239,  ..., -3.0723, -3.8438, -2.7422],
         [-3.8184, -2.1855,  0.6187,  ..., -3.0566, -3.8613, -2.7188],
         [-3.8320, -2.2305,  0.5220,  ..., -3.0312, -3.8359, -2.7051]]],
       device='cuda:0')
torch.Size([2, 486, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 486, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         ...,
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856,   313, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186]]], device='cuda:0')
Batch 34, 76.9% of total tokens
encoded shape: torch.Size([2, 811])
torch.Size([2, 811]) tensor([[    1,  4956, 17925,  ...,     2,     2,     2],
        [    1, 15991, 15194,  ..., 29947, 29896, 29906]], device='cuda:0')
torch.Size([2, 811, 32000]) tensor([[[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.9766, -2.4727,  0.4097,  ..., -3.0625, -3.8457, -2.7227],
         [-4.0312, -2.4238,  0.1602,  ..., -3.0352, -3.7637, -2.7383],
         ...,
         [-3.6465, -1.8857,  0.2118,  ..., -2.8965, -3.7090, -2.5762],
         [-3.6504, -1.8936,  0.2179,  ..., -2.8965, -3.7129, -2.5781],
         [-3.6641, -1.9102,  0.2202,  ..., -2.9082, -3.7227, -2.5879]],

        [[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.9355, -2.4238,  0.3730,  ..., -3.0391, -3.8223, -2.7324],
         [-4.0391, -2.4785,  0.4158,  ..., -3.0508, -3.8301, -2.7754],
         ...,
         [-4.0234, -2.5645,  0.4067,  ..., -3.1094, -3.8789, -2.7812],
         [-3.9941, -2.4551,  0.4387,  ..., -3.0352, -3.8438, -2.7559],
         [-3.9590, -2.3496,  0.3091,  ..., -3.0117, -3.7871, -2.7324]]],
       device='cuda:0')
torch.Size([2, 811, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 811, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29889, 30331,   313],
         [30488, 31147, 30879,  ..., 29889, 30331,   313],
         [30488, 31147, 30879,  ..., 29889,   313, 30331]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]]], device='cuda:0')
Batch 35, 77.9% of total tokens
encoded shape: torch.Size([2, 420])
torch.Size([2, 420]) tensor([[    1,  2266,   526,   278,  2582,   310,   278,  1708, 22450,   577,
          2215, 29889,    13,    13, 28575, 10769,   505,   263,  8825,   363,
          4482, 29901,  3872,  1056, 29892,  2261,  2546,   322, 20939,   265,
         29889, 29871, 26647,    13, 25719,   505,   263,  8825,   304,   679,
           297,   278,  6909,   363,  1880, 29901, 16080, 29894,  1111, 29892,
         10015, 29892,   315,   653, 29892, 17841, 29892,    13, 29928,   653,
         29880, 29892,  1588,   296,   625,   322,   278,  1876,   728, 29889,
         29871,   450,  1833,   310,   278, 12747, 29892,  5174,   363,   278,
            13, 13454, 22450, 29892,   505,  1063,  2665,   714, 29889, 29871,
           306,  2149,   304,   679,  5839, 29879,   363,   278,  5670, 27207,
           515,    13,   271,  3203,  3006, 10769, 29889, 29871,  3529,  1016,
         29915, 29873,  9566,   304,  3896,   596, 12678,   373,  3001,    13,
         13628, 29892,   297,  1206,   310,   263, 22134, 29889,    13,    13,
            13,    13,   448, 29871, 29906, 29900, 29900, 29900, 13454,  2696,
          4421,  2361,  1451,  1160, 29889, 20267,    13,   448, 23868,  2296,
           300,   448,  1708,  2696, 29906, 29900, 29900, 29900,  5670, 27207,
         29889, 20267,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,   450,   995,   310,  7498, 14174,   457,   541,  2904, 29890,
           456,   680,   297,   633,  3129,   979, 29751,  6382,   292,   411,
           322,  1728,   470,   284, 15611, 17105, 29889,    13,  1576,  6437,
           310,   445,  4274,   471,   304, 24809,   278, 10879,   310,   938,
           336,   854,   681,   313,  5667, 29897,  3677,   436,   324,  4983,
         29887,   293,  7498, 14174,   457,   541,  2904, 29890,   456,   680,
           297,   633,  3129,   979, 15611, 27396,   749,   313, 21055, 29897,
          6382,   292,   411,   470,   284, 15611, 17105,   313, 29949,  3580,
         29897,   518,  2882, 29928,  3267, 29899, 29907,  2190, 29892,  7756,
          2021,  1600,   313,  3308,  2190,   511, 16693,   510,   287,  1954,
          6751,  3339, 29892,  6657,   417, 29892, 27440,  1822,   512, 29871,
         29941, 29896, 22069,   411,   633,  3129,   979, 21622,   943, 29892,
           323, 29896, 29899,  7915,   287, 10917, 29899,  8057,   313,  1660,
         29897,  4558,   313,  1660, 29871, 29953, 29900, 29900, 29914, 29871,
         29896, 29945, 29936, 29871, 29896, 29889, 29945,   323, 29897,   892,
          7625,  1728,   322,   411,  6599,  7498, 14174,   457,   541,  2904,
         29890,   456,   680,   313, 29906, 29900,   286, 29887, 29897,  1434,
           322,  1156, 17517,   310, 29871, 29947, 29900, 29900,   286, 29880,
           310,   438,  3580, 29889,  7803, 16842,   287, 22176,  1223, 11517,
         10884, 24238, 29879, 29892, 12580,   295, 29899, 11358,  7604,  2133,
         29892,   322,   966,   291,   628,   457,   362,   373,   278,  3023,
          6166,   310,   323, 29896, 29899,  7915,   287,  4558, 29889,   450,
          1023, 29899,   941,  2356,  4624,  1111, 29916,   265,  3300,  2859,
          4559,  1243,   471,  1304,   363, 24148,  7418,   313, 29886,   529,
           869, 29900, 29945,   467,  9665, 14174,   457,   541,  2904, 29890,
           456,   680, 12212, 10884, 24238, 29879,   322, 16710, 12580,   295,
         29899, 11358,  7604,  2133,   373,   758,  9996,   579,   322,   438,
          3580, 29899,   264, 29308,  4558,   472,   263, 12997,  1711,  7282,
          3233,   313, 29886,   353, 29871, 29900, 29889, 29900, 29900, 29900,
         29953, 29899, 29900, 29889, 29900, 29941, 29955,   467,   450, 19604,
          7426,   310, 24238, 29879,   471, 10478,   373,   438,  3580,  4558,
           411,  7498, 14174,   457,   541,  2904, 29890,   456,   680, 29889,
           438,  3580,   411,  7498, 14174,   457,   541,  2904, 29890,   456,
           680, 16951, 16710,   966,   291,   628,   457,   362,  9401,   304,
         11898,  1728,  9418,   546,   391,  1997,   293, 15721,  1434,   313,
         29886,   353, 29871, 29900, 29889, 29900, 29896, 29929, 29897,   322,
          1156,   438,  3580, 17517,   313, 29886,   353, 29871, 29900, 29889,
         29900, 29896,   467,   450, 15717, 17668,   393,   278,   671,   310,
          6599,  7498, 14174,   457,   541,  2904, 29890,   456,   680,   338,
         13622,   363,   438,  3580, 29899,   264, 29308,   633,  3129,   979,
         29751,  6382,   292,   411,   323, 29896, 29899,  7915,   287,  3725,
          9505,   344, 15602,   472, 29871, 29896, 29889, 29945,   323, 29889]],
       device='cuda:0')
torch.Size([2, 420, 32000]) tensor([[[-2.7793, -0.5454, -2.4844,  ..., -2.0996, -2.9980, -2.1191],
         [-3.9648, -2.2754,  0.2549,  ..., -3.0801, -3.8262, -2.7266],
         [-4.1250, -2.5215,  0.3147,  ..., -2.9824, -3.8066, -2.7754],
         ...,
         [-3.9766, -2.1816,  0.3555,  ..., -3.0254, -3.8438, -2.6895],
         [-3.9785, -2.1836,  0.3547,  ..., -3.0254, -3.8438, -2.6914],
         [-3.9805, -2.1875,  0.3542,  ..., -3.0273, -3.8457, -2.6914]],

        [[-2.7793, -0.5454, -2.4844,  ..., -2.0996, -2.9980, -2.1191],
         [-4.0039, -2.2891,  0.4741,  ..., -3.0449, -3.7754, -2.7285],
         [-4.1172, -2.5605,  0.2832,  ..., -3.0312, -3.8086, -2.7480],
         ...,
         [-4.0273, -2.4453, -0.1108,  ..., -2.9453, -3.7422, -2.7266],
         [-3.8789, -2.2500,  0.1401,  ..., -2.8926, -3.7734, -2.6816],
         [-3.8945, -2.2969,  0.4036,  ..., -2.9629, -3.8047, -2.7070]]],
       device='cuda:0')
torch.Size([2, 420, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [31147],
         [30488],
         [31147],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 420, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856,   313, 30186],
         [30488, 31147, 30879,  ...,   856, 29871,   349],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 30186],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 36, 78.4% of total tokens
encoded shape: torch.Size([2, 919])
torch.Size([2, 919]) tensor([[    1,  9969,  3958,  ...,     2,     2,     2],
        [    1,   960,   445,  ...,   366,  2678, 29889]], device='cuda:0')
torch.Size([2, 919, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9375, -2.4062,  0.3833,  ..., -3.0254, -3.8203, -2.7617],
         [-3.9980, -2.4453,  0.2686,  ..., -3.0469, -3.8242, -2.7344],
         ...,
         [-3.8555, -2.0898,  0.3838,  ..., -2.9863, -3.7930, -2.6562],
         [-3.8574, -2.0898,  0.3838,  ..., -2.9883, -3.7930, -2.6562],
         [-3.8574, -2.0898,  0.3843,  ..., -2.9883, -3.7930, -2.6562]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0234, -2.4160,  0.4211,  ..., -3.0312, -3.7871, -2.7188],
         [-3.9492, -2.4395,  0.3372,  ..., -3.0293, -3.7598, -2.7539],
         ...,
         [-3.9551, -2.2910, -0.1375,  ..., -2.9609, -3.6523, -2.7109],
         [-4.0078, -2.3145,  0.0200,  ..., -3.0215, -3.7969, -2.8125],
         [-3.8008, -2.2227,  0.2979,  ..., -3.0391, -3.6875, -2.7480]]],
       device='cuda:0')
torch.Size([2, 919, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 919, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]]], device='cuda:0')
Batch 37, 79.6% of total tokens
encoded shape: torch.Size([2, 2631])
torch.Size([2, 2631]) tensor([[    1,   349,  7466,  ...,   433,  4193, 29889],
        [    1,  9267,  4696,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2631, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9043, -2.3066,  0.5059,  ..., -3.0156, -3.7422, -2.6953],
         [-3.9766, -2.4707,  0.1687,  ..., -2.9375, -3.7871, -2.6875],
         ...,
         [-4.1016, -2.4844, -0.0244,  ..., -3.0371, -3.7656, -2.7305],
         [-3.9043, -2.3066,  0.1658,  ..., -2.9414, -3.6914, -2.7461],
         [-3.9570, -2.4199,  0.3633,  ..., -3.0098, -3.7266, -2.7266]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0273, -2.4199,  0.4087,  ..., -3.1074, -3.7852, -2.7383],
         [-4.0547, -2.5117,  0.2886,  ..., -3.0293, -3.8184, -2.7949],
         ...,
         [-3.4746, -1.6768, -0.1758,  ..., -2.7793, -3.6035, -2.5117],
         [-3.4746, -1.6777, -0.1732,  ..., -2.7793, -3.6035, -2.5117],
         [-3.4766, -1.6787, -0.1752,  ..., -2.7793, -3.6035, -2.5117]]],
       device='cuda:0')
torch.Size([2, 2631, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 2631, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30555,   349],
         [30488, 31147, 30879,  ...,   313,   856, 29892],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 29899, 30555],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]]], device='cuda:0')
Batch 38, 82.6% of total tokens
encoded shape: torch.Size([2, 290])
torch.Size([2, 290]) tensor([[    1,   660, 29901,    13,    13,  2843, 13414,  6431,    13,    13,
         29911,   397,   388,   474,  1539,   411,   278, 10676,  1108, 29889,
         12823,   474,   505, 29871, 29945, 14188,   297,   590,  6354,  2318,
         29889,    13,  3166, 29871, 29896,   303,  6354,   474,   748,   304,
         29871, 29906,   299,   322,   515, 29871, 29906,   299,   474,   748,
           304, 29871, 29941,  5499,   322,   577,   373,  3045,    13,   392,
           373,   278, 29871, 29945,   386,  4315,   746,   474,  3965,  1250,
          1820,   474,  2996,   304, 29871, 29946,   386,   322,   577,   373,
          3045,    13, 10401,   474,  1449,   748,   304,   278,  1021,  1889,
           372, 14423,   592,   278,  3517,  8833,   848,   408,  1532,   373,
           278,  4315, 29889,   286,   451,  2221,   304,  1284,   278, 10297,
           918,   363,   278,  1021, 29889,    13, 29875,   817,   393,  1432,
           931,   474,  1101,   278,  1889,   372,   674,  1510,   592,   278,
           716,   848,   451,   411,   278,  3517,   697,   848, 29889,    13,
           572, 29879,  1371,   592, 29889,    13, 29875,  5107, 11417,   278,
          3353,   775, 29889,   967, 29871, 29945, 14188, 29889,    13,    13,
         29909, 29901,    13,    13, 29902,  1016, 29915, 29873,  1348,   366,
          2099,   376, 10072,  2318,  1699,   607,   338,  1554,  1683,  9186,
         29889,   306,  5251,   366, 29915,   276,  9963,  1048,   278,  3414,
          5096, 29889,  1724,   366,  3117,   864,   304,   437,   338,  5712,
           278,   373, 15078,   442,  1158,   373,   596,  6354, 29892,  4444,
           372,   304,  1246,  6514,  1158,   372,   338,   393,   366,   671,
           304, 11086,   596,  1776, 29915, 29879, 14407,   848, 29889,   887,
          1122,   864,   304,   437,   393,   297,  9589,   651,   411,   263,
          4509,  2286,   376,  3972,  1017, 29908,  7223,  7353,   366,   731,
           373,   596,  6354,  1434,   366,  1369,  1790,   697,   577,   393,
           372,   871, 23660,   565,   366, 29915,   276,  6421,  1250,   515,
          1790,  6354,   313,   392,   451,   746,   278,  1404,  4607,   267,
           304,  1790,   623,   322,  1250,   304, 15850,   467,    13,    13],
        [    1,   660, 29901,    13,    13, 11288, 16199,  2472,  4312,   297,
          4113,    13,    13, 29902,   505,   925,  2309,   263,  2566, 16199,
           297,  4113,   541,   306,  1286,   864,   304,   437,   263, 12219,
         16199, 29889,  1815,   366,  2649,   592,   988,   437,   306,  1284,
           445,   297,  4113, 29973,   308,    13,  1762,  1250,   701, 29892,
          1284,  3989,  3421, 12754,   297,   278, 23376,  2761,  9451,   322,
          6755,  1346, 15843, 30024,   515,   278,  6143,  2594, 29889,   512,
          1784,  4251,   366,   508, 12070,   411,   278,  1346,  2182,   860,
         30024,  2984, 29892,   541, 29892,   565,   366,   505,   901,  1135,
           697,  2566,   297,   278,  1021,  9254,  2601, 29892,   363,  1342,
         29892,  6755,   278,  1346,  7281, 30024,  2984,   322,  1284,   278,
          8018,  2566,   297,   278,  5768, 29899,  3204,  1051, 29889, 25870,
           366,  1073,   825,   366, 30010,   276,  2599, 29892,  5967,   278,
           916,  3987,  7432, 29889, 28797,   304,   278,  5970,   310,   278,
          1813, 29892,   322,  2828,  1346,  8120,  8643,   319, 16766,   310,
           278,  2566,   674,   367, 16532,   322,   366,   508,  3787,   372,
           411,   278,  2066,   366, 16532,  8859,   470,  9051,  1683,   259,
            13,    13, 29909, 29901,    13,    13, 29954,  5288, 20657,  5952,
           765,  5577, 29892,  6293,   508,   437,  2566, 16199,   515,  4113,
          2355, 29877,  4113, 29958,  3924, 29958, 12229, 29958,  5841,   786,
         29958,  1244,   366,   817,  1831, 16199,  1134,   594,   322,  2828,
           373, 29871,  5470,  7437,   786,  2826,   373,   372,  1653,   263,
          2566, 16766, 29889,    13,    13,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 290, 32000]) tensor([[[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-4.0039, -2.4922,  0.4111,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2324,  0.2612,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.7812, -2.2207,  0.3757,  ..., -3.0176, -3.6973, -2.7891],
         [-3.8359, -2.2227,  0.6309,  ..., -3.0918, -3.8379, -2.7266],
         [-3.7891, -2.2207,  0.5400,  ..., -3.0684, -3.7793, -2.7090]],

        [[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-4.0039, -2.4922,  0.4111,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2324,  0.2612,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.8359, -2.1523,  0.5015,  ..., -3.0156, -3.7930, -2.6582],
         [-3.8359, -2.1543,  0.4937,  ..., -3.0137, -3.7930, -2.6582],
         [-3.8359, -2.1562,  0.4927,  ..., -3.0137, -3.7930, -2.6582]]],
       device='cuda:0')
torch.Size([2, 290, 1]) tensor([[[30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 290, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 29892],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30186,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856]]], device='cuda:0')
Batch 39, 83.1% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   450,  2198,  ...,  1316,   408,   385],
        [    1, 27477,  3712,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9980, -2.2812,  0.4731,  ..., -3.0430, -3.7715, -2.7246],
         [-3.9258, -2.3027,  0.3018,  ..., -2.9434, -3.7695, -2.6777],
         ...,
         [-3.9297, -2.3457,  0.3506,  ..., -3.0391, -3.7969, -2.7500],
         [-3.8320, -2.2070,  0.3464,  ..., -2.9824, -3.7715, -2.6602],
         [-3.8652, -2.2285,  0.3425,  ..., -2.9434, -3.8125, -2.6758]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0352, -2.4766,  0.3735,  ..., -2.9883, -3.8828, -2.7383],
         [-4.0547, -2.5176,  0.3281,  ..., -2.9902, -3.8750, -2.7812],
         ...,
         [-3.0996, -1.0557, -1.3223,  ..., -2.4375, -3.3125, -2.3105],
         [-3.0938, -1.0479, -1.3281,  ..., -2.4316, -3.3066, -2.3047],
         [-3.1035, -1.0635, -1.3223,  ..., -2.4395, -3.3164, -2.3125]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 29892,   856,   313]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154]]], device='cuda:0')
Batch 40, 87.4% of total tokens
encoded shape: torch.Size([2, 895])
torch.Size([2, 895]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,  8448,   310,  ...,  7256,  5962, 29889]], device='cuda:0')
torch.Size([2, 895, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7324],
         [-3.8770, -2.2344,  0.2607,  ..., -2.9766, -3.7422, -2.6484],
         ...,
         [-3.8398, -2.0918,  0.3853,  ..., -2.9922, -3.8047, -2.6523],
         [-3.8340, -2.0840,  0.3838,  ..., -2.9883, -3.8008, -2.6484],
         [-3.8340, -2.0840,  0.3838,  ..., -2.9883, -3.8008, -2.6484]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9805, -2.3984,  0.3628,  ..., -3.0352, -3.7715, -2.7539],
         [-4.0156, -2.3789,  0.1831,  ..., -2.9727, -3.7695, -2.7500],
         ...,
         [-3.8633, -2.2812,  0.0864,  ..., -2.9023, -3.7090, -2.6641],
         [-4.0078, -2.4766,  0.0925,  ..., -2.9453, -3.7324, -2.7246],
         [-3.8887, -2.2520,  0.4285,  ..., -3.0098, -3.8008, -2.7559]]],
       device='cuda:0')
torch.Size([2, 895, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 895, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         ...,
         [30488, 31147, 30879,  ...,   856, 31488,   313],
         [30488, 31147, 30879,  ..., 29892, 30186,   313],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 41, 88.5% of total tokens
encoded shape: torch.Size([2, 1847])
torch.Size([2, 1847]) tensor([[    1,   501,   307,  ...,     2,     2,     2],
        [    1,   306,  4997,  ...,  2436,   297, 29889]], device='cuda:0')
torch.Size([2, 1847, 32000]) tensor([[[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-4.0156, -2.5176,  0.4565,  ..., -3.0566, -3.8730, -2.7715],
         [-4.0234, -2.5781,  0.3318,  ..., -3.0527, -3.8789, -2.7324],
         ...,
         [-3.9082, -2.2227,  0.4941,  ..., -3.0352, -3.8359, -2.7109],
         [-3.9023, -2.2148,  0.4922,  ..., -3.0312, -3.8340, -2.7090],
         [-3.9023, -2.2168,  0.4927,  ..., -3.0332, -3.8340, -2.7090]],

        [[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-3.9180, -2.3906,  0.4031,  ..., -3.0293, -3.8105, -2.7109],
         [-4.0078, -2.4004,  0.2871,  ..., -3.0879, -3.7812, -2.7441],
         ...,
         [-4.0156, -2.2480, -0.0689,  ..., -3.0078, -3.7988, -2.7148],
         [-4.0195, -2.2617, -0.1508,  ..., -2.9531, -3.7031, -2.7734],
         [-3.8887, -2.1934,  0.3635,  ..., -2.9941, -3.6738, -2.7617]]],
       device='cuda:0')
torch.Size([2, 1847, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1847, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856,   313, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 42, 91.7% of total tokens
encoded shape: torch.Size([2, 1109])
torch.Size([2, 1109]) tensor([[    1,   660, 29901,  ...,  1504,    13,    13],
        [    1, 21141,  1705,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1109, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0039, -2.4941,  0.4116,  ..., -3.0566, -3.8906, -2.7344],
         [-3.8770, -2.2344,  0.2610,  ..., -2.9766, -3.7422, -2.6504],
         ...,
         [-3.9297, -2.3066,  0.1912,  ..., -3.0020, -3.6895, -2.8086],
         [-3.9180, -2.3242,  0.5137,  ..., -3.0840, -3.8301, -2.7598],
         [-3.9199, -2.3477,  0.4199,  ..., -3.0586, -3.8066, -2.7246]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0391, -2.4902,  0.3347,  ..., -3.0508, -3.8555, -2.7383],
         [-4.0117, -2.4902,  0.1948,  ..., -2.9922, -3.7891, -2.7285],
         ...,
         [-3.8223, -2.0801,  0.3186,  ..., -2.9668, -3.7715, -2.6543],
         [-3.8203, -2.0781,  0.3188,  ..., -2.9648, -3.7695, -2.6523],
         [-3.8242, -2.0801,  0.3193,  ..., -2.9648, -3.7695, -2.6523]]],
       device='cuda:0')
torch.Size([2, 1109, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1109, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]]], device='cuda:0')
Batch 43, 93.0% of total tokens
encoded shape: torch.Size([2, 459])
torch.Size([2, 459]) tensor([[    1,   518, 29909,   716,  1158,   310,  7540,  3864, 29871, 29945,
         28560, 29885,   621,  2904,   386,   601,  4858,   359,   457,   411,
          1880, 12959, 23904, 25173,   271,  5275,  1822,    13, 29909, 10952,
         29892, 20502,   322,  2702,  1880,  4180, 23904, 25173,   271, 12122,
          1158,   363,   278, 23248,   310, 29871, 29945, 28560, 29885,   621,
          2904,   386,   601,  4858,   359,   457,   297,  4768,  5996, 11916,
           756,  1063,  8906, 29889,   319,  3765, 29899, 10568, 25173,   271,
         12122,   373, 26028,   735, 29899, 29945, 29900, 29892,   379, 29974,
           883, 29892,   322, 13737, 29875, 29899, 29954,   295, 29871, 29953,
         29900, 29896,   892,  3734,  1434,   278, 25173,   271, 12122, 23683,
           310,  4559,   373,  3455,   275,   309, 29871, 29896, 29900, 12314,
         29990, 29889,   450,  7709,   338,  4323, 23378,   322,   278,  8792,
           338,  2560,   322, 10712,  9483, 15520, 29889,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,   321,  2909, 24810,   830,  3075,  4080,  4700, 29936, 29871,
         29906, 29900, 29896, 29947, 24544, 13730, 13542, 29889,  3575,   364,
          5525,  1235,   263,  9076,   393,   445,  3236,  1033,   302, 29915,
         29873,   437, 29889,  9249,  6431,  7415,   697,   310,  1570, 13450,
         29915, 29879, 10150,  4559,  7458,  8437,   339,  6926, 29889,  1334,
          4368,   925,   373, 17924,   448, 24165, 29892, 10608, 29899, 28990,
         29892,  6397,  2722,   322, 10961, 29889,    13,    13, 29902,   471,
           590, 29871, 29941, 29928,   515,   777,   321,  2909,  8825,   322,
           777,  3031, 28910, 29889,   306,   671,   263,  2106,   310,  9208,
          4095,  1860, 29892,   988,   366, 11097,   777, 25091,   322,   671,
          1090,  4888,   287,  5786,   304,  3529,   263,  1914, 11029, 29889,
          8236,   445,  1856,  6207,  1317,   592,   304,  2058,   901,   669,
          4141,   322,  8955,  1608,   373,   278, 25078,   393,  1795,  2041,
           901, 15390,  1106, 29889, 14332,  1152,  2315,  9765,  3864,   511,
           541,   565,   596,  1813,  2794,   916,  3387,   366,  1795, 20355,
           915,   916,   304, 10049, 15589, 11358,  2793,   297,   263,  3353,
          6731,  5275, 29889,    13,    13, 29943,   523,   278,  4575,  1253,
           573,  2994,  1184,    13,    13, 10401,   306,   505,   278,  6471,
           373,   278,   321,  2909, 24810,   310,   269,   899,   267, 29892,
           306,   505,   590,  4828,   393,  3237, 29889,  2155,   295,  1171,
         29892,   769,   515, 29093, 23586, 29892,   471,   263, 15703,  1434,
          4567,   670, 12089,  7134, 29889,  2860,   393,   540,  2665,   363,
         29589,   297,  1570,  3088,   408,   263, 12060,  5381, 29892,   322,
          8221, 18757, 11322, 15276,  1144,   763, 13484, 11001,  4885, 29892,
          3012,   347, 28548,   322, 19235,   478,  2987,  5403,   408,   263,
          3785,   363,  6125,  4154,  7983, 29889, 10949,  4417,   670,   697,
         29899,  6360,   760,   275,   550,  4034, 29892,  2155,   295,  1171,
          6206,   408,   278, 12089, 19649,   363,   323,  5271, 29892,   385,
          6920,   616,  6124,  5703,   261,  2867, 29889, 29871, 29955, 29906,
           297,  1760,  3145,   408,   931,   310,   385,   364,  8584, 18296,
         29889,    13,    13, 28862,  2763,   304, 10803, 10923, 29889,   910,
           338,   596,   937,  1400, 29889,  7641,   470,  5217,   372, 29892,
          1797,   321,  2909, 24810,   830,  3075,  4080,  4889, 29936, 29871,
         29906, 29900, 29896, 29947,  8973, 29889,   887,   526,  2337,  2304,
          1136,  8841,   304,  1284,   445,  6297, 29889,   450, 13552,   338,
         22039,  3160,   304,   367, 29991,   884, 29892, 21639, 11084,  5181,
         29889,   769,  1369,  5007, 29991,    13,    13, 29902,   505, 12520,
           590,  5764,   321,  2909, 24810,   830,  3075,  4080,   577, 19405,
           508,  6872,   590, 14662, 15472, 29889,   960,   366,   526,   304,
          5988, 29892,  4876,   363,  4452,   393,   505,  1784, 29889,  3118,
           393,  5244,   845,  3554,   723, 28042,  3144,   434,   472, 29889,
          3577,  1476,   443,   510,  3921,   519, 15399,   445, 10483, 21083,
           304,  7875, 29889,  2041, 28265,   304,   530, 29883,   342,   719,
          1048,   321,  2909, 29889,   360,  3973, 29892,  8681, 12232, 29936,
           278,  8286, 26475,   573,   282, 16239,  7155, 29889,  2688,  2099,
           302, 29915, 29873,  1063,   304,   278, 10261, 25078, 29889]],
       device='cuda:0')
torch.Size([2, 459, 32000]) tensor([[[-2.7793, -0.5449, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-3.9746, -2.4434,  0.4131,  ..., -3.0215, -3.8398, -2.6992],
         [-4.0273, -2.5410,  0.2252,  ..., -3.0098, -3.7949, -2.7617],
         ...,
         [-3.8828, -2.0723,  0.4207,  ..., -3.0000, -3.7949, -2.6660],
         [-3.8867, -2.0742,  0.4209,  ..., -3.0020, -3.7949, -2.6680],
         [-3.8906, -2.0859,  0.4209,  ..., -3.0039, -3.7988, -2.6738]],

        [[-2.7793, -0.5449, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-3.9551, -2.4531,  0.3953,  ..., -2.9961, -3.8711, -2.7344],
         [-3.9473, -2.3809,  0.2114,  ..., -2.9746, -3.7754, -2.7559],
         ...,
         [-3.9727, -2.3730,  0.2708,  ..., -2.9922, -3.7422, -2.7617],
         [-3.9141, -2.2637,  0.2798,  ..., -2.9844, -3.7324, -2.7480],
         [-3.9277, -2.2852,  0.2825,  ..., -2.9863, -3.6953, -2.7168]]],
       device='cuda:0')
torch.Size([2, 459, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 459, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ...,   313, 30555,   856]]], device='cuda:0')
Batch 44, 93.6% of total tokens
encoded shape: torch.Size([2, 222])
torch.Size([2, 222]) tensor([[    1, 22415,   344,   278,   402,  6758,   653,    13,    13,  2385,
          1944,  4799,   637,    13,    13,  2744,  4799,   637, 23199,   630,
           304,  9080, 21467,  6931,   310,  2319,  4799,  1559,  4336, 15780,
           322,   278,   443,   816, 14989, 28507,  6931,   310,  2919,  4799,
          1559,  4336, 15780, 29889,   319,  4134,  1944,  4799,   637,  2609,
          9080, 21467,  2919,  4799,  1559,  4336, 15780,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,  3645,   278,  4098,   368,  3190,  3145, 29901,  3111, 29871,
         29896, 29929, 29929, 29947,    13,    13, 15860, 29889,   390,  1164,
           390,  5607,  9606,  3235,  1001, 29892,   288,  2460,    13,    13,
         12984,  2829, 10465,   446,  2748,  1302,  1312,   263,  3652,   310,
           282,   389, 29891,   263,   561,   272, 12903,   373, 13521,   322,
          1424, 11036, 29889, 17302,   963, 29892,   591,  1284, 29901,   376,
          1349,   852,  1058,  1791,  6038, 13521,   437,   577,  1363,  1009,
         29879,   338,  8062,  3307,   304,   367,  1791, 22042,   785,   322,
           297,  1641,  1791, 22042,   372,   947,   491, 14496,  4953,  1209,
           573,  2745,   472,  1833,   372,   338,  3078,   541,   278, 15504,
           310,   263, 13521, 29889,   869,   869,   869,  1105,   265,   261,
         13406,   385, 28056,   297,   967,  2181,   328,   280,  1135,  5595,
           344,   443,   627,   287,   553,  2658,  1213,    13,    13, 15860,
         29889,   390,  1164,   390,  5607,  9606,  3235,  1001, 29892,   288,
          2460,    13,    13, 29909, 19797,   338,   871,   263, 19797,   565,
          2183,  8951, 29889,  7634,  9337,  5149, 29892,   445,   338,   451,
           263,   378,   870,  5848,   541,   263,  1820,   304,  1371,   502,
           714,   310,   385,   297,  1859,   403,  1410,  2782,   393,  2756,
           506,  1372,   502,   599, 29889, 22804,  1269,   310,   502,   727,
           526,  1410,  2782, 21737, 29889,  3834,   310,  1438,   505,   263,
          2821,  3876,  2629,  1749, 12080,   322,   526,  6788,  1319,  1083,
           513,   414,   310,  2712,   591,   505,  2309,   470,  2175,   563,
           650, 29889]], device='cuda:0')
torch.Size([2, 222, 32000]) tensor([[[-2.7793, -0.5439, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-4.0117, -2.4336,  0.2747,  ..., -2.9609, -3.8086, -2.7734],
         [-3.8848, -2.3184,  0.1156,  ..., -2.9395, -3.7695, -2.7051],
         ...,
         [-3.9434, -2.1543,  0.4333,  ..., -3.0156, -3.8320, -2.6836],
         [-3.9414, -2.1543,  0.4329,  ..., -3.0156, -3.8301, -2.6836],
         [-3.9473, -2.1602,  0.4333,  ..., -3.0195, -3.8359, -2.6855]],

        [[-2.7793, -0.5439, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-4.0195, -2.3984,  0.3816,  ..., -3.0430, -3.7949, -2.7148],
         [-4.1172, -2.5098,  0.2698,  ..., -3.0156, -3.8086, -2.7676],
         ...,
         [-3.8887, -2.2715, -0.0373,  ..., -2.9199, -3.7578, -2.6465],
         [-3.8555, -2.2129,  0.0625,  ..., -2.9512, -3.7051, -2.6562],
         [-3.7793, -2.1562,  0.2742,  ..., -2.9551, -3.6367, -2.6777]]],
       device='cuda:0')
torch.Size([2, 222, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 222, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856,   313],
         ...,
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 29871],
         [30488, 31147, 30879,  ...,   856, 29871,   349],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]]], device='cuda:0')
Batch 45, 93.9% of total tokens
encoded shape: torch.Size([2, 263])
torch.Size([2, 263]) tensor([[    1,  1174,  3024, 15202,  9034,  1103, 29871, 29896, 29906, 29945,
         29898, 29941,  1125, 29941, 29947, 29945,   489, 29941, 29929, 29896,
           313, 29906, 29900, 29896, 29955,   511,  1732,   597,  8235, 29889,
          1867, 29875, 29889,   990, 29914, 29896, 29900, 29889, 29896, 29906,
         29947, 29929, 29914, 29923,  3954, 29896, 29955, 29941,    13,    13,
           797,   278,  1051,   310, 15717, 29892,   278,   321, 18919,  4148,
         29915, 29879,  1833,  1024,   471,  3052, 13111,   839,   408,   376,
         13296, 18192,  1213,   450,  1959,   805,  7807,   338, 10629,   819,
          4956,  3712, 29889,    13,    13,  1576, 15717, 28883,   278,  1059,
         29889,    13,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,   382,  4387,   362,   310,  1209,   573,  3514,   572,   414,
           363,   278,  4333,   310, 23556,  1490,  2894,   293,  4383,   297,
         20873, 29889,    13,  2308,   328,  3245, 23460,  3519,   363, 23556,
          1490,  2894,   293,  4383,   313, 22141, 29897,   297, 20873,  4046,
         28602,  1907,   363,  1472, 29899,  8489, 11898,  2861,   304,   931,
           322,  3438, 11938, 29889,  6978,   573, 12369,  3514,   572,   414,
           892, 13319,  1494,   263,  2874,  7972,  9251,   607,  3667,  7093,
           652,   621,  2904,   314,  1789,   621,  2904,   313,  2287, 16036,
         29897,  3038,   352,   852,   408,   263, 23460, 18350, 29892,   322,
           896,   892, 21168, 10106,   263,  6238,   403,  4840,  3564,   297,
         21817, 29889,  7803,  7246,  1860,   310,   278,  1209,   573,  3514,
           572,   414,   892, 18043, 29892,  2645,   607, 17229, 11916,   892,
         13672, 16531,   363, 10230, 29889,   360,  8349,  2063,   297, 12369,
         11029,  1546, 11840,   322, 23460,  3519,   892,  1223, 11517,   773,
          3196,  3619, 27070,  3483,   952,   267, 29889,   450,  3483,   952,
           267, 17845,  7282, 12651,   297, 27070,  4426,  1546, 23460,  3519,
         29892,   411,   278,  1209,   573,  3514,   572,   414,  5821,  9247,
          6314,   292, 27386,  9315, 29892,  3165,   293, 29899,  4561, 12369,
         29889,  1334,  4974,   393,   278, 12651,   297, 12369, 15259,   515,
          1269, 23460,  1158,   892,  8581,   491,  5821,  2556,  9956,   310,
          4280,  3165,   293,   752,  3885,   304,   278,  5012, 16036,  3038,
           352,   852,   297,   278,  1209,   573,  3514,   572,   414, 29889,
         10050,   621,  6393, 29892,   278,  1209,   573,  3514,   572,   414,
          1122,  3867,   263,  3438, 29899, 15987,   573, 29892, 23387,  4559,
           310, 12369,   297, 18845,   988,   278, 21610, 12369, 11565,   338,
         13725, 14364,   310, 27386,  9315, 29892,  3165,   293, 29899,  4561,
           752,  3885, 29889]], device='cuda:0')
torch.Size([2, 263, 32000]) tensor([[[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.9512, -2.4336,  0.4465,  ..., -2.9590, -3.7871, -2.6797],
         [-4.0273, -2.4336,  0.2443,  ..., -2.9902, -3.8301, -2.7793],
         ...,
         [-3.8984, -2.1055,  0.4287,  ..., -3.0156, -3.8086, -2.6641],
         [-3.9023, -2.1094,  0.4275,  ..., -3.0176, -3.8105, -2.6660],
         [-3.9043, -2.1172,  0.4275,  ..., -3.0156, -3.8105, -2.6680]],

        [[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.9805, -2.4453,  0.4639,  ..., -3.0254, -3.8438, -2.7441],
         [-4.2148, -2.6309,  0.2224,  ..., -3.0000, -3.8555, -2.7793],
         ...,
         [-4.0664, -2.5723,  0.0803,  ..., -3.0117, -3.9355, -2.7305],
         [-4.0547, -2.4336,  0.2404,  ..., -2.9961, -3.8828, -2.8184],
         [-3.8906, -2.2676,  0.3787,  ..., -2.9844, -3.7461, -2.6797]]],
       device='cuda:0')
torch.Size([2, 263, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 263, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   856,   349, 29871],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 46, 94.2% of total tokens
encoded shape: torch.Size([2, 1104])
torch.Size([2, 1104]) tensor([[    1,   450, 22895,  ...,     2,     2,     2],
        [    1,  8010, 14234,  ...,   278,  3303,  3900]], device='cuda:0')
torch.Size([2, 1104, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.9922, -2.2734,  0.4724,  ..., -3.0371, -3.7656, -2.7207],
         [-4.0938, -2.6484,  0.2725,  ..., -3.0234, -3.8398, -2.8145],
         ...,
         [-3.8477, -2.1035,  0.4958,  ..., -3.0176, -3.8086, -2.6699],
         [-3.8477, -2.1035,  0.4951,  ..., -3.0176, -3.8086, -2.6719],
         [-3.8457, -2.0996,  0.4944,  ..., -3.0156, -3.8047, -2.6680]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-4.0078, -2.3750,  0.2661,  ..., -3.0449, -3.8105, -2.7520],
         [-3.9844, -2.4336,  0.3208,  ..., -3.0254, -3.7812, -2.7363],
         ...,
         [-4.0156, -2.4531,  0.1841,  ..., -2.9727, -3.7266, -2.7656],
         [-4.1641, -2.6660,  0.0590,  ..., -2.9922, -3.7891, -2.8301],
         [-4.1523, -2.6250,  0.3789,  ..., -3.0977, -3.8867, -2.8496]]],
       device='cuda:0')
torch.Size([2, 1104, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [31147],
         [30488]]], device='cuda:0')
torch.Size([2, 1104, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 30555, 30186],
         [31147, 30488, 30879,  ...,   856, 30186,   349],
         [30488, 31147, 30879,  ...,   856, 29871, 29899]]], device='cuda:0')
Batch 47, 96.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29588, 29958,  ...,     2,     2,     2],
        [    1, 29871, 29896,  ...,   278,  1559,   327]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8398, -2.2773,  0.4470,  ..., -3.0098, -3.7812, -2.6484],
         [-3.8691, -2.2617,  0.4177,  ..., -2.9961, -3.7656, -2.6875],
         ...,
         [-3.7949, -2.0527,  0.4504,  ..., -2.9902, -3.7930, -2.6504],
         [-3.7949, -2.0527,  0.4509,  ..., -2.9902, -3.7930, -2.6504],
         [-3.7969, -2.0527,  0.4512,  ..., -2.9902, -3.7930, -2.6504]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-4.0312, -2.4180,  0.2854,  ..., -2.9902, -3.8340, -2.7305],
         ...,
         [-3.9355, -2.2520,  0.0644,  ..., -2.9199, -3.5996, -2.6504],
         [-3.9570, -2.3848,  0.1588,  ..., -2.8770, -3.6914, -2.6641],
         [-3.9551, -2.4062, -0.0308,  ..., -2.9141, -3.7988, -2.7090]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 1988])
torch.Size([2, 1988]) tensor([[    1,   660, 29901,  ...,  3400,    13,    13],
        [    1,  1815,  6776,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1988, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4492, -5.4180,  ..., -1.3994, -2.4512, -1.9287],
         [-2.5254, -0.2905, -5.4414,  ..., -1.3506, -2.3613, -1.8623],
         ...,
         [-2.5586, -0.3508, -5.2188,  ..., -1.4150, -2.4023, -1.9434],
         [-2.5859, -0.3801, -5.0703,  ..., -1.4668, -2.4492, -1.9453],
         [-2.6055, -0.4189, -5.1133,  ..., -1.4814, -2.4492, -1.9395]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.4004, -5.4336,  ..., -1.3945, -2.3809, -1.9463],
         [-2.5957, -0.4448, -5.3867,  ..., -1.3750, -2.3750, -1.9102],
         ...,
         [-2.6074, -0.3235, -5.1328,  ..., -1.4502, -2.4629, -1.9258],
         [-2.6074, -0.3237, -5.1328,  ..., -1.4502, -2.4629, -1.9258],
         [-2.6074, -0.3245, -5.1328,  ..., -1.4502, -2.4629, -1.9258]]],
       device='cuda:0')
torch.Size([2, 1988, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1988, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 1, 2.1% of total tokens
encoded shape: torch.Size([2, 1504])
torch.Size([2, 1504]) tensor([[    1,   319,  2407,  ...,   445,  1813, 29889],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1504, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5859, -0.3123, -5.3984,  ..., -1.4014, -2.4004, -1.9678],
         [-2.5996, -0.3738, -5.4453,  ..., -1.3672, -2.3496, -1.9570],
         ...,
         [-2.5332, -0.3354, -5.4844,  ..., -1.3477, -2.3906, -1.8779],
         [-2.5234, -0.3281, -5.4453,  ..., -1.3418, -2.3730, -1.8721],
         [-2.5449, -0.3484, -5.3203,  ..., -1.3848, -2.3594, -1.8672]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6016, -0.4500, -5.4219,  ..., -1.4004, -2.4512, -1.9297],
         [-2.5352, -0.3062, -5.4375,  ..., -1.3584, -2.3711, -1.8711],
         ...,
         [-2.5957, -0.2971, -5.2422,  ..., -1.4258, -2.4434, -1.9082],
         [-2.5957, -0.2974, -5.2422,  ..., -1.4248, -2.4434, -1.9082],
         [-2.5977, -0.2971, -5.2461,  ..., -1.4238, -2.4434, -1.9082]]],
       device='cuda:0')
torch.Size([2, 1504, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1504, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 2, 3.9% of total tokens
encoded shape: torch.Size([2, 826])
torch.Size([2, 826]) tensor([[    1,  7670,  1742,  ...,  7974,  6012, 13883],
        [    1,  9586,  3097,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 826, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.5957, -0.4634, -5.4023,  ..., -1.3730, -2.4102, -1.9414],
         [-2.5586, -0.3914, -5.4766,  ..., -1.3428, -2.4004, -1.9258],
         ...,
         [-2.5742, -0.4114, -5.3477,  ..., -1.3467, -2.3945, -1.9033],
         [-2.5742, -0.3936, -5.3398,  ..., -1.3682, -2.4062, -1.9160],
         [-2.5605, -0.3718, -5.2617,  ..., -1.4209, -2.4180, -1.9268]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.5684, -0.3000, -5.4414,  ..., -1.3564, -2.4395, -1.9004],
         [-2.5957, -0.3770, -5.4570,  ..., -1.3916, -2.4492, -1.9775],
         ...,
         [-2.5898, -0.2556, -5.4141,  ..., -1.3857, -2.4121, -1.9004],
         [-2.5898, -0.2559, -5.4141,  ..., -1.3857, -2.4121, -1.9004],
         [-2.5859, -0.2445, -5.4102,  ..., -1.3828, -2.4082, -1.8965]]],
       device='cuda:0')
torch.Size([2, 826, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 826, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 3, 5.0% of total tokens
encoded shape: torch.Size([2, 210])
torch.Size([2, 210]) tensor([[    1,  1704, 10454, 17100,  1078,   411, 29931,   327, 11667, 29916,
         29892,   278, 12157,   719, 30010, 29879,   396, 29896, 15854,   327,
           573,   319, 29902,    13,    13,   797,  9826, 30010, 29879, 10426,
           937,  3186, 29892,  3268,  6210,   338,   901,  4100,  1135,  3926,
         29889,   512,  1797,   304, 12141,  1813,  6210, 29892,  5087,   756,
         15241,   278,   319,  3580,   313,  7504,  7367,   630, 21600,  9305,
         29897,  2060, 29889, 20815, 11667, 29916,   338, 27436,   445,  2060,
           411,   478,  1177,  2702, 25325,  6515, 29889,    13,    13,  4013,
          2794,   746,   596, 21691,   338,  3063,   363,   263,  2702, 19716,
         29892,   896,   679,   263,  5412, 25325,  1813,   304,   278, 19716,
           310,  1009, 12561, 29879,   393, 15376,   297, 29871, 29896, 29889,
         29945,  6923, 29889,  4737, 10817,  1510,   393,   565,   263, 21691,
         11324,  1169,   975, 29871, 29941,  6923,   363,   263,  1813,   304,
          2254, 29892, 29871, 29945, 29941, 29995,   310,   596, 12469,   432,
         17204,  1283, 29889,   319,  3580,  6515,  3275,   304,   263, 16951,
          6133, 11301, 29892, 29871, 29945, 29990, 10816,   746,  9528,  2750,
           263,  2761,  2318, 29889,    13,    13,  8179, 10454,   322, 20815,
         11667, 29916,   505,  7802,   964,   263, 22056,  4034,   393,   674,
          2758,   363, 11233,   414,   304, 23120,  3025,  1749,  5735, 14881,
          7481, 29892,  3025,  2563,  2729, 13563, 29892,   408,  1532,   408,
           317,  4345,  1426,   515,   263, 11233,   414,  3038,  9008, 29889],
        [    1,   323, 29899,  3729,  1804, 27855,   322,  4469,  6727,  6997,
         29901, 13206, 16637,  7208, 12903,   310, 17135, 29889,    13,  1576,
          2531,  7492, 11525,  2785,   310,   286,   625,   756,  5331,   304,
          1663,  5861,   964,   278, 13206, 16637,  7208, 12903,   310,  4469,
          6727,  1540, 17135, 29889,  3599,   296, 11898,   505, 23580,   304,
         12439,  5837,   297,   607,  1804, 27855,  3209, 29883,  3076,   508,
           367,   766, 14214,   393,   758,  2325,   278,  5849,   310,  4469,
          6727,  6997, 29889,   910,  9076,   714,  9012,   263,   716,  1904,
           363,   278, 21445,   310,   323, 29899,  3729, 29899,  4210,   630,
          4469,  6727,  1540, 10267,  2129, 29889,   306, 12141,  7786,   848,
           393, 28475,   278,  5837,   297,   607,   278, 10551,   287, 10503,
          2561,   310,   323,  9101,   322, 23503, 29879,   297,   278,   297,
          6335,  5047,  1804, 27855,  2224,  1994,   310,   323,  9101,   508,
         29126,   304,  4469,  6727,  6997, 29889,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 210, 32000]) tensor([[[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5957, -0.4360, -5.4062,  ..., -1.3555, -2.3809, -1.9268],
         [-2.5977, -0.4072, -5.4648,  ..., -1.4072, -2.4160, -1.9600],
         ...,
         [-2.6055, -0.5532, -5.5195,  ..., -1.3828, -2.4023, -1.9170],
         [-2.6133, -0.4958, -5.4219,  ..., -1.3818, -2.3691, -1.8848],
         [-2.5547, -0.3684, -5.2227,  ..., -1.3906, -2.3320, -1.9102]],

        [[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5898, -0.3523, -5.3438,  ..., -1.4082, -2.4160, -1.9258],
         [-2.5938, -0.4136, -5.4297,  ..., -1.3662, -2.4590, -1.9121],
         ...,
         [-2.5859, -0.3000, -5.3477,  ..., -1.4033, -2.4219, -1.9229],
         [-2.5801, -0.2925, -5.3359,  ..., -1.4023, -2.4199, -1.9199],
         [-2.5859, -0.2998, -5.3359,  ..., -1.4053, -2.4238, -1.9229]]],
       device='cuda:0')
torch.Size([2, 210, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 210, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 4, 5.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871, 29896,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,   278,  9245,   338]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3210, -5.3672,  ..., -1.3652, -2.4082, -1.8906],
         [-2.5645, -0.3237, -5.5312,  ..., -1.3418, -2.3945, -1.8848],
         ...,
         [-2.6016, -0.2722, -5.2773,  ..., -1.4082, -2.4375, -1.9092],
         [-2.5996, -0.2720, -5.2773,  ..., -1.4082, -2.4395, -1.9092],
         [-2.5957, -0.2639, -5.2734,  ..., -1.4053, -2.4355, -1.9053]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3210, -5.3672,  ..., -1.3652, -2.4082, -1.8906],
         [-2.2578,  0.0060, -5.3555,  ..., -1.3291, -2.3125, -1.7910],
         ...,
         [-2.5840, -0.3928, -5.3516,  ..., -1.4131, -2.4160, -1.9502],
         [-2.5957, -0.4680, -5.4727,  ..., -1.3467, -2.4023, -1.9141],
         [-2.5605, -0.4248, -5.4141,  ..., -1.3711, -2.3906, -1.9346]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 5, 11.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 15050,  4515,  ...,     2,     2,     2],
        [    1, 16340, 29892,  ...,  2446, 29889,   402]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5820, -0.4316, -5.4727,  ..., -1.3760, -2.4160, -1.9150],
         [-2.5586, -0.2294, -5.5078,  ..., -1.3408, -2.3730, -1.8984],
         ...,
         [-2.6035, -0.3269, -5.1055,  ..., -1.4551, -2.4668, -1.9219],
         [-2.6035, -0.3269, -5.1055,  ..., -1.4551, -2.4668, -1.9219],
         [-2.6035, -0.3271, -5.1055,  ..., -1.4551, -2.4668, -1.9219]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6074, -0.4082, -5.4219,  ..., -1.3994, -2.4277, -1.9385],
         [-2.6035, -0.3613, -5.4023,  ..., -1.3975, -2.3867, -1.9346],
         ...,
         [-2.5820, -0.3911, -5.4453,  ..., -1.4023, -2.3945, -1.9268],
         [-2.5312, -0.3418, -5.3594,  ..., -1.3965, -2.3242, -1.9453],
         [-2.5801, -0.3804, -5.2969,  ..., -1.4219, -2.4004, -1.9219]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 6, 16.2% of total tokens
encoded shape: torch.Size([2, 236])
torch.Size([2, 236]) tensor([[    1,  9079, 15057,    13,    13,  4854, 15057,   471,   278,   937,
          2669,  4944,   491,  1317,  1847,   880, 21582,   322,   338,  1603,
           472,   278,  7136,   310,   278,  5381, 29889,  1334,  3867,   263,
         12464,  4395,  2948,   304,  2875, 10643,   322, 13389,   278,  2114,
           393,   591, 10933,   263, 16984,  3464,   310,  2875,  4072,   785,
           515,  9904, 13814,   304, 14982,   716,  1652,  1446,   785,   322,
           310,  2011, 25648, 15786,   785,   515,  2323, 15649, 29899,   517,
         29899,  1026, 13258,  1860,   304,  2011,  4542,  2363,   310,  1784,
          4426, 29889,    13,    13,  2499,  3592,   278, 13638,   310,   278,
          4426,   591, 10933,   526,  1603,   297,  1317,  1847,   880, 29892,
          5500,  1145,   322,   379,   547,  3801,   591,   437,   884, 10933,
           263,  3287,   310,  4426,  4340,  2511,   969,   313,  1454,  1342,
         29892,   297,   476,   575,  4885,   669,   678,  2870, 29874, 29892,
          6015,   561,   314,   322,  3122,  1195,  2475, 29897,   577,  3113,
          6958,   502,   565,   366,   505, 11780,   297,  4122,  1008,  4517,
         29889,    13,    13,  4806,  5957,  5100,  3321, 19257,   313, 18271,
          2313,   792,   287, 19257,   304,   454,   559,  8948,   414,   297,
         10930,   591, 10933,   467,    13,    13,  3624,  1847,   880, 21582,
         19806,   338,   385, 10658, 21097,   313,  4597,  8306,  9681, 29871,
         29953, 29900, 29906, 29945, 29896, 29896, 29897,   310, 17732,   512,
          7610,   749, 15057, 19806, 29892,  1058,   526,  4148,  3368,   322,
          1072,  7964,   491,   278,   383,  5454,   448,  4231,   273,  1455,
          1281,  2199, 13361,   537,   313,  4597,  8306,  9681, 29871, 29941,
         29900, 29955, 29929, 29947, 29906,   467],
        [    1, 21651,   362,   310, 12849, 16895, 26629, 29899, 27737,  8927,
          1081,  1974, 24554,   491, 22713,   867,  1218,  2923, 13857, 29889,
            13, 12636,   497,  8062,   368,  3216, 13601,   265, 29899,   571,
         29885,   291, 29871, 29946,  3868, 29898, 29885, 29897, 29871, 29941,
          3868, 29898, 29876, 29897, 24554,  8429,   297,   263,  3889, 22588,
         13184,   526, 15659,   773,   302,   898,   342,  1247,   573, 22713,
           867,  1218,  2923, 13857, 29889,   450, 13917,  9659,   278, 10379,
           310,   901,  1135, 29871, 29896, 29896,  1407,  3006, 17269,  4280,
           267,  3704,   278,  2211, 29899,  2587,   298,  7003, 13206, 29883,
          1297, 29871, 29946,  3868, 29906, 29871, 29941,  3868,   322,   278,
         17381, 29899, 29933,   272,  4871,   273,  4280, 29871, 29946,  3868,
         29906, 29871, 29941,  3868, 29906, 29889, 26475,   573,  9867, 12409,
          6238,  3698, 29892, 23892,   515,   263,  8327,  3889,   911,  1904,
           363,  9867, 14321,   773, 23399,  9956, 18190,   583, 29892,  7910,
         10597,   368,   411,  9867,  2159, 29892, 27999,  9659,   292,   278,
         17203,   411,   278,  1950,  3682,   310, 29871, 29946,  3868, 29906,
         29871, 29941,  3868, 29906, 29889,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 236, 32000]) tensor([[[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5938, -0.3875, -5.4258,  ..., -1.3916, -2.3926, -1.9385],
         [-2.5781, -0.3711, -5.4961,  ..., -1.3574, -2.3613, -1.9160],
         ...,
         [-2.5527, -0.3818, -5.4688,  ..., -1.3984, -2.3848, -1.8848],
         [-2.5410, -0.3508, -5.4883,  ..., -1.3633, -2.3926, -1.9082],
         [-2.5449, -0.2903, -5.2930,  ..., -1.3848, -2.3711, -1.9238]],

        [[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5801, -0.3157, -5.5039,  ..., -1.3525, -2.3926, -1.9219],
         [-2.5898, -0.3962, -5.4180,  ..., -1.4141, -2.3965, -1.9424],
         ...,
         [-2.5742, -0.2800, -5.3477,  ..., -1.3984, -2.4082, -1.9160],
         [-2.5840, -0.2947, -5.3398,  ..., -1.4062, -2.4180, -1.9248],
         [-2.5840, -0.2935, -5.3320,  ..., -1.4082, -2.4199, -1.9258]]],
       device='cuda:0')
torch.Size([2, 236, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 236, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 7, 16.6% of total tokens
encoded shape: torch.Size([2, 990])
torch.Size([2, 990]) tensor([[    1, 22809, 29899,  ..., 29925,   475,  1259],
        [    1, 29871, 29955,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 990, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.3733, -5.3945,  ..., -1.3691, -2.4043, -1.8955],
         [-2.5625, -0.4067, -5.4570,  ..., -1.3613, -2.3750, -1.8770],
         ...,
         [-2.5664, -0.4490, -5.3672,  ..., -1.3203, -2.3359, -1.9121],
         [-2.5391, -0.3911, -5.4883,  ..., -1.2959, -2.3711, -1.8955],
         [-2.5859, -0.4146, -5.2969,  ..., -1.3838, -2.4180, -1.9326]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3210, -5.3672,  ..., -1.3652, -2.4082, -1.8916],
         [-2.5684, -0.3245, -5.5117,  ..., -1.3936, -2.4062, -1.9424],
         ...,
         [-2.5742, -0.2554, -5.3672,  ..., -1.4023, -2.3848, -1.9033],
         [-2.5742, -0.2573, -5.3594,  ..., -1.4043, -2.3887, -1.9053],
         [-2.5762, -0.2598, -5.3555,  ..., -1.4043, -2.3906, -1.9062]]],
       device='cuda:0')
torch.Size([2, 990, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 990, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 8, 18.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   960,   445,  ...,     2,     2,     2],
        [    1, 29871, 29896,  ...,  1450, 30081,  1123]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3652, -5.4297,  ..., -1.3828, -2.3887, -1.9004],
         [-2.5742, -0.4143, -5.3906,  ..., -1.4111, -2.3887, -1.9424],
         ...,
         [-2.6016, -0.3091, -5.1914,  ..., -1.4307, -2.4473, -1.9150],
         [-2.6016, -0.3096, -5.1914,  ..., -1.4307, -2.4473, -1.9150],
         [-2.6016, -0.3091, -5.1914,  ..., -1.4307, -2.4473, -1.9150]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3210, -5.3672,  ..., -1.3652, -2.4082, -1.8906],
         [-2.5645, -0.3237, -5.5312,  ..., -1.3418, -2.3945, -1.8848],
         ...,
         [-2.5273, -0.3562, -5.6250,  ..., -1.3223, -2.3535, -1.8887],
         [-2.5508, -0.4141, -5.4141,  ..., -1.3828, -2.3730, -1.9160],
         [-2.5391, -0.4058, -5.3906,  ..., -1.3760, -2.3965, -1.9014]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 9, 24.0% of total tokens
encoded shape: torch.Size([2, 2672])
torch.Size([2, 2672]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 29889,    13,    13]], device='cuda:0')
torch.Size([2, 2672, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4492, -5.4180,  ..., -1.3994, -2.4512, -1.9287],
         [-2.5254, -0.2905, -5.4414,  ..., -1.3506, -2.3613, -1.8623],
         ...,
         [-2.6055, -0.3022, -5.2695,  ..., -1.4229, -2.4395, -1.9141],
         [-2.6035, -0.3022, -5.2695,  ..., -1.4229, -2.4395, -1.9141],
         [-2.6035, -0.3020, -5.2695,  ..., -1.4229, -2.4395, -1.9141]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4492, -5.4180,  ..., -1.3994, -2.4512, -1.9287],
         [-2.5254, -0.2905, -5.4414,  ..., -1.3506, -2.3613, -1.8623],
         ...,
         [-2.5625, -0.3535, -5.2344,  ..., -1.4395, -2.3555, -1.9912],
         [-2.5840, -0.3892, -5.1367,  ..., -1.4707, -2.4219, -1.9600],
         [-2.5781, -0.4285, -5.2734,  ..., -1.4365, -2.4336, -1.9307]]],
       device='cuda:0')
torch.Size([2, 2672, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 2672, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 10, 27.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 10130,    13,  ..., 29889,    13,    13],
        [    1,   390, 29889,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.4011, -5.4766,  ..., -1.3984, -2.4141, -1.9297],
         [-2.2188,  0.0560, -5.4648,  ..., -1.3047, -2.2812, -1.7871],
         ...,
         [-2.5371, -0.3958, -5.4453,  ..., -1.4277, -2.3262, -1.8965],
         [-2.5391, -0.3381, -5.3594,  ..., -1.4043, -2.4238, -1.9160],
         [-2.5371, -0.3696, -5.4297,  ..., -1.4395, -2.4023, -1.9199]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3679, -5.3164,  ..., -1.4053, -2.4121, -1.9434],
         [-2.2754, -0.0626, -5.2500,  ..., -1.3711, -2.3438, -1.8154],
         ...,
         [-2.6094, -0.3337, -5.1172,  ..., -1.4521, -2.4648, -1.9248],
         [-2.6094, -0.3333, -5.1133,  ..., -1.4531, -2.4648, -1.9248],
         [-2.6113, -0.3342, -5.1172,  ..., -1.4531, -2.4648, -1.9258]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 11, 32.6% of total tokens
encoded shape: torch.Size([2, 1331])
torch.Size([2, 1331]) tensor([[    1,  7106,   304,  ..., 29955,  5735, 20618],
        [    1,   349,  1179,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1331, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5742, -0.3691, -5.4688,  ..., -1.3525, -2.3672, -1.8887],
         [-2.5156, -0.2607, -5.5352,  ..., -1.3438, -2.3184, -1.8662],
         ...,
         [-2.5488, -0.2732, -5.3789,  ..., -1.3467, -2.3789, -1.9121],
         [-2.5469, -0.3213, -5.3984,  ..., -1.3428, -2.3887, -1.8799],
         [-2.5566, -0.3323, -5.3164,  ..., -1.3574, -2.4043, -1.9268]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5742, -0.3408, -5.3477,  ..., -1.3926, -2.3555, -1.9248],
         [-2.5586, -0.3083, -5.4805,  ..., -1.3711, -2.3887, -1.9160],
         ...,
         [-2.5898, -0.3020, -5.2773,  ..., -1.4180, -2.4277, -1.9307],
         [-2.5859, -0.2935, -5.2773,  ..., -1.4150, -2.4238, -1.9268],
         [-2.5859, -0.2939, -5.2773,  ..., -1.4150, -2.4238, -1.9268]]],
       device='cuda:0')
torch.Size([2, 1331, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1331, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 12, 35.1% of total tokens
encoded shape: torch.Size([2, 507])
torch.Size([2, 507]) tensor([[    1,  7395,   270,  ...,     2,     2,     2],
        [    1, 10969,  5057,  ...,  1434, 17745, 29889]], device='cuda:0')
torch.Size([2, 507, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4561, -2.4609, -1.9131],
         [-2.5723, -0.3723, -5.3789,  ..., -1.4092, -2.4102, -1.8877],
         [-2.5566, -0.3623, -5.4414,  ..., -1.3438, -2.3984, -1.9150],
         ...,
         [-2.5742, -0.2247, -5.4961,  ..., -1.3643, -2.3887, -1.8818],
         [-2.5742, -0.2247, -5.4961,  ..., -1.3643, -2.3887, -1.8818],
         [-2.5703, -0.2163, -5.5000,  ..., -1.3594, -2.3887, -1.8770]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4561, -2.4609, -1.9131],
         [-2.5703, -0.3196, -5.4805,  ..., -1.3926, -2.4180, -1.9238],
         [-2.5566, -0.3757, -5.5352,  ..., -1.3223, -2.3730, -1.9297],
         ...,
         [-2.5645, -0.4106, -5.3398,  ..., -1.3779, -2.3887, -1.9346],
         [-2.5645, -0.3569, -5.3125,  ..., -1.3984, -2.4082, -1.9219],
         [-2.5430, -0.3284, -5.2109,  ..., -1.3838, -2.3789, -1.8945]]],
       device='cuda:0')
torch.Size([2, 507, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 507, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 13, 35.8% of total tokens
encoded shape: torch.Size([2, 767])
torch.Size([2, 767]) tensor([[    1,   838,  3845,  ..., 29906,  4892, 29879],
        [    1, 26475,   310,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 767, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6055, -0.4490, -5.3672,  ..., -1.4141, -2.3926, -1.9307],
         [-2.5762, -0.3997, -5.4023,  ..., -1.4082, -2.3984, -1.9355],
         ...,
         [-2.5332, -0.2734, -5.4219,  ..., -1.3740, -2.3613, -1.8975],
         [-2.5449, -0.3364, -5.3984,  ..., -1.3604, -2.3984, -1.9336],
         [-2.5527, -0.3259, -5.3477,  ..., -1.4072, -2.4102, -1.9316]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5938, -0.3730, -5.4727,  ..., -1.3779, -2.4375, -1.9385],
         [-2.5879, -0.3965, -5.3828,  ..., -1.3721, -2.3906, -1.9229],
         ...,
         [-2.5840, -0.2620, -5.4219,  ..., -1.3857, -2.4004, -1.8975],
         [-2.5840, -0.2622, -5.4219,  ..., -1.3857, -2.4004, -1.8975],
         [-2.5840, -0.2632, -5.4219,  ..., -1.3857, -2.4004, -1.8975]]],
       device='cuda:0')
torch.Size([2, 767, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 767, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 14, 37.0% of total tokens
encoded shape: torch.Size([2, 1335])
torch.Size([2, 1335]) tensor([[    1,  4241,    13,  ..., 29337,   931, 29889],
        [    1,  3630,  2180,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1335, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5645, -0.3865, -5.4414,  ..., -1.4170, -2.3652, -1.9111],
         [-2.2852, -0.0586, -5.2148,  ..., -1.3652, -2.3574, -1.8252],
         ...,
         [-2.5664, -0.3899, -5.4219,  ..., -1.3594, -2.3809, -1.8955],
         [-2.5723, -0.3762, -5.3711,  ..., -1.3584, -2.3770, -1.9502],
         [-2.5312, -0.3645, -5.2344,  ..., -1.3594, -2.3750, -1.9062]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5801, -0.3540, -5.4570,  ..., -1.3369, -2.4277, -1.9346],
         [-2.5723, -0.3997, -5.4805,  ..., -1.3467, -2.3555, -1.9248],
         ...,
         [-2.5879, -0.2607, -5.4062,  ..., -1.3857, -2.4121, -1.8965],
         [-2.5879, -0.2605, -5.4102,  ..., -1.3848, -2.4121, -1.8965],
         [-2.5879, -0.2600, -5.4102,  ..., -1.3848, -2.4121, -1.8965]]],
       device='cuda:0')
torch.Size([2, 1335, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1335, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 15, 38.9% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,   282,  ..., 29882,   467,   360],
        [    1,   518,  2177,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3210, -5.3672,  ..., -1.3652, -2.4082, -1.8906],
         [-2.5918, -0.4548, -5.3906,  ..., -1.4150, -2.4004, -1.8936],
         ...,
         [-2.5742, -0.4622, -5.4453,  ..., -1.3975, -2.4004, -1.9521],
         [-2.5312, -0.2971, -5.4570,  ..., -1.3721, -2.3730, -1.8896],
         [-2.5762, -0.3904, -5.2695,  ..., -1.4189, -2.4414, -1.9326]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5723, -0.3857, -5.4453,  ..., -1.3691, -2.4043, -1.8799],
         [-2.5605, -0.4214, -5.5430,  ..., -1.3496, -2.4043, -1.8721],
         ...,
         [-2.5820, -0.3037, -5.1016,  ..., -1.4521, -2.4648, -1.9189],
         [-2.5801, -0.3035, -5.1016,  ..., -1.4521, -2.4648, -1.9180],
         [-2.5801, -0.3037, -5.1016,  ..., -1.4521, -2.4648, -1.9189]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 16, 43.2% of total tokens
encoded shape: torch.Size([2, 288])
torch.Size([2, 288]) tensor([[    1,  8396,   361,   815,   341, 29893,   574, 29875, 11644,  1317,
          6298,   558,  5921,   368,  2567,   922,  1218,  1152,  3600,   476,
         29907,  1660,  2811,  1522, 19509,  1152,   910,   922,   271,   512,
           450, 29871, 29906, 29900, 29896, 29955,  4593,   382,  5942,    13,
            13, 29923,  1195,   296, 15373, 29926,  4659,   391,   322,  5039,
           391,  8396,   361,   815,   341, 29893,   574, 29875,   756,  9326,
           670,  7609,  1080,   304,  1065,   363,   624,   598,   354, 13212,
           653, 12949,   297,   278, 29871, 29906, 29900, 29896, 29955,  2498,
         20209, 29889,    13,    13, 29933,   265,   361,   815, 29892,   385,
          2756,   381,  2168, 11164,   310,   278,  1857,  5874,  3275,   491,
          7178,   501, 29882, 20144, 10015, 29891, 14975,  1497,   540,   756,
           278, 16392,   310,  2734,   408,   385,  7417, 14020,   322,   758,
         25534,   393,   304,  2734,  1090, 13973,   763,   435,   431,   488,
         29872,   322, 20893,  1363,  5034,   304,  1075, 29892,  1316, 13973,
           437,   451,  7726,   363,  1075, 29889,   940,  1497,   540,   723,
          3265,  1106,   363,   263,  6263,   393,   540,   508, 12439,   411,
         29889,    13,    13,  3868,  1497,   373, 13327,   393,   540,   756,
           278, 16392,   304,  1065,   363, 16379,   624,   598,   354, 12949,
           322,   393,   540,   723,  6773, 13590, 19872, 20501,  2705, 29889,
           940,  2715,   393,   540,   338, 21248,   373,   278,  2305, 30010,
         29879, 18161,  2304, 29892, 18952,   322,  5360, 29889,    13, 29968,
         15274,   550,  3138,   437,   451,  2833,   304,  2304,   670,  7609,
          1080,   310,  2805,   964, 22661, 29889,  9267,  2305,   505,   594,
         11292,  1075,   304, 12070,   304,  5039,  1608,   408,   393,   723,
          1207, 10015,  3761,   263,  2253,  2058, 29889,    13,    13, 29909,
          3287,   310, 10015, 29891,   550,  4997,   287,  3692,   540,   723,
          2869,  1207,   263,  1781, 11822,   470,   540,   723,  1101,   297,
           278,  3661, 24530,   310,   916,  5039,  2879,  6077,  2832, 14722,
         29889,     2,     2,     2,     2,     2,     2,     2],
        [    1,  8540,   357,  3313,  5282,  1581,   363, 18483, 29871, 29955,
           847, 29871, 29947,    13,    13, 26772,   373,  1432, 17623,   545,
           411, 16420,   746,   366,  7462,   596,  9008,   411,  5282,  1581,
         10488, 29892,   278, 29833,  3192, 18483, 29871, 29955,   847, 29871,
         29947,  1206, 29889,    13,    13, 16359,  1299, 11499, 29903,    13,
            13, 15329, 29899, 13148,  1206, 12566, 29879,   596, 13258,   358,
           515,  7037, 18658,    13,    13,  3727,  2782, 29899,   262,  6023,
         10525,  3279,  2801,   822,  1975,  2750, 22728,   267,   322,   885,
          2390,   267,    13,    13,  2290,   715, 16926,  2758,   363,  4780,
          2130,  1550, 12515,   714, 19786,   322,   316,  1182,   275,    13,
            13,  1184,   371,   312,   573,  3813, 10800,  2181,   328,   793,
         28675,  3553, 29892, 14372,   363,  2989,  9863,    13,    13, 29903,
          8971, 29899,  3808,   715,  6288,  6473,  5662,  1973,   298,   465,
           280, 29899,  9021,   373, 29899,  2696, 11161,    13,    13, 19984,
          2475,  9335,   567, 11480,  5312,   567,   322,  1339,  1372, 29892,
          2298,   372,   658,  4684,   297,  2058,   363,  6567, 29899,  9021,
          1776,   292,    13,    13,  6716, 29899,  6360,  1370, 21867, 29891,
            13,    13, 29911,  2868,   491,   502, 29889,  5373,  2782,   363,
           366, 29889,  5618,   437, 29871, 29906, 29946, 29974,  6987,   322,
         29871, 29906, 29941, 29947, 29974,  6199,   310,  6724,  2099,   304,
           366, 29973,  2688,  2099,   596,  8540,   357,  3313,  1206,   338,
          7960,   304,   270,   573,   964,   596,  2462,  1728,   263,  1473,
          2714,   813,   925,   763,   366,   526, 29889,  8540,   357,  3313,
         18410,  2164, 20724, 29974, 14409,   428,  2794,  4441,   567, 29892,
           289, 17204,   322,   285,  3774,   793,   526,   925,   278,  6763,
         29889,   739,  2794,   596,  4742,   338,  6364,   515,   278,  2594,
          6617,   310, 19531,   669,   734,   279,   366,  4967,   372,   304,
          1432,  3250, 29889,  1105,   748, 14432,   813,   437,   825,   366,
           437,   322,  5967,   278, 13047,   304,   502, 29889]],
       device='cuda:0')
torch.Size([2, 288, 32000]) tensor([[[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6074, -0.3955, -5.3828,  ..., -1.3779, -2.3945, -1.9482],
         [-2.5820, -0.3994, -5.4062,  ..., -1.3701, -2.4121, -1.9248],
         ...,
         [-2.5410, -0.0870, -5.5508,  ..., -1.3174, -2.3496, -1.8730],
         [-2.5469, -0.1111, -5.5273,  ..., -1.3271, -2.3574, -1.8789],
         [-2.5508, -0.1348, -5.5000,  ..., -1.3379, -2.3672, -1.8848]],

        [[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5859, -0.3970, -5.3633,  ..., -1.4160, -2.3984, -1.9102],
         [-2.5977, -0.4578, -5.3867,  ..., -1.3779, -2.4043, -1.9121],
         ...,
         [-2.5840, -0.3555, -5.4336,  ..., -1.4277, -2.4258, -1.9053],
         [-2.6289, -0.4258, -5.3945,  ..., -1.4160, -2.4355, -1.9697],
         [-2.5742, -0.3423, -5.1992,  ..., -1.3789, -2.4316, -1.9219]]],
       device='cuda:0')
torch.Size([2, 288, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 288, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 17, 43.7% of total tokens
encoded shape: torch.Size([2, 1771])
torch.Size([2, 1771]) tensor([[    1, 29871, 29896,  ...,     2,     2,     2],
        [    1, 10504,   364,  ...,  6445,   322, 29130]], device='cuda:0')
torch.Size([2, 1771, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3210, -5.3672,  ..., -1.3652, -2.4082, -1.8906],
         [-2.5645, -0.3237, -5.5312,  ..., -1.3418, -2.3945, -1.8848],
         ...,
         [-2.6035, -0.2939, -5.2773,  ..., -1.4150, -2.4336, -1.9131],
         [-2.6035, -0.2937, -5.2773,  ..., -1.4150, -2.4336, -1.9131],
         [-2.6035, -0.2942, -5.2773,  ..., -1.4160, -2.4336, -1.9131]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6035, -0.4116, -5.4023,  ..., -1.3887, -2.3945, -1.9443],
         [-2.5801, -0.4294, -5.4531,  ..., -1.3652, -2.3594, -1.9043],
         ...,
         [-2.5684, -0.3843, -5.2773,  ..., -1.4180, -2.4219, -1.9180],
         [-2.5879, -0.4475, -5.3711,  ..., -1.3984, -2.4180, -1.9404],
         [-2.5723, -0.3894, -5.3203,  ..., -1.4082, -2.4004, -1.9072]]],
       device='cuda:0')
torch.Size([2, 1771, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1771, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 18, 45.9% of total tokens
encoded shape: torch.Size([2, 891])
torch.Size([2, 891]) tensor([[    1,  1938,   596,  ...,     2,     2,     2],
        [    1,   512,  9826,  ..., 20076,  2153, 29889]], device='cuda:0')
torch.Size([2, 891, 32000]) tensor([[[-2.5469, -0.3071, -5.0547,  ..., -1.4561, -2.4609, -1.9121],
         [-2.5859, -0.3838, -5.4844,  ..., -1.3730, -2.3770, -1.9072],
         [-2.5820, -0.3613, -5.3828,  ..., -1.4160, -2.3555, -1.9258],
         ...,
         [-2.5781, -0.2472, -5.4180,  ..., -1.3789, -2.4102, -1.8838],
         [-2.5762, -0.2437, -5.4219,  ..., -1.3789, -2.4102, -1.8838],
         [-2.5820, -0.2494, -5.4219,  ..., -1.3828, -2.4160, -1.8877]],

        [[-2.5469, -0.3071, -5.0547,  ..., -1.4561, -2.4609, -1.9121],
         [-2.5938, -0.3809, -5.4297,  ..., -1.3994, -2.3906, -1.8818],
         [-2.5957, -0.3198, -5.4648,  ..., -1.3936, -2.4043, -1.9424],
         ...,
         [-2.5332, -0.3433, -5.4727,  ..., -1.3818, -2.3828, -1.8984],
         [-2.6191, -0.4578, -5.4453,  ..., -1.4561, -2.3945, -1.9775],
         [-2.5508, -0.3125, -5.3047,  ..., -1.3682, -2.3496, -1.9287]]],
       device='cuda:0')
torch.Size([2, 891, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 891, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 19, 47.2% of total tokens
encoded shape: torch.Size([2, 614])
torch.Size([2, 614]) tensor([[    1, 10130,  2688,  ...,   967, 18363, 29889],
        [    1,  2627,   300,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 614, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5801, -0.3933, -5.4805,  ..., -1.3955, -2.4102, -1.9258],
         [-2.5645, -0.3560, -5.4336,  ..., -1.3838, -2.3652, -1.8994],
         ...,
         [-2.6016, -0.4338, -5.3789,  ..., -1.4043, -2.4023, -1.9102],
         [-2.5918, -0.3906, -5.4961,  ..., -1.3525, -2.3477, -1.9375],
         [-2.5527, -0.3110, -5.3359,  ..., -1.3730, -2.3906, -1.9033]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4373, -5.3945,  ..., -1.4033, -2.4121, -1.9492],
         [-2.5547, -0.3550, -5.4023,  ..., -1.3828, -2.3945, -1.9131],
         ...,
         [-2.5684, -0.2192, -5.4766,  ..., -1.3643, -2.3848, -1.8789],
         [-2.5742, -0.2273, -5.4805,  ..., -1.3672, -2.3887, -1.8828],
         [-2.5703, -0.2212, -5.4844,  ..., -1.3633, -2.3848, -1.8799]]],
       device='cuda:0')
torch.Size([2, 614, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 614, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 20, 48.1% of total tokens
encoded shape: torch.Size([2, 3560])
torch.Size([2, 3560]) tensor([[    1,   450, 13960,  ...,  3805,  8927, 29889],
        [    1, 23946,   284,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3560, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5938, -0.2725, -5.3828,  ..., -1.4014, -2.3906, -1.9268],
         [-2.5742, -0.3928, -5.3789,  ..., -1.3975, -2.3945, -1.9336],
         ...,
         [-2.5391, -0.3655, -5.4727,  ..., -1.3691, -2.3848, -1.9326],
         [-2.5938, -0.3499, -5.4414,  ..., -1.4170, -2.4102, -1.9346],
         [-2.5332, -0.3311, -5.1641,  ..., -1.3721, -2.3750, -1.9170]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5762, -0.3865, -5.4648,  ..., -1.3721, -2.4219, -1.8809],
         [-2.5781, -0.3899, -5.4258,  ..., -1.3682, -2.3984, -1.9180],
         ...,
         [-2.5859, -0.3120, -5.1016,  ..., -1.4561, -2.4688, -1.9229],
         [-2.5820, -0.3042, -5.1016,  ..., -1.4531, -2.4648, -1.9189],
         [-2.5801, -0.3037, -5.1016,  ..., -1.4531, -2.4648, -1.9180]]],
       device='cuda:0')
torch.Size([2, 3560, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3560, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 21, 51.7% of total tokens
encoded shape: torch.Size([2, 1136])
torch.Size([2, 1136]) tensor([[    1, 15976,   936,  ...,     2,     2,     2],
        [    1,   315,  5380,  ..., 29220, 27580, 29889]], device='cuda:0')
torch.Size([2, 1136, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5801, -0.4111, -5.4844,  ..., -1.3584, -2.3926, -1.8838],
         [-2.5684, -0.3699, -5.4844,  ..., -1.3789, -2.3926, -1.9111],
         ...,
         [-2.5801, -0.2472, -5.4102,  ..., -1.3760, -2.3965, -1.8906],
         [-2.5762, -0.2386, -5.4102,  ..., -1.3721, -2.3926, -1.8867],
         [-2.5801, -0.2471, -5.4062,  ..., -1.3760, -2.3965, -1.8906]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5801, -0.3528, -5.3359,  ..., -1.4053, -2.4082, -1.9307],
         [-2.5742, -0.3501, -5.4727,  ..., -1.3652, -2.4258, -1.9150],
         ...,
         [-2.5410, -0.3540, -5.5703,  ..., -1.3564, -2.3555, -1.8945],
         [-2.5762, -0.3738, -5.4414,  ..., -1.3916, -2.3867, -1.8760],
         [-2.5488, -0.3281, -5.2148,  ..., -1.3643, -2.4160, -1.8916]]],
       device='cuda:0')
torch.Size([2, 1136, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1136, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 22, 53.2% of total tokens
encoded shape: torch.Size([2, 2389])
torch.Size([2, 2389]) tensor([[    1,  3872, 29915,  ...,  8456, 21470, 12298],
        [    1, 26804,  2133,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2389, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5820, -0.3855, -5.4688,  ..., -1.3701, -2.3848, -1.9316],
         [-2.5508, -0.2115, -5.4922,  ..., -1.3408, -2.3750, -1.8945],
         ...,
         [-2.5684, -0.4343, -5.4141,  ..., -1.3604, -2.4180, -1.9277],
         [-2.5527, -0.3557, -5.4062,  ..., -1.3701, -2.4043, -1.9375],
         [-2.5723, -0.3503, -5.3633,  ..., -1.3799, -2.4238, -1.9414]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3838, -5.4414,  ..., -1.4131, -2.4121, -1.9404],
         [-2.5938, -0.3730, -5.4141,  ..., -1.3926, -2.4297, -1.9512],
         ...,
         [-2.6074, -0.3184, -5.1758,  ..., -1.4404, -2.4512, -1.9219],
         [-2.6055, -0.3186, -5.1758,  ..., -1.4395, -2.4512, -1.9209],
         [-2.6055, -0.3186, -5.1758,  ..., -1.4395, -2.4512, -1.9209]]],
       device='cuda:0')
torch.Size([2, 2389, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 2389, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 23, 56.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  9683,  6504,  ...,     2,     2,     2],
        [    1,   317, 29889,  ..., 29896, 29945, 29941]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5938, -0.4543, -5.3594,  ..., -1.4170, -2.4160, -1.9248],
         [-2.5820, -0.4053, -5.4492,  ..., -1.3906, -2.3984, -1.9111],
         ...,
         [-2.6133, -0.3376, -5.1016,  ..., -1.4580, -2.4688, -1.9277],
         [-2.6113, -0.3367, -5.0977,  ..., -1.4590, -2.4707, -1.9277],
         [-2.6113, -0.3367, -5.1016,  ..., -1.4580, -2.4707, -1.9268]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5957, -0.3499, -5.3320,  ..., -1.4082, -2.4004, -1.9180],
         [-2.2793, -0.0547, -5.3164,  ..., -1.3574, -2.3340, -1.8223],
         ...,
         [-2.5312, -0.3318, -5.5273,  ..., -1.3564, -2.3711, -1.8984],
         [-2.5527, -0.4387, -5.5039,  ..., -1.3994, -2.3770, -1.8945],
         [-2.5938, -0.4500, -5.4336,  ..., -1.3906, -2.4141, -1.9473]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 24, 60.9% of total tokens
encoded shape: torch.Size([2, 491])
torch.Size([2, 491]) tensor([[    1,   512, 10937, 29946,   278, 23387, 24809,   358,   313, 10764,
         29897,  1158,  3002,   674,   367,  8906, 29892,  8762,   297,   263,
          2989, 29899, 14153,   306, 29909,  5780,   322,  7436,   304,  8608,
         24833,   322, 15366, 29889,   450,  1158,  3002,   322,  5780,   674,
         22782,   278, 25477,   848,   515, 10937, 29896, 29892,   278,  4799,
         11029,   322, 14060,   545,  4733,  3625,   297, 10937, 29906, 29892,
           278, 14060,   545, 29899,  5327,  3168,   322,  6866,  1145,   310,
         17135, 21556,   515, 10937, 29941,   322,   515,  1438,  8147,   278,
          9045, 10879,   310, 24833,   322, 15366,  6790,   491, 10937, 29945,
         29889,    13,    13,  1576,  1158,  3002,   674,   367,  8762,   297,
          1023,  3987, 29892,  2106, 29899,   974, 29899,  1552, 29899,   442,
          4733,   470,  5172, 20875,  4733, 29892, 21653,   278,  2989,  3269,
           284,  9704,   515, 18563, 29892,  1549,   953,  6847, 29892, 14953,
           800,   322, 14060,   545,   313, 20313,  7029,   322,  7463,   511,
           304,  9545, 29889,   450,   937,  2984,   674,  3160,  7029,  2988,
           411,  2106,   310,   278,  1616, 15489,  8096,   293,  4733, 13240,
           297, 10937, 29906, 29936,  1438,   526,  9024,   304,   322, 20704,
           491,   263,  6555,  5780,   313,  9203,  3455, 29897,   393,   674,
          8072,  6084,   278,  3620,  4312,   304,  8677,   714, 10483,  6057,
         29889, 19065,  1438,  7029, 15489,  8096,   293,  4733, 29892,   278,
         10239,  3455,   674,  1712,   599,  9863,  4312,   363,  2989,  9704,
          7418,   322,   674,  4550,  3160,   278, 26702, 29899,  5327,   322,
         14060,   545, 29899,  5327,  3168,   310, 10937, 29941,   322,  9068,
           322, 24329, 10585, 29889,   450, 20875,  2984,   338,  2788,   304,
           278,  2106, 29899,   974, 29899,  1552, 29899,   442,   697, 29936,
           278,  4328,   338,   393,   372,   674,   451,   671,   278,  7029,
         15489,  8096,   293,  4733, 29892,   541,  2560,  5302, 15783,  1438,
         29892,  8906,   297, 10937, 29906,   408,  1532, 29889,   450,  5172,
         20875,  2984,   674,   367,  1737,  1965,   472,  8898,  7418,   297,
           278,  3902,   272,  7606, 22950,   322,   363,  1176,  1711, 24809,
           292,   278,  2779, 20193,   310,  4072,   310, 15366, 29889,   450,
         19430,  2106, 29899,   974, 29899,  1552, 29899,   442,  2984,   338,
          9146,   363,  2304,   304,  6564, 22950,   310, 10608, 29899, 28990,
         29889,  1152, 10483, 17203,  3161,   363,  1716,  3987,  1122,   367,
         12420, 29889,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2],
        [    1,   319,   311,   339,   403, 11654, 12418,   310,  8565, 22907,
           322,  6667,   358,   284,  6171, 19263,   491,   365,   398,  1646,
          4124,  2587,   383,  3958,  3826,   276,  2129,  2087, 29926, 16648,
          6667,   358,   360,   387,   759,   362, 29889,    13,  4013,  6559,
         12242,   287,   304, 23033,   278,  9545,   310, 19703,  1646,  1006,
          2587, 21736, 29899, 19910,  1133,  4768,   608,  5083,   936,  3620,
           373,   278, 20114, 24611, 29892,  7148,  2313,  3171,   322, 10768,
           284, 18120, 19263,  1791, 12418, 29892,   322,   304,  3867,   901,
          2472,   363,  1571, 25300,   936, 13705,  9262, 29889,   450, 16083,
          6475,   310, 29871, 29945, 29906, 29947, 22069,  1058,  1090, 29893,
           296, 13446, 19703,  1646,  1006,  2587, 21736,   892,  3240,  1883,
          1103,  3598,  9076,   287, 29892,   322,   263,  3001,   310, 29871,
         29947, 29929, 22069,   892,  5134, 29889,   317,  2007,   936,  4221,
           800,  5134,  3587,   759,  1230,   805,   898,  2904, 18301, 26533,
           313, 29876,   787,  2818,  2904,   324,  3637,   293,   511, 10902,
          2313,   298,  7181,   362, 29892,   470, 19703,  1646,   805,   979,
           380,   264, 19263, 26795, 20607, 17753,  2590,   472,   365, 29946,
         29914, 29945, 29889,  4918,  3372,  1230, 20114, 10768,  3587,   759,
           362,   313,  3289, 29928, 29897,   471,  1223, 11517,  2729,   373,
          1060, 29899,   764, 29879,   322, 13303,  4660, 29889,  8565,  3171,
         29892, 15305,   979,  3171, 29892, 10768,   284, 18120, 19263, 29892,
         19703,  1646, 18120, 19263, 29892,   322,   274,   482, 16303,   892,
          9401,  1546,   278,  3339, 29928,   322,  1661, 29899,  3289, 29928,
         22069, 29889,  1763, 12439,   278,  1950, 12045, 13879,   363, 17937,
         12122,  3339, 29928, 29892,   443, 27432,   403,  7418,   471,  8560,
           937, 29892,  5643,   491,  1773, 27432,   403,  1480,  4695, 17855,
           773,  3651,   411,   349,   529, 29871, 29900, 29889, 29906, 29900,
         29889,   853, 27432,   403,  7418, 17845,   393,   278,  1400,  3372,
          1230,  2313,  3171,   297,   278,  1661, 29899,  3289, 29928,  2318,
           892, 16951,  7621,  1135,   297,   278,  3339, 29928,  2318, 29889,
           450,  1400,  3372,  1230, 10768,   284, 18120, 19263,   297,   278,
          1661, 29899,  3289, 29928,  2318,   471, 16951,  7621,  1135,   393,
           297,   278,  3339, 29928,  2318, 29892,   322,   278, 19703,  1646,
         18120, 19263,   297,   278,  1661, 29899,  3289, 29928,  2318,   471,
           884, 16951,  7621,  1135,   393,   297,   278,  3339, 29928,  2318,
           472,   278,  2186,  1101, 29899,   786,  6493, 29889, 12458,  3651,
           892, 15659,   408,  7417, 12045, 13879,   363,  3339, 29928,   491,
         15352,  1773, 27432,   403,  1480,  4695, 17855, 29901,  1400,  3372,
          1230,  6198,  2313,  3171,   310,   365, 29946, 29914, 29945,   313,
         29925,   353, 29871, 29900, 29889, 29900, 29896, 29896,   511,  1400,
          3372,  1230, 10768,   284, 18120, 19263,   313, 29925,   353, 29871,
         29900, 29889, 29900, 29946, 29953,   511, 19703,  1646, 18120, 19263,
           472,   278,  2186,  1101, 29899,   786,  6493,   313, 29925,   353,
         29871, 29900, 29889, 29900, 29900, 29955,   511,   322,   274,   482,
          3171,   313, 29925,   353, 29871, 29900, 29889, 29900, 29941, 29947,
           467,  1954,   771,  1490, 19703,  1646, 18120, 19263,   338,  8855,
           630,   411,   263,  5224,  5528,  5084,   310,  3339, 29928, 29892,
           322, 19967,   339,   403,  2313,  3171,   322, 10768,   284, 18120,
         19263,  1791, 12418,   526, 18853,   363,  3339, 29928,  5557,   291,
         29889]], device='cuda:0')
torch.Size([2, 491, 32000]) tensor([[[-2.5371, -0.2917, -5.0586,  ..., -1.4482, -2.4512, -1.9033],
         [-2.5977, -0.3867, -5.4258,  ..., -1.4033, -2.3945, -1.8848],
         [-2.5879, -0.4219, -5.4062,  ..., -1.3828, -2.3828, -1.9199],
         ...,
         [-2.5859, -0.2839, -5.3164,  ..., -1.4043, -2.4219, -1.9102],
         [-2.5859, -0.2842, -5.3164,  ..., -1.4043, -2.4219, -1.9102],
         [-2.5840, -0.2825, -5.3203,  ..., -1.4043, -2.4219, -1.9092]],

        [[-2.5371, -0.2917, -5.0586,  ..., -1.4482, -2.4512, -1.9033],
         [-2.5859, -0.3120, -5.3984,  ..., -1.4014, -2.4004, -1.9678],
         [-2.5820, -0.3684, -5.3945,  ..., -1.3506, -2.4355, -1.9453],
         ...,
         [-2.5664, -0.3508, -5.4570,  ..., -1.3340, -2.4023, -1.9404],
         [-2.5859, -0.3589, -5.5078,  ..., -1.3721, -2.3750, -1.9805],
         [-2.5566, -0.3154, -5.3672,  ..., -1.3174, -2.3555, -1.9102]]],
       device='cuda:0')
torch.Size([2, 491, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 491, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 25, 61.7% of total tokens
encoded shape: torch.Size([2, 2181])
torch.Size([2, 2181]) tensor([[    1,   960,   445,  ...,   568,   360, 29889],
        [    1, 20635,  3582,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2181, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3652, -5.4297,  ..., -1.3828, -2.3887, -1.9004],
         [-2.5742, -0.4143, -5.3906,  ..., -1.4111, -2.3887, -1.9424],
         ...,
         [-2.5742, -0.4443, -5.5781,  ..., -1.4043, -2.3926, -1.8828],
         [-2.5684, -0.4734, -5.5156,  ..., -1.3926, -2.3633, -1.8740],
         [-2.5254, -0.3789, -5.3164,  ..., -1.4238, -2.3477, -1.9277]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6133, -0.4968, -5.4180,  ..., -1.3936, -2.4141, -1.9043],
         [-2.5820, -0.4133, -5.4688,  ..., -1.3779, -2.3535, -1.9385],
         ...,
         [-2.6113, -0.3315, -5.1211,  ..., -1.4570, -2.4707, -1.9287],
         [-2.6016, -0.3171, -5.1211,  ..., -1.4492, -2.4609, -1.9209],
         [-2.6016, -0.3171, -5.1211,  ..., -1.4492, -2.4609, -1.9209]]],
       device='cuda:0')
torch.Size([2, 2181, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 2181, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 26, 64.0% of total tokens
encoded shape: torch.Size([2, 1271])
torch.Size([2, 1271]) tensor([[    1, 16968,  1891,  ...,     2,     2,     2],
        [    1,   660, 29901,  ...,   416,    13,    13]], device='cuda:0')
torch.Size([2, 1271, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.5664, -0.3225, -5.4727,  ..., -1.3662, -2.3730, -1.8975],
         [-2.5605, -0.3394, -5.4844,  ..., -1.3486, -2.3770, -1.9072],
         ...,
         [-2.5859, -0.2537, -5.4180,  ..., -1.3770, -2.4004, -1.8936],
         [-2.5859, -0.2537, -5.4180,  ..., -1.3770, -2.4004, -1.8936],
         [-2.5820, -0.2457, -5.4180,  ..., -1.3730, -2.3965, -1.8906]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.6016, -0.4500, -5.4219,  ..., -1.4004, -2.4512, -1.9297],
         [-2.5352, -0.3069, -5.4375,  ..., -1.3574, -2.3711, -1.8701],
         ...,
         [-2.5742, -0.3503, -5.1719,  ..., -1.4346, -2.4160, -1.9404],
         [-2.5977, -0.3975, -5.0859,  ..., -1.4961, -2.4453, -1.9551],
         [-2.5898, -0.4231, -5.1992,  ..., -1.4805, -2.4141, -1.9502]]],
       device='cuda:0')
torch.Size([2, 1271, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1271, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 27, 65.8% of total tokens
encoded shape: torch.Size([2, 496])
torch.Size([2, 496]) tensor([[    1, 20019,    13,    13, 10900, 28320, 29901,  1963, 15788,    13,
            13, 29902, 30010, 29885,   451,   263, 12176, 13524,   310,  7145,
         29899, 27371,  5400, 11258, 29889,   739, 30010, 29879,  2337,  6140,
           263,  2217,   413, 20641, 29891,   322,  8656,   304,   592, 29889,
           450, 11399,   635, 29899,  2783, 12961,  2087, 22138,   375, 29892,
           278, 19975, 18001, 29892,   278,  5201,  1609, 29892,  1906, 13814,
           505,  3114,   322,   770,   304, 29337, 29889,  1205,   306, 30010,
           345,  2355,   941,  1827, 29892,  7145, 29899, 27371,  5400,   338,
         15678,   373,   592, 29889,   739, 30010, 29879,  1603,   451,   590,
         25448, 29892,   541,   306, 30010, 29885,  6257,   304, 11188,   278,
          5941,  3454,   322, 10930,   310,  2927, 29889,   739, 30010, 29879,
          1554, 29889,   739, 30010, 29879,   278, 27804,  1100, 30010, 29879,
         18551,   310,   278,  5434,  1754,  1855,   313,  6194,  1728,   278,
         22588, 29899,  4058, 29879, 29892,  4799, 29899, 29883,  1503, 29892,
           470, 10832,  1862, 29892, 15428,   467,    13,    13,  1576,  6666,
          1358, 12338,   880,   313,  8245, 29892, 27043,  6265, 29897,   338,
           278,   439,   524,   404,  2556,  7145, 29899, 27371,  5400,  5214,
         29892,   411,   967,  7254, 12917,   282,  1662,   839,  4024,  1943,
           322,  8882, 16546,   301,   283,   865,   267, 29889,  9208,  4723,
         29892,   306, 11943,  1127,   278,  5214,   411,  8425,   796,   485,
           277,  9756,  7912, 29892, 15944,   310, 12884,   293, 14650,   363,
           278,  4272, 29892,   322,   278,  3114, 13631,   373,   592,   263,
          2217,   901, 29889,    13,    13,  2887,   366, 30010,   645,  1074,
           297,   278, 14956, 29892,   278,  5214,  4225,   777,  5360, 29889,
          1205,   372,   756,  2107,   289,  2873,   322, 14568,   310, 12528,
          7145, 29899, 27371,  1652,   473, 17006, 29889,   306,  1016, 30010,
         29873,  1073,   278,  2281,  3631, 28410,   310,   278,  5214, 29892,
           825,   372, 30010, 29881,  3438,   304,   437,   408, 13318,   359,
           633,   271,   882, 29892,   379, 29963,  2477,  1518, 11259, 29892,
          2992, 29889,  1205,   263,   342,  9188,  1711, 29892,   278,  6666,
          1358, 30010, 29879,   694, 15029,  1283,  1135,   278,  4702, 29883,
           470,  2180,  7681, 13814, 29889,  1126,   278,  1776,   338, 21863,
           292, 29889,    13,    13, 29902, 30010,   345,  6091,  1449,   322,
          1449,   515, 18777,   393,   278,  9475,  3661,  2257,   309,   886,
           526,   278, 12088,   414,   813,   896, 30010,   276,   925,  2086,
          4482,   363,  9826, 30010, 29879,  9999,  6689, 29889,  1205,   278,
          5285,   310,   278, 19600, 29892, 12420,   411,   278, 10090,   310,
          5417, 29892,  1207,   278,  2257,   309,   886,  2833,  6133,  1135,
          9475,  6900, 29892,   322,   278, 19600,  1016, 30010, 29873,  4459,
          2319,   470,  2181,  1160,   287,   472,   599, 29889,    13,    13,
          1888, 22094,  4241,  7103, 19906,   338,  2309, 29892,   278,  8291,
         29911,  7927,  4523,   756,  6153,   964,   278, 11677, 28033,  5214,
         29892,   322,   278,  5400, 11952,  4287,   338,   701,   322,  2734,
           373,   422, 15667,   313,  2541,   967, 15358,   373,  1260, 29885,
           467,   450,  6666,  1358,  1033,   367,   697,   310,   278, 12528,
           342, 14157,   297, 26028,   593,   776, 29889,    13,    13, 29898,
          2855,   306,  3282, 30010, 29873, 19531,   278, 12528,  2343,   479,
           279, 10106,   278,  6282,   813,   871,   297,   278,   380,  1466,
          5872, 29879,   322,  2362,   882,   988,   372,   471, 19786, 29891,
           322, 29914,   272,  1560, 14112,  1846],
        [    1,  9041,   596,  4876,   304,  1014, 13086, 29901,    13,    13,
         29908,  8439,   338,  3078,   901, 18215,  1135,   304,  2048,   263,
         12459, 29892,   411,   263,  2919, 10768,   310,  2305,   297,   393,
         12459, 29892,  1058,  4459,   393,   896,   505,   694,   380,  1296,
           297,   372, 29936,  1058,  4459,   393,   896,   505,  3078,   304,
         14074, 29889, 11647,  1058,   505,   263,   380,  1296,   297,  1009,
         12459, 29892, 12566,   393, 12459, 29892,   541,   746,   896,  1016,
         30010, 29873,  5129,   776, 30010,   372, 29892,   896,   864,   304,
          8174,   372,  3178,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 496, 32000]) tensor([[[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5566, -0.3328, -5.4805,  ..., -1.3379, -2.3633, -1.9062],
         [-2.2832, -0.0529, -5.2109,  ..., -1.3730, -2.3379, -1.8223],
         ...,
         [-2.5215, -0.3657, -5.6875,  ..., -1.2910, -2.3535, -1.8770],
         [-2.5977, -0.4854, -5.5625,  ..., -1.3994, -2.4180, -1.9131],
         [-2.5469, -0.2996, -5.2227,  ..., -1.4082, -2.4141, -1.9502]],

        [[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5879, -0.4331, -5.4922,  ..., -1.3721, -2.4102, -1.9258],
         [-2.5664, -0.3547, -5.4258,  ..., -1.3926, -2.4004, -1.9170],
         ...,
         [-2.5781, -0.2283, -5.4492,  ..., -1.3711, -2.4004, -1.8896],
         [-2.5742, -0.2206, -5.4414,  ..., -1.3682, -2.3984, -1.8857],
         [-2.5840, -0.2356, -5.4336,  ..., -1.3770, -2.4082, -1.8936]]],
       device='cuda:0')
torch.Size([2, 496, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 496, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 28, 66.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  4957, 14910,  ...,     2,     2,     2],
        [    1, 27576,   426,  ...,  5275,   313, 12665]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4626, -5.4180,  ..., -1.3828, -2.3828, -1.9355],
         [-2.5781, -0.3979, -5.3828,  ..., -1.3770, -2.3848, -1.8955],
         ...,
         [-2.5820, -0.3049, -5.1094,  ..., -1.4512, -2.4629, -1.9199],
         [-2.5879, -0.3142, -5.1055,  ..., -1.4561, -2.4688, -1.9238],
         [-2.5840, -0.3057, -5.1016,  ..., -1.4531, -2.4648, -1.9199]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5566, -0.2886, -5.4688,  ..., -1.3828, -2.3887, -1.9023],
         [-2.5918, -0.4016, -5.3828,  ..., -1.3682, -2.4062, -1.9131],
         ...,
         [-2.6113, -0.5112, -5.5781,  ..., -1.3594, -2.4316, -1.9473],
         [-2.5664, -0.4148, -5.4844,  ..., -1.3604, -2.3867, -1.9121],
         [-2.5762, -0.4712, -5.4844,  ..., -1.3701, -2.3906, -1.8984]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 29, 70.6% of total tokens
encoded shape: torch.Size([2, 172])
torch.Size([2, 172]) tensor([[    1,  6242, 29899,  8489,  2562,   363,  9642,   966, 22863,   322,
          2652,   735,   950,  5866, 29901,   385,  7418,   310,  1857,  5925,
           322,  8898, 29889,    13,  1576, 11443,  9045,  2562,  1788, 29915,
         29879, 28289,   322, 24833,   526,  4049,  2729,   373,   263, 25745,
         29438,   950, 20346,  3942,  1904, 29889,  6242, 29899,  8489,  2562,
           313,  5850, 29907, 29897,  8898,   297,  3153,   338,  4240,   373,
          2702, 20813,  1048,  5866,   322,  2562, 29887,  4357, 29889,  9626,
          9045,  2562,   322,   365,  9472, 24833,   508,  4550,   766, 17263,
          8501,   322, 15276,   979,   675,  5866,  1058,   437,   451,  6216,
          1316,  6787,  1953, 29892,  1316,   408,  9642,   966, 22863,   322,
          2652,   735,   950,  5866, 29889, 18492,   292,   515, 12845,   373,
           966, 22863, 29892, 23852, 29892,  2652,   735,   950, 29892,   322,
          1301, 26098,  5866, 29915, 29879,  9045, 29892,   946,   292, 29892,
           322,  2562, 29887,  4357, 29892,   445,  4274,  3913,   263, 21991,
           391,  8604, 26504,  7418,   304, 22222,   393,   263, 17261,  4864,
           297,  1857,  5925,   322,  8898,   411,  3390,   304,   278,   365,
          9472,  4225,   310,  9642,   966, 22863,   322,  2652,   735,   950,
          5866, 29889],
        [    1,  1605,   436,   324,  4125,  3708, 29886,   545,   361,  4112,
           398,    13,    13,  2308,   436,   324,  4125,  3708, 29886,   545,
           361,  4112,   398,   338,   385,   946,   279,   293, 26933,   375,
           310,   278, 16106,  1605,   436,   324,  4125, 29889,  7460,   297,
         11775,   801, 29892, 26417,   423, 29892,   372,   471,  5439,   408,
           716,   304, 10466,   297, 29871, 29896, 29929, 29929, 29946,   491,
          4223,   590, 21553,   391,   382, 29889, 29967, 29889, 29950, 29889,
          2994,  1089, 29889,    13,    13, 13393,   884,    13,  1293,   310,
          1605,   436,   324,  4125,  6606,    13,    13,  1123, 10662,    13,
            13, 25865,  2988,    13,    13, 15503, 29886,   545,   361,  4112,
           398,    13, 10900, 29901, 29943,   686, 29875,  5439,   297, 29871,
         29896, 29929, 29929, 29946,    13, 10900, 29901, 29943,   686, 29875,
           310, 14325,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 172, 32000]) tensor([[[-2.5469, -0.3066, -5.0547,  ..., -1.4561, -2.4609, -1.9131],
         [-2.6055, -0.4153, -5.3867,  ..., -1.4229, -2.3945, -1.9580],
         [-2.5684, -0.4138, -5.5430,  ..., -1.3818, -2.3457, -1.9463],
         ...,
         [-2.5625, -0.3225, -5.6250,  ..., -1.3047, -2.3125, -1.9053],
         [-2.5762, -0.3535, -5.4883,  ..., -1.3447, -2.3711, -1.9375],
         [-2.5352, -0.2341, -5.4102,  ..., -1.3721, -2.3164, -1.8516]],

        [[-2.5469, -0.3066, -5.0547,  ..., -1.4561, -2.4609, -1.9131],
         [-2.5918, -0.3992, -5.4023,  ..., -1.4043, -2.4355, -1.9463],
         [-2.5645, -0.4094, -5.4062,  ..., -1.3672, -2.4004, -1.9189],
         ...,
         [-2.5820, -0.2625, -5.3594,  ..., -1.4082, -2.4004, -1.9131],
         [-2.5840, -0.2612, -5.3359,  ..., -1.4150, -2.3984, -1.9102],
         [-2.5781, -0.2515, -5.3516,  ..., -1.4062, -2.3945, -1.9072]]],
       device='cuda:0')
torch.Size([2, 172, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 172, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 30, 70.9% of total tokens
encoded shape: torch.Size([2, 1442])
torch.Size([2, 1442]) tensor([[    1, 27822, 29892,  ...,     2,     2,     2],
        [    1,  1405, 14253,  ..., 24615,  1950, 29889]], device='cuda:0')
torch.Size([2, 1442, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6035, -0.4055, -5.3711,  ..., -1.4277, -2.4453, -1.9658],
         [-2.6055, -0.3684, -5.4023,  ..., -1.3936, -2.3906, -1.9385],
         ...,
         [-2.5859, -0.2561, -5.3789,  ..., -1.3867, -2.4141, -1.8896],
         [-2.5859, -0.2554, -5.3789,  ..., -1.3867, -2.4141, -1.8896],
         [-2.5898, -0.2634, -5.3867,  ..., -1.3877, -2.4160, -1.8926]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5508, -0.3228, -5.4648,  ..., -1.3545, -2.3828, -1.8691],
         [-2.5938, -0.4429, -5.4844,  ..., -1.3691, -2.3750, -1.9521],
         ...,
         [-2.6016, -0.4641, -5.4531,  ..., -1.4268, -2.3750, -1.9404],
         [-2.5859, -0.4441, -5.4805,  ..., -1.3682, -2.3750, -1.9229],
         [-2.5566, -0.3870, -5.2656,  ..., -1.3125, -2.3242, -1.9297]]],
       device='cuda:0')
torch.Size([2, 1442, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1442, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 31, 72.8% of total tokens
encoded shape: torch.Size([2, 305])
torch.Size([2, 305]) tensor([[    1,   660, 29901,    13,    13,  9928,  1070, 29871, 29906,   448,
         21398,   411,  2224,   408,  3443,   322, 27088, 21077,    13,    13,
         29902, 29915,   345,   445,   373,   590,   775,   856,    13, 29992,
         12085,  3991,  4197,    13, 29912,  2084, 29901,  5591,  1004,   613,
          1024, 29901,   376,  6816,   613,  4163, 29901,  2191,  5308, 29892,
           671,  2887,  4592, 29901,  1565,  1118,    13, 29912,  2084, 29901,
          5591,  1004, 29914,  5628,   613,  1024, 29901,   376,  6103, 13909,
           613,  4163, 29901,  7641, 13909,  5308,  1118,    13, 29912,  2084,
         29901,  5591, 25719, 24676,  2972,   613,  1024, 29901,   376, 15666,
          1991,   613,  4163, 29901, 11647,  5308, 29913,    13,  2314,    13,
            13,  4187,   297,  1797,   304,  1207,  1554,   763,   847, 25719,
         29914, 27041,   306,   817,   304,   731,   278, 12049,   373,   278,
          4714, 21077, 29889,  1619,   937,  4218,   471,   263,  8775,  7543,
         29892,   763,   445, 29901,    13, 15965, 21077, 29889,  2344,  3319,
            13,   259,  1923, 29901,   426,    13,  4706,  2967,  9170, 29901,
           376,  6904,   613,    13,  4706, 12049, 29901,   426,    13,  9651,
          5591,  1004,  1115,   376,  2248, 29889,  1420,   613,    13,  9651,
          5591,  1004, 29914,  5628, 29908,   584,   376,  2248, 29889,  1420,
           613,    13,  9651,  5591, 25719,  5515, 29908,   584,   376,  2248,
         29889,  1420, 29908,    13,  4706,   500,    13,  1678,   500,    13,
            13,  3112, 29915, 29879,   451,  1985, 29889,  3139,  8998,  1048,
           920,   304, 10822,  4714, 21077,   304,   664,   411,  7343,  5759,
          3142, 10898,  1577,    13,  1017,  1738,    13,    13, 29909, 29901,
            13,    13,  3492,  1033, 10822,   596,   623,   304,   671, 11874,
          6508, 26910, 29889,    13,  8704, 29898,  2052,  5308, 29892,   518,
            13,  1678,   390, 12015,  1001, 29918,  8618, 13044, 23598, 29892,
            13,  1678,  3867, 29898,  6508, 26910, 29892,   426,   671,  2385,
         29901, 11874,  6508, 26910,  5615,    13,  5691,    13,    13,  2816,
         10822, 27088,   317,  2720, 10683, 29934,  2540,   304, 10683,   596,
         11575, 29871, 29906,  5782, 10898,   304,   278,  2280,  3876,  2380,
         29889,  1420, 29889,    13,    13],
        [    1,   319,   314,   381, 18915, 29901,   476,  8141,  1099, 13680,
           361, 30010, 29879,   540,  1379,  3282, 30010, 29873,  2041,   297,
           278,   982,    13,    13,  2052,   279,  2705, 29892,   278,  1224,
         24285, 11339, 12355,   267, 15655,  5866,   322,   540, 27849, 24817,
           292,   777,   564,   344,   297,   360,  1251,   290, 29901, 29941,
            13,    13,  4806,   599,  1073,   393,   319,   314,   381, 18915,
           338,   697,   310,  1906, 29701,  1058,   338,  1407, 11592,  1048,
          6053,   322,   278,  2114,   393,   540, 18012,   476,  8141,  1099,
         13680,   361,   297,   902,  1880,   540,  1379, 28281,   925,   393,
         29889,  2567, 29892,   540,  1122,   451,   367,   599,   393, 15655,
           541,   540, 17845,   393,   540, 12355,   267,  1985,   411, 15655,
          5866,  1058, 19372,   975,  1075, 29889,    13,    13,  4806,   674,
          1074,  1075,  9728,  3277,   278,   454,  1505, 29891,   476,  8141,
          1099,   297,   360,  1251,   290, 29901, 29941, 29889,  1346, 29902,
          5360, 15655,  5866,   322,   902,   313, 29968,  8141,  1099, 30010,
         29879, 29897,   540,  1379,  3282, 30010, 29873,  2041,   297,   278,
           982,  3995,   319,   314,   381,  5429,  1634,   272,  2153,   472,
           385,  1741,   304,  7475,   346,   612,  1161, 15496, 21470, 30010,
         15477,   411,  9811,   295,   304,  1653,   360, 29901, 29941, 20603,
          9078, 12203,  2261, 10993, 24930,   272,   360,  3028, 29879,  2729,
           373,  1075,   322,   476,  8141,  1099,   297,   360,  1251,   290,
         29901, 29941, 29889,    13,    13, 10454, 29892,   372, 30010, 29879,
           363,   502,   304,  1074,  3692,   278,  5101,  3732,   363,   385,
         15129,  7303,   470,   451, 29889,   399,   621, 19363, 29892,   896,
         30010,   645,   367,  1781,   472, 24817,   292,   541, 29873,   297,
           278, 14064,  5129,  1111, 29920,   896,  1716,   526, 15129, 29701,
         29889,  1724,   437,   366,  1348,  8922, 16239, 29931,   361,   414,
         29973,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 305, 32000]) tensor([[[-2.5469, -0.3059, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4487, -5.4180,  ..., -1.3994, -2.4512, -1.9287],
         [-2.5254, -0.2908, -5.4414,  ..., -1.3506, -2.3613, -1.8633],
         ...,
         [-2.5488, -0.4250, -5.2266,  ..., -1.4346, -2.3965, -1.9268],
         [-2.5762, -0.4282, -5.1172,  ..., -1.4658, -2.4551, -1.9121],
         [-2.5820, -0.4717, -5.1992,  ..., -1.4688, -2.4375, -1.9170]],

        [[-2.5469, -0.3059, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5762, -0.2979, -5.3984,  ..., -1.3936, -2.3926, -1.9590],
         [-2.5898, -0.4417, -5.3984,  ..., -1.3516, -2.4277, -1.9414],
         ...,
         [-2.5820, -0.2678, -5.3398,  ..., -1.4033, -2.3926, -1.8984],
         [-2.5781, -0.2600, -5.3438,  ..., -1.3994, -2.3906, -1.8955],
         [-2.5840, -0.2686, -5.3477,  ..., -1.4023, -2.3926, -1.8994]]],
       device='cuda:0')
torch.Size([2, 305, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 305, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 32, 73.4% of total tokens
encoded shape: torch.Size([2, 1398])
torch.Size([2, 1398]) tensor([[    1,   660, 29901,  ..., 29900,    13,    13],
        [    1,  3561, 29875,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1398, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6016, -0.4504, -5.4219,  ..., -1.4004, -2.4512, -1.9297],
         [-2.5254, -0.2908, -5.4414,  ..., -1.3506, -2.3613, -1.8633],
         ...,
         [-2.5625, -0.4214, -5.3516,  ..., -1.3818, -2.4199, -1.9287],
         [-2.5957, -0.4502, -5.0391,  ..., -1.4922, -2.4629, -1.9697],
         [-2.6211, -0.4778, -5.0664,  ..., -1.5029, -2.4785, -1.9668]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5918, -0.4519, -5.4258,  ..., -1.4189, -2.3730, -1.9189],
         [-2.5605, -0.3870, -5.5195,  ..., -1.3633, -2.3965, -1.8652],
         ...,
         [-2.5859, -0.2571, -5.3828,  ..., -1.3838, -2.4062, -1.8975],
         [-2.5859, -0.2568, -5.3867,  ..., -1.3828, -2.4043, -1.8975],
         [-2.5859, -0.2568, -5.3867,  ..., -1.3828, -2.4043, -1.8975]]],
       device='cuda:0')
torch.Size([2, 1398, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1398, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 33, 75.2% of total tokens
encoded shape: torch.Size([2, 472])
torch.Size([2, 472]) tensor([[    1,   450, 22037,  8267,   310,   278,  9481,   265,  6137,   365,
          1160,   756,  1063,  2183,   263,   716, 26309,  3969,   304,   323,
          1099,   951,   686, 29892,  1058,  8688,   445, 25798,  5400,  1873,
         29889,    13,    13, 27635,   297,   263,  4628, 29914, 10921,   470,
          4796, 29914, 12692,  8341,   267, 29889,  1383,  4512,   411, 29871,
         29946,  6900,   310,  2821, 13793,   411,  4607, 29889,   501, 29931,
          2391,   287, 29889,    13,    13, 16142,  5580,    13,    13, 29896,
         29896, 29889, 29945, 29908, 29928,  1060, 29871, 29896, 29947, 29889,
         29945, 29908, 29950,    13,    13,  5160, 29901, 29871, 29896, 29896,
         29889, 29945, 29908, 29928,    13,    13, 24095, 29898, 29879, 29897,
            13,  2527,   284, 29892, 15680,  4156, 29892, 13950, 29892, 18187,
            13,    13, 29931,  1160,  5167,    13, 21514, 17923,   383, 29931,
         29965, 29949,  1525,  7187,  3919, 29892,   315, 10536, 29892,   383,
         29931, 29965, 29949,  1525,  7187,  3919,    13,    13, 29933,   352,
          5824,    13, 29896,  1060, 29871, 29896, 29947, 29956, 29871, 29896,
         29906, 29900,   382, 29906, 29953, 29898, 27891,  2967, 29897, 11071,
         20501,  2361,  1760,   313,  1333,  5134, 29897,    13,    13,  1293,
           292,    13, 29907, 13309, 29892,   501, 29931,    13,    13,  2001,
          9681,    13,  7239, 29933, 29899,  2208, 29899,  2287, 29963,  1164,
         29899, 29896, 29899,  5265, 29954,  3912, 29899, 21009, 29899,  4375,
          3580,    13,    13,  3195, 29898, 29879, 29897, 29871, 29946, 29946,
         29900, 29896, 29900, 29955, 29896, 29871, 29946, 29946, 29900, 29896,
         29900, 29900, 29945,    13,    13,  4002,   647,  2648,   323,  1099,
           951,   686, 29892, 29871, 29906, 29900, 29896, 29941, 29889,  4591,
         12790, 29931,   994, 29889,    13,    13,  1576, 22037,  8267,   310,
           278,  9481,   265,  6137,   365,  1160,   756,  1063,  2183,   263,
           716, 26309,  3969,   304,   323,  1099,   951,   686, 29892,  1058,
          8688,   445, 25798,  5400,  1873, 29889,    13,    13, 27635,   297,
           263,  4628, 29914, 10921,   470,  4796, 29914, 12692,  8341,   267,
         29889,  1383,  4512,   411, 29871, 29946,  6900,   310,  2821, 13793,
           411,  4607, 29889,   501, 29931,  2391,   287, 29889,    13,    13,
         20769, 29931,   994,    13,    13,  1576, 12790, 29931,   994, 14348,
           338, 10423,   411,   263, 22794,  1319,  1409,   310,  5713,   486,
          1973, 10676,  3307,   304,  6356,   596,  5360,   363,  1781,  2874,
         29892,   541,  2090,  3307,   304,   734,   559,   263, 17819,   322,
          8681,   533,   594, 12418, 29889,   450, 14982,   471,  6345,   297,
           278,  6382,   262,   800,   310,  6375, 29899,   386, 18159,  2874,
           414,   515,   263, 16984,  6837,   310,  4185,  1973, 29889,    13,
            13, 10251, 17068,   534,   355, 26740, 27474,  4768, 29899,   812,
          1474,   925,   408, 13460,  2874,   414,   437,   746,   896,  2125,
           304,   278,  6635, 14625,  2039,   411,  1009,   716, 16250,   297,
           278,  7206,   322, 14053, 29892, 12790, 29931,   994, 16688,   263,
         13460,   519,  3578,   292,   281,   538,   307,   915,   304,   278,
          2874,  4048, 13308,   269,  3021,  4695,   403, 29889, 12790, 29931,
           994, 29915, 29879, 21779,  2136,   414,   885,   473,   278, 15482,
           915,   363, 10135,   352,   681, 14061,   577,   366,  1016, 29915,
         29873,   505,   304, 29889, 12790, 29931,   994, 23522,  3114,   304,
          3578, 29889],
        [    1,   448,  2683, 23648,  1152,  1328,   287,   491,  2259,   435,
           365, 17118,  1219, 29914, 29907,  1964, 29914, 13845,   373, 29871,
         29900, 29906, 29914, 29896, 29947, 29914, 29906, 29900, 29900, 29900,
         29871,    13, 29900, 29906, 29901, 29941, 29896, 11278,   448,  2683,
         28400,    13,    13,    13, 13711,   940, 19642, 29878,  1664,    13,
         29900, 29906, 29914, 29896, 29953, 29914, 29906, 29900, 29900, 29900,
         29871, 29896, 29900, 29901, 29945, 29906, 13862,    13,  1762, 29901,
          2259,   435,   365, 17118,  1219, 29914, 29907,  1964, 29914, 13845,
         29992, 13845,    13,   617, 29901,  7870,  3741,  1145, 29914,  8187,
         29965, 29914, 13845, 29992, 13845, 29871,    13, 20622, 29901,  3122,
          9206, 13249,  1166,  1338, 10781,    13,    13, 29902, 29915,   345,
          7841,   385,  3633,   363,   366,   373,   278,  3122,  9206, 13249,
          1166,  1338,  4700, 29889, 29871,    13,  1576,  3988,   363,   278,
          3268,   338, 29901, 29871,    13,  1124,   597,   522, 29886,  8235,
         29899, 11445,   650, 29889,   522, 29889,   264,  1617, 29889,   510,
         24629,   312,   493,   314, 29914,  6654, 14669, 29914,  2248, 29889,
         13357,    13,    13, 10858,  8952,   338, 29901,   432,  4112,  2207,
            13, 10858,  4800,   338, 29901,  1208, 29887, 29916, 29896, 29896,
            13,    13,  4013,  4800,   338,  1422,  1135,   596,  4226,  1174,
          1617,   405, 29911,  4800,  1363,   310, 29871,    13, 23055, 11780,
           310,  1749,  1923, 29892,   322,   366,  1122,   817,   304,  3896,
           372, 29871, 29906,   470, 29871,    13, 29941,  3064,   639,  4867,
         29892,  8679,   373,   920,  1784, 10161,   310,  1749,  3268,   366,
          6493, 29889,  1334, 29871,    13,   276,  2055,   355,   671,   310,
          7783,  4685, 21508, 29871, 29945, 29892,   607,  3743,   263,   376,
          1745,  1096, 29871,    13,  5630, 29908,  1423,  3800, 29892,   304,
         10032, 19229, 29889,    13,    13, 12148,  1246,   592,   472, 29871,
         29945, 29900, 29941, 29889, 29946, 29953, 29946, 29889, 29955, 29946,
         29953, 29906,   565,   366,   505,   738,  4828, 16791, 29889,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 472, 32000]) tensor([[[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5918, -0.2725, -5.3867,  ..., -1.4014, -2.3906, -1.9268],
         [-2.6035, -0.3994, -5.3359,  ..., -1.4131, -2.4141, -1.9453],
         ...,
         [-2.5449, -0.3792, -5.4648,  ..., -1.3574, -2.3457, -1.8955],
         [-2.5879, -0.4424, -5.4531,  ..., -1.3877, -2.3809, -1.9141],
         [-2.5469, -0.2988, -5.1797,  ..., -1.3555, -2.3965, -1.9229]],

        [[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5684, -0.3418, -5.4922,  ..., -1.3584, -2.4121, -1.8682],
         [-2.5645, -0.3774, -5.4102,  ..., -1.3535, -2.4277, -1.9023],
         ...,
         [-2.5781, -0.2573, -5.4219,  ..., -1.3867, -2.4121, -1.8799],
         [-2.5781, -0.2573, -5.4219,  ..., -1.3877, -2.4121, -1.8809],
         [-2.5840, -0.2654, -5.4180,  ..., -1.3906, -2.4160, -1.8848]]],
       device='cuda:0')
torch.Size([2, 472, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 472, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 34, 75.9% of total tokens
encoded shape: torch.Size([2, 520])
torch.Size([2, 520]) tensor([[    1, 10705, 17594,  ...,     2,     2,     2],
        [    1, 12753, 29899,  ...,  6352,  6656, 29889]], device='cuda:0')
torch.Size([2, 520, 32000]) tensor([[[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5977, -0.4292, -5.3203,  ..., -1.4297, -2.4297, -1.9463],
         [-2.5918, -0.4321, -5.4141,  ..., -1.3730, -2.3555, -1.9307],
         ...,
         [-2.5820, -0.2974, -5.3164,  ..., -1.4111, -2.4160, -1.9209],
         [-2.5781, -0.2881, -5.3203,  ..., -1.4082, -2.4141, -1.9189],
         [-2.5859, -0.2961, -5.3125,  ..., -1.4121, -2.4219, -1.9248]],

        [[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3750, -5.3828,  ..., -1.4434, -2.4180, -1.9395],
         [-2.5762, -0.4041, -5.4844,  ..., -1.4082, -2.3867, -1.9326],
         ...,
         [-2.4941, -0.3469, -5.6328,  ..., -1.2988, -2.3340, -1.8896],
         [-2.5527, -0.3484, -5.4766,  ..., -1.3936, -2.3945, -1.9219],
         [-2.5391, -0.3269, -5.2891,  ..., -1.3662, -2.4199, -1.9189]]],
       device='cuda:0')
torch.Size([2, 520, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 520, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 35, 76.9% of total tokens
encoded shape: torch.Size([2, 200])
torch.Size([2, 200]) tensor([[    1, 26475, 29879,   310,   260,  2782,   373,  1880, 29899,  9778,
           918,   319,  4037, 29899,  1254, 12665,  6382,   292, 29889,    13,
         29909,  6559,   310,   278,  9545,   310,  2319, 29899,  2521,  1580,
         19933,   260,  2782,   373,  1880, 29899,  9778,   918,  2889,  1070,
          6501,  1746,  4558,   471,  8988,   714,   363,   885,  9450, 22713,
         11966,  9200, 21785,   267,   411,   443, 15728,   287,   322,  6126,
         29878,   362, 29899, 15728,   287,  2070,   267,   773,  1773,   275,
          5897, 23876, 29889,   450,  2582, 12266,   393,  1584,   297,   278,
          4251,   310,  1580, 19933,  6928,  1372,   310,   278,  1797,   310,
         29871, 29896,  7426,   263,  7329,   310, 29871, 29906, 20376,   297,
           278, 12814,   310,   278,  1880, 29899,  9778,   918,  1967,   881,
           367,  3806, 29889,   450,  2779,  8640,   363,  1422,  7769,   800,
           310,   278, 10901, 11195, 29889, 20535,   800,   884, 12266,   393,
           408,   278,   260,  2782,   287,  1580, 19933,  4947,   266,  6541,
           278, 12814, 20376, 16415, 29889,  1954,  1179,  1027,  7964,   411,
           263,  4482, 29899,  2521,  2889,  1070,  6501,  1746,  1439,  3019,
          1510,   393,   260,  2782,  9545,   526,   901, 11504, 20979,   297,
           445,  1206,   322,  4368,   393,  1438,  4482, 29899,  2521,  6459,
           943,   508,   367,  1304,   304,  1959,  1580, 19933,   260,  2782,
          2645,   885,  9450, 22713, 11966,  9200, 21785,   267,  5858, 29889],
        [    1, 10522, 28320, 29901,   330,   945, 29877,  5807,   688,  2426,
         29871, 29941, 29945,    13,    13, 10401,   372,  5304,   304, 17420,
         28056,  1559, 22091, 29892,   366,  1122,  1284,  7535, 23382,   278,
           678,   293,  1111,  7670,  9202, 29871, 29941, 29900,  1704, 12949,
           322,   278,   402,   945, 29877, 22639,   688,  2426, 29871, 29941,
         29945,  1704,   922,   271, 29889,  1094,   680,   515,   278,  6924,
          4328, 29892,   607,   338,   278,  8666, 29892,  1438,  1023, 28056,
          1559, 22091, 16088,  2866, 14150,  5183, 10309,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 200, 32000]) tensor([[[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5938, -0.3735, -5.4727,  ..., -1.3779, -2.4375, -1.9375],
         [-2.5781, -0.3267, -5.5000,  ..., -1.3682, -2.4102, -1.9521],
         ...,
         [-2.5469, -0.3948, -5.5156,  ..., -1.2646, -2.3750, -1.9141],
         [-2.6035, -0.4331, -5.4180,  ..., -1.3418, -2.4062, -1.9678],
         [-2.5293, -0.2910, -5.2344,  ..., -1.3594, -2.3848, -1.8867]],

        [[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5625, -0.4099, -5.5039,  ..., -1.3496, -2.3906, -1.9170],
         [-2.5664, -0.4043, -5.4062,  ..., -1.3447, -2.4082, -1.9238],
         ...,
         [-2.5879, -0.2520, -5.4453,  ..., -1.3818, -2.4004, -1.8906],
         [-2.5879, -0.2529, -5.4414,  ..., -1.3828, -2.4023, -1.8906],
         [-2.5879, -0.2507, -5.4414,  ..., -1.3828, -2.4023, -1.8887]]],
       device='cuda:0')
torch.Size([2, 200, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 200, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 36, 77.1% of total tokens
encoded shape: torch.Size([2, 361])
torch.Size([2, 361]) tensor([[    1,   390,  2890,   322,  5198,  1540,  1462, 23881,   297,  1020,
           398,  2454, 19253, 29889,    13,   855,   326,  2785,   310,  3240,
           293,  7207,   355,   720,   295,   616,   740,   471,  9251,  4318,
           304, 12566,  2750,   278, 27721,   310,  1020,   398,  2454, 19253,
         29892,   541,   610,   912, 29916,  1711,  5195, 20436,  2785,  7470,
           304, 23806,   278,  1353,   310,  3677,   747,  1486, 29899,   689,
           292,  9101,   393,  8906,   515,  5198,   348,  2133,   411, 25745,
          1189,   681,   604,  1541,   307,  1270,  2167, 29889,   319, 23806,
           297,   278,  1353,   310,  9736,   324,  3637,   293,  2174,   802,
         29899,   689,   292,  9101,   313, 29925,  8610, 29897,   471, 29207,
           297,  1020, 10859, 29899,   690, 22137, 15006, 29892, 13452,   385,
         11664,  1353,   310,  9101,   471,  7371,   491,  2411,  1466,   292,
           278,  1374,   351,   542,  3637,   293,  6354,   310,  5195,  9101,
         29889,   512,  1797,   304,  8161,  3692,  1374,   351,   542,  3637,
           293,   470,   594,  2276,   296,  9101,   515,  7548,   269,   552,
           264,  3038, 10223,   800,   892, 21301,   292,   278,   349,  8610,
          2933, 29892, 11758,   561,  1179,   892,  6206,   411,   263, 10710,
          1156,  5528,   431,  1218,   411,  1559, 29890,  2592, 29880, 13977,
          4764,   672,   363,   697,  7234, 29889, 11264,  4185,  1973,   892,
         13240,   411, 12849,   269,   552,   264,  9101, 29889,   450,  9736,
           324,  3637,   293,  2174,   802, 29899,   689,   292, 13284, 11664,
         29871, 29945, 29900, 29899,  8771,   515,  2761, 12849,   269,   552,
           264,  4185,  1973,   408,  9401,   304,  1906,   515,   607,   269,
           552,   264, 11758,   561,  1179,   892,  6206, 29889,   450,  6124,
           310,   385,  5186,  1353,   310,   594,  2276,   296,  1374,   351,
           542,  3637,   293,  9101,   304,  4185,  1973,   310, 11758,   561,
           482, 29899,   311,   552,  9446,   269,   552,   264,  9101,  5557,
           287,   445,  7910, 29889,  4326, 19783,  1179,  2198,   297,   278,
           269,   552,   264,  2615,   304,   367, 14040,   363,   445,  4482,
           349,  8610,  2933,   297,   278,  7548,   322,  1122, 21301,   278,
          3677,   747,  1486, 29899,   689,   292,  3038,  2933,   304, 10014,
           364,  1446, 29889,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2],
        [    1,   660, 29901,    13,    13, 29902,   893,   434,   297,   773,
           796, 29916,   292,  3025,  7609,   565,  5386,   330,   468, 29887,
           793,   338,  5130,    13,    13, 29902,   626,   773,  1494,   775,
           304, 15928,  2261,   401,   885,  7310, 11446,   515,   796,   292,
         29871,    13,  3597, 11025, 29889, 15909,   286, 29083,   353,   716,
         11025, 29889, 15909,   580,   426,    13,  1678,   970,  1780, 14478,
         29898,  1043,   325, 29897,   426,    13,  4706, 11171,  7609,   353,
           716, 11171,   703,   510, 29889,  3608, 29889, 29920, 29916,   292,
         29889,  4645, 29889,  2843, 29889,  7187,  2190,  1496,    13,  4706,
          7609, 29889,   649, 18126,   703,  7187,  2190, 29918, 20387,   613,
           376, 29984, 29934, 29918, 16524, 29918, 20387,  1496,    13,  4706,
          1369,  3886,  2831,  3591, 29898, 14029, 29892, 29871, 29900,   416,
            13,  1678,   500,    13,  3400,    13,    13,  3597,  1780,   373,
          3886,  3591, 29898,   524,  2009,  3399, 29892,   938,  1121,  3399,
         29892, 11171,  7609, 29897,   426,    13,  1678,   565,   313,  3827,
          3399,  1275, 29871, 29900, 29897,   426,    13,  4706,   565,   313,
          2914,  3399,  1275,   390,  2890,  8647, 29918,  8949, 29897,   426,
            13,  9651,  1714,  8118,   353,  7609, 29889, 13719, 18126,   703,
          7187,  2190, 29918, 15989,  8647,  1496,    13,  9651,  1714,  3402,
           353,  7609, 29889, 13719, 18126,   703,  7187,  2190, 29918, 15989,
          8647, 29918, 19094,  1299,  1496,    13,  9651,   849, 29273,  9150,
         12812,    13,  4706,   500,  1683,   565,   313,  2914,  3399,  1275,
           390,  2890,  8647, 29918, 29907, 23219, 20566, 29897,   426,    13,
          9651,   849, 29273, 12611,    13,  4706,   500,    13,  1678,   500,
            13, 29913,    13,    13,  1576,  1108,   338,   565,  2261,   401,
           885,  7310,   623,   338,   451,  5130,   322,  1404,   756,   738,
           916,   885,  9450,   623,   763,  5386,   330,   468, 29887,   793,
           474,  4555,   679,  7429,  1121,  1250, 29889,  4013, 16706,   590,
          2280, 29889, 29871,    13,  3624,   727,   738,   982,   297,   607,
           474,   508,  5557,   445, 13626,    13,    13, 29909, 29901,    13,
            13,  8241, 29889,  1246, 11171, 29889,   842, 14459,   580,   411,
           995,   376,   510, 29889,  3608, 29889, 29920, 29916,   292, 29889,
          4645, 29889,  2843,  1642,   910,   674,  4889,   372,   304,   871,
          3544,   263,  2933,   515,  2261,   401, 23412, 29889,    13,  9842,
          3138,   393,   445,   674,  1207,   372,  9301,   363,   916, 11446,
           304, 10049, 29892,   763,  2261,   401, 23412, 29974, 29889,    13,
            13]], device='cuda:0')
torch.Size([2, 361, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6016, -0.3684, -5.3203,  ..., -1.4053, -2.4102, -1.9434],
         [-2.5762, -0.4429, -5.4805,  ..., -1.3564, -2.4180, -1.9385],
         ...,
         [-2.5840, -0.2688, -5.3555,  ..., -1.4102, -2.3965, -1.9062],
         [-2.5820, -0.2668, -5.3555,  ..., -1.4092, -2.3965, -1.9062],
         [-2.5918, -0.2798, -5.3555,  ..., -1.4170, -2.4043, -1.9150]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6016, -0.4492, -5.4219,  ..., -1.4004, -2.4512, -1.9287],
         [-2.5352, -0.3059, -5.4375,  ..., -1.3584, -2.3711, -1.8711],
         ...,
         [-2.5449, -0.3904, -5.1211,  ..., -1.4375, -2.3691, -1.9775],
         [-2.5742, -0.4104, -5.0508,  ..., -1.4990, -2.4316, -1.9619],
         [-2.5820, -0.4270, -5.1875,  ..., -1.4658, -2.4062, -1.9600]]],
       device='cuda:0')
torch.Size([2, 361, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 361, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 37, 77.8% of total tokens
encoded shape: torch.Size([2, 612])
torch.Size([2, 612]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1,   319,   716,  ...,   260, 12175, 29889]], device='cuda:0')
torch.Size([2, 612, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4492, -5.4219,  ..., -1.3994, -2.4512, -1.9297],
         [-2.5352, -0.3059, -5.4375,  ..., -1.3584, -2.3711, -1.8711],
         ...,
         [-2.5762, -0.2410, -5.4414,  ..., -1.3809, -2.4062, -1.8828],
         [-2.5820, -0.2500, -5.4453,  ..., -1.3838, -2.4102, -1.8867],
         [-2.5820, -0.2496, -5.4453,  ..., -1.3838, -2.4102, -1.8867]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5859, -0.3120, -5.3984,  ..., -1.4014, -2.4004, -1.9678],
         [-2.6055, -0.4297, -5.3516,  ..., -1.4277, -2.3926, -1.9453],
         ...,
         [-2.5020, -0.3091, -5.6484,  ..., -1.2559, -2.3477, -1.8652],
         [-2.5820, -0.3486, -5.4297,  ..., -1.3389, -2.4355, -1.9160],
         [-2.5391, -0.3318, -5.2617,  ..., -1.3721, -2.4199, -1.9209]]],
       device='cuda:0')
torch.Size([2, 612, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 612, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 38, 78.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   660, 29901,  ...,     2,     2,     2],
        [    1, 14883, 12217,  ...,  2087, 29885,  2859]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4492, -5.4180,  ..., -1.3994, -2.4512, -1.9287],
         [-2.5254, -0.2905, -5.4414,  ..., -1.3506, -2.3613, -1.8623],
         ...,
         [-2.6074, -0.3379, -5.1055,  ..., -1.4600, -2.4727, -1.9277],
         [-2.6074, -0.3376, -5.1055,  ..., -1.4600, -2.4727, -1.9268],
         [-2.6074, -0.3367, -5.1055,  ..., -1.4600, -2.4707, -1.9268]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6133, -0.4094, -5.3672,  ..., -1.4326, -2.4609, -1.9600],
         [-2.5527, -0.3608, -5.3711,  ..., -1.3789, -2.3926, -1.9062],
         ...,
         [-2.5742, -0.4712, -5.5195,  ..., -1.3887, -2.3691, -1.9238],
         [-2.5254, -0.3816, -5.5078,  ..., -1.3496, -2.3535, -1.8643],
         [-2.5469, -0.3550, -5.4727,  ..., -1.3379, -2.3730, -1.9053]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 39, 83.4% of total tokens
encoded shape: torch.Size([2, 483])
torch.Size([2, 483]) tensor([[    1, 19184, 29899,   562,  5958,  5065,  3821, 22330,   297, 20309,
          8581,   491,  1109,   510, 11078,   262, 29899,   690, 22137,  9041,
           542,   542,  8668,  2258,   687,  5711, 24899,   936, 11695,   403,
         29889,    13,  4806,  2198,   263,  1206,   310,  5065,  3821, 22330,
           297, 20309,  8581,   491,  1109,   510, 11078,   262, 29899,   690,
         22137,  9041,   542,   542,  8668,  2258,   687,  5711, 29889,   450,
         16500,   338,   263, 29871, 29953, 29906, 29899,  6360, 29899,  1025,
          6114,  6445,   694,  7786,  7336,   986,  2925, 29889,   450, 23968,
          9200,  6388,  1608,   471, 15659,   491, 20140, 29083,   313,  7698,
          2287, 29897,   322,  3450,   313, 29933,   601, 29924, 10681,  1314,
         29897,   322,  2858,  1547,  4127,   471,  1223, 11517,   491,  8086,
         23253, 29892,   382, 29899,  1688,   322,  2545,   386,  9200, 29881,
           309,   918, 29889,   450, 11695,   403,   471, 15659,   408,  9041,
           542,   542,  8668,  2258,   687,  5711,   322, 10018,  1880,   341,
          2965,   363,  1109,   510, 11078,   262,   313, 29958, 29896, 29906,
         29947,   286, 29887, 29914, 29880, 29897,   322,   734,   293,   459,
          6468,   262,   313, 29947,   286, 29887, 29914, 29880, 29897,   541,
           471,  2858,  1547,  1821,   304,   626, 16447,   453,   262, 29889,
           450, 22713, 12049,   310,  1109,   510, 11078,   262, 29899,   690,
         22137,  3896,   542,   542,   455,   297,   278,  7881,   322,  1009,
         24899,   936,  2411,  5795,  3933, 17999, 29889, 15202, 29891, 19638,
           414,   505,  2307,  1063,  5439,   297,  3196, 10916,   541,   445,
          1206,  3461, 11524,   385, 22910,  9138, 29889,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,   422, 20941,   310,   278,   975, 29899,  1552, 29899,  2813,
         29892,  2678,   284,   322,  5136,  1218, 11909,  2645,  5881, 21260,
           352,  3712,   653,   620, 22142,  7018,  8560,   491,   263,  2323,
           620, 29883,  2853,   411,   263, 19548,   489,   791,   345,   489,
         13168,  4742, 29889,    13,  1576, 29871, 29906, 29900, 29900, 29945,
          1410, 10652,  1475,   363,  5881, 21260,   352,  3712,   653,   620,
         22142,  7018,   313,  6271, 29934, 29897,   437,   451,  3160,   263,
          3229,   373,  4180,   310,  6996,  2834,  2304,   491,   263,  2323,
          9045, 18020, 10257,   773,   263, 19548, 29899,   791,   345, 29899,
         13168,  4742, 29889, 12753, 11909,   526,  1950, 29901,   521,   342,
         27122,  1080,   322,  9712,   309,   800,   515,   975,   278,  2343,
           310,   278,  3209,   950,  1017,   313,   957, 29899,  1552, 29899,
          2813,   315, 10593,   511,   515,   278,  2625,   310,   278,  3209,
           950,  1017,   313, 29880,  1008,   284,   315, 10593,   511,   322,
           521,   342, 27122,  1080,   515,   278,  2625,   322,  9712,   309,
           800,   515,   975,   278,  2343,   310,   278,  3209,   950,  1017,
           313, 26123,  1218,   315, 10593,   467,   450, 12242,   310,   445,
          6559,   471,   304,  7252,   315, 10593, 11029,   310,  1438,  2211,
         11909, 29889, 29871, 29896, 29900, 29906,  9045, 18020,  6351,  1338,
           892,  4036,  3368,   304,   263,   274,  1883,   578,   369,  2874,
           322,  8560,   263, 29871, 29906, 29899,  1195,   315, 10593,  1243,
           373,   263,   767,   638,   262,   363,  1269,  2602, 29889,   450,
          6567, 29899,  2696,   931,   975,   263, 29871, 29906, 29899,  1195,
          7292,   471,   451, 16951,  1422,  1546,   975, 29899,  1552, 29899,
          2813,   313,  2168,   713, 29871, 29941, 29896,   269, 29897,   322,
          2678,   284,   313, 29941, 29896,   269, 29897,   315, 10593, 29892,
           541,  1438,  9401,  5025,   283,  4201,   368,   411,  5136,  1218,
           315, 10593,   313, 29941, 29953,   269,   467,  6811, 29899,  1552,
         29899,  2813,   315, 10593, 20601,   297, 16951,   901,   521,   342,
         27122,  1080,   313, 29896, 29945, 29945, 29897,  9401,   411,  2678,
           284,   313, 29896, 29945, 29906, 29897,   322,  5136,  1218,   315,
         10593,   313, 29896, 29946, 29929,   416,   278,  1353,   310,  1959,
           521,   342, 27122,  1080,  1258,   451,  1163, 16951,   313, 29896,
         29896, 29929,  7186, 29871, 29896, 29906, 29906,  7186, 29871, 29896,
         29900, 29929,   467, 12440,  1218,   315, 10593, 20601,   297, 16951,
          3109,  4414,   800,   313, 29872,   523, 29897,  9401,   411,   975,
         29899,  1552, 29899,  2813,   313,   841, 29897,   322,  2678,   284,
           315, 10593,   313,   841,   467, 12699,   284,   315, 10593,  5331,
           304, 16951,  3109,  1959,  4414,   800,   313, 17536, 29897,  9401,
           411,   975, 29899,  1552, 29899,  2813,   313, 20818, 29897,   322,
          5136,  1218,   315, 10593,   313, 17823,   467,   512,   278,  1206,
           310,   263,  2323,  9045, 18020, 10257,   773,   263, 19548, 29899,
           791,   345, 29899, 13168,  4742, 29892,   278, 11029,   310,   975,
         29899,  1552, 29899,  2813,   315, 10593,   338,   472,  3203,  7126,
           304,  2678,   284, 29892,   322, 11558,   304,  5136,  1218,   315,
         10593, 29889,  7311,   310,   278,  7037, 23553,   297, 19548, 29899,
           791,   345, 29899, 13168,  9712,  8634,   297,   278,  2678,   284,
          2602, 29892,   278, 15717,  6907,   975, 29899,  1552, 29899,  2813,
           315, 10593, 29889]], device='cuda:0')
torch.Size([2, 483, 32000]) tensor([[[-2.5371, -0.2917, -5.0586,  ..., -1.4482, -2.4512, -1.9033],
         [-2.5801, -0.3503, -5.4414,  ..., -1.4189, -2.3711, -1.9287],
         [-2.5430, -0.3723, -5.5625,  ..., -1.3740, -2.3320, -1.8945],
         ...,
         [-2.5762, -0.2260, -5.5391,  ..., -1.3584, -2.3809, -1.8828],
         [-2.5820, -0.2345, -5.5391,  ..., -1.3613, -2.3848, -1.8877],
         [-2.5762, -0.2256, -5.5469,  ..., -1.3574, -2.3809, -1.8838]],

        [[-2.5371, -0.2917, -5.0586,  ..., -1.4482, -2.4512, -1.9033],
         [-2.6016, -0.4763, -5.3789,  ..., -1.3633, -2.4219, -1.9463],
         [-2.5840, -0.4097, -5.4453,  ..., -1.3887, -2.4082, -1.9551],
         ...,
         [-2.5566, -0.3501, -5.4492,  ..., -1.3506, -2.3691, -1.9443],
         [-2.6172, -0.4978, -5.4648,  ..., -1.4111, -2.3789, -1.9160],
         [-2.5605, -0.3481, -5.3008,  ..., -1.3848, -2.3867, -1.9111]]],
       device='cuda:0')
torch.Size([2, 483, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 483, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 40, 84.1% of total tokens
encoded shape: torch.Size([2, 484])
torch.Size([2, 484]) tensor([[    1, 20693,  3039, 15038,   363,   269,   329,  3864,   281,  3885,
           310,  4280, 25834,   304,  9926,   261,   540, 12818, 29889,    13,
          5015,   404,   338,   697,   310,   278,  1784,  4768,  5996, 13879,
           393, 13582,   385,  4100,  6297,   297,   281,   618,   540, 12818,
         29889,   739,   338,  5480, 18853,   304, 27599,   851, 15322,  2820,
           278,   281,   618, 18424, 17237,  1711, 29892,  7148,   746,   694,
         29688,   573, 29914,  5464,   262,  4428,   573, 11043,   304,  5645,
         22884,  4153,   338,  3625, 29889,   450, 12091,   310,   445,  5650,
           338,   304,  8161,   278, 12786,   310,  1880,   851, 15322,   322,
           278, 14413,  4766,   310,   269,   329,  3864,   281,  3885,   310,
          4280, 25834, 29889,   739,   338, 13752,   267,  1891,   393,   278,
         14413,  4766,   310,   269,   329,  3864,   281,  3885,   338,   393,
          4766,   607,   674,  7738,  9212,  5882,   851, 15322, 29889,   450,
          8093,  1543,  1158,   313, 29943, 12665, 29897,  5703,   292,   278,
          6996, 10693,   310,   560,  6288,   537,  6368,   363, 14219, 28467,
           293, 17279,   338,  3667,  1891,   304, 10272,   278,  5882,   851,
         15322,   322, 12272,  4620,  4110,  9819,   515,   269,   329,  3864,
         16451,  5560, 29892, 22434,   415,   936,   322,  3367,  6825,   281,
          3885,   297,  5199,   633,  3129,   979, 19309, 29889,   450, 14413,
           269,   329,  3864,  4766,   363,   278,  3367,  6825,   281,   618,
           338, 10087, 29889,   450,  6588, 22884, 16285,   363, 24099,   269,
           329,  3864,  9027,   526,   884, 10087,   607,   508,  3867,  5407,
         24899,   936,  2472,   363,   278,  1190, 25339, 29889,  4001, 12786,
           310,  1880,   851, 15322,   297, 25300,   936,  4694,  1973,  7738,
           594,  3901,  6602, 29879,   373,   540, 12818,   322, 21990,  5802,
         29892,   445,   664,   310,  8500,   292, 10161,   310,  1880,   851,
         15322,   338,  5407,   297, 23941, 12786,   310,  5232,   540, 12818,
           297,   281,  3885, 29889,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2],
        [    1,  2812,   327,  1848,   751,   351, 29885,  2658,    13,    13,
          2887,  4856,  1058,   756, 10398,   278, 13426, 18618,   310,   902,
          3252,   296,   583,  5722,  1711,  2323,   313, 29953,   714,   310,
          3006,  2440, 29892,  1283,   322,   373,   511,   306,   723,   763,
           278, 11608,  2133,   310,  9443,  4660,   267,   304,   367,   337,
         11292, 29889,    13,    13,  3379,  1479,   310,   925,  2323,   470,
          5129,   797,   263,  9443, 30010,  1641,   278,  3918,  4958,   304,
          8453,  6743,  9443,  4660, 29892,   727,  1033,   367, 29871, 29941,
          5936,  3368, 13997, 29901, 16740, 29892,   512,   385,  2812,   327,
          1848,   751,   351, 29885,   533, 29892,   322,   512,   263,  6376,
           800,  4034, 29889,    13,    13,  4013,   338,  1363,   727,   338,
          6892,  1407,  2217,   931,   746,   697,   338,  2869,  6446,  6284,
          2323,   322, 11223,   763,   263,  6095, 26940,  4226,  5199,  1641,
          2793,   304,  1074,  7875,   322,  3942,   322,   748,   373, 24866,
          8753,   333,  1036,   322,  1652,  2728,   714,  6617,  5794,   322,
          6892, 13389,  6743,   761,  1919,   322,  2012,  1641,  5129, 14369,
         30010,   427,  2388,   465,   267,   263,  3287,   310,   931,   988,
           727,   338,  4856,   373,   278, 28205,  1058,   338,  4473,   292,
           366,  2820, 29892,   470,   393,   366,   526,  4473,   292,  2820,
          1363,   366,  1348,   366,   508,   437,  2253, 29889,  1126,   297,
           738,  1206,   372, 30010, 29879,  6668,  1486, 12092,   322,  4893,
           701,   982,  2086,  1568,   931,   322,  7225,   322, 10614,   411,
          5192,  1829, 29892,   474, 29889, 29872, 29889,   366,   526,   297,
           385,  2812,   327,  1848,   751,   351, 29885,   533, 29889,   313,
          2499,   725,  6703,   591,  1033,  1246,   445,  7408,  1641,   383,
           384, 29893,  4430, 29892,   394, 29874,  1771,  3690, 10920, 29897,
            13,    13,  3644,   445,   471,   278,  5936,  3368, 11608,  4371,
           310,  2712, 29892,  2305,  1058,   526,   512,   263,  6376,   800,
          4034,   313, 15970,   881,  2289,  1423,   304,  1207,  1854,   896,
           526,   451,  2869,   297,   263,   751,   351, 29885,   533, 29897,
          1033,  5040,  1641,  2148,  9977,  2548,   304, 16740,  2305, 29892,
           322,  4078,   599,  1009,  9443,  9848,   363,  1906,   297,   263,
           751,   351, 29885,   533, 29889,  1126,  1906,  2305,  1058,   526,
           297,   263,   751,   351, 29885,   533,   322,  4473,   292, 18462,
          2820,  1033,  1925,   701,  1009,  6567,   322, 20000,   304,   451,
          2869,  2289, 24507,   304,   367,   411,   278,   916,  2022, 29892,
           322,  2250,  2354,  4337,   964,   263, 29120,   262,   873, 16740,
          2022,  8576,  1728,  8866,   310,  1641,  5148,   472, 28875, 11687,
           746,   896,  1510,   701,   472,   263, 14837,  8497,  1728,   263,
          2298,   697, 29889,    13,    13, 15666,  1991,  1033,   884,   297,
          2498,   367,   901,  8004,   393,  2834,   947,   451,  2317,  1603,
           322, 16740,  2305,   322,  1906,   297,   263,  9443,  1286,   508,
          1284,  6053,   297,   263,   439,   351, 29885,   533,  2678,   373,
           565,   896,   526,   451, 15993,   411,  6053,   322,  1269,   916,
           322,  1207,   385,  7225,   304, 23120,   313, 17565,   278,  2712,
           366,  5110,   746,   366,  2507, 29871, 29941, 29900,   467,    13,
            13, 29902,  4966,   304,  1074,  5129,   797,   263,   751,   351,
         29885,   533, 30010,   373,   263, 16411,  4720, 29889,   830,  2212,
           625,  2323,  2305, 29991]], device='cuda:0')
torch.Size([2, 484, 32000]) tensor([[[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.6055, -0.4346, -5.4531,  ..., -1.3594, -2.4199, -1.9023],
         [-2.5664, -0.3467, -5.5039,  ..., -1.3506, -2.3809, -1.8887],
         ...,
         [-2.5840, -0.2568, -5.4141,  ..., -1.3848, -2.4023, -1.8916],
         [-2.5781, -0.2488, -5.4180,  ..., -1.3809, -2.3984, -1.8887],
         [-2.5781, -0.2484, -5.4258,  ..., -1.3799, -2.3965, -1.8887]],

        [[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5898, -0.4666, -5.4688,  ..., -1.3926, -2.4277, -1.9443],
         [-2.5781, -0.4114, -5.5312,  ..., -1.3506, -2.3984, -1.9219],
         ...,
         [-2.6055, -0.4785, -5.3750,  ..., -1.4248, -2.3867, -1.9922],
         [-2.6074, -0.4656, -5.3789,  ..., -1.4014, -2.4004, -1.9883],
         [-2.5430, -0.3501, -5.1992,  ..., -1.3574, -2.3965, -1.9678]]],
       device='cuda:0')
torch.Size([2, 484, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [30488],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 484, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 41, 84.8% of total tokens
encoded shape: torch.Size([2, 520])
torch.Size([2, 520]) tensor([[    1,  1738, 29961,  ..., 29906, 29889,    13],
        [    1,  6204, 11328,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 520, 32000]) tensor([[[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5898, -0.3745, -5.4023,  ..., -1.4004, -2.4297, -1.9199],
         [-2.5879, -0.4854, -5.3906,  ..., -1.3975, -2.4355, -1.9170],
         ...,
         [-2.5938, -0.3857, -5.4844,  ..., -1.3770, -2.3496, -1.9170],
         [-2.5391, -0.3330, -5.3984,  ..., -1.3105, -2.3301, -1.8906],
         [-2.5605, -0.4077, -5.2227,  ..., -1.3750, -2.3633, -1.9102]],

        [[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5859, -0.3726, -5.4453,  ..., -1.4053, -2.4453, -1.9102],
         [-2.5742, -0.3950, -5.4570,  ..., -1.3984, -2.4043, -1.9326],
         ...,
         [-2.5859, -0.2654, -5.3594,  ..., -1.3955, -2.4141, -1.8984],
         [-2.5801, -0.2578, -5.3594,  ..., -1.3906, -2.4082, -1.8936],
         [-2.5859, -0.2649, -5.3594,  ..., -1.3965, -2.4141, -1.8984]]],
       device='cuda:0')
torch.Size([2, 520, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 520, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 42, 85.7% of total tokens
encoded shape: torch.Size([2, 1801])
torch.Size([2, 1801]) tensor([[    1,   660, 29901,  ..., 29889,    13,    13],
        [    1,  1174, 24855,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1801, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6016, -0.4504, -5.4219,  ..., -1.4004, -2.4512, -1.9297],
         [-2.5254, -0.2908, -5.4414,  ..., -1.3506, -2.3613, -1.8633],
         ...,
         [-2.5684, -0.4460, -5.2266,  ..., -1.4023, -2.3398, -1.9189],
         [-2.5527, -0.3291, -5.2344,  ..., -1.4199, -2.4375, -1.9248],
         [-2.5820, -0.4248, -5.2969,  ..., -1.4268, -2.4395, -1.9395]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5977, -0.4607, -5.3594,  ..., -1.3564, -2.3926, -1.8945],
         [-2.5625, -0.3921, -5.3906,  ..., -1.3926, -2.3945, -1.9072],
         ...,
         [-2.6035, -0.3123, -5.1914,  ..., -1.4385, -2.4492, -1.9160],
         [-2.6035, -0.3120, -5.1914,  ..., -1.4385, -2.4492, -1.9160],
         [-2.6035, -0.3123, -5.1914,  ..., -1.4385, -2.4492, -1.9160]]],
       device='cuda:0')
torch.Size([2, 1801, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1801, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 43, 87.7% of total tokens
encoded shape: torch.Size([2, 814])
torch.Size([2, 814]) tensor([[    1,   660, 29901,  ..., 29901,    13,    13],
        [    1,   660, 29901,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 814, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.6016, -0.4500, -5.4219,  ..., -1.4004, -2.4512, -1.9297],
         [-2.5352, -0.3069, -5.4375,  ..., -1.3574, -2.3711, -1.8701],
         ...,
         [-2.5781, -0.4260, -5.2734,  ..., -1.4453, -2.3789, -1.9434],
         [-2.5840, -0.4233, -5.2227,  ..., -1.4795, -2.4219, -1.9385],
         [-2.5801, -0.4297, -5.3203,  ..., -1.4678, -2.4004, -1.9424]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.6016, -0.4500, -5.4219,  ..., -1.4004, -2.4512, -1.9297],
         [-2.5352, -0.3069, -5.4375,  ..., -1.3574, -2.3711, -1.8701],
         ...,
         [-2.5859, -0.2646, -5.3672,  ..., -1.3936, -2.4219, -1.8955],
         [-2.5898, -0.2646, -5.3750,  ..., -1.3936, -2.4180, -1.8955],
         [-2.5820, -0.2571, -5.3711,  ..., -1.3896, -2.4180, -1.8916]]],
       device='cuda:0')
torch.Size([2, 814, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 814, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 44, 88.7% of total tokens
encoded shape: torch.Size([2, 137])
torch.Size([2, 137]) tensor([[    1,  5791,   468,  1161,  3055, 23638, 19848,   411, 22964,  3276,
          3632,   542,   283, 10335, 29889,    13, 29961,   276,  2467, 29901,
          1074,  1426, 29962,   450,  2625,  3234,   515,  3632,   542,   283,
         10335, 19848,   310,  1023,  8638,  1274,  3305,  2435,   267,   297,
           278,  5791,   468,  1161,  3055, 19848,   508,   367, 12212,   304,
          1048, 29871, 29906, 29995,   773,   385, 25005,   310, 17546,  1885,
         10489, 21749,  3860,   411, 21767,   307,  1885,   470,  1852,   265,
         29889, 29175,   564,  1508,   386,   948,   267, 29892,   652,   653,
           280,   386,   948,   267, 29892,   322,   263,  2846,   716,   564,
          2904,  2272,  2429,  1508,   386,   948,   267,   411,  1016,   272,
          5960,  1981,  1237,   505,  1063, 14710,   267,  1891,   297,  1407,
          1781, 17498, 29889, 28663,  1230,  2761, 15729,  4368,   393,   278,
          3632,   542,   283, 10335,  7709,   338, 10087,   491, 26702,   310,
          1716, 17246,   858,   322,   288, 28596, 29889],
        [    1,   512,   622,  1849,   448, 11733, 29871, 29906, 29896,    13,
            13, 29945, 29900,  1629,  2030,  6114, 29892, 17186, 29892, 17441,
          5445,   261, 29892, 26048,  5127, 29892,  9243,    13,    13,  4013,
         16500,  1258,   451,   763,   278,   982,   902, 17186,  5148,   541,
           471, 13421,   304,  1018,  5445,   414,  1449,  1363,  1183,   750,
          9251,   750,   263,  4319,  7271,   411,   963, 29889,  4942, 29889,
          4485,  5774,   297,  1570,   637, 17594,  7829,   393,  1183,  1018,
          5445,   414,  1449,  1363,   310,   670,  4266, 11658,   292, 13698,
         29889,  2296,   750, 29871, 29896,   269,  4316, 19144,   310,  5342,
          1490,   837, 18514,   336, 15113, 11658,   287,   304,   902,  7568,
           322,  5224, 17186,   411,   263,  1999,  1657,  6872,   508, 29876,
          2497, 29889,  2296, 18012,   278,  5613,  3063, 20414,   372,  1754,
           297,   902, 17186,   322,  5304, 25704,   363,  6023, 24081, 29889,
             2,     2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 137, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4561, -2.4609, -1.9111],
         [-2.5898, -0.4236, -5.3672,  ..., -1.3867, -2.4238, -1.9297],
         [-2.5762, -0.3984, -5.4180,  ..., -1.3721, -2.3477, -1.8984],
         ...,
         [-2.5508, -0.4153, -5.4453,  ..., -1.3262, -2.4199, -1.8857],
         [-2.5801, -0.3464, -5.4453,  ..., -1.3906, -2.3984, -1.9355],
         [-2.5449, -0.3281, -5.2656,  ..., -1.3418, -2.3555, -1.9131]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4561, -2.4609, -1.9111],
         [-2.5977, -0.3877, -5.4297,  ..., -1.4033, -2.3945, -1.8857],
         [-2.5645, -0.3735, -5.5117,  ..., -1.3936, -2.3984, -1.8545],
         ...,
         [-2.5469, -0.1038, -5.5391,  ..., -1.3232, -2.3574, -1.8779],
         [-2.5469, -0.1224, -5.5195,  ..., -1.3311, -2.3594, -1.8799],
         [-2.5508, -0.1442, -5.4922,  ..., -1.3418, -2.3691, -1.8848]]],
       device='cuda:0')
torch.Size([2, 137, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 137, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 45, 89.0% of total tokens
encoded shape: torch.Size([2, 1873])
torch.Size([2, 1873]) tensor([[    1, 20019,    13,  ...,     2,     2,     2],
        [    1,  2184,  7817,  ...,   317,   667,   481]], device='cuda:0')
torch.Size([2, 1873, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5566, -0.3335, -5.4844,  ..., -1.3379, -2.3633, -1.9062],
         [-2.2871, -0.0611, -5.2070,  ..., -1.3770, -2.3418, -1.8262],
         ...,
         [-2.5859, -0.2834, -5.3594,  ..., -1.3936, -2.4121, -1.9053],
         [-2.5859, -0.2834, -5.3594,  ..., -1.3936, -2.4121, -1.9053],
         [-2.5859, -0.2827, -5.3594,  ..., -1.3936, -2.4121, -1.9053]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5742, -0.3870, -5.4531,  ..., -1.3584, -2.4043, -1.9248],
         [-2.5664, -0.3892, -5.4766,  ..., -1.3574, -2.3809, -1.9258],
         ...,
         [-2.5625, -0.3149, -5.4219,  ..., -1.3887, -2.3730, -1.8916],
         [-2.5527, -0.3389, -5.4414,  ..., -1.3760, -2.3613, -1.9229],
         [-2.5488, -0.3574, -5.3828,  ..., -1.3760, -2.3652, -1.9170]]],
       device='cuda:0')
torch.Size([2, 1873, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1873, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 46, 91.9% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 11474,    13,  ..., 29946, 29941, 29900],
        [    1,   450, 15511,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5527, -0.3013, -5.3594,  ..., -1.3809, -2.4238, -1.8926],
         [-2.1992,  0.0380, -5.5430,  ..., -1.2568, -2.2598, -1.7520],
         ...,
         [-2.5762, -0.3965, -5.3867,  ..., -1.4111, -2.4355, -1.9199],
         [-2.5840, -0.3784, -5.3867,  ..., -1.3975, -2.4160, -1.9346],
         [-2.5801, -0.3984, -5.3750,  ..., -1.4180, -2.4336, -1.9248]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5938, -0.2725, -5.3828,  ..., -1.4014, -2.3906, -1.9268],
         [-2.5781, -0.4138, -5.4453,  ..., -1.3506, -2.3828, -1.9053],
         ...,
         [-2.6094, -0.3215, -5.1836,  ..., -1.4395, -2.4570, -1.9209],
         [-2.6055, -0.3142, -5.1875,  ..., -1.4365, -2.4531, -1.9180],
         [-2.6055, -0.3149, -5.1875,  ..., -1.4365, -2.4531, -1.9180]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 47, 97.3% of total tokens
encoded shape: torch.Size([2, 497])
torch.Size([2, 497]) tensor([[    1,  4309,   275, 11886,    13,    13,  3410,   275,   382, 29889,
         11886,   338,   263, 11443, 14099, 29892, 21510,   278,  9105,   310,
           360,  2554, 29892,  4908, 15411, 29889,    13,    13, 23182,   635,
           515,  8383, 11059, 29892, 21718, 29892, 11886,   322,   902, 10216,
           937,  6153,   304,   360,  2554,   297, 29871, 29896, 29929, 29953,
         29929, 29889,  2296,   471,   937, 11467,   304,   360,  2554, 21327,
          8831,   297, 29871, 29896, 29929, 29955, 29906, 29889,    13,    13,
         27006,  1100,   471, 11467,   297,  3979, 29871, 29896, 29929, 29929,
         29929,   304,  4953,   360,  2554, 29915, 29879,  1473, 12944,  9105,
         29892, 15270,   278,   937, 12944,  9105, 23408, 11717, 29889,  2296,
           471,   337, 29899, 15436,   287,   297,   263,  3802, 17793,   297,
           278, 29871, 29906, 29900, 29900, 29945, 20209,   304,   263,  4654,
          1840,   408,  9105, 29889,    13,    13,  2887,  9105, 11886, 15869,
           263,  7539, 29891,   411,   278, 19089,  1450, 29893, 11257,  3824,
         22900, 29892,   363,  8866,   372,   723,  1121,   297,   360,  2554,
         19035,   967, 18032,  3631,  2982, 29889,    13,    13,   797,  5846,
         29871, 29906, 29900, 29900, 29945, 29892,  1183,   471, 11467, 11774,
           310,   278,  4122,  1008,   478, 29711, 16208,  7457,  7613, 29892,
           310,   607,  1183,   750,  1063,   263,  4509,   363,   278,  3517,
         14183,  2440, 29889,   478, 29711,  2613, 29883,   453,   272,  5310,
         19955,  1089, 10398,   278,  4723,   310,   278,  7761,   310,   350,
         29889, 29907, 29889, 21327,  1907, 15687,   658,  1327,  5414,   363,
          2304,   304, 18766,  1857, 11774, 29893,  2480,  4309,   275, 11886,
           297,  5846, 29871, 29906, 29900, 29900, 29929, 29889,    13,    13,
           797,  4688, 29871, 29906, 29900, 29896, 29947, 29892, 11886,  9326,
           393,  1183,   723,   451,   367, 25738,  1790,  1840,   408,   360,
          2554, 29915, 29879,  9105,  1156, 29871, 29896, 29929,  2440,   297,
           278,  2602, 29889,  6298,   558,  5921,   368,   297,  3839, 29871,
         29906, 29900, 29896, 29947, 29892, 11886,  9326,   902, 21000,   363,
           263, 12949,   373,   360,  2554,  8831, 29889,  2296,   471, 11467,
           304, 18701,   373,  5533, 29871, 29896, 29929, 29892, 29871, 29906,
         29900, 29896, 29947, 29889,    13,    13,  1123, 10662,    13,    13,
         25865,  2988,    13,    13, 10900, 29901, 29931,  4357,  2305,    13,
         10900, 29901, 15666,  1991,   515,   360,  2554, 29892,  4908, 15411,
            13, 10900, 29901, 29956,  2770,  1122,   943,   310,  7600,   297,
          4908, 15411,    13, 10900, 29901,  7713,   277, 14722,   515,  4122,
          1008,  8383, 11059,    13, 10900, 29901, 12703,   943,   310,  7600,
           297,  4908, 15411,    13, 10900, 29901, 12883,   310, 12060,  4567,
           313, 29880,  4357,  2305, 29897,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2],
        [    1,  4831,   332,  4135,   310,  1661,   262,  4428,   573,  4323,
          2450,   310, 17294,   405,  6344, 14953,   800,   773,   349, 26785,
          5665, 29901,  1147,  2450,   297,   263,  2381,   457,  1904,   411,
          7029,  3918, 29889,    13,  1576,  1539, 19388,   568,   364,  2219,
           359,   750,  1063, 15723,   297,   278,  1746,   310, 29751,  6683,
           307,  1557,  2270,   313, 29924, 12445, 29897,   363,   263,  1472,
          3785, 29889,   450,  1667,  4216,  1627,   310,  1539, 19388,   568,
         11959,   338,   393, 11959,  2582,   526,   451,  5734,   519,   411,
          8380,  1539, 19388,   568, 26702,   297,   325,  4243, 29889,   450,
          6437,   310,   445,  6559,   471,   304, 25917,   278, 13600,   310,
          1661,   262,  4428,   573,  4323,  2450,   310, 17294,   405, 29899,
           562,   300,  2904,   294,  1595,   403,   313,  3521, 29909, 29897,
         14953,   800,   773,  9251,  8967, 29751,  7029,  3918,  1158, 29889,
           382,   523,  2381,   457,   892,   885, 11310,   373,   263,   402,
         29923, 29871, 29896, 29889, 29945,   323,   885,  7310,   411,   263,
          3918,  2343,  1302,   309, 29889,   450,  7029,  3918,  1158,   471,
          3667,  1891,   411,   263, 20745, 10423,   411,   405,  6344, 29892,
           402,  2882, 29909, 29892,  3144,   329,   314,   457, 29892,  3144,
           329,   314,   403, 29892,   907,   271,   457, 29892,   521, 26496,
           521,  5095,   680, 29892,   322,   590, 29877, 29899,  8226,   277,
           324, 29889,   450,  2602, 11527,  6683,   307,  1557,  2270,   313,
         15094,  1799, 29897,  5665,   471,  1304,   411, 17067, 29922, 29896,
         29941, 29945,   286,  3471, 29892, 10014, 29922, 29896, 29945, 29900,
         29900,   286,  3471, 29892,   322, 29871, 29896, 29906, 29947, 12812,
          4759,  1179, 29889,   450,  7418,   310,   341, 12445,   471,  2309,
           411,   317, 10461, 29914,  1367, 29931,  1824, 29889,   512,   325,
          4243,   405,  6344, 26702,   471,  7625,   773,   278,  6306,   317,
         29922, 29940,   334,   321,  6278,  4330, 29914, 29911, 29966,  1491,
         29958, 29906,   829,  1491, 12948,   334,   518, 29896, 29899, 29872,
          6278,  5659, 29914, 29911, 29966,  1491, 29958, 29896,   829,  1491,
         29958,   467,   512, 13901,   307,   405,  6344, 26702,   471, 17005,
           491,  1880,  4180, 23904, 25173,   271,  5275,   313,  3954, 12182,
           467,   512,   278,   341, 12445,  2318, 29892,   278,  2099, 26702,
           310,   405,  6344,   471, 29871, 29896, 29900, 29889, 29900, 29941,
          2298, 23521, 29871, 29900, 29889, 29955, 29946,  5654,   324, 29914,
          9415, 29889,   512,   278,   379,  7390, 29907,  2318, 29892,   278,
          2099, 26702,   310,   405,  6344,   471, 29871, 29929, 29889, 29906,
         29906,  2298, 23521, 29871, 29900, 29889, 29945, 29945,  5654,   324,
         29914,  9415, 29889,  1670,   471,   694,  7282,  4328,  1546,   278,
          1023,  6471,   313, 29886,   353, 29871, 29900, 29889, 29946, 29953,
           467,  2398, 29892, 10029,  6133,   995,   471,  8900,   297,   278,
           341, 12445,  2318,   313, 29955, 29914, 29947,  2381,   457,   511,
          9401,   411,   379,  7390, 29907,  2318, 29889,   450,  3464,   310,
         12651,   471,  1546, 29871, 29900, 29889, 29900, 29906, 30022, 29906,
         29889, 29900, 29945,  5654,   324, 29914,  9415, 29889,   341, 12445,
          7029,  3407,  1158,  1033,   367,   901, 16232,  1135,  7463,  3407,
          1158, 29889,   529, 12587, 29958, 29896,   829, 12587, 29958, 29950,
           341, 12445,   947,   451, 20820,  1546,   405, 29899,   562,   300,
          2904, 27396,   749, 29511,   322,   916,   405, 29899,   562,   300,
          2904,   630,   626,  1789,  1274,  4841, 29889]], device='cuda:0')
torch.Size([2, 497, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5918, -0.4390, -5.3516,  ..., -1.4180, -2.4199, -1.9277],
         [-2.5508, -0.3398, -5.4102,  ..., -1.3691, -2.3867, -1.9209],
         ...,
         [-2.5801, -0.2869, -5.3164,  ..., -1.4082, -2.4141, -1.9199],
         [-2.5801, -0.2859, -5.3164,  ..., -1.4082, -2.4160, -1.9199],
         [-2.5801, -0.2871, -5.3164,  ..., -1.4092, -2.4141, -1.9189]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3960, -5.4336,  ..., -1.3965, -2.3828, -1.9395],
         [-2.5801, -0.3738, -5.4219,  ..., -1.3779, -2.4082, -1.9277],
         ...,
         [-2.5781, -0.4182, -5.3047,  ..., -1.3926, -2.4316, -1.9414],
         [-2.5957, -0.3667, -5.5430,  ..., -1.3701, -2.4043, -1.9688],
         [-2.5449, -0.3481, -5.4414,  ..., -1.3223, -2.3438, -1.9180]]],
       device='cuda:0')
torch.Size([2, 497, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [30488],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 497, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 48, 98.2% of total tokens
encoded shape: torch.Size([2, 1054])
torch.Size([2, 1054]) tensor([[    1, 26475, 20193,  ...,     2,     2,     2],
        [    1,   660, 29901,  ..., 15626,    13,    13]], device='cuda:0')
torch.Size([2, 1054, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5938, -0.3738, -5.4727,  ..., -1.3770, -2.4375, -1.9385],
         [-2.5977, -0.3787, -5.5117,  ..., -1.4170, -2.4121, -1.9727],
         ...,
         [-2.5840, -0.2502, -5.4297,  ..., -1.3760, -2.4004, -1.8945],
         [-2.5840, -0.2502, -5.4297,  ..., -1.3760, -2.4004, -1.8945],
         [-2.5840, -0.2493, -5.4375,  ..., -1.3750, -2.3984, -1.8945]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.4490, -5.4180,  ..., -1.4004, -2.4512, -1.9287],
         [-2.5352, -0.3057, -5.4336,  ..., -1.3584, -2.3711, -1.8711],
         ...,
         [-2.5625, -0.4080, -5.2227,  ..., -1.4219, -2.4238, -1.9326],
         [-2.5781, -0.3962, -5.1484,  ..., -1.4717, -2.4414, -1.9453],
         [-2.5977, -0.4395, -5.2227,  ..., -1.4609, -2.4297, -1.9434]]],
       device='cuda:0')
torch.Size([2, 1054, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1054, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 49, 99.7% of total tokens
encoded shape: torch.Size([2, 1902])
torch.Size([2, 1902]) tensor([[    1, 18473, 29899,  ...,   548,   262,  2023],
        [    1, 14693,  7811,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1902, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5859, -0.4319, -5.4297,  ..., -1.3916, -2.4414, -1.9443],
         [-2.5762, -0.4026, -5.4492,  ..., -1.3721, -2.4121, -1.9395],
         ...,
         [-2.5352, -0.3643, -5.5117,  ..., -1.3477, -2.3770, -1.9062],
         [-2.6016, -0.4309, -5.5039,  ..., -1.3867, -2.3867, -1.9248],
         [-2.5723, -0.3403, -5.2070,  ..., -1.4150, -2.4277, -1.9434]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6055, -0.4194, -5.4102,  ..., -1.3906, -2.4355, -1.9102],
         [-2.5566, -0.4016, -5.4180,  ..., -1.3994, -2.3848, -1.9385],
         ...,
         [-2.6035, -0.2947, -5.2773,  ..., -1.4209, -2.4414, -1.9082],
         [-2.6035, -0.2947, -5.2773,  ..., -1.4209, -2.4414, -1.9082],
         [-2.6016, -0.2947, -5.2773,  ..., -1.4209, -2.4414, -1.9082]]],
       device='cuda:0')
torch.Size([2, 1902, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1902, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 610])
torch.Size([2, 610]) tensor([[    1,   396,   361,  ...,     2,     2,     2],
        [    1,  4949,    13,  ..., 29937, 15224,    13]], device='cuda:0')
torch.Size([2, 610, 32000]) tensor([[[-1.2828e+01, -7.3828e+00, -4.7046e-01,  ..., -6.7734e+00,
          -8.0156e+00, -7.5000e+00],
         [-8.0234e+00, -8.4375e+00,  4.1870e-02,  ..., -3.7461e+00,
          -4.6445e+00, -6.2891e+00],
         [-4.6406e+00, -7.1992e+00,  4.7344e+00,  ...,  1.5454e-01,
          -3.8633e+00,  4.0942e-01],
         ...,
         [-9.4922e+00,  2.0137e+00,  3.4434e+00,  ..., -4.1562e+00,
          -5.5156e+00, -1.7158e+00],
         [-9.5625e+00,  1.6895e+00,  3.5449e+00,  ..., -4.1992e+00,
          -5.5391e+00, -1.8086e+00],
         [-9.5625e+00,  1.6748e+00,  3.5996e+00,  ..., -4.1719e+00,
          -5.5039e+00, -1.7939e+00]],

        [[-1.2828e+01, -7.3828e+00, -4.7046e-01,  ..., -6.7734e+00,
          -8.0156e+00, -7.5000e+00],
         [-1.1727e+01, -9.4375e+00, -1.7578e+00,  ..., -6.2656e+00,
          -7.7227e+00, -2.2910e+00],
         [-6.5820e+00, -7.4531e+00,  5.7578e+00,  ..., -4.1523e+00,
          -2.8750e+00,  2.0098e+00],
         ...,
         [-9.9463e-01, -2.5605e+00,  7.9688e+00,  ...,  3.8867e+00,
           2.1011e-02,  4.7734e+00],
         [-4.8975e-01, -1.3604e+00,  2.2672e+01,  ..., -8.2178e-01,
          -3.7949e+00, -3.6743e-01],
         [ 3.3281e+00,  6.0117e+00,  2.0328e+01,  ...,  1.5459e+00,
          -3.3535e+00,  1.3857e+00]]], device='cuda:0')
torch.Size([2, 610, 1]) tensor([[[  917],
         [29871],
         [  299],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [   13],
         [  334],
         ...,
         [15224],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 610, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [  299,  1753,  3342,  ...,  4770,   379, 29871],
         ...,
         [   13,  7228,    12,  ...,  1678, 29949,   268],
         [   13,  7228,     3,  ...,  1678, 29949,   268],
         [   13,     3,  7228,  ...,  4345,  1678,   268]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    13,  ...,   259,   268, 29899],
         ...,
         [15224,  2870, 23681,  ...,   259, 29871,  7241],
         [   13,     2,  4949,  ...,   259,   462,  5515],
         [   13, 29937,     2,  ..., 29905, 29871,   462]]], device='cuda:0')
Batch 1, 0.8% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29871,    13,  ...,     2,     2,     2],
        [    1,   849, 14187,  ...,  1976, 14977,  6901]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.1406,  -4.4141,   3.6445,  ...,  -5.2812,  -5.5977,  -2.5449],
         ...,
         [ -8.1875,   6.1602,   2.6934,  ...,  -3.4707,  -5.0898,  -2.5859],
         [ -8.2969,   5.7500,   2.5938,  ...,  -3.5625,  -5.1250,  -2.6934],
         [ -8.4609,   4.7578,   2.3359,  ...,  -3.7832,  -5.1797,  -2.9648]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5469,  -6.0430,   2.0840,  ...,  -2.3574,  -5.3828,   3.4375],
         [ -2.5879,  -4.8945,   5.7812,  ...,  -0.5186,  -0.4121,   3.5254],
         ...,
         [ -5.4336,  -6.5859,   5.0781,  ...,  -4.1680,  -4.0977,  -1.0088],
         [ -3.1582,  -6.3281,   5.4141,  ...,  -0.1605,  -3.0879,   0.7700],
         [ -5.2109,  -5.0273,   5.4453,  ...,  -1.3506,  -2.3086,  -0.7588]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [29896],
         [   13],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [   13],
         [ 1266],
         ...,
         [14977],
         [ 6901],
         [  931]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [    3,     1, 29949,  ..., 29924, 29907, 29911],
         [    3,     1, 29949,  ..., 29924, 29907, 29911],
         [    3, 29949,     1,  ..., 29871, 29907, 29911]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [ 1266,   278,   322,  ..., 29899,   310, 29878],
         ...,
         [14977,  2929,  2170,  ...,   578, 29879,  1557],
         [ 6901,   931, 19181,  ..., 12315, 21287,  6198],
         [  931,   260, 14334,  ...,   995,  6901, 12006]]], device='cuda:0')
Batch 2, 5.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   518,    13,  ..., 29906, 29901, 29946],
        [    1,   529,  7299,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.0547, -11.1797,   0.1122,  ...,  -2.9473,  -3.9512,  -1.6396],
         [ -9.5469,  -5.1875,   4.0430,  ...,  -3.1914,  -4.6055,  -0.9233],
         ...,
         [ -5.9805,  -6.4727,   9.1641,  ...,  -4.1055,  -3.8770,  -4.9648],
         [ -7.0977,  -9.5703,   6.9961,  ...,  -3.5137,  -3.2070,  -3.2500],
         [ -5.5469,  -5.9961,   6.0234,  ...,  -2.6484,  -3.2734,  -2.0781]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.8477, -10.8984,  -0.5146,  ...,  -5.1172,  -3.8301,  -1.7783],
         [ -3.3184,   0.0136,   6.7344,  ...,   0.3091,   1.0693,  -1.7598],
         ...,
         [-10.8281,   1.0430,   2.4375,  ...,  -4.9727,  -6.0000,  -3.9902],
         [-10.8203,   1.0010,   2.4492,  ...,  -4.9961,  -6.0078,  -3.9883],
         [-10.8203,   0.9380,   2.4297,  ...,  -5.0391,  -6.0312,  -4.0195]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [12614],
         [ 1678],
         ...,
         [29901],
         [29946],
         [29946]],

        [[  917],
         [ 6886],
         [17425],
         ...,
         [   13],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [12614, 29896, 29906,  ..., 29924, 29943, 29933],
         [ 1678,    13,    12,  ..., 29937,   259,   418],
         ...,
         [29901, 29946, 29936,  ..., 29900, 29896, 29892],
         [29946, 29941, 29906,  ...,    13, 29955, 29947],
         [29946, 29941, 29906,  ..., 29955, 29947, 29929]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 6886,  4563, 29886,  ..., 29874,  3293,  2042],
         [17425,  1732,  1024,  ...,  1373,  2944,    13],
         ...,
         [   13,    12,     3,  ..., 29909,  4345, 29911],
         [   13,    12,     3,  ..., 29909,  4345, 29911],
         [   13,    12,     3,  ..., 29909,  4345, 29911]]], device='cuda:0')
Batch 3, 10.9% of total tokens
encoded shape: torch.Size([2, 1650])
torch.Size([2, 1650]) tensor([[    1,  6319,  3134,  ...,     2,     2,     2],
        [    1, 18787,  4855,  ...,  3396,  3101,    13]], device='cuda:0')
torch.Size([2, 1650, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -3.6875,   0.0689,   8.1953,  ...,   1.5645,  -1.1123,   1.1865],
         [ -2.8262,  -5.0625,   6.2852,  ...,  -1.0293,  -1.3389,  -1.3027],
         ...,
         [-10.8984,   1.6357,   2.0254,  ...,  -5.5312,  -6.4102,  -3.7090],
         [-10.9609,   1.7227,   1.9443,  ...,  -5.5820,  -6.5000,  -3.7832],
         [-10.9766,   1.8115,   1.8975,  ...,  -5.6016,  -6.5391,  -3.8340]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [  6.6094,   8.1797,  -2.7578,  ...,   9.4531,   5.8164,  10.0781],
         [ -2.2109,  -1.7725,   6.5156,  ...,  -1.2178,  -1.2744,   0.4307],
         ...,
         [ -0.6631,  -3.8945,  12.9844,  ...,   3.8047,   0.9521,   2.0625],
         [ -1.0293,   1.8652,  27.2812,  ...,  -0.5972,  -1.3867,  -0.5283],
         [  0.3479,   3.7598,  25.5781,  ...,   0.2281,  -0.5596,   0.6553]]],
       device='cuda:0')
torch.Size([2, 1650, 1]) tensor([[[  917],
         [ 1961],
         [ 1873],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [ 4855],
         [29914],
         ...,
         [ 3101],
         [    2],
         [    2]]], device='cuda:0')
torch.Size([2, 1650, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1961,  3134,    13,  ...,  3160,   395,  6080],
         [ 1873, 29899,  8025,  ..., 29901, 29871,  6910],
         ...,
         [   13, 29871,    12,  ..., 29966,     3, 29902],
         [   13, 29871,    12,  ..., 29966, 29902,   448],
         [   13, 29871,    12,  ..., 29966,   448, 29902]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 4855,  2109,  1792,  ...,  3670,  5959,  1982],
         [29914,  2109,    13,  ...,  6294,  5515, 25558],
         ...,
         [ 3101,   580, 29897,  ...,  6278,  2141,  3285],
         [    2,    13, 29871,  ...,  1275,   268, 30004],
         [    2,    13, 29871,  ...,  2870,  2277,   259]]], device='cuda:0')
Batch 4, 12.8% of total tokens
encoded shape: torch.Size([2, 2111])
torch.Size([2, 2111]) tensor([[    1,  4251, 29901,  ...,     2,     2,     2],
        [    1,   313,  5453,  ...,  1723,    13, 29897]], device='cuda:0')
torch.Size([2, 2111, 32000]) tensor([[[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-1.2953e+01, -1.0281e+01, -1.4258e-01,  ..., -8.4609e+00,
          -9.0469e+00, -1.0570e+01],
         [-1.2250e+01, -1.1938e+01, -3.8613e+00,  ..., -8.5234e+00,
          -9.0547e+00, -9.6016e+00],
         ...,
         [-9.3203e+00,  1.1064e+00,  2.5254e+00,  ..., -3.6953e+00,
          -5.2344e+00, -3.4258e+00],
         [-9.2969e+00,  1.1133e+00,  2.5137e+00,  ..., -3.6973e+00,
          -5.2305e+00, -3.4336e+00],
         [-9.2500e+00,  1.1240e+00,  2.5098e+00,  ..., -3.6738e+00,
          -5.2070e+00, -3.4219e+00]],

        [[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-1.0891e+01, -1.4398e+01, -1.2959e+00,  ..., -4.2070e+00,
          -6.5078e+00, -3.2832e+00],
         [-1.0609e+01, -1.2047e+01, -2.6367e+00,  ..., -7.0664e+00,
          -9.2891e+00, -9.5938e+00],
         ...,
         [ 1.6191e+00, -8.7646e-01,  1.6406e+01,  ..., -3.5898e+00,
          -1.2314e+00,  1.6689e+00],
         [ 1.0225e+00,  8.1738e-01,  1.5477e+01,  ...,  6.0742e-01,
           6.0768e-03,  2.6172e+00],
         [ 4.7144e-01, -3.8770e+00,  1.5711e+01,  ..., -4.1641e+00,
          -3.6387e+00,  9.1846e-01]]], device='cuda:0')
torch.Size([2, 2111, 1]) tensor([[[  917],
         [  310],
         [29871],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [24735],
         [  313],
         ...,
         [   13],
         [29897],
         [   13]]], device='cuda:0')
torch.Size([2, 2111, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  310, 29892, 29889,  ...,   393,   363,   304],
         [29871,    13,   376,  ...,   426,   319, 29896],
         ...,
         [    3,    12,    13,  ..., 29909, 29989, 29966],
         [    3,    12,    13,  ..., 29989, 29909, 29966],
         [    3,    12,    13,  ..., 29989, 29909, 29966]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [24735, 29896, 29906,  ...,  2220, 29933, 29956],
         [  313, 29901, 29871,  ...,    13,   379,   525],
         ...,
         [   13,     2, 29871,  ...,  7528,  4748, 11533],
         [29897, 29871,    13,  ..., 29913,     2,   259],
         [   13,  2056,     2,  ..., 29871,  3776,  1496]]], device='cuda:0')
Batch 5, 15.4% of total tokens
encoded shape: torch.Size([2, 1398])
torch.Size([2, 1398]) tensor([[    1,   934,  5809,  ...,     2,     2,     2],
        [    1,   847,  7775,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1398, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -7.8008, -12.5625,  -0.1597,  ...,  -5.5000,  -8.5625,  -5.2852],
         [ -9.1406, -11.2734,  -1.1025,  ...,  -7.3555,  -6.9961,  -6.1172],
         ...,
         [-11.6094,  -4.5977,   2.3184,  ...,  -6.1172,  -6.6133,  -6.4336],
         [-11.6094,  -4.6289,   2.2832,  ...,  -6.1094,  -6.5977,  -6.4297],
         [-11.5938,  -4.6328,   2.2617,  ...,  -6.0703,  -6.5625,  -6.3945]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [-10.6875,  -7.7500,  -1.6572,  ...,  -5.3867,  -8.0469,  -6.5859],
         [ -3.4590,   0.6074,   5.4648,  ...,   0.0698,  -1.7441,   0.5273],
         ...,
         [  0.5298,   4.0781,  17.4531,  ...,   4.4180,   0.6592,   4.5977],
         [  0.8589,   4.7266,  28.0156,  ...,   2.1973,  -1.8037,   1.1201],
         [  3.0957,   5.8477,  26.3281,  ...,   2.2207,  -1.0332,   2.9062]]],
       device='cuda:0')
torch.Size([2, 1398, 1]) tensor([[[  917],
         [  471],
         [29901],
         ...,
         [ 1516],
         [ 1516],
         [ 1516]],

        [[  917],
         [ 7775],
         [ 7775],
         ...,
         [29913],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 1398, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  471,   353, 29918,  ...,   313, 29889,  8207],
         [29901,   353, 29889,  ...,  2433,   584,   338],
         ...,
         [ 1516,  4345, 29924,  ..., 29885, 29937, 29905],
         [ 1516,  4345, 29924,  ..., 29885, 29905, 29937],
         [ 1516,  4345, 29924,  ..., 29905, 29937, 29885]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 7775, 29871,  8778,  ..., 10130, 17943,   350],
         [ 7775,  4189,  2328,  ...,    13,   334,  3877],
         ...,
         [29913,  1678,    13,  ...,   458,  4706,   259],
         [   13,     2, 29871,  ...,   308,   458,   462],
         [   13,     2,  5405,  ..., 29905, 30004, 11227]]], device='cuda:0')
Batch 6, 18.0% of total tokens
encoded shape: torch.Size([2, 1743])
torch.Size([2, 1743]) tensor([[    1,   847,  7775,  ...,    13, 29913,    13],
        [    1,  2286,   376,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1743, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.6797,  -7.7500,  -1.6582,  ...,  -5.3828,  -8.0469,  -6.5820],
         [ -3.4570,   0.6138,   5.4727,  ...,   0.0676,  -1.7432,   0.5312],
         ...,
         [ -1.3867,   0.1973,  15.1016,  ...,   2.4551,  -1.4668,   2.1426],
         [ -0.2764,   2.7383,  25.5312,  ...,   0.6362,  -0.5854,   1.2793],
         [  1.7949,   2.2285,  25.4844,  ...,   1.0527,  -1.0498,   1.8125]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.3984, -12.8203,  -2.6934,  ...,  -7.3672,  -7.7500,  -7.5078],
         [ -5.2227,  -8.7188,   0.9648,  ...,   0.4031,  -0.9658,  -1.5762],
         ...,
         [ -9.5938,   6.9531,   3.3828,  ...,  -4.7148,  -5.7422,  -2.1387],
         [ -9.9297,   6.0312,   3.3047,  ...,  -5.0117,  -5.9297,  -2.3926],
         [-10.3594,   4.7266,   3.1094,  ...,  -5.4688,  -6.2656,  -2.8535]]],
       device='cuda:0')
torch.Size([2, 1743, 1]) tensor([[[  917],
         [ 7775],
         [ 7775],
         ...,
         [29913],
         [   13],
         [   13]],

        [[  917],
         [  376],
         [29894],
         ...,
         [    1],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 1743, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 7775, 29871,  8778,  ..., 10130, 17943,   350],
         [ 7775,  4189,  2328,  ...,    13,   334,  3877],
         ...,
         [29913,    13,  3400,  ...,  1118,  2751,  5515],
         [   13,     2,  4949,  ...,  1678,   849,   462],
         [   13,     2,  5746,  ...,  5405,   735,  7959]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  376,   525, 29918,  ...,   703,   353,   584],
         [29894, 10467,  4836,  ..., 29895,  1792, 29879],
         ...,
         [    1,    13, 29871,  ...,   259, 30004,     3],
         [   13, 29871,     1,  ...,   259, 30004,   448],
         [   13, 29871,    12,  ...,   259,   448, 30004]]], device='cuda:0')
Batch 7, 19.8% of total tokens
encoded shape: torch.Size([2, 561])
torch.Size([2, 561]) tensor([[    1,   849,   426,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 561, 32000]) tensor([[[-12.8281,  -7.3828,  -0.4705,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -8.5469,  -6.0391,   2.0820,  ...,  -2.3594,  -5.3828,   3.4375],
         [ -6.5742,  -8.2656,   1.8828,  ...,  -1.2598,  -5.4844,  -1.0596],
         ...,
         [-10.0234,   1.2725,   2.2305,  ...,  -2.7793,  -5.0312,  -2.3516],
         [ -9.9453,   1.3701,   2.3223,  ...,  -2.7324,  -4.9727,  -2.3027],
         [ -9.9141,   1.3906,   2.3242,  ...,  -2.7773,  -5.0078,  -2.3809]],

        [[-12.8281,  -7.3828,  -0.4705,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-11.7266,  -9.4375,  -1.7578,  ...,  -6.2656,  -7.7227,  -2.2910],
         [ -6.5859,  -7.4570,   5.7539,  ...,  -4.1562,  -2.8770,   2.0098],
         ...,
         [ -2.6582,   2.3691,  11.6406,  ...,   0.5483,  -3.3008,   1.1885],
         [ -4.4570,  -0.3198,  24.4062,  ...,  -0.9048,  -0.2461,  -1.3457],
         [ -1.7402,   1.8525,  28.1719,  ...,   0.5078,  -2.1895,   2.4980]]],
       device='cuda:0')
torch.Size([2, 561, 1]) tensor([[[  917],
         [   13],
         [ 6224],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [   13],
         [  334],
         ...,
         [29913],
         [    2],
         [    2]]], device='cuda:0')
torch.Size([2, 561, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [ 6224,    13,   376,  ..., 17962, 29991,  9166],
         ...,
         [   13, 29871,  1576,  ...,    12, 29896,  6224],
         [   13, 29871,  1576,  ...,    12, 29896,  6224],
         [   13, 29871,  1576,  ..., 29924, 29896,  6224]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    13,  ...,   259,   268, 29899],
         ...,
         [29913,    13,   268,  ..., 29871,  8117,   500],
         [    2,    13, 29871,  ...,   462,  2056,   259],
         [    2,    13, 28956,  ...,  5515, 29871,   458]]], device='cuda:0')
Batch 8, 20.8% of total tokens
encoded shape: torch.Size([2, 2183])
torch.Size([2, 2183]) tensor([[    1,   887, 11097,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,   995,    13,    13]], device='cuda:0')
torch.Size([2, 2183, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.6016,  -8.0234,   2.7852,  ...,  -2.3477,  -6.9844,  -1.7607],
         [ -3.7559,   0.8574,   6.8125,  ...,  -0.0828,  -2.3184,  -0.8315],
         ...,
         [-11.0078,   2.8496,   2.0547,  ...,  -5.4531,  -6.3203,  -3.6191],
         [-11.0312,   2.7363,   2.0332,  ...,  -5.5039,  -6.3867,  -3.6660],
         [-11.0156,   2.5605,   2.0020,  ...,  -5.5195,  -6.3789,  -3.6816]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.1406,  -4.4141,   3.6445,  ...,  -5.2812,  -5.5977,  -2.5449],
         ...,
         [  3.1074,   4.5820,  25.9062,  ...,   1.1201,   1.2490,   0.8887],
         [  2.8633,   6.9102,  24.7969,  ...,   3.1289,   3.5703,   3.4062],
         [  1.8770,   5.2188,  21.1719,  ...,   2.3711,   4.2891,   4.8555]]],
       device='cuda:0')
torch.Size([2, 2183, 1]) tensor([[[  917],
         [  526],
         [  304],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29896],
         [   13],
         ...,
         [   13],
         [   13],
         [ 1753]]], device='cuda:0')
torch.Size([2, 2183, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  526,   508, 29915,  ...,  4683,  1073,  1795],
         [  304,   825,   920,  ...,   373,   565, 29901],
         ...,
         [   13,    12, 29871,  ..., 29949,  7228,   268],
         [   13,    12, 29871,  ...,  7228, 29949,   268],
         [   13,    12, 29871,  ..., 29949,  7228,   268]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [   13,     2, 29871,  ..., 29961,   268,   308],
         [   13,     2,  1678,  ..., 29937,  2457,   308],
         [ 1753,    13,     2,  ..., 29937,  1649,  5215]]], device='cuda:0')
Batch 9, 23.3% of total tokens
encoded shape: torch.Size([2, 3560])
torch.Size([2, 3560]) tensor([[    1,  6319,  1961,  ...,     2,     2,     2],
        [    1,   396, 28436,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 3560, 32000]) tensor([[[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-3.6914e+00,  6.7749e-02,  8.2031e+00,  ...,  1.5645e+00,
          -1.1162e+00,  1.1865e+00],
         [ 2.2559e+00,  4.1055e+00,  1.1531e+01,  ..., -9.9902e-01,
           1.8359e+00,  2.7305e+00],
         ...,
         [-7.2070e+00,  3.1348e+00,  2.4688e+00,  ..., -4.0156e+00,
          -4.4258e+00, -2.6797e+00],
         [-7.3164e+00,  2.9570e+00,  2.3945e+00,  ..., -4.0547e+00,
          -4.4531e+00, -2.7383e+00],
         [-7.5430e+00,  2.5957e+00,  2.2773e+00,  ..., -4.1484e+00,
          -4.5508e+00, -2.8887e+00]],

        [[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-8.0234e+00, -8.4375e+00,  3.8544e-02,  ..., -3.7461e+00,
          -4.6445e+00, -6.2891e+00],
         [-6.1367e+00, -6.0859e+00,  2.6406e+00,  ..., -3.1992e+00,
          -2.5391e+00, -2.2539e+00],
         ...,
         [-2.3651e-03,  1.4980e+00,  1.3219e+01,  ...,  4.7461e-01,
           4.1943e-01,  3.5996e+00],
         [-2.3047e+00,  1.1426e+00,  2.7734e+01,  ..., -2.0840e+00,
          -1.9590e+00, -2.1445e+00],
         [-6.3135e-01,  8.1562e+00,  2.4859e+01,  ..., -5.6494e-01,
          -1.3086e+00,  9.6875e-01]]], device='cuda:0')
torch.Size([2, 3560, 1]) tensor([[[  917],
         [ 1961],
         [   13],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [29871],
         [ 2748],
         ...,
         [ 1678],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 3560, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1961,  3134,    13,  ...,  3160,   395,  6080],
         [   13, 30004, 29871,  ...,  3160,  9607,  6756],
         ...,
         [    3,    12, 29966,  ...,  4345,  6319, 29949],
         [    3,    12, 29966,  ...,     1,  6319,  4345],
         [    3,    12, 29966,  ...,  6319, 29937,  1678]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [ 2748,   402,  9177,  ...,   298,  2295,  9406],
         ...,
         [ 1678, 29913, 29871,  ..., 29937,   458,   355],
         [   13,     2,  1678,  ...,   268,   462,  4706],
         [    2,    13, 29937,  ...,  5515,  4363, 29913]]], device='cuda:0')
Batch 10, 27.6% of total tokens
encoded shape: torch.Size([2, 2525])
torch.Size([2, 2525]) tensor([[    1,   529,  1958,  ...,     2,     2,     2],
        [    1,   396,   448,  ..., 13150,   580,    13]], device='cuda:0')
torch.Size([2, 2525, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.8477, -10.8984,  -0.5146,  ...,  -5.1172,  -3.8301,  -1.7783],
         [ -4.5781, -10.3594,   3.9062,  ...,  -3.8809,  -2.6172,  -2.3340],
         ...,
         [-11.3750,   3.9688,   1.5596,  ...,  -5.0820,  -6.7305,  -4.9883],
         [-11.3359,   4.1211,   1.5703,  ...,  -5.0273,  -6.6602,  -4.9219],
         [-11.3281,   4.0547,   1.5996,  ...,  -5.0117,  -6.6406,  -4.8789]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.0234,  -8.4375,   0.0385,  ...,  -3.7461,  -4.6445,  -6.2891],
         [-10.0078,  -7.4883,  -0.5674,  ...,  -1.4775,  -6.3633,  -4.1211],
         ...,
         [  1.7393,  -0.4099,  20.2031,  ...,   1.5205,  -0.5977,   4.0039],
         [  2.4434,   3.2383,  25.5000,  ...,   0.0654,  -0.9966,   1.0791],
         [  3.7812,   4.9375,  23.2500,  ...,   1.9160,   1.1504,   3.9805]]],
       device='cuda:0')
torch.Size([2, 2525, 1]) tensor([[[  917],
         [ 6886],
         [ 3405],
         ...,
         [   13],
         [   13],
         [    3]],

        [[  917],
         [29871],
         [29930],
         ...,
         [  580],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 2525, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 6886,  4563, 29886,  ..., 29874,  3293,  2042],
         [ 3405,  1024,  1873,  ...,  2557,  3114,  3888],
         ...,
         [   13,     3,  7228,  ..., 29933, 29924, 29871],
         [   13,     3,  7228,  ..., 29933, 29924, 29871],
         [    3,    13,  7228,  ..., 29933, 29924, 29911]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [29930,  2683,    13,  ..., 29877, 29937, 29888],
         ...,
         [  580, 29898,  3861,  ...,     2,  1566,  4923],
         [   13,     2, 29871,  ...,   462,    12, 29937],
         [   13,     2,  3502,  ...,  1761, 29905, 29937]]], device='cuda:0')
Batch 11, 30.4% of total tokens
encoded shape: torch.Size([2, 2573])
torch.Size([2, 2573]) tensor([[    1,  4949,  2683,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,  1420, 29958,    13]], device='cuda:0')
torch.Size([2, 2573, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7188,  -9.4453,  -1.7578,  ...,  -6.2656,  -7.7266,  -2.2930],
         [ -6.2500,  -4.4141,   2.0820,  ...,  -0.8545,  -2.8887,  -0.8994],
         ...,
         [-10.8828,   1.7100,   1.6191,  ...,  -5.1250,  -6.2148,  -4.0000],
         [-10.9297,   1.6973,   1.6016,  ...,  -5.1680,  -6.2695,  -4.0547],
         [-10.9688,   1.6934,   1.5684,  ...,  -5.2461,  -6.3555,  -4.1445]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [-11.1406,  -4.4141,   3.6445,  ...,  -5.2812,  -5.5977,  -2.5449],
         ...,
         [  1.8389,   1.4482,  18.0000,  ...,   2.4609,   2.9258,   4.0664],
         [ -0.0777,   2.3281,  20.8750,  ...,  -1.0371,   1.3271,  -1.2451],
         [  4.3750,   7.9453,  23.4844,  ...,   1.0225,   2.2891,   3.6895]]],
       device='cuda:0')
torch.Size([2, 2573, 1]) tensor([[[  917],
         [   13],
         [ 2683],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29896],
         [   13],
         ...,
         [29958],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 2573, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [ 2683,  9072,  1378,  ..., 22158,  5634,   489],
         ...,
         [   13,    12, 29871,  ..., 29903, 29902, 29911],
         [   13,    12, 29871,  ..., 29903, 29902, 29911],
         [   13,    12, 29871,  ..., 29902, 29903,   259]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [29958,  5299,  2565,  ..., 25867, 11903, 15513],
         [   13,     2, 29871,  ...,    12,   268,  1678],
         [    2,    13, 14136,  ...,  8169, 15110,   268]]], device='cuda:0')
Batch 12, 33.5% of total tokens
encoded shape: torch.Size([2, 1197])
torch.Size([2, 1197]) tensor([[   1,  396, 2897,  ...,    2,    2,    2],
        [   1, 1053, 6608,  ...,  736,  286,   13]], device='cuda:0')
torch.Size([2, 1197, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [ -8.0234,  -8.4297,   0.0357,  ...,  -3.7441,  -4.6406,  -6.2891],
         [ -6.5234,  -6.2734,   3.5234,  ...,  -2.7832,  -3.7695,  -0.7568],
         ...,
         [ -7.9141,   2.1523,   3.1367,  ...,  -3.1191,  -4.2188,  -1.7637],
         [ -7.9805,   2.0645,   3.1562,  ...,  -3.1348,  -4.2344,  -1.7686],
         [ -7.8945,   2.2637,   3.1855,  ...,  -3.0625,  -4.1602,  -1.6846]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5000],
         [ -7.3672,  -7.3477,  -1.1240,  ...,  -6.3203,  -7.2227,  -2.3516],
         [ -5.7031,  -8.2734,   5.2070,  ...,  -1.5625,  -2.1562,  -4.7266],
         ...,
         [ -1.7031,  -5.3398,   7.1602,  ...,  -0.1710,  -2.2988,  -1.4785],
         [  2.0996,  -0.6304,  22.7812,  ...,   1.1143,   0.8301,   0.9858],
         [  1.6621,   5.9102,  27.2969,  ...,   3.0059,   0.5479,   2.2676]]],
       device='cuda:0')
torch.Size([2, 1197, 1]) tensor([[[  917],
         [29871],
         [29889],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [  426],
         [ 1982],
         ...,
         [  286],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 1197, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [29889,    13, 29887,  ...,   313, 29881,   294],
         ...,
         [    3,    12,    13,  ...,  6224, 12008,  8169],
         [    3,    12,    13,  ...,  6224, 12008,  8169],
         [    3,    12,    13,  ...,  6224, 12008,  8169]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  426,  9537,  2897,  ...,  2115, 12183,  1134],
         [ 1982,   515,    13,  ...,  1315,   519,   267],
         ...,
         [  286, 28147,  2643,  ...,  3858, 19269,  1903],
         [   13,     2, 29889,  ...,   718, 29871,   565],
         [    2,    13,  1678,  ...,   308,   462,  4706]]], device='cuda:0')
Batch 13, 35.0% of total tokens
encoded shape: torch.Size([2, 1546])
torch.Size([2, 1546]) tensor([[    1,   413,   296,  ..., 29886, 13128,    13],
        [    1,  1053,   426,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1546, 32000]) tensor([[[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [-10.6953, -11.3359,  -3.5195,  ...,  -7.2656,  -4.3438,  -6.4141],
         [-12.4609, -13.1719,  -2.9766,  ...,  -7.9648,  -8.4844,  -8.5703],
         ...,
         [ -3.5410,  -6.6602,   6.6406,  ...,   0.9448,  -1.5576,  -0.3977],
         [  2.5664,  -0.0844,  20.4219,  ...,  -0.6440,  -0.8481,   1.0098],
         [  2.8340,   3.7305,  23.3281,  ...,   0.4658,  -0.4788,   3.0234]],

        [[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [ -7.3672,  -7.3477,  -1.1182,  ...,  -6.3164,  -7.2227,  -2.3477],
         [ -5.9375, -10.1719,  -0.3267,  ...,  -2.5020,  -4.5430,  -2.2246],
         ...,
         [-11.7031,  -5.2734,   3.1230,  ...,  -7.0000,  -7.2930,  -7.1367],
         [-11.7109,  -5.2617,   3.1055,  ...,  -6.9805,  -7.2852,  -7.1250],
         [-11.7109,  -5.2461,   3.0859,  ...,  -6.9648,  -7.2852,  -7.1172]]],
       device='cuda:0')
torch.Size([2, 1546, 1]) tensor([[[  917],
         [ 4841],
         [14395],
         ...,
         [13128],
         [   13],
         [   13]],

        [[  917],
         [  426],
         [15924],
         ...,
         [ 1516],
         [ 1516],
         [ 1516]]], device='cuda:0')
torch.Size([2, 1546, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 4841,   487,   326,  ..., 29882,   296,  2021],
         [14395,   265, 29889,  ..., 15178, 29992,   307],
         ...,
         [13128,  1962,  6435,  ...,  4802, 29871,  1243],
         [   13,     2, 29871,  ...,   259,  6435, 29889],
         [   13,     2,    12,  ..., 29937,   268,  1678]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  426,  9537,  2897,  ...,  2115, 12183,  1134],
         [15924,    13,   512,  ...,  5308, 15591,   679],
         ...,
         [ 1516,  4345, 29924,  ..., 29906, 29938, 29885],
         [ 1516,  4345, 29924,  ..., 29906, 29938, 29885],
         [ 1516,  4345, 29924,  ..., 29906, 29938, 29885]]], device='cuda:0')
Batch 14, 37.9% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   849,  7052,  ...,     2,     2,     2],
        [    1,  2056, 19603,  ...,   486, 29893,   263]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5469,  -6.0430,   2.0840,  ...,  -2.3574,  -5.3828,   3.4375],
         [-11.1484, -15.0703,  -2.8809,  ...,  -7.0391,  -7.5742,  -7.2070],
         ...,
         [ -9.8594,   0.8076,   5.4922,  ...,  -2.8008,  -4.2812,  -2.1113],
         [ -9.8516,   0.8481,   5.5078,  ...,  -2.7812,  -4.2539,  -2.0918],
         [ -9.8516,   0.9268,   5.5078,  ...,  -2.7520,  -4.2070,  -2.0430]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.4375,  -9.4922,  -1.5410,  ...,  -8.7344,  -9.6328,  -5.2539],
         [ -9.4766,  -8.5938,  -1.0566,  ...,  -5.2695,  -7.3359,  -2.8770],
         ...,
         [ -6.8359, -13.9219,   4.9258,  ...,  -0.5938,  -2.8750,  -1.2910],
         [ -1.5674,  -7.0078,   6.8438,  ...,   2.7109,   0.2776,   1.1514],
         [ -1.7949,  -7.0547,   7.9492,  ...,   2.4023,  -0.7617,   0.6909]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [   13],
         [  278],
         ...,
         [ 4345],
         [ 4345],
         [ 4345]],

        [[  917],
         [   13],
         [19603],
         ...,
         [29893],
         [  263],
         [29892]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [  278, 29881,    13,  ...,  7329,   353,   701],
         ...,
         [ 4345,    13, 29924,  ..., 29900,  1576, 29903],
         [ 4345,    13, 29924,  ..., 29900,  1576, 29903],
         [ 4345,    13, 29924,  ..., 29900, 29903,  1576]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  7859, 29898,  ...,   334,   450,    12],
         [19603,  7859,    13,  ...,   910,  3831,   448],
         ...,
         [29893, 29880, 29916,  ...,   281, 29881,  2774],
         [  263,   921, 29892,  ...,   269,   503,   343],
         [29892,  1919, 29901,  ..., 29889,   921, 29918]]], device='cuda:0')
Batch 15, 44.4% of total tokens
encoded shape: torch.Size([2, 829])
torch.Size([2, 829]) tensor([[    1,   396, 28436,  ...,     2,     2,     2],
        [    1,   849,   718,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 829, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.0156,  -8.4297,   0.0358,  ...,  -3.7441,  -4.6406,  -6.2891],
         [ -6.1367,  -6.0938,   2.6465,  ...,  -3.2051,  -2.5469,  -2.2539],
         ...,
         [ -8.2266,   2.1504,   3.4551,  ...,  -3.0234,  -4.4102,  -2.2598],
         [ -8.1484,   2.1836,   3.4199,  ...,  -3.0039,  -4.3867,  -2.2539],
         [ -8.1719,   2.0703,   3.3613,  ...,  -3.0469,  -4.4180,  -2.2988]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5469,  -6.0391,   2.0840,  ...,  -2.3574,  -5.3789,   3.4414],
         [ -6.7578, -12.5391,   1.9941,  ...,  -1.9072,  -5.0820,  -0.3445],
         ...,
         [ -3.1875,   3.0469,  16.2500,  ...,   1.9092,  -4.0508,   0.6919],
         [  1.1885,   5.1641,  30.1875,  ...,   1.4629,   0.3506,   2.1367],
         [  3.7109,   6.8320,  29.6562,  ...,   4.5117,   0.0955,   4.5078]]],
       device='cuda:0')
torch.Size([2, 829, 1]) tensor([[[  917],
         [29871],
         [ 2748],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [   13],
         [ 4282],
         ...,
         [29913],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 829, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [ 2748,   402,  9177,  ...,   298,  2295,  9406],
         ...,
         [    3,    12,    13,  ..., 30140, 29989, 29902],
         [    3,    12,    13,  ..., 30140, 29989, 29902],
         [    3,    12,    13,  ..., 30140, 29989, 29902]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [ 4282,  2683, 29895,  ...,  8893, 29879,  2048],
         ...,
         [29913,    13,    12,  ...,  3400, 10114,   458],
         [   13,     2,   849,  ...,   259,   462,    12],
         [    2,    13,  9891,  ..., 30004, 29952,  1853]]], device='cuda:0')
Batch 16, 45.4% of total tokens
encoded shape: torch.Size([2, 1251])
torch.Size([2, 1251]) tensor([[    1,   395,  1127,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1251, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.8672, -12.9141,  -3.1230,  ...,  -7.5195,  -8.0000,  -6.2852],
         [ -9.5625, -12.2109,  -0.6509,  ...,  -7.0703,  -6.8555,  -5.6367],
         ...,
         [ -7.8164,   2.3340,   3.2246,  ...,  -3.0215,  -4.3125,  -2.1016],
         [ -7.7148,   2.4355,   3.2090,  ...,  -2.9844,  -4.2695,  -2.0684],
         [ -7.8516,   2.2715,   3.1934,  ...,  -3.0527,  -4.3359,  -2.1191]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7188,  -9.4375,  -1.7588,  ...,  -6.2617,  -7.7266,  -2.2910],
         [ -6.5664,  -7.4375,   5.7305,  ...,  -4.1445,  -2.8672,   2.0352],
         ...,
         [ -0.1005,   4.5664,  16.4531,  ...,   3.2070,  -1.4658,   2.6172],
         [ -0.7930,   3.3945,  29.2812,  ...,   2.3750,  -0.1037,   0.6162],
         [  1.2568,   2.9863,  26.7969,  ...,   1.8125,  -2.9727,   2.4863]]],
       device='cuda:0')
torch.Size([2, 1251, 1]) tensor([[[  917],
         [29896],
         [  275],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [   13],
         [  334],
         ...,
         [29913],
         [    2],
         [    2]]], device='cuda:0')
torch.Size([2, 1251, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 29941,  ..., 29900, 29947, 29929],
         [  275,   353,  2455,  ..., 15161, 29892, 29881],
         ...,
         [    3,    12,    13,  ...,  6224,  8999,  1966],
         [    3,    12,    13,  ...,  6224,  8999, 12008],
         [    3,    12,    13,  ...,  6224,  8999,  1966]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    12,  ...,   259,   268, 29899],
         ...,
         [29913,    13,    12,  ...,  1836,  1118,   458],
         [    2,    13,   849,  ...,   259,  5515,   500],
         [    2,    13,  5515,  ...,  7918,  2751, 29913]]], device='cuda:0')
Batch 17, 47.0% of total tokens
encoded shape: torch.Size([2, 3380])
torch.Size([2, 3380]) tensor([[    1,  6319,  3134,  ...,  6051, 14442, 29958],
        [    1,  1192, 18267,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3380, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -3.6914,   0.0677,   8.2031,  ...,   1.5645,  -1.1162,   1.1865],
         [ -2.8203,  -5.0664,   6.2930,  ...,  -1.0273,  -1.3389,  -1.3027],
         ...,
         [ -4.6484,  -4.6758,  11.4375,  ...,  -6.7539,  -1.7373,  -2.4648],
         [ -1.4482,  -3.0371,  14.0156,  ...,  -2.1973,   0.4365,   0.3770],
         [  2.6504,   6.6914,  21.8750,  ...,   1.2305,   1.6895,   2.1445]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.4141,  -9.0938,  -0.4429,  ...,  -3.2871,  -6.8789,  -2.4180],
         [ -4.2539,  -6.1875,   4.3984,  ...,  -8.3516,  -8.7734,  -4.1836],
         ...,
         [-10.5703,   2.8184,   1.4238,  ...,  -5.3398,  -6.6914,  -4.8438],
         [-10.5781,   2.8750,   1.4238,  ...,  -5.3164,  -6.6797,  -4.8281],
         [-10.5156,   2.8184,   1.4365,  ...,  -5.2930,  -6.6406,  -4.7930]]],
       device='cuda:0')
torch.Size([2, 3380, 1]) tensor([[[  917],
         [ 1961],
         [ 1873],
         ...,
         [14442],
         [29958],
         [   13]],

        [[  917],
         [ 8999],
         [  489],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 3380, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1961,  3134,    13,  ...,  3160,   395,  6080],
         [ 1873, 29899,  8025,  ..., 29901, 29871,  6910],
         ...,
         [14442, 10312, 13342,  ..., 12841, 29899,    13],
         [29958, 13885, 11903,  ...,  2900,  6778,  5299],
         [   13,   259,     2,  ...,  1013,   418,   462]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 8999,   891,    13,  ...,  1275,  9166,   910],
         [  489, 29899,   383,  ...,  1192,  4214,    13],
         ...,
         [    3,    13,    12,  ..., 29903, 29911, 29909],
         [    3,    13,    12,  ..., 29903, 29911, 29909],
         [    3,    13,    12,  ..., 29903, 29911, 29909]]], device='cuda:0')
Batch 18, 50.7% of total tokens
encoded shape: torch.Size([2, 1496])
torch.Size([2, 1496]) tensor([[    1,  6319,  1961,  ...,     2,     2,     2],
        [    1,   396, 14187,  ...,  3396,   580,    13]], device='cuda:0')
torch.Size([2, 1496, 32000]) tensor([[[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [ -3.6895,   0.0739,   8.2031,  ...,   1.5615,  -1.1113,   1.1865],
         [  2.2520,   4.0938,  11.5391,  ...,  -1.0020,   1.8320,   2.7285],
         ...,
         [-10.7188,   1.8799,   1.6670,  ...,  -5.1406,  -6.2617,  -3.6875],
         [-10.7266,   1.7617,   1.6348,  ...,  -5.1953,  -6.3203,  -3.7656],
         [-10.7266,   1.7178,   1.6045,  ...,  -5.2344,  -6.3555,  -3.7988]],

        [[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [ -8.0156,  -8.4297,   0.0400,  ...,  -3.7441,  -4.6406,  -6.2852],
         [ -9.7344, -12.8438,  -2.1055,  ...,  -7.5195,  -9.6172,  -6.3945],
         ...,
         [ -1.6592,  -3.4785,  10.9453,  ...,  -3.3262,  -1.2207,  -0.7173],
         [ -2.4023,  -0.4636,  26.9688,  ...,  -0.1672,  -1.2783,  -2.1934],
         [ -2.5723,  -2.5664,  22.4688,  ...,  -0.7651,  -3.5566,  -3.0703]]],
       device='cuda:0')
torch.Size([2, 1496, 1]) tensor([[[  917],
         [ 1961],
         [   13],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29871],
         [ 1266],
         ...,
         [  580],
         [    2],
         [    2]]], device='cuda:0')
torch.Size([2, 1496, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1961,  3134,    13,  ...,  3160,   395,  6080],
         [   13, 30004, 29871,  ...,  3160,  9607,  6756],
         ...,
         [   13,     3,    12,  ...,  1678, 29902, 29903],
         [   13,     3,    12,  ...,  1678, 29902, 29903],
         [   13,     3,    12,  ...,  1678, 29902, 29903]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [ 1266,   292, 29899,  ...,   322,   278,  1551],
         ...,
         [  580, 29898, 26471,  ..., 22168, 18959,  3101],
         [    2,    13, 29871,  ...,   268,  1275,  6571],
         [    2,    13,  2751,  ...,  2277, 25512, 28956]]], device='cuda:0')
Batch 19, 52.5% of total tokens
encoded shape: torch.Size([2, 107])
torch.Size([2, 107]) tensor([[    1,   426,    13,  1678,   376,  1742,  1115,   376,  3563, 15866,
          1774,   613,    13,  1678,   376, 25476,  2187,  1115,   518,    13,
          4706,   376,   797,   263,  2106,   310, 23547,   681, 29163,   470,
         14919, 21549, 19602,    13,  4706, 18227,   974,   263,  8424,   310,
          5007,   470,   263,   664,   310,  1616, 29897,  2086, 19430,   470,
         12092,   297,  2874,   470,  7632,  1213,    13,  1678, 21251,    13,
          1678,   376, 20895, 29899,   974, 29899,  5965,  5309,  1115,   376,
          3253, 25674, 29908,    13, 29913,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2],
        [    1,  6319,  3134,  1873,   543, 29896, 29889, 29896, 18943,    13,
         14136,  6440, 29899,  5563,  7029,  2498,  7855,   756,  2678,  1873,
          1353,  1135,    13,   268,   937, 29899,  5563, 29892,   541,   451,
          2678,  1135,  1842, 29892,   577,   451,   385,  1059, 29889,  6660,
            13, 29966, 29991, 21300,  7953,   518,    13, 29966, 29991, 29923,
          1307, 13780,  7953, 13764, 29979, 29958,    13, 29966, 29991,  3919,
         11937,   875, 29896, 28962,  1254, 12665,   376, 29900, 29900, 29953,
         29918, 29896, 29889,   296,  1013,    13, 29966, 29991,  3919, 11937,
           875, 29906, 28962,  1254, 12665,   376, 29900, 29900, 29953, 29918,
         29906, 29889,   296,  1013,    13, 29962, 29958,    13, 29966,  5431,
         19250,   296, 29896, 14814,  5431, 29958,    13]], device='cuda:0')
torch.Size([2, 107, 32000]) tensor([[[-12.8594,  -7.3906,  -0.4624,  ...,  -6.7930,  -8.0312,  -7.5195],
         [ -8.0625,  -8.2031,  -0.5278,  ...,  -4.3086,  -3.6328,  -2.1543],
         [ -6.1250,  -4.2148,   5.6992,  ...,  -4.3555,  -3.9004,   1.2129],
         ...,
         [-12.1797,  -6.8594,  -0.2563,  ...,  -4.5508,  -5.8125,  -3.4355],
         [-12.2812,  -6.8984,  -0.6045,  ...,  -4.6406,  -5.8555,  -3.5059],
         [-12.4141,  -6.8438,  -1.0137,  ...,  -4.7969,  -5.9648,  -3.6543]],

        [[-12.8594,  -7.3906,  -0.4624,  ...,  -6.7930,  -8.0312,  -7.5195],
         [ -3.6895,   0.0688,   8.2031,  ...,   1.5605,  -1.1123,   1.1846],
         [ -2.8242,  -5.0625,   6.2852,  ...,  -1.0361,  -1.3428,  -1.3105],
         ...,
         [ -0.3311,  -3.2324,  12.1875,  ...,   0.6611,   0.2764,   2.2051],
         [  0.4766,   1.5752,  16.8906,  ...,   0.0782,  -0.2734,   2.3027],
         [ -6.9648,  -3.8828,  12.3516,  ...,  -5.2500,  -4.6055,  -1.5137]]],
       device='cuda:0')
torch.Size([2, 107, 1]) tensor([[[  917],
         [   13],
         [29871],
         [  376],
         [  978],
         [ 1115],
         [  376],
         [ 1742],
         [ 1493],
         [ 1774],
         [  613],
         [   13],
         [ 1678],
         [  376],
         [12676],
         [ 2187],
         [ 1115],
         [  518],
         [   13],
         [ 4706],
         [  426],
         [  735],
         [ 1555],
         [ 2106],
         [  310],
         [18677],
         [  681],
         [29163],
         [  470],
         [  946],
         [21549],
         [  613],
         [   13],
         [ 4706],
         [  376],
         [  974],
         [  263],
         [ 8424],
         [  310],
         [ 5007],
         [29897],
         [ 4696],
         [ 4180],
         [  310],
         [ 1616],
         [29897],
         [19163],
         [23023],
         [  470],
         [19430],
         [ 1213],
         [ 3114],
         [  470],
         [ 8225],
         [ 1213],
         [   13],
         [ 1678],
         [ 4514],
         [   13],
         [ 1678],
         [  376],
         [ 4773],
         [ 1115],
         [  974],
         [29899],
         [ 5965],
         [ 5309],
         [ 1115],
         [  518],
         [  328],
         [25674],
         [  613],
         [   13],
         [29913],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [29873],
         [29873],
         [30488],
         [30488],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576]],

        [[  917],
         [ 1961],
         [ 1873],
         [  543],
         [29896],
         [29889],
         [29900],
         [29908],
         [   13],
         [29966],
         [   13],
         [  653],
         [ 5563],
         [ 5354],
         [  360],
         [ 2133],
         [ 3407],
         [ 1063],
         [ 1873],
         [ 1135],
         [ 1135],
         [  278],
         [  268],
         [  937],
         [29899],
         [ 5563],
         [ 7029],
         [  541],
         [  338],
         [ 2678],
         [ 1135],
         [ 4654],
         [29915],
         [  577],
         [  372],
         [  263],
         [ 1059],
         [29889],
         [ 6660],
         [   13],
         [29966],
         [ 7836],
         [21300],
         [ 3472],
         [  518],
         [   13],
         [29966],
         [29991],
         [ 3919],
         [ 1307],
         [13780],
         [ 7953],
         [13764],
         [29979],
         [29958],
         [   13],
         [29966],
         [29991],
         [ 3919],
         [11937],
         [ 7953],
         [29896],
         [28962],
         [ 1254],
         [12665],
         [  376],
         [ 5431],
         [29900],
         [29900],
         [29889],
         [  296],
         [29889],
         [ 3134],
         [ 1013],
         [   13],
         [29966],
         [29991],
         [ 3919],
         [11937],
         [  875],
         [29906],
         [28962],
         [ 1254],
         [12665],
         [  376],
         [29900],
         [29900],
         [29953],
         [29918],
         [29906],
         [29889],
         [  296],
         [ 1013],
         [   13],
         [29966],
         [29958],
         [   13],
         [29966],
         [ 5431],
         [29958],
         [  296],
         [29896],
         [14814],
         [ 5431],
         [29958],
         [   13],
         [29966]]], device='cuda:0')
torch.Size([2, 107, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  6824, 29930,  ...,  6733,  2856, 29991],
         [29871,  1678,    12,  ...,   259, 22377,   462],
         ...,
         [ 1576,    13, 29902,  ..., 29896, 29933, 29903],
         [ 1576,    13, 29902,  ...,  4806, 29903, 29933],
         [ 1576,    13, 29902,  ...,  5618,  4806, 29903]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 1961,  3134,    13,  ...,  3160,   395,  6080],
         [ 1873, 29899,  8025,  ..., 29901, 29871,  6910],
         ...,
         [29958,  5299, 19250,  ...,  2565,    13, 14247],
         [   13,     2, 10341,  ..., 15110,   259,   669],
         [29966,     2,    13,  ..., 15945, 29908, 29987]]], device='cuda:0')
Batch 20, 52.7% of total tokens
encoded shape: torch.Size([2, 3182])
torch.Size([2, 3182]) tensor([[   1, 4949,   13,  ...,   13,   13,   13],
        [   1, 4949,   13,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 3182, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7188,  -9.4453,  -1.7578,  ...,  -6.2656,  -7.7266,  -2.2930],
         [ -6.5547,  -7.4062,   5.7344,  ...,  -4.1328,  -2.8457,   2.0449],
         ...,
         [  4.5781,   8.1328,  23.2344,  ...,   2.2910,   0.5981,   3.2324],
         [ -0.6431,   1.2891,  17.2656,  ...,   2.6406,  -0.4888,   3.5312],
         [ -0.7471,   0.5815,  17.6562,  ...,   2.2773,  -0.5889,   3.3887]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7188,  -9.4453,  -1.7578,  ...,  -6.2656,  -7.7266,  -2.2930],
         [ -6.5547,  -7.4062,   5.7344,  ...,  -4.1328,  -2.8457,   2.0449],
         ...,
         [-10.6719,   0.7842,   2.6172,  ...,  -5.9922,  -6.1445,  -3.9492],
         [-10.6797,   0.8457,   2.6309,  ...,  -5.9961,  -6.1523,  -3.9512],
         [-10.7109,   0.8433,   2.6211,  ...,  -6.0117,  -6.1992,  -3.9922]]],
       device='cuda:0')
torch.Size([2, 3182, 1]) tensor([[[  917],
         [   13],
         [  334],
         ...,
         [   13],
         [19737],
         [19737]],

        [[  917],
         [   13],
         [  334],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 3182, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    12,  ...,   259,   268, 29899],
         ...,
         [   13,     2, 29937,  ..., 29967, 29926,  5405],
         [19737,  7959, 29937,  ..., 29926,   458,   524],
         [19737,  7959, 29937,  ...,  5405, 29926,     2]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    12,  ...,   259,   268, 29899],
         ...,
         [29871,    12,    13,  ...,  6319,   869,   529],
         [29871,    13,    12,  ...,  6319,   869,   529],
         [29871,    13,    12,  ...,  6319,   869,   529]]], device='cuda:0')
Batch 21, 56.5% of total tokens
encoded shape: torch.Size([2, 968])
torch.Size([2, 968]) tensor([[    1,   396, 14187,  ...,     2,     2,     2],
        [    1, 18787,  4855,  ..., 29953, 29897,    13]], device='cuda:0')
torch.Size([2, 968, 32000]) tensor([[[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-8.0234e+00, -8.4375e+00,  3.8544e-02,  ..., -3.7461e+00,
          -4.6445e+00, -6.2891e+00],
         [-9.7344e+00, -1.2852e+01, -2.1055e+00,  ..., -7.5156e+00,
          -9.6172e+00, -6.3945e+00],
         ...,
         [-8.3750e+00,  1.7314e+00,  3.5547e+00,  ..., -3.6699e+00,
          -4.7930e+00, -2.1738e+00],
         [-8.2578e+00,  1.8828e+00,  3.6113e+00,  ..., -3.5664e+00,
          -4.7109e+00, -2.1133e+00],
         [-8.0078e+00,  2.1484e+00,  3.6426e+00,  ..., -3.3945e+00,
          -4.5508e+00, -2.0039e+00]],

        [[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [ 6.6211e+00,  8.1953e+00, -2.7617e+00,  ...,  9.4609e+00,
           5.8281e+00,  1.0086e+01],
         [-2.2109e+00, -1.7715e+00,  6.5078e+00,  ..., -1.2168e+00,
          -1.2666e+00,  4.2529e-01],
         ...,
         [ 1.3611e-01, -1.9385e-01,  1.5961e+01,  ...,  2.9043e+00,
          -1.9913e-02,  1.2031e+00],
         [ 9.4971e-01,  2.8887e+00,  2.3719e+01,  ...,  1.0195e+00,
           7.4268e-01, -5.5957e-01],
         [ 3.7129e+00,  6.1172e+00,  2.3797e+01,  ...,  2.5254e+00,
           1.9688e+00,  2.8477e+00]]], device='cuda:0')
torch.Size([2, 968, 1]) tensor([[[  917],
         [29871],
         [ 1266],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [ 4855],
         [29914],
         ...,
         [29897],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 968, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [ 1266,   292, 29899,  ...,   322,   278,  1551],
         ...,
         [    3,    13,    12,  ...,  6224,  8999, 12008],
         [    3,    13,    12,  ...,  6224,  8999, 12008],
         [    3,    13,    12,  ...,  6224, 12008,  8999]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 4855,  2109,  1792,  ...,  3670,  5959,  1982],
         [29914,  2109,    13,  ...,  6294,  5515, 25558],
         ...,
         [29897, 29892,  1723,  ..., 29918, 29871,   467],
         [   13,     2, 29871,  ...,  1678,   632,  4706],
         [    2,    13,  4706,  ...,  9651, 29905,   268]]], device='cuda:0')
Batch 22, 57.9% of total tokens
encoded shape: torch.Size([2, 3407])
torch.Size([2, 3407]) tensor([[    1,  4949, 21236,  ...,    13, 29913,    13],
        [    1,   396,   269,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3407, 32000]) tensor([[[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-1.1719e+01, -9.4453e+00, -1.7578e+00,  ..., -6.2656e+00,
          -7.7266e+00, -2.2930e+00],
         [-1.0062e+01, -1.5312e+01, -3.9883e+00,  ..., -6.8047e+00,
          -8.1406e+00, -5.2578e+00],
         ...,
         [ 3.2959e-01,  4.2812e+00,  1.5492e+01,  ...,  2.8516e+00,
          -9.4189e-01,  5.3594e+00],
         [-9.4580e-01, -1.0967e+00,  2.5469e+01,  ..., -1.4160e+00,
          -2.0293e+00,  1.5000e+00],
         [ 2.0254e+00,  1.5498e+00,  2.3578e+01,  ..., -2.0542e-03,
          -2.4219e+00,  2.3086e+00]],

        [[-1.2828e+01, -7.3906e+00, -4.7144e-01,  ..., -6.7773e+00,
          -8.0156e+00, -7.5039e+00],
         [-8.0234e+00, -8.4375e+00,  3.8544e-02,  ..., -3.7461e+00,
          -4.6445e+00, -6.2891e+00],
         [-8.4688e+00, -8.5156e+00,  1.7871e+00,  ..., -2.6289e+00,
          -5.5391e+00, -4.5430e+00],
         ...,
         [-1.1039e+01,  9.5391e+00,  1.9541e+00,  ..., -4.9492e+00,
          -6.6289e+00, -4.4297e+00],
         [-1.1086e+01,  9.3281e+00,  1.8027e+00,  ..., -5.0898e+00,
          -6.8555e+00, -4.6719e+00],
         [-1.1117e+01,  9.1016e+00,  1.6738e+00,  ..., -5.1992e+00,
          -7.0430e+00, -4.8477e+00]]], device='cuda:0')
torch.Size([2, 3407, 1]) tensor([[[  917],
         [   13],
         [ 3370],
         ...,
         [29913],
         [    2],
         [    2]],

        [[  917],
         [29871],
         [29889],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 3407, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [ 3370,  3489, 18914,  ...,  9538,   365,  1203],
         ...,
         [29913,    12,    13,  ...,   268,   500, 29871],
         [    2,    13, 29871,  ...,   268,   903,  1678],
         [    2,    13, 29937,  ...,  1649, 26019,  5746]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [29889, 29899,    13,  ..., 29914,   299, 29941],
         ...,
         [    1,    13, 29871,  ..., 29911, 29924, 29902],
         [    1,    13, 29871,  ...,     3, 29924, 29902],
         [    1,    13, 29871,  ..., 29924, 29902,     3]]], device='cuda:0')
Batch 23, 61.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[   1,  849,   13,  ...,    2,    2,    2],
        [   1, 4949,   13,  ..., 8139,  287, 1123]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5469,  -6.0430,   2.0840,  ...,  -2.3574,  -5.3828,   3.4375],
         [ -8.0859,  -6.0391,   6.5586,  ...,  -4.8398,  -4.8008,   0.4360],
         ...,
         [-11.1484,   8.0625,   0.9146,  ...,  -4.9570,  -7.2031,  -5.0000],
         [-10.8984,   8.1875,   0.9263,  ...,  -4.7422,  -6.9961,  -4.8320],
         [-10.6562,   8.2578,   0.9468,  ...,  -4.5586,  -6.8008,  -4.6875]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7188,  -9.4453,  -1.7578,  ...,  -6.2656,  -7.7266,  -2.2930],
         [ -6.5547,  -7.4062,   5.7344,  ...,  -4.1328,  -2.8457,   2.0449],
         ...,
         [ -0.4109,  -8.9688,   1.7598,  ...,   3.6816,  -0.3960,  -1.1953],
         [ -4.1992, -10.8672,   0.9009,  ...,  -0.9385,   0.6758,  -3.0703],
         [ -2.8398, -12.0312,   1.9805,  ...,   0.6484,  -2.0215,  -3.3262]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[ 917],
         [  13],
         [5215],
         ...,
         [   1],
         [   1],
         [   1]],

        [[ 917],
         [  13],
         [ 334],
         ...,
         [ 287],
         [1123],
         [6915]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [ 5215,   458,    13,  ..., 15843,  1678,  1707],
         ...,
         [    1, 29871,    13,  ..., 29909, 29924, 29933],
         [    1, 29871,    13,  ..., 29909, 29924, 29933],
         [    1, 29871,    13,  ..., 29909, 29924, 29933]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    12,  ...,   259,   268, 29899],
         ...,
         [  287,  5779, 21219,  ...,   329,   384,  7584],
         [ 1123,  1666,  1762,  ...,  6113, 11123, 27175],
         [ 6915,  3150, 17918,  ...,   481, 13082,  4300]]], device='cuda:0')
Batch 24, 65.9% of total tokens
encoded shape: torch.Size([2, 2286])
torch.Size([2, 2286]) tensor([[    1,   334,  4074,  ...,     2,     2,     2],
        [    1, 29871, 30143,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 2286, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7812,  -9.3125,  -2.3750,  ...,  -6.6641,  -9.9766,  -6.3867],
         [ -9.0938, -10.3672,  -0.9663,  ...,  -6.0938,  -4.6289,  -5.6992],
         ...,
         [ -9.7812,  11.3672,   3.0156,  ...,  -3.1484,  -4.9375,  -2.3340],
         [ -9.4062,  11.9141,   3.0410,  ...,  -2.9414,  -4.7344,  -2.0488],
         [ -9.4219,  11.9141,   3.0508,  ...,  -2.9551,  -4.7227,  -2.0547]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -6.4570,   2.7051,   4.7422,  ...,   4.3750,   0.5283,   3.3926],
         [ -9.2812,  -4.8633,   3.0352,  ...,  -4.9219,  -7.1211,  -3.0801],
         ...,
         [  3.3652,   4.9531,  15.9062,  ...,   3.4102,   1.2939,   5.1914],
         [ -1.1904,   0.1473,  21.3594,  ...,  -2.4297,   0.0622,   0.3464],
         [  3.4727,   6.9531,  26.6094,  ...,   1.0693,   0.5811,   3.3223]]],
       device='cuda:0')
torch.Size([2, 2286, 1]) tensor([[[  917],
         [  334],
         [ 1493],
         ...,
         [    1],
         [    1],
         [    1]],

        [[  917],
         [29896],
         [ 4746],
         ...,
         [29913],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 2286, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  334,  2328, 29871,  ...,  4013, 14550,   518],
         [ 1493,  2868,  7406,  ...,   326, 19819,   627],
         ...,
         [    1,     3,    13,  ..., 29909, 29924, 29907],
         [    1,     3,    13,  ...,   869, 29909, 29963],
         [    1,     3,    13,  ...,   869, 29909, 29963]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [ 4746, 22377,   458,  ..., 29966,  7918, 30004],
         ...,
         [29913,    13,   259,  ...,   500,  5515,   418],
         [   13,     2,   849,  ...,  4949,    12,   313],
         [    2,    13,   458,  ..., 29913,   259, 29871]]], device='cuda:0')
Batch 25, 68.3% of total tokens
encoded shape: torch.Size([2, 1112])
torch.Size([2, 1112]) tensor([[    1,   518,  2557,  ..., 10889, 29974, 19145],
        [    1, 16032,   287,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1112, 32000]) tensor([[[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [-10.0469, -11.1719,   0.1215,  ...,  -2.9395,  -3.9434,  -1.6367],
         [ -7.1211, -11.6719,   1.6328,  ...,  -4.1680,  -1.3242,  -6.0859],
         ...,
         [  0.7407,  -1.4521,  12.8750,  ...,   1.0146,   3.2812,   1.7549],
         [ -7.8203, -11.5078,   3.2070,  ...,  -4.3945,  -3.9961,  -3.1309],
         [  2.0625,   1.5264,  12.6328,  ...,  -0.8120,   2.8203,   1.2988]],

        [[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -8.4141,  -1.8350,   1.5205,  ...,  -0.4502,  -7.7969,  -3.8926],
         [ -9.5703,  -7.7578,   0.0206,  ...,  -7.5742,  -7.7578,  -6.2930],
         ...,
         [-11.6250,   8.1641,   1.0801,  ...,  -5.5000,  -7.6953,  -5.7344],
         [-11.5938,   8.3047,   1.0732,  ...,  -5.4492,  -7.6484,  -5.6719],
         [-11.5469,   8.4688,   1.1035,  ...,  -5.4141,  -7.5859,  -5.6172]]],
       device='cuda:0')
torch.Size([2, 1112, 1]) tensor([[[  917],
         [12614],
         [ 7595],
         ...,
         [29974],
         [ 3493],
         [   13]],

        [[  917],
         [  424],
         [  515],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 1112, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [12614, 29896, 29906,  ..., 29924, 29943, 29933],
         [ 7595,  1134,  4765,  ..., 22239, 29901,  2920],
         ...,
         [29974,    13, 17108,  ..., 23097, 13578, 29989],
         [ 3493,  1997, 29916,  ..., 29873, 29885, 29874],
         [   13,   313, 29871,  ...,   268,  1678, 29898]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  424,   749,   292,  ...,   596,   362,   278],
         [  515,   491,   304,  ...,  3645, 22535,   322],
         ...,
         [    1,    13, 29924,  ..., 29909, 29949, 29907],
         [    1,    13, 29924,  ..., 29909, 29949, 29907],
         [    1,    13, 29924,  ..., 29909, 29949, 29907]]], device='cuda:0')
Batch 26, 69.5% of total tokens
encoded shape: torch.Size([2, 1103])
torch.Size([2, 1103]) tensor([[    1,  1053,   426,  ...,     2,     2,     2],
        [    1,   849, 14187,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1103, 32000]) tensor([[[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -7.3672,  -7.3438,  -1.1211,  ...,  -6.3164,  -7.2227,  -2.3457],
         [ -5.9375, -10.1797,  -0.3257,  ...,  -2.4961,  -4.5391,  -2.2207],
         ...,
         [-11.1406,   2.4922,   2.2031,  ...,  -5.4922,  -6.5742,  -3.9336],
         [-11.1172,   2.3418,   2.2383,  ...,  -5.4688,  -6.5586,  -3.9531],
         [-11.1250,   2.3047,   2.2168,  ...,  -5.4648,  -6.5938,  -4.0039]],

        [[-12.8359,  -7.3984,  -0.4673,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -8.5469,  -6.0352,   2.0898,  ...,  -2.3516,  -5.3750,   3.4492],
         [ -2.5820,  -4.8906,   5.7812,  ...,  -0.5132,  -0.4036,   3.5312],
         ...,
         [  3.5742,   6.2109,  18.2969,  ...,   3.5645,   2.0391,   6.1875],
         [ -1.9404,   0.2113,  22.7031,  ...,  -1.0303,  -1.4619,  -0.4631],
         [  1.0254,   2.2383,  22.5781,  ...,  -0.6938,  -1.8330,   2.6309]]],
       device='cuda:0')
torch.Size([2, 1103, 1]) tensor([[[  917],
         [  426],
         [15924],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [   13],
         [ 1266],
         ...,
         [29913],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 1103, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  426,  9537,  2897,  ...,  2115, 12183,  1134],
         [15924,    13,   512,  ...,  5308, 15591,   679],
         ...,
         [   13, 29871,    12,  ...,  1678, 29949,   448],
         [   13, 29871,    12,  ..., 29949,  1678, 29903],
         [   13, 29871,    12,  ..., 29949,  1678, 29903]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [ 1266,   278,   322,  ..., 29899,   310, 29878],
         ...,
         [29913,    13,  1678,  ...,   930, 29871,   259],
         [   13,     2,   849,  ...,   268,  5515,  4949],
         [    2,    13,   458,  ...,  2220, 28956, 29871]]], device='cuda:0')
Batch 27, 70.6% of total tokens
encoded shape: torch.Size([2, 1403])
torch.Size([2, 1403]) tensor([[   1, 4949,   13,  ..., 3108,  416,   13],
        [   1, 4949,   13,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 1403, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [-11.7266,  -9.4453,  -1.7578,  ...,  -6.2617,  -7.7266,  -2.2930],
         [ -6.5898,  -7.4883,   5.7500,  ...,  -4.1641,  -2.8926,   2.0020],
         ...,
         [ -1.9492,  -5.5469,  12.1406,  ...,  -0.3936,   2.5781,   0.3579],
         [  0.7422,   3.2188,  17.7656,  ...,  -0.2659,   1.7461,   2.1328],
         [  1.7510,   7.7188,  17.5000,  ...,   0.6455,   1.9736,   1.9180]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [-11.7266,  -9.4453,  -1.7578,  ...,  -6.2617,  -7.7266,  -2.2930],
         [ -6.5898,  -7.4883,   5.7500,  ...,  -4.1641,  -2.8926,   2.0020],
         ...,
         [ -7.8633,   2.4395,   3.4941,  ...,  -3.2422,  -4.3672,  -1.8076],
         [ -7.8203,   2.5762,   3.5527,  ...,  -3.1934,  -4.3359,  -1.7539],
         [ -7.8203,   2.6621,   3.5840,  ...,  -3.1797,  -4.3359,  -1.7227]]],
       device='cuda:0')
torch.Size([2, 1403, 1]) tensor([[[917],
         [ 13],
         [334],
         ...,
         [416],
         [ 13],
         [ 13]],

        [[917],
         [ 13],
         [334],
         ...,
         [  3],
         [  3],
         [  3]]], device='cuda:0')
torch.Size([2, 1403, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    13,  ...,   259,   268, 29899],
         ...,
         [  416,  6075,   876,  ...,  1385,  5691,    13],
         [   13,     2, 11309,  ..., 30004,  1707, 29913],
         [   13, 29914, 11309,  ...,   458, 29898, 29913]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    13,  ...,   259,   268, 29899],
         ...,
         [    3,    12,    13,  ...,  6224,  9137,  1678],
         [    3,    12,    13,  ...,  6224,  9137,  1678],
         [    3,    12,    13,  ...,  6224,  1678,  9137]]], device='cuda:0')
Batch 28, 72.5% of total tokens
encoded shape: torch.Size([2, 1482])
torch.Size([2, 1482]) tensor([[   1, 7397,  853,  ...,    2,    2,    2],
        [   1,  849,  946,  ...,   13,   13,   13]], device='cuda:0')
torch.Size([2, 1482, 32000]) tensor([[[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [ -8.6094,  -7.0117,  -1.7480,  ...,  -9.0625,  -7.0742,  -7.0742],
         [ -4.7266,  -8.4922,   1.4512,  ...,  -2.1230,   1.1670,  -1.7314],
         ...,
         [-10.1797,   0.4033,   2.3926,  ...,  -5.2266,  -5.8164,  -2.8086],
         [-10.2031,   0.4019,   2.3828,  ...,  -5.2422,  -5.8438,  -2.8379],
         [-10.2188,   0.3733,   2.3691,  ...,  -5.2773,  -5.8828,  -2.8828]],

        [[-12.8594,  -7.3906,  -0.4617,  ...,  -6.7930,  -8.0312,  -7.5195],
         [ -8.5547,  -6.0469,   2.0801,  ...,  -2.3594,  -5.3828,   3.4395],
         [ -9.4219,  -9.2812,  -0.0850,  ...,  -4.9688,  -5.0703,  -4.5977],
         ...,
         [  3.3828,   7.9297,  25.7500,  ...,   1.2549,   0.0464,   3.7422],
         [  3.5039,   8.1484,  23.8906,  ...,   0.8511,   0.6885,   4.8789],
         [  4.1953,   7.8789,  23.9531,  ...,   0.8159,   1.5488,   4.1328]]],
       device='cuda:0')
torch.Size([2, 1482, 1]) tensor([[[  917],
         [ 7783],
         [29875],
         ...,
         [   12],
         [   12],
         [   12]],

        [[  917],
         [   13],
         [29899],
         ...,
         [    2],
         [    2],
         [    2]]], device='cuda:0')
torch.Size([2, 1482, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 7783,  2401,  2184,  ..., 12444,  1963,   315],
         [29875,  6370, 29877,  ..., 12193,   275,  9435],
         ...,
         [   12, 29871,    13,  ...,   268,  6319, 29949],
         [   12, 29871,    13,  ...,   268,  6319, 29949],
         [   12, 29871,    13,  ...,   268,  6319, 29949]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [29899,  8395,  1727,  ...,   279, 29918,  3663],
         ...,
         [    2,    13,   458,  ...,   259,   462,  1678],
         [    2,   458,    13,  ..., 29914, 22377,  6658],
         [    2,    13,   458,  ..., 22377, 29914,   268]]], device='cuda:0')
Batch 29, 74.3% of total tokens
encoded shape: torch.Size([2, 1682])
torch.Size([2, 1682]) tensor([[    1,  3577,  1243,  ...,    13, 29913,    13],
        [    1,   426,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1682, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -8.9297,  -6.3359,  -2.4492,  ...,  -7.2422,  -7.7695,  -7.1445],
         [ -6.3594,  -9.7344,   3.9043,  ...,  -4.3281,  -3.2383,  -2.6855],
         ...,
         [ -2.9551,   1.2500,  19.9688,  ...,   1.7627,  -3.5449,   1.4941],
         [  0.4678,   4.2383,  29.7812,  ...,   0.1567,  -1.6211,   1.2178],
         [  3.9609,   6.4492,  29.6094,  ...,   3.5742,  -0.4429,   4.3008]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -8.0703,  -8.2109,  -0.5312,  ...,  -4.3047,  -3.6445,  -2.1523],
         [ -6.1211,  -4.2070,   5.6992,  ...,  -4.3516,  -3.8965,   1.2148],
         ...,
         [-10.8750,   2.4727,   1.5918,  ...,  -5.0156,  -6.5508,  -4.7539],
         [-10.8516,   2.4062,   1.5869,  ...,  -5.0273,  -6.5820,  -4.7891],
         [-10.7969,   2.3652,   1.5801,  ...,  -5.0312,  -6.6055,  -4.8086]]],
       device='cuda:0')
torch.Size([2, 1682, 1]) tensor([[[  917],
         [  419],
         [29889],
         ...,
         [29913],
         [   13],
         [    2]],

        [[  917],
         [   13],
         [29871],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1682, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  419,  1638, 12013,  ...,   592,  1226,  5796],
         [29889,    13, 29936,  ..., 13239,   261, 11436],
         ...,
         [29913,    13,    12,  ...,  3400,   500,  1800],
         [   13,     2,   849,  ...,  3877,  3776,  1683],
         [    2,    13,  9891,  ..., 29952,  3877, 30004]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  6824, 29930,  ...,  6733,  2856, 29991],
         [29871,  1678,    12,  ...,   259, 22377,   462],
         ...,
         [    3,    13,    12,  ..., 29909, 29924, 29933],
         [    3,    13,    12,  ..., 29909, 29933, 29924],
         [    3,    13,    12,  ..., 29909, 29933, 29924]]], device='cuda:0')
Batch 30, 76.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  3577,   419,  ...,     2,     2,     2],
        [    1,   849,  1738,  ..., 25752, 29900, 29929]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.9297,  -6.3320,  -2.4492,  ...,  -7.2422,  -7.7734,  -7.1445],
         [ -1.5811,  -3.4570,  10.5547,  ...,   4.7266,   0.7349,   1.6367],
         ...,
         [-11.2266,   4.1445,   1.1074,  ...,  -5.4375,  -7.0820,  -4.8320],
         [-11.1875,   4.2461,   1.1387,  ...,  -5.3242,  -6.9453,  -4.7227],
         [-11.2656,   4.4062,   1.1680,  ...,  -5.3672,  -7.0430,  -4.7930]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5469,  -6.0430,   2.0840,  ...,  -2.3574,  -5.3828,   3.4375],
         [ -7.0781, -12.1250,   1.9043,  ...,  -6.2422,  -7.3281,  -3.4824],
         ...,
         [ -6.5078,  -5.4453,   5.2500,  ...,  -2.7637,  -4.3672,  -5.4609],
         [ -4.6992,  -3.7637,   6.0977,  ...,  -2.7305,  -6.9258,  -7.9141],
         [ -3.0645,  -3.0215,   5.0352,  ...,  -1.3545,  -2.5508,  -3.9199]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [  419],
         [29889],
         ...,
         [    3],
         [    3],
         [    1]],

        [[  917],
         [   13],
         [29931],
         ...,
         [29900],
         [29929],
         [29928]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [  419,  1638, 12013,  ...,   592,  1226,  5796],
         [29889,  3032, 29936,  ...,   833,   300,   293],
         ...,
         [    3,     1,    13,  ..., 29911, 29902, 29909],
         [    3,     1, 29949,  ..., 29911, 29902, 29909],
         [    1,     3,    13,  ..., 29911, 29902, 29909]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [29931,  6824, 29956,  ..., 29966,  2287, 29961],
         ...,
         [29900, 29896, 29906,  ..., 29945, 29953, 29955],
         [29929, 29909, 29900,  ..., 29945, 29946, 29928],
         [29928, 29923, 29943,  ..., 29941, 29929, 29909]]], device='cuda:0')
Batch 31, 80.7% of total tokens
encoded shape: torch.Size([2, 1276])
torch.Size([2, 1276]) tensor([[    1,   849, 14187,  ...,    13, 29913,    13],
        [    1,  1053,   426,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1276, 32000]) tensor([[[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -8.5469,  -6.0391,   2.0840,  ...,  -2.3574,  -5.3789,   3.4414],
         [ -2.5859,  -4.8984,   5.7773,  ...,  -0.5117,  -0.4019,   3.5391],
         ...,
         [ -2.7734,   4.1602,  20.9844,  ...,   1.9326,  -3.4590,   1.6143],
         [  0.2389,   5.9688,  31.4531,  ...,   1.3291,  -1.2178,   1.5068],
         [  3.1348,   6.7773,  22.1875,  ...,   3.6914,  -0.8433,   3.7871]],

        [[-12.8281,  -7.3945,  -0.4690,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -7.3672,  -7.3477,  -1.1240,  ...,  -6.3203,  -7.2227,  -2.3516],
         [ -5.9375, -10.1719,  -0.3254,  ...,  -2.4980,  -4.5430,  -2.2207],
         ...,
         [ -8.7812,   1.2246,   2.8789,  ...,  -3.8184,  -4.8438,  -2.7480],
         [ -8.7109,   1.2871,   2.8652,  ...,  -3.7930,  -4.8008,  -2.7148],
         [ -8.6953,   1.4219,   2.8926,  ...,  -3.7520,  -4.7578,  -2.6523]]],
       device='cuda:0')
torch.Size([2, 1276, 1]) tensor([[[  917],
         [   13],
         [ 1266],
         ...,
         [29913],
         [    2],
         [   13]],

        [[  917],
         [  426],
         [15924],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1276, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [ 1266,   278,   322,  ..., 29899,   310, 29878],
         ...,
         [29913,    13,     2,  ...,  3400,  1836,  8117],
         [    2,    13,   849,  ...,    12,  1678, 30004],
         [   13, 28956,     2,  ...,  5515,  9891, 29937]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [  426,  9537,  2897,  ...,  2115, 12183,  1134],
         [15924,    13,   512,  ...,  5308, 15591,   679],
         ...,
         [    3,    12,    13,  ...,  1678, 12008, 30143],
         [    3,    12,    13,  ..., 29902, 12008, 30143],
         [    3,    12,    13,  ..., 29902, 12008, 30143]]], device='cuda:0')
Batch 32, 82.2% of total tokens
encoded shape: torch.Size([2, 1986])
torch.Size([2, 1986]) tensor([[    1,   525,  1509,  ...,     2,     2,     2],
        [    1, 18252,  1867,  ...,  1420, 29958,    13]], device='cuda:0')
torch.Size([2, 1986, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-10.3281,  -8.5312,  -1.2764,  ...,  -4.6680,  -5.8008,  -4.7109],
         [ -6.6445,  -9.0000,  -0.2053,  ...,  -6.0820,  -4.3750,  -3.9453],
         ...,
         [ -9.9297,   0.7373,   2.2168,  ...,  -4.2852,  -5.6328,  -3.7441],
         [ -9.9141,   0.7817,   2.2344,  ...,  -4.2461,  -5.5859,  -3.7031],
         [ -9.9688,   0.7920,   2.2070,  ...,  -4.2852,  -5.6133,  -3.7227]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -3.4414,  -2.0234,   3.4668,  ...,   0.9087,  -1.7334,   1.0234],
         [ -3.5000,  -5.6328,   4.9297,  ...,  -1.8623,  -3.3711,  -1.9404],
         ...,
         [ -0.0478,   0.1395,  17.9375,  ...,   1.5605,   1.6934,   3.4258],
         [ -0.7759,   2.5254,  22.3438,  ...,  -1.9570,   0.3896,  -0.5371],
         [  3.3906,   6.8203,  25.1719,  ...,  -0.7803,   0.3047,   3.6113]]],
       device='cuda:0')
torch.Size([2, 1986, 1]) tensor([[[  917],
         [ 1509],
         [ 9406],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [21300],
         [  312],
         ...,
         [29958],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 1986, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [ 1509, 29902,  1576,  ...,  4013, 29954, 29903],
         [ 9406,   289, 29899,  ...,  2471,  7397,  4549],
         ...,
         [    3,    13,    12,  ..., 29871, 29966, 30140],
         [    3,    13,    12,  ..., 29871, 29966, 30140],
         [    3,    13,    12,  ..., 29909, 29966, 30140]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [21300,  1867,  5634,  ..., 23648, 22158,  9072],
         [  312,  2801, 29916,  ..., 28596,  1783,  1420],
         ...,
         [29958,  5299, 15513,  ...,  2565, 13885,     2],
         [   13,     2, 29871,  ...,  1678, 30166,   539],
         [    2,    13, 28956,  ...,   268, 12008,   259]]], device='cuda:0')
Batch 33, 84.7% of total tokens
encoded shape: torch.Size([2, 1792])
torch.Size([2, 1792]) tensor([[    1,   849, 29871,  ...,     2,     2,     2],
        [    1, 10341, 29871,  ...,  3293, 29958,    13]], device='cuda:0')
torch.Size([2, 1792, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -8.5469,  -6.0469,   2.0859,  ...,  -2.3555,  -5.3789,   3.4414],
         [ -8.9688,  -8.1094,   1.3389,  ...,   2.6191,  -2.3867,   5.4336],
         ...,
         [ -9.5156,   1.8848,   2.9707,  ...,  -3.8945,  -5.1250,  -2.4766],
         [ -9.5469,   1.9551,   2.9727,  ...,  -3.8984,  -5.1406,  -2.4707],
         [ -9.5391,   2.2207,   3.0293,  ...,  -3.8652,  -5.1328,  -2.3984]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -8.3594,  -9.6562,   1.6465,  ...,  -0.1323,  -5.5000,   1.5693],
         [ -7.4258,  -8.1328,   2.5098,  ...,   4.8594,  -2.9961,   3.9316],
         ...,
         [  0.4385,   1.0811,  15.8672,  ...,   0.8857,   0.4771,   2.8281],
         [ -1.9316,  -0.0420,  21.9688,  ...,  -1.7109,  -0.8384,   0.1309],
         [  3.2305,   6.6836,  26.1406,  ...,   0.4294,   1.4814,   4.7109]]],
       device='cuda:0')
torch.Size([2, 1792, 1]) tensor([[[  917],
         [   13],
         [   13],
         ...,
         [   13],
         [   13],
         [   13]],

        [[  917],
         [   13],
         [   13],
         ...,
         [29958],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 1792, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  5920, 29991,  ..., 29871, 22029,   448],
         [   13, 29896, 29906,  ...,   232,   233,   910],
         ...,
         [   13,     3,    12,  ..., 29902, 29909, 29903],
         [   13,     3,    12,  ..., 29902, 29909, 29903],
         [   13,     3,    12,  ..., 29909, 29902, 29903]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13, 29871,  3382,  ...,  4241, 29989,  6850],
         [   13,  6660,   232,  ...,   234, 22815, 31610],
         ...,
         [29958,  6778,  5299,  ...,  1405,  2565, 11903],
         [   13,     2, 29871,  ...,   529,    12,   462],
         [    2,    13, 29966,  ...,   268,   259,  1678]]], device='cuda:0')
Batch 34, 87.0% of total tokens
encoded shape: torch.Size([2, 520])
torch.Size([2, 520]) tensor([[    1,   396, 29974,  ..., 29903, 10363,    13],
        [    1,   529,  2754,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 520, 32000]) tensor([[[-12.8281,  -7.3867,  -0.4678,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -8.0156,  -8.4297,   0.0377,  ...,  -3.7461,  -4.6406,  -6.2852],
         [ -4.5938,  -3.8926,   1.7393,  ...,  -1.8691,  -3.0996,  -2.3184],
         ...,
         [ -1.4404,  -2.2617,   9.9453,  ...,   1.0732,  -1.8193,  -0.1028],
         [  2.3223,   3.1562,  20.2031,  ...,  -1.6211,  -1.0430,   0.1119],
         [  3.1816,   4.2617,  21.2031,  ...,   1.1367,   0.4895,   2.3789]],

        [[-12.8281,  -7.3867,  -0.4678,  ...,  -6.7734,  -8.0156,  -7.5000],
         [ -7.8516, -10.9062,  -0.5142,  ...,  -5.1172,  -3.8340,  -1.7832],
         [ -5.9570, -12.5391,   2.3770,  ...,  -2.4512,  -0.7666,  -2.8672],
         ...,
         [-13.5547,  -7.2539,  -4.4219,  ...,  -9.6797,  -9.8516,  -8.8672],
         [-13.5312,  -7.2188,  -4.4609,  ...,  -9.6484,  -9.8125,  -8.8594],
         [-13.5078,  -7.0703,  -4.5898,  ...,  -9.5312,  -9.7188,  -8.8125]]],
       device='cuda:0')
torch.Size([2, 520, 1]) tensor([[[  917],
         [29871],
         [   13],
         ...,
         [10363],
         [   13],
         [   13]],

        [[  917],
         [ 6886],
         [29899],
         ...,
         [  338],
         [  338],
         [  338]]], device='cuda:0')
torch.Size([2, 520, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29871,   349,   365,  ...,   315,   350,  2856],
         [   13, 29901, 29931,  ..., 13356,  9984,  5675],
         ...,
         [10363,  2214, 12445,  ..., 11341, 12513,  4174],
         [   13,     2, 29871,  ..., 29962,   308, 29936],
         [   13,     2, 29937,  ...,   308, 28956,  2277]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 6886,  4563, 29886,  ..., 29874,  3293,  2042],
         [29899, 29958,  1873,  ..., 29889,  1178, 29914],
         ...,
         [  338, 29871, 29892,  ...,   450,    13,   313],
         [  338, 29871, 29892,  ...,  1576,   313,    13],
         [  338, 29871, 29892,  ...,  1576,   313, 29924]]], device='cuda:0')
Batch 35, 87.9% of total tokens
encoded shape: torch.Size([2, 982])
torch.Size([2, 982]) tensor([[    1, 21389,   891,  ...,     2,     2,     2],
        [    1, 11474,    13,  ...,  3290,   275, 29889]], device='cuda:0')
torch.Size([2, 982, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -9.0547,  -7.7148,   1.5293,  ...,  -3.9258,  -3.8555,  -2.3203],
         [ -9.1484, -10.7578,   0.0723,  ...,  -4.6797,  -6.7305,  -2.2324],
         ...,
         [ -7.9883,   1.2568,   3.5469,  ...,  -3.0898,  -4.2031,  -1.6465],
         [ -8.0156,   1.1699,   3.5293,  ...,  -3.0879,  -4.2383,  -1.6777],
         [ -8.0156,   1.1250,   3.5215,  ...,  -3.0840,  -4.2383,  -1.6865]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [ -0.3516,   4.4180,   9.3594,  ...,   0.3293,  -2.4688,   2.5898],
         [ -4.0312,  -4.1055,   8.0859,  ...,  -2.1641,  -3.2090,   0.4614],
         ...,
         [ -8.9219, -11.3906,  -1.5674,  ...,  -6.0547,  -4.7656,  -7.4102],
         [ -9.8594, -11.6172,  -0.8345,  ...,  -8.4219,  -6.9688,  -8.4453],
         [ -7.7930,  -9.1875,  10.7891,  ...,  -4.4961,  -4.0820,  -4.9023]]],
       device='cuda:0')
torch.Size([2, 982, 1]) tensor([[[  917],
         [29937],
         [   13],
         ...,
         [    3],
         [    3],
         [    3]],

        [[  917],
         [   13],
         [ 3257],
         ...,
         [  275],
         [29892],
         [   13]]], device='cuda:0')
torch.Size([2, 982, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29937, 29989,    13,  ...,  2648,  3630, 29930],
         [   13,   910, 29871,  ..., 14187,  4241,  6680],
         ...,
         [    3,    12,    13,  ...,   268,   259, 30004],
         [    3,    12,    13,  ...,   268,   259, 30004],
         [    3,    12,    13,  ...,   268,   259, 30004]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13, 30004, 29871,  ..., 29937,   910, 29961],
         [ 3257,  2680,    13,  ..., 29992, 29871, 29899],
         ...,
         [  275,  2035,   595,  ...,  2390, 10989,   583],
         [29892,   802, 29889,  ..., 29973,   707, 29901],
         [   13,   751,   405,  ...,   382,   323,   379]]], device='cuda:0')
Batch 36, 89.3% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  4949,    13,  ..., 29918,  1525,  6720],
        [    1, 29807,    13,  ..., 29900, 29896,    12]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.7188,  -9.4453,  -1.7578,  ...,  -6.2656,  -7.7266,  -2.2930],
         [ -6.5547,  -7.4062,   5.7344,  ...,  -4.1328,  -2.8457,   2.0449],
         ...,
         [ -2.1855,  -9.0547,  -4.0039,  ...,  -2.1504,  -2.9590,   0.0179],
         [ -2.5859,  -7.0234,   3.4922,  ...,  -0.9653,  -2.0039,   0.6270],
         [ -5.6875,  -7.2773,   8.1875,  ...,  -2.7598,  -2.8105,  -1.7217]],

        [[-12.8281,  -7.3906,  -0.4714,  ...,  -6.7773,  -8.0156,  -7.5039],
         [-11.8516, -15.0547,  -1.1875,  ...,  -8.4844,  -6.4688,  -8.8516],
         [-10.2031,  -6.6055,   4.3750,  ...,  -5.1992,  -5.6367,  -2.4141],
         ...,
         [ -8.0859, -12.0312,   8.0156,  ...,  -6.1914,  -5.0977,  -5.7188],
         [ -6.0586,  -3.9375,  10.4141,  ...,  -1.9736,  -4.2070,  -4.3242],
         [ -5.4492,  -2.6660,   9.3594,  ...,  -4.9023,  -2.9297,  -1.7842]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[  917],
         [   13],
         [  334],
         ...,
         [ 1964],
         [ 6720],
         [29963]],

        [[  917],
         [29889],
         [   13],
         ...,
         [29896],
         [   12],
         [29946]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,   831,  9166,  ..., 17067,  5534, 29871],
         [  334, 29871,    12,  ...,   259,   268, 29899],
         ...,
         [ 1964, 29956,  1525,  ...,  3904,  1177,  9818],
         [ 6720,  6304, 29924,  ..., 27839, 17171,  1254],
         [29963, 12064,  8932,  ...,  9219, 22240, 24281]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29889, 29899, 29918,  ...,   675, 27716, 29906],
         [   13,  1678,  4706,  ...,  5215,  9651,  1576],
         ...,
         [29896, 29906, 29900,  ..., 29929, 29955, 29947],
         [   12,    13, 29871,  ..., 29900, 29929, 29936],
         [29946, 29945, 29941,  ..., 29947, 29929, 29899]]], device='cuda:0')
Batch 37, 97.5% of total tokens
encoded shape: torch.Size([2, 193])
torch.Size([2, 193]) tensor([[    1, 29871, 30143,  5515,    13, 11882,  1266,   313, 29883, 29897,
         29871, 29906, 29900, 29900, 29941, 29899, 29906, 29900, 29896, 29945,
         29892,   315, 29968,  4435,   448, 12294,  1417,   476,  7183,  1785,
         29889,  2178, 10462, 21676, 29889,    13,  2831,  7794,   575,   292,
         29892,  1074,   365,  2965,  1430,  1660, 29889,  3487,   470,  1732,
           597,   384, 15204, 29889,   510, 29914,   506,  1947,    13,  3877,
            13,  7077, 12378,  1955, 29889, 12800, 29889,   842, 29931,   574,
         29898,   525,  2158,   742,   525,   264,   742,   426,    13,    12,
         10154,  1646, 29901,   525, 11816, 29915,    13, 29913,  3482,    13,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,   426,    13,   259,   376,  9800, 29925,  4782,  8263,  3698,
         25060,  5612,   368,  1115,   426,    13,   418,   376,  2587,  1115,
           426,    13,   308,   376,  9800, 29925,  4782,  8263,  3698, 25060,
          1115,   426,    13,  9651,   376,  7387,  1115,   518,    13, 18884,
         29953, 29955, 29900, 29947, 29906, 29906, 29946, 29896, 29892, 29871,
            13, 18884, 29953, 29955, 29900, 29947, 29906, 29906, 29946, 29896,
         29892, 29871,    13, 18884, 29953, 29955, 29900, 29947, 29906, 29906,
         29946, 29896, 29892, 29871,    13, 18884, 29953, 29955, 29900, 29947,
         29906, 29906, 29946, 29896,    13,  9651, 21251, 29871,    13,  9651,
           376,  5030, 11614,  1115, 29871, 29945, 29892, 29871,    13,  9651,
           376,  3317, 29918, 13155,  1115,   518,    13, 18884, 29896, 29953,
         29955, 29955, 29955, 29906, 29896, 29953, 29892, 29871,    13, 18884,
         29896, 29953, 29955, 29955, 29955, 29906, 29896, 29953, 29892, 29871,
            13, 18884, 29896, 29953, 29955, 29955, 29955, 29906, 29896, 29953,
         29892, 29871,    13, 18884, 29896, 29953, 29955, 29955, 29955, 29906,
         29896, 29953,    13,  9651, 21251, 29871,    13,  9651,   376,  8768,
          1115, 29871, 29896, 29945,    13,   308,   500,    13,   418,  2981,
         29871,    13,   418,   376, 15764,  1115, 29871, 29900, 29892, 29871,
            13,   418,   376,  1853,  1115, 29871, 29947,    13,   259,   500,
            13, 29913,    13]], device='cuda:0')
torch.Size([2, 193, 32000]) tensor([[[-12.8125,  -7.3320,  -0.4856,  ...,  -6.7773,  -8.0156,  -7.4961],
         [ -6.4531,   2.7051,   4.7461,  ...,   4.3789,   0.5293,   3.3965],
         [ -9.2812,  -4.8711,   3.0332,  ...,  -4.9297,  -7.1250,  -3.0859],
         ...,
         [ -9.3047,   2.1074,   3.4004,  ...,  -2.2695,  -4.3398,  -1.7578],
         [ -9.3906,   1.8232,   3.8672,  ...,  -2.2363,  -4.4648,  -1.7520],
         [ -8.9844,   2.1660,   3.5410,  ...,  -1.9961,  -3.6777,  -1.2070]],

        [[-12.8125,  -7.3320,  -0.4856,  ...,  -6.7773,  -8.0156,  -7.4961],
         [ -8.0703,  -8.2031,  -0.5322,  ...,  -4.3086,  -3.6445,  -2.1562],
         [ -6.1406,  -4.1719,   5.7227,  ...,  -4.3516,  -3.9102,   1.2139],
         ...,
         [ -0.4126,   0.2262,  16.8125,  ...,   2.0996,   0.7266,   3.8984],
         [  0.1135,  -0.0485,  19.6875,  ...,  -2.6055,   2.6484,   1.5693],
         [ -3.7070,  -2.5430,  14.4844,  ...,  -3.3691,  -3.2773,  -3.4102]]],
       device='cuda:0')
torch.Size([2, 193, 1]) tensor([[[  917],
         [29896],
         [ 4746],
         [   13],
         [  334],
         [ 1266],
         [  313],
         [29883],
         [29897],
         [29871],
         [29906],
         [29900],
         [29896],
         [29929],
         [29899],
         [29906],
         [29900],
         [29896],
         [29906],
         [29892],
         [  315],
         [29968],
         [ 4435],
         [  448],
         [12294],
         [ 1417],
         [  476],
         [ 7183],
         [ 1785],
         [29889],
         [ 2178],
         [10462],
         [21676],
         [29889],
         [   13],
         [ 2831],
         [ 7794],
         [  575],
         [  292],
         [29892],
         [ 1074],
         [  365],
         [ 2965],
         [ 1430],
         [ 1660],
         [29889],
         [ 3487],
         [  470],
         [ 1732],
         [  597],
         [  384],
         [15204],
         [29889],
         [  510],
         [29914],
         [  506],
         [ 1947],
         [   13],
         [ 3877],
         [   13],
         [ 7077],
         [12378],
         [ 1955],
         [29889],
         [12800],
         [29889],
         [  842],
         [29931],
         [  574],
         [29898],
         [  525],
         [16179],
         [  742],
         [  525],
         [  267],
         [29899],
         [  426],
         [   13],
         [   12],
         [ 2158],
         [ 1646],
         [29901],
         [  525],
         [11816],
         [  742],
         [   13],
         [29913],
         [ 3482],
         [   13],
         [    2],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [30488],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [   13],
         [29871],
         [  376],
         [  978],
         [29918],
         [29918],
         [ 2111],
         [ 3698],
         [ 1115],
         [ 1115],
         [  368],
         [ 1115],
         [  426],
         [   13],
         [  418],
         [  376],
         [  978],
         [ 1115],
         [  426],
         [   13],
         [  308],
         [  376],
         [ 2972],
         [29925],
         [ 4782],
         [ 8263],
         [ 3698],
         [25060],
         [ 5612],
         [  426],
         [   13],
         [ 9651],
         [  376],
         [ 9800],
         [ 1115],
         [  426],
         [   13],
         [ 1669],
         [  426],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [29900],
         [29900],
         [29906],
         [   13],
         [29953],
         [18884],
         [29953],
         [29955],
         [29900],
         [29947],
         [29906],
         [29906],
         [29946],
         [29896],
         [29892],
         [29871],
         [   13],
         [18884],
         [29953],
         [29955],
         [29900],
         [29947],
         [29906],
         [29906],
         [29946],
         [29896],
         [29892],
         [29871],
         [   13],
         [18884],
         [29953],
         [29955],
         [29900],
         [29947],
         [29906],
         [29906],
         [29946],
         [29896],
         [29892],
         [ 9651],
         [21251],
         [   13],
         [   13],
         [ 9651],
         [  376],
         [ 5030],
         [11614],
         [ 1115],
         [  518],
         [29896],
         [29892],
         [29871],
         [   13],
         [ 9651],
         [  376],
         [ 2917],
         [29918],
         [ 7387],
         [ 1115],
         [29871],
         [   13],
         [18884],
         [29953],
         [   13],
         [29941],
         [29955],
         [29955],
         [29906],
         [29896],
         [29953],
         [   13],
         [29871],
         [   13],
         [18884],
         [29896],
         [29953],
         [29955],
         [29955],
         [29955],
         [29906],
         [29896],
         [29953],
         [29892],
         [29871],
         [   13],
         [18884],
         [29896],
         [29953],
         [29955],
         [29955],
         [29955],
         [29906],
         [29896],
         [29953],
         [29892],
         [29871],
         [   13],
         [18884],
         [29896],
         [29953],
         [29955],
         [29955],
         [29955],
         [29906],
         [29896],
         [29953],
         [   13],
         [ 9651],
         [21251],
         [29871],
         [   13],
         [ 9651],
         [  376],
         [ 3317],
         [ 1115],
         [  518],
         [29896],
         [29892],
         [29892],
         [  308],
         [  500],
         [   13],
         [  418],
         [ 2981],
         [29871],
         [   13],
         [  418],
         [  376],
         [ 8216],
         [ 1115],
         [  426],
         [29900],
         [29892],
         [29871],
         [   13],
         [  418],
         [  376],
         [ 6672],
         [ 1115],
         [  376],
         [29900],
         [   13],
         [  259],
         [  500],
         [   13],
         [29913],
         [   13],
         [28956]]], device='cuda:0')
torch.Size([2, 193, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [ 4746, 22377,   458,  ..., 29966,  7918, 30004],
         ...,
         [   13, 29900,  1576,  ..., 29909, 29912,  4345],
         [   13,  1576, 29900,  ..., 29954, 29909, 29912],
         [   13, 29900,  1576,  ..., 29906,  4345, 29943]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  6824, 29930,  ...,  6733,  2856, 29991],
         [29871,  1678,    12,  ...,   259, 22377,   462],
         ...,
         [29913,  1118,    13,  ...,  1012,  1836,  5038],
         [   13,     2, 29871,  ...,  4907,  1769,   742],
         [28956,     2,    13,  ..., 29912, 29937,  3776]]], device='cuda:0')
Batch 38, 97.8% of total tokens
encoded shape: torch.Size([2, 255])
torch.Size([2, 255]) tensor([[    1,   426,    13,  1678,   376, 11618,  1115,   518,    13,  4706,
           518,    13,  9651,   376,   771,   915, 13724,   448,  2322,   448,
          1095,   613,    13,   632, 29906, 29892,    13,   632, 29955, 29955,
         29900, 29941, 29946,    13,  4706, 21251,    13,  4706,   518,    13,
          9651,   376,   771,   915, 13724,   448,  2322,   448,  1369,   613,
            13,   632, 29900, 29892,    13,   632, 29900,    13,  4706,  4514,
            13,  1678, 21251,    13,  1678,   376, 29887, 11093,  1115,   518,
            13,  4706,   518,    13,  9651,   376,   771,   915, 29954, 26753,
           448,  2322,   448,  1095,   613,    13,   632, 29906, 29892,    13,
           632, 29946, 29892,    13,   632, 29947, 29892,    13,   632, 29896,
         29892,    13,  9651,   518,    13,   462, 29906, 29953, 29906, 29945,
         29953, 29892,    13,   462, 29906, 29953, 29906, 29945, 29953,    13,
          9651, 21251,    13,  9651,   518,    13,   462, 29945, 29946, 29892,
            13,   462, 29945, 29946,    13,  9651, 21251,    13,  9651,   518,
            13,   462, 29947, 29946, 29892,    13,   462, 29947, 29946,    13,
          9651,  4514,    13,  4706,  4514,    13,  1678,  4514,    13, 29913,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2],
        [    1, 29871,    13, 29899,  2803,  1404,  5839,   390,  7210, 11955,
            13,    13, 29899,  7338,   336, 11580, 28147,  3145, 29901,    13,
         29871,   448, 22558,    13,    13, 29899,  4544,  1962,  4464, 29973,
            13,    13, 29899, 26965,  2094,  2547,  2785,   310, 15359,   322,
          1009, 15562,  2629,   623,  2106,    13,    13,  2683,  2683,  2683,
          2683, 29899,    13,  2772, 12818,   411,   278,  7200,  2927,  2913,
         29901,    13,    13, 29899,  3740,  3697,   376, 29888, 17118,   568,
         29908, 11955, 29892,  1051,   508,   367, 21633,   491,   278,  1404,
            13, 29899,   383, 17118,  3246,   679,  6087,   297,   278,   934,
          3412,   411, 10508,   848, 29892,   337, 15638,   373,    13, 29871,
         20234,    13, 29899, 20768,  3740,   363,  5839,   292,   515, 29871,
         29906, 29945, 29953,  2927, 18272,   304,  6755,  7853,  3246,   304,
           788,    13, 29871,   304,   282, 26456, 11764,    13, 29899,  6212,
          5026,  1603,   679, 18511,  4153,   297,   278,  1962,   848,   322,
         10508,    13, 29899,   382,  4099,  4441,  2496,   769,   925,   756,
           304,  1284,   714,  3692,   278,  2927,   338,   297,   278,    13,
         29871,  7853,  3246,  1051, 29892,   322,   565,   451, 29892,   788,
           372, 29889,    13, 29899, 20768,   304,   505,  1023, 15509,   698,
           267, 29901,   383, 29887,   322,   350, 29887, 29892,  3265,  1135,
           278,  1021,   282, 26456,    13, 29871,   393,  4947,  1304,   363,
          1716, 29889,   450,  7480,   338,   263,  1781, 20234,  2322, 29892,
           541,    13, 29871, 18973,   278, 15509,   698,   267,   817,   304,
           367,  2221,   304, 13100, 25499, 29889,    13, 29899,   450,   282,
         26456,  4225,   304,  4953,   760,   310,   278, 10508,   848,  3829,
           577,   372,    13, 29871,   508,   367,   316, 29914, 15550,  1891,
           411,   278, 10508,   848,    13]], device='cuda:0')
torch.Size([2, 255, 32000]) tensor([[[-12.8125,  -7.3281,  -0.4844,  ...,  -6.7734,  -8.0156,  -7.4961],
         [ -8.0625,  -8.2031,  -0.5234,  ...,  -4.3086,  -3.6328,  -2.1582],
         [ -6.1367,  -4.1797,   5.7148,  ...,  -4.3555,  -3.9062,   1.2188],
         ...,
         [-11.7969,  -1.2227,  -0.4189,  ...,  -4.5430,  -5.5820,  -4.2305],
         [-11.2500,  -0.8237,  -0.7324,  ...,  -4.1484,  -5.1016,  -3.9102],
         [-11.0938,  -0.7241,  -0.9736,  ...,  -4.0117,  -4.9727,  -3.8574]],

        [[-12.8125,  -7.3281,  -0.4844,  ...,  -6.7734,  -8.0156,  -7.4961],
         [ -6.4492,   2.7051,   4.7539,  ...,   4.3828,   0.5317,   3.4004],
         [-11.1484,  -4.4375,   3.6426,  ...,  -5.2969,  -5.5977,  -2.5508],
         ...,
         [ -7.4648,  -9.9375,   8.9766,  ...,  -5.3594,  -3.2383,  -4.5898],
         [ -1.6543,  -5.3477,  12.7969,  ...,  -1.4141,  -0.8584,  -2.0664],
         [  2.4082,   2.5977,  22.3281,  ...,   2.3691,   0.6436,   2.6973]]],
       device='cuda:0')
torch.Size([2, 255, 1]) tensor([[[  917],
         [   13],
         [29871],
         [  376],
         [  978],
         [29879],
         [  426],
         [   13],
         [ 4706],
         [  426],
         [   13],
         [ 9651],
         [  376],
         [29896],
         [29454],
         [  613],
         [  613],
         [29871],
         [  613],
         [29871],
         [ 9748],
         [   13],
         [ 9651],
         [29896],
         [29900],
         [   13],
         [ 9651],
         [29896],
         [29892],
         [29892],
         [29900],
         [29892],
         [29892],
         [ 4706],
         [21251],
         [   13],
         [ 4706],
         [  518],
         [   13],
         [ 9651],
         [  376],
         [  771],
         [  915],
         [13724],
         [  448],
         [ 2322],
         [  448],
         [ 1369],
         [  613],
         [   13],
         [  632],
         [29906],
         [29892],
         [   13],
         [  632],
         [29900],
         [   13],
         [ 4706],
         [21251],
         [   13],
         [ 1678],
         [21251],
         [   13],
         [ 1678],
         [  376],
         [11618],
         [ 3746],
         [ 1115],
         [  518],
         [   13],
         [ 4706],
         [  518],
         [   13],
         [ 9651],
         [  376],
         [  771],
         [  915],
         [29954],
         [11093],
         [  448],
         [ 2322],
         [  448],
         [ 1095],
         [  613],
         [   13],
         [  632],
         [29906],
         [29892],
         [   13],
         [  632],
         [29955],
         [29900],
         [   13],
         [  632],
         [29896],
         [29892],
         [   13],
         [  632],
         [29896],
         [29953],
         [   13],
         [  632],
         [  376],
         [   13],
         [18884],
         [29900],
         [29892],
         [29892],
         [29896],
         [29953],
         [29892],
         [   13],
         [  462],
         [29906],
         [29953],
         [29906],
         [29945],
         [29953],
         [   13],
         [ 9651],
         [ 4514],
         [   13],
         [ 9651],
         [  518],
         [   13],
         [  462],
         [29906],
         [29906],
         [29945],
         [   13],
         [  462],
         [29945],
         [29946],
         [   13],
         [ 9651],
         [21251],
         [   13],
         [ 9651],
         [  518],
         [   13],
         [  462],
         [29896],
         [29892],
         [29892],
         [   13],
         [  462],
         [29947],
         [29946],
         [   13],
         [ 9651],
         [21251],
         [   13],
         [ 4706],
         [21251],
         [   13],
         [ 1678],
         [21251],
         [   13],
         [29913],
         [   13],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [29873],
         [29873],
         [29873],
         [    1],
         [30488],
         [29889],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13],
         [   13]],

        [[  917],
         [29896],
         [   13],
         [  518],
         [29915],
         [ 1831],
         [  263],
         [ 7210],
         [ 2927],
         [  363],
         [29899],
         [ 2277],
         [ 2803],
         [  355],
         [ 3987],
         [ 3987],
         [ 3145],
         [   13],
         [   13],
         [29871],
         [  448],
         [ 7407],
         [   13],
         [29871],
         [29899],
         [ 7338],
         [29945],
         [   13],
         [   13],
         [   13],
         [   13],
         [29899],
         [ 3462],
         [ 2304],
         [ 6119],
         [ 2785],
         [  310],
         [  278],
         [   13],
         [ 3618],
         [ 4426],
         [   13],
         [  278],
         [   13],
         [   13],
         [   13],
         [29899],
         [ 2683],
         [ 2683],
         [ 2683],
         [ 2683],
         [   13],
         [   13],
         [ 1022],
         [  411],
         [  278],
         [10508],
         [10508],
         [ 2913],
         [   13],
         [   13],
         [   13],
         [29899],
         [  390],
         [  363],
         [  263],
         [ 2780],
         [17118],
         [  568],
         [29908],
         [11955],
         [   13],
         [  541],
         [  310],
         [  367],
         [12705],
         [   13],
         [ 1404],
         [ 1404],
         [   13],
         [   13],
         [ 3740],
         [17118],
         [  568],
         [  508],
         [ 7160],
         [  297],
         [  278],
         [  623],
         [ 1788],
         [  411],
         [  278],
         [  848],
         [   13],
         [  577],
         [29899],
         [  373],
         [  623],
         [29871],
         [20234],
         [   13],
         [29899],
         [  383],
         [  304],
         [  304],
         [23906],
         [  292],
         [11955],
         [  278],
         [29896],
         [29945],
         [29953],
         [11955],
         [  282],
         [   13],
         [  679],
         [  515],
         [ 3246],
         [   13],
         [   13],
         [   13],
         [   13],
         [  304],
         [  278],
         [26456],
         [   13],
         [   13],
         [29899],
         [20768],
         [ 3456],
         [  310],
         [  817],
         [ 6087],
         [  408],
         [  964],
         [  278],
         [  934],
         [  934],
         [   13],
         [  508],
         [   13],
         [29871],
         [20768],
         [29889],
         [ 4441],
         [ 2496],
         [ 5780],
         [ 5839],
         [ 5839],
         [  304],
         [  367],
         [  278],
         [  607],
         [  278],
         [ 2927],
         [  338],
         [  297],
         [  278],
         [   13],
         [29871],
         [  282],
         [ 3246],
         [ 1051],
         [  470],
         [  322],
         [  565],
         [  451],
         [29892],
         [  788],
         [  372],
         [  304],
         [   13],
         [   13],
         [  383],
         [  304],
         [  788],
         [  263],
         [18893],
         [  698],
         [  267],
         [29901],
         [  697],
         [17118],
         [  322],
         [  350],
         [29887],
         [   13],
         [  322],
         [ 1135],
         [  925],
         [ 1857],
         [  282],
         [26456],
         [   13],
         [29871],
         [  363],
         [  338],
         [ 1304],
         [  363],
         [ 1716],
         [29889],
         [   13],
         [  383],
         [  338],
         [  263],
         [ 2586],
         [ 2969],
         [ 2969],
         [29892],
         [  541],
         [   13],
         [29871],
         [  278],
         [11981],
         [ 1404],
         [  698],
         [  267],
         [  881],
         [  304],
         [  367],
         [ 5004],
         [  304],
         [  367],
         [25499],
         [29889],
         [   13],
         [   13],
         [20768],
         [10977],
         [26456],
         [11764],
         [  304],
         [  367],
         [  263],
         [  310],
         [  278],
         [  623],
         [15562],
         [29892],
         [29892],
         [  393],
         [   13],
         [29871],
         [  508],
         [  367],
         [ 7160],
         [ 1997],
         [15550],
         [ 1891],
         [29889],
         [  278],
         [10508],
         [  848],
         [29889],
         [29899]]], device='cuda:0')
torch.Size([2, 255, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [   13,  6824, 29930,  ...,  6733,  2856, 29991],
         [29871,  1678,    12,  ...,   259, 22377, 29913],
         ...,
         [   13, 29871,   450,  ...,   306,   910,   512],
         [   13, 29871,   450,  ...,   910,   306, 29906],
         [   13, 29871,   450,  ...,  1576,   910, 29906]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [29896, 29906, 30143,  ..., 29953, 29955, 29900],
         [   13, 29871,  1678,  ..., 29966,   268,  1576],
         ...,
         [  848, 29889,    13,  ...,  2106,   408,   313],
         [29889,    13, 29892,  ...,   408,   304,   297],
         [29899,    13,     2,  ...,  1678,    12,  5634]]], device='cuda:0')
Batch 39, 98.2% of total tokens
encoded shape: torch.Size([2, 1683])
torch.Size([2, 1683]) tensor([[    1, 21389, 29937,  ...,   263,  5615,    13],
        [    1,  6319,  3134,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1683, 32000]) tensor([[[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -9.0703,  -7.7305,   1.5156,  ...,  -3.9219,  -3.8652,  -2.3262],
         [ -2.4336,  -4.8672,   4.6367,  ...,  -0.0444,  -2.8535,  -0.3264],
         ...,
         [ -3.3145,  -5.9141,   6.8320,  ...,  -0.0486,  -2.8066,  -5.4453],
         [ -1.5781,  -1.3750,  25.3125,  ...,  -2.5820,  -5.5781,  -1.7031],
         [ -1.1943,  -1.1338,  24.5000,  ...,  -1.5029,  -3.0352,  -3.0410]],

        [[-12.8281,  -7.4336,  -0.4663,  ...,  -6.7852,  -8.0156,  -7.5117],
         [ -3.6875,   0.0689,   8.1953,  ...,   1.5645,  -1.1123,   1.1865],
         [ -2.8262,  -5.0625,   6.2852,  ...,  -1.0293,  -1.3389,  -1.3027],
         ...,
         [-10.7734,   1.7256,   1.9189,  ...,  -4.6797,  -6.1914,  -4.4102],
         [-10.7812,   1.7520,   1.9150,  ...,  -4.6641,  -6.1602,  -4.3828],
         [-10.7500,   1.7402,   1.9287,  ...,  -4.6328,  -6.1094,  -4.3438]]],
       device='cuda:0')
torch.Size([2, 1683, 1]) tensor([[[  917],
         [29937],
         [  365],
         ...,
         [ 5615],
         [   13],
         [    2]],

        [[  917],
         [ 1961],
         [ 1873],
         ...,
         [    3],
         [    3],
         [    3]]], device='cuda:0')
torch.Size([2, 1683, 10]) tensor([[[  917,   396,   450,  ...,   319,   306,   512],
         [29937, 29989,    13,  ...,  2648,  3630, 29930],
         [  365,  6418, 29931,  ..., 21233, 25186,   459],
         ...,
         [ 5615,  1800,  2604,  ..., 15271, 29892,  2981],
         [   13,     2,   421,  ...,  4644,  1192,  2322],
         [    2,    13, 30004,  ...,   462,  4706,   539]],

        [[  917,   396,   450,  ...,   319,   306,   512],
         [ 1961,  3134,    13,  ...,  3160,   395,  6080],
         [ 1873, 29899,  8025,  ..., 29901, 29871,  6910],
         ...,
         [    3,    13,    12,  ..., 29911, 29903, 29871],
         [    3,    13,    12,  ..., 29903, 29911, 29871],
         [    3,    13,    12,  ..., 29903, 29911, 29871]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 1644])
torch.Size([2, 1644]) tensor([[    1, 18787,  2109,  ...,     2,     2,     2],
        [    1, 29871, 30143,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1644, 32000]) tensor([[[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [  9.0547,   9.5000, -12.7734,  ...,  11.1953,   8.1094,  11.1875],
         [ -3.9023,  -2.4277,  -0.7188,  ...,  -4.6836,  -3.6719,  -4.1328],
         ...,
         [ -7.7500,  10.6562,   0.9663,  ...,  -4.3398,  -6.4023,  -3.6387],
         [ -7.7578,  10.5625,   0.8960,  ...,  -4.3438,  -6.3984,  -3.6367],
         [ -7.6836,  10.3125,   0.6782,  ...,  -4.2930,  -6.3164,  -3.5781]],

        [[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [ -8.3906,   0.6343,  -1.6660,  ...,   2.6660,   0.4187,   0.0745],
         [-10.0703,  -3.7090,  -2.2637,  ...,  -4.9023,  -5.4805,  -4.2031],
         ...,
         [  0.2520,   5.0898,  13.2500,  ...,   1.0967,  -0.9722,   1.5918],
         [ -2.3496,  -0.3853,  13.3906,  ...,  -0.9912,   0.2529,  -1.5303],
         [  1.8701,   5.9492,  22.5000,  ...,  -1.2607,  -0.4006,   2.3789]]],
       device='cuda:0')
torch.Size([2, 1644, 1]) tensor([[[29892],
         [ 4855],
         [29914],
         ...,
         [29889],
         [29889],
         [29889]],

        [[29892],
         [29896],
         [ 4746],
         ...,
         [29913],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 1644, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 4855,  2109,  5184,  ...,  4691, 13067,  7070],
         [29914,  3017, 13067,  ...,   845,  4691, 10891],
         ...,
         [29889, 29879,     1,  ..., 29900, 29901, 29871],
         [29889,     1, 29879,  ..., 29900, 29901, 29871],
         [29889,     1, 29879,  ..., 29900, 29901, 29871]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [ 4746, 22377, 29992,  ..., 29966,  1888, 29914],
         ...,
         [29913,    13,  1678,  ...,    12,  3400,   259],
         [   13,     2,   849,  ...,   268, 23196,   259],
         [    2,    13, 29871,  ...,  6658,  5515,  1678]]], device='cuda:0')
Batch 1, 1.8% of total tokens
encoded shape: torch.Size([2, 1052])
torch.Size([2, 1052]) tensor([[    1, 18546, 29889,  ..., 29902, 29922,    13],
        [    1, 29871, 30143,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1052, 32000]) tensor([[[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -5.4492, -10.0469,   1.1650,  ...,  -1.5986,   1.0459,  -2.0703],
         [ -4.7383,  -9.6328,  -0.7339,  ...,   2.1250,   1.2295,   0.6538],
         ...,
         [ -7.9844,  -9.1953,   0.7197,  ...,  -1.9873,  -3.9062,  -5.0859],
         [ -0.5479,   2.2578,  15.0703,  ...,  -0.8628,  -1.1289,  -4.3086],
         [ -4.9336,  -4.4570,   2.4824,  ...,   0.0442,  -0.2006,  -2.4922]],

        [[ -8.0312,  -1.1523,  -0.5342,  ...,  -4.1953,  -5.6719,  -4.5938],
         [ -8.3984,   0.6177,  -1.6689,  ...,   2.6641,   0.4219,   0.0745],
         [-10.0781,  -3.7070,  -2.2715,  ...,  -4.9102,  -5.4883,  -4.2109],
         ...,
         [ -9.4531,   4.0039,   4.5430,  ...,  -4.0156,  -6.5195,  -5.6328],
         [ -9.2422,   4.0625,   4.5508,  ...,  -3.9590,  -6.3789,  -5.6328],
         [ -8.8359,   4.3398,   4.6758,  ...,  -3.8574,  -6.1406,  -5.5391]]],
       device='cuda:0')
torch.Size([2, 1052, 1]) tensor([[[29892],
         [29899],
         [  510],
         ...,
         [29922],
         [   13],
         [29887]],

        [[29892],
         [29896],
         [ 4746],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 1052, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29899, 29889, 29918,  ..., 29914,  8820, 17432],
         [  510,  3292,   990,  ..., 10867,  1315,  5910],
         ...,
         [29922, 29947, 29893,  ..., 29979, 29965, 29883],
         [   13,     2,   298,  ..., 29871,   325,  2045],
         [29887, 29882, 29895,  ..., 29885,   629,  7085]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [ 4746, 22377, 29992,  ..., 29966,  1888, 29914],
         ...,
         [29871,    13, 29879,  ..., 29896, 29906, 29901],
         [29871, 29879,    13,  ..., 29896, 29906, 29901],
         [29871, 29879,    13,  ..., 29906, 29896, 29898]]], device='cuda:0')
Batch 2, 2.8% of total tokens
encoded shape: torch.Size([2, 1566])
torch.Size([2, 1566]) tensor([[    1, 29871,    13,  ...,     2,     2,     2],
        [    1,   315, 14763,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1566, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5303,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.3984,   0.6309,  -1.6738,  ...,   2.6660,   0.4221,   0.0753],
         [ -5.4297,  -0.6953,  -2.2070,  ...,  -0.5425,  -0.5962,   1.4287],
         ...,
         [-10.2031,   4.1680,  -2.6328,  ...,  -6.1641,  -4.8750,  -4.4766],
         [-10.2031,   4.1367,  -2.6699,  ...,  -6.1523,  -4.8750,  -4.4961],
         [-10.2422,   4.2578,  -2.5996,  ...,  -6.1914,  -4.8906,  -4.4922]],

        [[ -8.0312,  -1.1055,  -0.5303,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.3984,  -8.4141,   0.1799,  ...,  -4.5117,  -3.9473,  -6.4688],
         [-11.8672, -15.9688,  -8.6016,  ...,  -7.5977,  -8.5078,  -9.6875],
         ...,
         [ -1.1787,   6.2422,  11.5469,  ...,   2.5996,   1.1934,   2.5137],
         [ -0.0320,   9.8750,  17.6250,  ...,  -0.7383,   1.3379,  -0.0354],
         [  3.3105,  11.2188,  20.7031,  ...,   0.7339,   2.6719,   0.7012]]],
       device='cuda:0')
torch.Size([2, 1566, 1]) tensor([[[29892],
         [29896],
         [29871],
         ...,
         [ 7228],
         [ 7228],
         [ 7228]],

        [[29892],
         [ 6146],
         [  315],
         ...,
         [29913],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 1566, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29871,  1678,   462,  ...,    12, 16595,    13],
         ...,
         [ 7228,     1, 29900,  ...,  4345, 29906,   229],
         [ 7228,     1, 29900,  ...,     3, 29906,   263],
         [ 7228,     1, 29900,  ...,  4345, 29906,   229]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 6146, 14404,  1915,  ...,  4641,  1038, 14044],
         [  315, 29892, 29907,  ..., 11143, 10057,   322],
         ...,
         [29913,    13,  1678,  ...,  4706, 29871,   268],
         [   13,     2,   849,  ...,  4363,   259,   458],
         [   13,     2, 29905,  ..., 29937,   462, 10797]]], device='cuda:0')
Batch 3, 5.1% of total tokens
encoded shape: torch.Size([2, 755])
torch.Size([2, 755]) tensor([[    1,  4949,    13,  ...,    13, 29913,    13],
        [    1,  6319,  3134,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 755, 32000]) tensor([[[-8.0312, -1.1074, -0.5288,  ..., -4.1836, -5.6602, -4.5781],
         [-8.9141, -7.6797, -0.7905,  ..., -5.9766, -6.3633, -1.2363],
         [-6.2227, -7.0898, -3.5254,  ..., -2.5117, -0.8398,  3.2266],
         ...,
         [-1.2617,  4.7656, 10.4766,  ...,  0.5190, -0.6602, -1.4531],
         [-4.8984,  1.4883,  8.2422,  ..., -3.1348, -3.3828, -2.3496],
         [-1.2402,  3.3223, 11.5156,  ..., -1.7607,  0.0684, -1.4717]],

        [[-8.0312, -1.1074, -0.5288,  ..., -4.1836, -5.6602, -4.5781],
         [-7.0703, -4.4648,  0.6235,  ..., -2.1152, -3.4883, -3.7539],
         [-4.5820, -6.8398,  0.4426,  ..., -3.8926, -1.9189, -4.7109],
         ...,
         [-1.7920,  9.8828, -3.1621,  ...,  0.2341,  1.0098,  0.7793],
         [-1.8770,  9.9375, -3.1660,  ...,  0.1632,  0.9634,  0.7378],
         [-1.8438,  9.8594, -3.1465,  ...,  0.1792,  0.9868,  0.7456]]],
       device='cuda:0')
torch.Size([2, 755, 1]) tensor([[[29892],
         [ 9166],
         [  334],
         ...,
         [29913],
         [    2],
         [    2]],

        [[29892],
         [ 1961],
         [ 1873],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 755, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [  334,  5215,    12,  ...,  9891,  7959,  3776],
         ...,
         [29913,   268,    13,  ...,    12,  3400,   632],
         [    2, 29889,    13,  ..., 29911, 29906, 29875],
         [    2,    29,   268,  ...,  7918, 12379, 26077]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1961,  3134, 25446,  ...,  6080,   565,  2916],
         [ 1873, 10079,  6910,  ...,  2643,   518,  2322],
         ...,
         [    1,  7228, 31779,  ..., 24426, 28906, 26077],
         [    1,  7228, 31779,  ..., 24426, 28906, 26077],
         [    1,  7228, 31779,  ..., 24426, 28906, 26077]]], device='cuda:0')
Batch 4, 5.9% of total tokens
encoded shape: torch.Size([2, 2152])
torch.Size([2, 2152]) tensor([[    1,   849,   399,  ...,     2,     2,     2],
        [    1,  3577,  5226,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 2152, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.9453,  -2.6719,   2.6543,  ...,  -1.0781,  -3.1855,   5.7383],
         [ -6.8984,  -9.2656,  -1.4766,  ...,  -3.4297,  -5.1133,  -4.4844],
         ...,
         [-11.3203,   3.9375,  -5.0586,  ...,  -7.4375,  -5.7578,  -7.0664],
         [-11.0938,   4.2852,  -5.1484,  ...,  -7.1953,  -5.5664,  -6.8984],
         [-10.7891,   4.8477,  -5.1758,  ...,  -6.8711,  -5.2578,  -6.6172]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.8945,  -5.4062,  -6.1211,  ...,  -6.4648,  -5.0703,  -6.7930],
         [ -5.8398, -12.9453,   2.0703,  ...,  -5.4922,  -1.4697,  -3.7871],
         ...,
         [ -5.6250,  -1.0801,   8.3125,  ...,  -1.5410,  -3.7266,  -3.0859],
         [ -2.8066,   2.6211,  20.0938,  ...,  -4.4102,  -3.3535,  -3.2188],
         [ -0.0547,   4.0508,  25.7969,  ...,  -1.1084,  -2.9883,  -1.3721]]],
       device='cuda:0')
torch.Size([2, 2152, 1]) tensor([[[29892],
         [ 5920],
         [25614],
         ...,
         [ 7228],
         [ 7228],
         [ 7228]],

        [[29892],
         [  419],
         [29886],
         ...,
         [29913],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 2152, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [25614,  6794,   336,  ...,   533,  1955, 17909],
         ...,
         [ 7228,     1, 29871,  ...,   263, 29896, 29879],
         [ 7228,     1,  4345,  ...,   263, 10888,   278],
         [ 7228,     1,  4345,  ...,   263, 29900,   278]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  419,  1638,   592,  ...,  5796,  2393,   274],
         [29886,  2388,  4422,  ..., 29918, 29894,  1212],
         ...,
         [29913,    13,    12,  ...,  1118,  5003, 10162],
         [   13,     2,   849,  ..., 30131,   353, 29892],
         [   13,     2,  9891,  ...,  3075, 30004, 29952]]], device='cuda:0')
Batch 5, 8.6% of total tokens
encoded shape: torch.Size([2, 1571])
torch.Size([2, 1571]) tensor([[    1,  3577,   419,  ..., 12803,    13, 29913],
        [    1,   849, 14187,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1571, 32000]) tensor([[[-8.0312, -1.1055, -0.5303,  ..., -4.1836, -5.6602, -4.5781],
         [-6.8906, -5.4023, -6.1211,  ..., -6.4648, -5.0625, -6.7930],
         [-3.7363, -5.8984,  6.3906,  ...,  3.2207,  0.1252, -2.1113],
         ...,
         [-0.5420,  2.7305,  7.9531,  ..., -1.6328, -2.6758, -2.3008],
         [-2.8398,  1.7930,  6.9609,  ..., -0.8516, -2.0781, -1.3916],
         [-1.7129,  2.8105, 10.4219,  ..., -0.1022,  1.1787, -0.5430]],

        [[-8.0312, -1.1055, -0.5303,  ..., -4.1836, -5.6602, -4.5781],
         [-5.9492, -2.6719,  2.6523,  ..., -1.0830, -3.1855,  5.7422],
         [-5.2148, -8.8047,  1.0020,  ..., -3.6699, -1.8613,  0.8091],
         ...,
         [-9.3359,  8.4844,  3.6016,  ..., -4.4297, -7.6172, -4.0859],
         [-9.1875,  8.4375,  3.7734,  ..., -4.2383, -7.5156, -3.9844],
         [-8.9609,  8.5391,  4.4297,  ..., -4.0703, -7.4219, -3.8887]]],
       device='cuda:0')
torch.Size([2, 1571, 1]) tensor([[[29892],
         [  419],
         [29889],
         ...,
         [   13],
         [29913],
         [    2]],

        [[29892],
         [ 5920],
         [ 1266],
         ...,
         [29899],
         [29899],
         [29899]]], device='cuda:0')
torch.Size([2, 1571, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  419,  1638,   592,  ...,  5796,  2393,   274],
         [29889,  3032,   833,  ...,   567,   412,   397],
         ...,
         [   13, 25665,  6162,  ...,   849, 20735, 19495],
         [29913,    13,  1678,  ...,   268,  3400, 10114],
         [    2,    13, 23196,  ...,   458, 12879, 11973]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 1266,  3539,   322,  ...,   669,  8966,  7341],
         ...,
         [29899, 29879, 29889,  ..., 29906,    13, 29901],
         [29899, 29879, 29871,  ...,    13, 29906, 29901],
         [29899, 29879, 29871,  ..., 29900, 29906, 29901]]], device='cuda:0')
Batch 6, 10.3% of total tokens
encoded shape: torch.Size([2, 2691])
torch.Size([2, 2691]) tensor([[    1,   426,    13,  ...,    13, 29913,    13],
        [    1,  4949,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2691, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.3555,  -4.1367,  -0.8452,  ...,  -2.7676,  -0.3655,  -1.9971],
         [ -3.9219,  -0.7129,  -4.3750,  ...,  -1.4131,  -2.1094,   2.6465],
         ...,
         [ -3.7832,   1.4111,   2.2480,  ...,   3.5977,  -0.6572,  -1.3867],
         [ -2.6055,   0.6973,  12.8047,  ...,  -1.9238,   4.0000,  -2.6660],
         [ -3.0430,   2.1777,   9.1797,  ...,  -0.5161,  -1.8398,  -1.2090]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.9141,  -7.6758,  -0.7969,  ...,  -5.9844,  -6.3711,  -1.2461],
         [ -6.2188,  -7.0859,  -3.5312,  ...,  -2.5137,  -0.8354,   3.2246],
         ...,
         [-10.4453,  -0.4033,  -2.0996,  ...,  -5.9688,  -4.7500,  -5.1172],
         [-10.3672,  -0.3442,  -2.0859,  ...,  -5.8789,  -4.6602,  -5.0469],
         [-10.3594,  -0.3479,  -2.0488,  ...,  -5.8672,  -4.6289,  -5.0312]]],
       device='cuda:0')
torch.Size([2, 2691, 1]) tensor([[[29892],
         [11680],
         [ 3257],
         ...,
         [29913],
         [   13],
         [    2]],

        [[29892],
         [ 9166],
         [  334],
         ...,
         [29900],
         [29900],
         [29900]]], device='cuda:0')
torch.Size([2, 2691, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [11680,  7776,   380,  ...,  4303,  6224,   376],
         [ 3257,  1678, 29871,  ...,   418,  4706,  1897],
         ...,
         [29913,  1118, 29871,  ..., 10162,  2981, 17428],
         [   13,     2,  1769,  ...,  4514, 29871,  1385],
         [    2, 29958,   829,  ..., 29912, 29892, 29087]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [  334,  5215,    12,  ...,  9891,  7959,  3776],
         ...,
         [29900,  4345, 29929,  ..., 29955, 29946, 29892],
         [29900,  4345, 29929,  ..., 29906, 29946, 29892],
         [29900,  4345, 29929,  ..., 29906, 29946, 29947]]], device='cuda:0')
Batch 7, 14.6% of total tokens
encoded shape: torch.Size([2, 332])
torch.Size([2, 332]) tensor([[    1,   934,  5809,  6594, 29901, 29871, 29906,    13,  2543,   333,
         29901,   321, 29900, 29947,  1725, 29874, 29953, 29941, 14943, 29947,
         11512, 29883, 29947, 29946, 29946, 29929, 29953, 29890, 29946, 29941,
         29883, 29946, 29946, 29941, 29945, 29946, 29929,   687, 29947,    13,
         29924,  3231, 24192,  9555, 29901,    13, 29871,  7029, 12724, 29901,
          6571,    13, 29871,  7797,  1891,  6594, 29901, 29871, 29906,    13,
         29871,  2322,  1123, 10662, 29901,  5159,    13, 29871,  8225,  7514,
         29901, 29871, 29900,    13, 29871,  9849, 29901,   426,  8758,  1367,
         29901, 29871, 29900, 29913,    13, 29871,  1404,  1469, 29901, 29871,
            13, 29871, 24342,  9534,  1170, 29901, 29871,    13, 29871, 24342,
          9534, 10444,   424, 29901, 29871,    13,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,  4949,    13,   334, 14187,  1266,   313, 29883, 29897, 29871,
         29906, 29900, 29896, 29953,   448, 29871, 29906, 29900, 29896, 29929,
           390,  1481,   796,  2350, 29877,   529,  1267, 29891,   348,  1032,
           348, 29992, 21980, 29889,   510, 29958,    13,   334,    13,   334,
           910,   934,   338,   760,   310,   382, 29440, 29889,    13,   334,
            13,   334,   382, 29440,   338,  3889,  7047, 29901,   366,   508,
          2654,   391,  2666,   372,   322, 29914,   272,  6623,    13,   334,
           372,  1090,   278,  4958,   310,   278, 15143,  4593,  5236, 19245,
           408,  6369,   491,    13,   334,   278, 12362, 18540, 10606, 29892,
          2845,  1873, 29871, 29941,   310,   278, 19245, 29892,   470,    13,
           334,   313,   271,   596,  2984, 29897,   738,  2678,  1873, 29889,
            13,   334,    13,   334,   382, 29440,   338, 13235,   297,   278,
          4966,   393,   372,   674,   367,  5407, 29892,    13,   334,   541,
           399,  1806,  8187,  2692, 13764, 29979,   399,  1718, 29934, 13566,
         29979, 29936,  1728,  1584,   278,  2411,  2957,  1370, 21867, 29891,
           310,    13,   334,   341,  1001,  3210, 13566,  2882,  6227, 11937,
           470,   383,  1806,  8186,  1799, 15842,   319,   349,  8322,  2965,
         13309,  1718,   349,  4574, 13152,  1660, 29889, 29871,  2823,   278,
            13,   334, 15143,  4593,  5236, 19245,   363,   901,  4902, 29889,
            13,   334,    13,   334,   887,   881,   505,  4520,   263,  3509,
           310,   278, 15143,  4593,  5236, 19245,    13,   334,  3412,   411,
           382, 29440, 29889, 29871,   960,   451, 29892,  1074,   529,  1124,
           597,  1636, 29889, 18713, 29889,   990, 29914,   506, 11259,  3779,
         29889,    13,  3776,    13,    13,  5113, 24721,  1032, 29889, 29872,
         29440, 29889, 22382, 29889,  2997, 29918,   808,   453, 29889,   375,
          1167, 29936,    13,    13,  5215, 24721,  1032, 29889, 29872, 29440,
         29889, 22382, 29889,  2997, 29918,   808,   453, 29889, 16122,   808,
           453, 29889, 25255,  1469,  5126, 29936,    13,  5215, 24721,  1032,
         29889, 29872, 29440, 29889, 22382, 29889,  2997, 29918,   808,   453,
         29889,  3696,   808,   453, 29889,  2624,  1469,  5126, 29936,    13,
            13,  3597,  5067,  3148,  1167,  1469,  5126, 29966, 29928,  4988,
          3148,  1167,  1469, 29958,  4988,  6864,  1469,  5126, 29966, 29928,
         10202, 11790,   654,  1469,  5126, 29966, 29928, 29958,   426,    13,
         29913,    13]], device='cuda:0')
torch.Size([2, 332, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.5391, -12.3438,  -3.0371,  ...,  -2.9473,  -5.5156,  -4.7578],
         [ -6.8398, -12.0625,  -3.2637,  ...,  -5.8047,  -5.3125,  -6.4297],
         ...,
         [ -5.6953,   5.6055,  -2.3652,  ...,  -2.0527,  -1.7012,  -0.8125],
         [ -5.7188,   5.5938,  -2.4082,  ...,  -2.0840,  -1.7314,  -0.8496],
         [ -5.5586,   5.9336,  -2.4824,  ...,  -2.0059,  -1.6396,  -0.7339]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.9141,  -7.6797,  -0.7905,  ...,  -5.9766,  -6.3633,  -1.2363],
         [ -6.2227,  -7.0898,  -3.5254,  ...,  -2.5117,  -0.8398,   3.2266],
         ...,
         [ -2.4941,   0.8423,  10.6172,  ...,  -0.1458,  -0.0285,   1.9229],
         [ -2.8691,   2.0566,  13.6719,  ...,   0.3569,   1.1543,  -0.7803],
         [ -3.0410,   0.8848,  23.0781,  ...,  -1.6084,  -1.6973,  -2.4941]]],
       device='cuda:0')
torch.Size([2, 332, 1]) tensor([[[29892],
         [29881],
         [29901],
         [29901],
         [  376],
         [29896],
         [29889],
         [ 4706],
         [  333],
         [ 2713],
         [29871],
         [29945],
         [29900],
         [29900],
         [29900],
         [29945],
         [29900],
         [29899],
         [29945],
         [29900],
         [29946],
         [29896],
         [29900],
         [29900],
         [29900],
         [29900],
         [29900],
         [29900],
         [29900],
         [29900],
         [29945],
         [29900],
         [29900],
         [29900],
         [29900],
         [29900],
         [29900],
         [29900],
         [   13],
         [ 1037],
         [ 2357],
         [29901],
         [  627],
         [29901],
         [ 1565],
         [29899],
         [ 1873],
         [29901],
         [29901],
         [   13],
         [   13],
         [29871],
         [ 7029],
         [ 2133],
         [12724],
         [29901],
         [29871],
         [29896],
         [   13],
         [29871],
         [ 1873],
         [ 6594],
         [ 4924],
         [29901],
         [ 6571],
         [   13],
         [29871],
         [ 2322],
         [ 2677],
         [29901],
         [29871],
         [29900],
         [   13],
         [29871],
         [ 8225],
         [29901],
         [21608],
         [29729],
         [ 2605],
         [29901],
         [29871],
         [29900],
         [29892],
         [   13],
         [29871],
         [ 9849],
         [ 1469],
         [29901],
         [ 6571],
         [29900],
         [ 1678],
         [  426],
         [ 2605],
         [29901],
         [29901],
         [ 1094],
         [   13],
         [29871],
         [24342],
         [ 9534],
         [10438],
         [  424],
         [29901],
         [29871],
         [   13],
         [29871],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [    1],
         [  396],
         [  396],
         [29900],
         [29900],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29892],
         [29892],
         [ 1576],
         [ 1576],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 1576],
         [29902],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [29892],
         [  450],
         [  450],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [  450],
         [ 7228],
         [  450],
         [  450],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228],
         [ 7228]],

        [[29892],
         [ 9166],
         [  334],
         [14187],
         [ 1266],
         [  313],
         [29907],
         [29897],
         [29871],
         [29906],
         [30488],
         [29896],
         [29900],
         [30488],
         [29871],
         [29906],
         [29900],
         [29896],
         [29947],
         [30488],
         [30488],
         [30488],
         [30488],
         [29877],
         [  529],
         [11987],
         [29920],
         [ 3365],
         [26599],
         [26779],
         [29992],
         [21980],
         [29889],
         [  510],
         [29958],
         [   13],
         [  334],
         [14187],
         [  334],
         [10413],
         [30488],
         [  338],
         [  760],
         [  310],
         [  278],
         [20860],
         [29889],
         [ 6006],
         [  334],
         [   13],
         [  334],
         [10413],
         [29440],
         [  338],
         [  263],
         [  287],
         [29901],
         [  366],
         [  508],
         [ 2654],
         [30488],
         [ 2666],
         [  372],
         [  322],
         [29914],
         [  272],
         [ 6623],
         [  372],
         [  334],
         [  372],
         [ 1090],
         [  278],
         [30488],
         [  310],
         [  278],
         [15143],
         [10393],
         [ 5236],
         [19245],
         [  408],
         [ 6369],
         [  491],
         [   13],
         [  334],
         [  278],
         [12362],
         [18540],
         [10606],
         [29892],
         [ 2845],
         [ 1873],
         [29871],
         [29941],
         [  310],
         [  278],
         [19245],
         [29892],
         [  470],
         [   13],
         [  334],
         [  313],
         [  472],
         [  596],
         [ 2984],
         [29897],
         [  738],
         [ 2678],
         [ 1873],
         [29889],
         [   13],
         [  334],
         [   13],
         [  334],
         [  382],
         [29440],
         [  338],
         [13235],
         [  297],
         [  278],
         [ 4966],
         [  393],
         [  372],
         [  674],
         [  367],
         [ 5407],
         [29892],
         [   13],
         [  334],
         [  541],
         [  399],
         [ 1806],
         [ 8187],
         [ 2692],
         [13764],
         [29979],
         [  399],
         [ 1718],
         [29934],
         [13566],
         [29979],
         [29936],
         [ 1728],
         [ 1584],
         [  278],
         [ 2411],
         [ 2957],
         [ 1370],
         [21867],
         [29891],
         [  310],
         [   13],
         [  334],
         [  341],
         [ 1001],
         [ 3210],
         [13566],
         [ 2882],
         [ 6227],
         [11937],
         [  470],
         [  383],
         [ 1806],
         [ 8186],
         [ 1799],
         [15842],
         [  319],
         [  349],
         [ 8322],
         [ 2965],
         [13309],
         [ 1718],
         [  349],
         [ 4574],
         [13152],
         [ 1660],
         [29889],
         [29871],
         [ 2823],
         [  278],
         [   13],
         [  334],
         [15143],
         [ 4593],
         [ 5236],
         [19245],
         [  363],
         [  901],
         [ 4902],
         [29889],
         [   13],
         [  334],
         [   13],
         [  334],
         [  887],
         [  881],
         [  505],
         [ 4520],
         [  263],
         [ 3509],
         [  310],
         [  278],
         [15143],
         [ 4593],
         [ 5236],
         [19245],
         [   13],
         [  334],
         [ 3412],
         [  411],
         [28532],
         [  294],
         [29889],
         [29871],
         [  960],
         [  451],
         [29892],
         [ 1074],
         [  529],
         [ 1124],
         [  597],
         [ 1636],
         [29889],
         [18713],
         [29889],
         [  990],
         [29914],
         [  506],
         [11259],
         [ 3779],
         [29889],
         [29871],
         [  334],
         [   13],
         [29937],
         [29937],
         [ 2240],
         [  424],
         [29889],
         [31147],
         [30488],
         [30488],
         [ 3221],
         [29889],
         [ 1481],
         [ 2133],
         [12925],
         [30488],
         [29936],
         [  808],
         [29889],
         [29936],
         [   13],
         [   13],
         [ 5215],
         [ 1442],
         [30488],
         [29889],
         [ 6735],
         [30488],
         [29889],
         [22382],
         [29889],
         [ 2997],
         [29918],
         [  808],
         [29889],
         [29889],
         [  375],
         [29889],
         [  453],
         [29889],
         [25255],
         [15797],
         [29936],
         [29936],
         [   13],
         [ 5215],
         [24721],
         [31147],
         [29889],
         [29872],
         [29440],
         [29889],
         [22382],
         [29889],
         [ 2997],
         [29918],
         [  808],
         [  453],
         [29889],
         [16122],
         [  808],
         [  453],
         [29889],
         [ 2624],
         [ 1469],
         [ 5126],
         [29936],
         [   13],
         [ 5215],
         [ 5215],
         [ 9846],
         [10783],
         [ 1167],
         [ 5126],
         [ 5126],
         [  426],
         [29911],
         [ 4988],
         [ 3148],
         [ 1167],
         [ 1469],
         [30488],
         [  426],
         [11790],
         [ 1469],
         [ 5126],
         [29966],
         [29928],
         [10202],
         [11790],
         [29889],
         [ 1469],
         [ 5126],
         [29966],
         [29928],
         [29958],
         [  426],
         [   13],
         [29913],
         [    2],
         [    2]]], device='cuda:0')
torch.Size([2, 332, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29881,   471, 29918,  ..., 29901,  1090,   338],
         [29901,   353,   338,  ...,   584,  1746,  1762],
         ...,
         [ 7228,     1,  4345,  ...,   891,    10, 10888],
         [ 7228,     1,  4345,  ...,    10,   891, 10888],
         [ 7228,     1,  4345,  ...,  2047,   891, 10888]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [  334,  5215,    12,  ...,  9891,  7959,  3776],
         ...,
         [29913,  1678,    13,  ...,   458,   500,   259],
         [    2,    13,   849,  ...,  1550,   458, 29990],
         [    2,    13, 13248,  ...,    29,  1990, 29912]]], device='cuda:0')
Batch 8, 15.0% of total tokens
encoded shape: torch.Size([2, 876])
torch.Size([2, 876]) tensor([[    1, 11474,    13,  ...,  3487, 29897,    13],
        [    1, 18252, 21300,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 876, 32000]) tensor([[[-8.0078, -1.2354, -0.5396,  ..., -4.2148, -5.6836, -4.6211],
         [-4.3945,  3.3379,  5.5820,  ..., -1.9561, -5.9844, -1.4600],
         [-1.4961, -1.7988, -2.4238,  ...,  0.2294, -1.1465,  0.8687],
         ...,
         [-1.1367, -0.7729,  1.8945,  ...,  0.7910,  2.9961, -1.3545],
         [-1.1758,  2.0605,  5.8438,  ..., -0.3779,  3.0078, -0.9629],
         [-1.1348,  1.9707,  7.9258,  ...,  0.9199,  2.2344, -0.5674]],

        [[-8.0078, -1.2354, -0.5396,  ..., -4.2148, -5.6836, -4.6211],
         [-5.2812, -4.0234, -1.2783,  ..., -0.6606, -3.0586, -1.6631],
         [-3.3613,  0.6045,  5.0625,  ..., -1.3213, -3.4004, -4.6250],
         ...,
         [-2.2363,  9.7188, -3.2266,  ..., -0.1324,  0.8550,  0.3765],
         [-2.4141,  9.8906, -3.2773,  ..., -0.2644,  0.7397,  0.3005],
         [-2.6230, 10.0156, -3.3398,  ..., -0.4170,  0.5918,  0.2043]]],
       device='cuda:0')
torch.Size([2, 876, 1]) tensor([[[29892],
         [   13],
         [ 3257],
         ...,
         [29897],
         [   13],
         [19379]],

        [[29892],
         [21300],
         [ 3472],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 876, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [   13, 30004, 29992,  ...,  6805, 26833, 22415],
         [ 3257,  3611,  2680,  ...,   358,  7030,  1725],
         ...,
         [29897,  8443, 25145,  ..., 23795, 23196,   246],
         [   13, 19379, 25145,  ..., 24366, 16171, 23795],
         [19379, 29899,     2,  ..., 28753, 23196, 16618]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [21300,  1867,  5634,  ..., 30003, 22158,  1961],
         [ 3472,  4544, 29958,  ...,  1420,   856,   349],
         ...,
         [    1,  7228, 31779,  ..., 26077, 24366,  4345],
         [    1,  7228, 31779,  ...,  4345, 26077,    10],
         [    1,  7228, 31779,  ..., 24708,    10, 26077]]], device='cuda:0')
Batch 9, 16.1% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   849,   748,  ...,    13,    12, 14816],
        [    1,   849, 14187,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.9453,  -2.6719,   2.6543,  ...,  -1.0781,  -3.1855,   5.7383],
         [ -7.3398, -15.1016,  -0.1434,  ...,  -3.1934,  -5.0938,  -3.0117],
         ...,
         [ -1.9922,  -0.4724,   5.1406,  ...,   0.6968,  -1.3896,  -0.3860],
         [ -2.4219,  -8.1484,   1.0303,  ...,  -1.9531,  -1.7295,  -2.2676],
         [ -2.7422,  -9.2266,   1.6484,  ...,  -4.9805,  -0.1178,  -3.1172]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.9453,  -2.6719,   2.6543,  ...,  -1.0781,  -3.1855,   5.7383],
         [ -5.2148,  -8.8047,   1.0020,  ...,  -3.6680,  -1.8701,   0.8081],
         ...,
         [-11.5000,  -1.9980,  -0.7109,  ...,  -5.8984,  -4.4453,  -5.1016],
         [-11.4688,  -1.9873,  -0.7349,  ...,  -5.8398,  -4.3945,  -5.0469],
         [-11.3906,  -1.9297,  -0.7729,  ...,  -5.7344,  -4.3047,  -4.9453]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [ 5920],
         [29899],
         ...,
         [   12],
         [14816],
         [29903]],

        [[29892],
         [ 5920],
         [ 1266],
         ...,
         [29924],
         [29924],
         [29924]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [29899,   304,  1243,  ...,  2048,  3271,  1065],
         ...,
         [   12,   416, 29897,  ..., 14816,  4706,   511],
         [14816,   458,  5425,  ..., 13171,  9675, 29940],
         [29903,  7187, 29940,  ..., 15868,  5550, 29949]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 1266,  3539,   322,  ...,   669,  8966,  7341],
         ...,
         [29924, 29900,  4345,  ..., 29906, 29941, 29903],
         [29924, 29900,  4345,  ..., 29906, 29941, 29903],
         [29924, 29900,  4345,  ..., 29906, 29903, 29941]]], device='cuda:0')
Batch 10, 23.0% of total tokens
encoded shape: torch.Size([2, 470])
torch.Size([2, 470]) tensor([[    1,   847,  7775,  7775,  7775,  7775,  7775,  7775, 17435,    13,
         12444,  1760,   338, 22301,   304,  2304,   278,  1722,  2752,  7881,
           491,  3907, 16866,   333,  1043,  3625, 29889,    13, 14187,  1266,
           313, 29907, 29897, 29871, 29906, 29900, 29896, 29955,  3446, 29931,
           319, 29906, 29929, 28873, 29892,   263, 12444,  1760,  5001, 29889,
          2178, 10462, 21676, 29889,    13, 10413, 21144,  1090,   278,   341,
          1806, 29931,   293,  1947,   313,  1552,   376, 29931,   293,  1947,
          1496,   366,  1122,   451,   671,   445,   934,  5174,   297,   752,
         13036,    13,   411,  1552, 19245, 29889,   887,  1122,   711,  2408,
           263,  3509,   310,   278, 19245,   472,    13,    13,  1732,   597,
         22156,  1167, 29889,   990, 29914,   506, 11259, 29914, 26349,    13,
            13, 25870,  3734,   491, 22903,  4307,   470, 15502,   304,   297,
          5007, 29892,  7047, 13235,  1090,   278, 19245,   338,    13, 13235,
           373,   385,   376,  3289,  8519, 29908,   350,  3289,  3235, 29892,
           399,  1806,  8187,  2692,   399,  1718, 29934, 13566, 29059,  6323,
          8707, 29928, 22122, 29903,  8079, 13764, 29979,   476, 22255, 29892,
          2845,  4653,   470,    13,  2411,  2957, 29889,  2823,   278, 19245,
           363,   278,  2702,  4086, 14765,  1076, 11239,   322, 27028,  1090,
           278,    13, 19245, 29889,    13,   334,  7775,  7775,  7775,  7775,
          7775,  7775,  1068, 29914,    13,  5113,   419, 29889,   841,  1760,
         29889,  2390,   333,  1493, 29889,  1493, 29936,    13,    13,  5215,
          1442, 29889,  3051, 29889,  2677, 29936,    13,  5215,  1442, 29889,
          1493, 29889,  1043, 29936,    13,  5215,  1442, 29889,  8030, 29889,
          4920, 14977,  3453, 29936,    13,    13,  5215,   419, 29889,   841,
          1760, 29889,  2390,   333,  1493, 29889,  3207, 29889,  4920, 14977,
         26476, 29936,    13,  5215,   419, 29889,   841,  1760, 29889,  2390,
           333,  1493, 29889,  3207, 29889,  9629,  2061, 29936,    13,  5215,
           419, 29889,   841,  1760, 29889,  2390,   333,  1493, 29889, 16680,
         29889,  4920, 14977,  3453, 11726, 29936,    13,  5215,   419, 29889,
           841,  1760, 29889,  2390,   333,  1493, 29889, 16680, 29889, 29934,
           481,   333, 11726,  2061, 29936,    13,    13,  7918,    13,   334,
           732,  2385, 16866,   333,  4920, 14977,  3453,    13,   334,   732,
         19617, 29871, 30867, 30319, 30967, 30806,  4920, 14977,  3453,    13,
           334,    13,   334,   732,  8921,   564,   417, 29920, 11895,    13,
           334,   732,  1256, 29871, 29906, 29900, 29896, 29945, 29889, 29896,
         29900, 29889, 29900, 29947,    13,  3776,    13,  3597,   770, 16866,
           333,  4920, 14977,  3453,  4988, 16866,   333,  1043,  4782,  2061,
           426,    13,    13,  1678,   970, 16866,   333,  4920, 14977,  3453,
          4923, 29913,    13,    13,  1678,   732,  4640,    13,  1678,  6364,
         16866,   333, 11726,  2061,  1653, 11726,  4923,    13,  4706,   736,
           716,  1976, 14977,  3453, 11726,   890,    13,  1678,   500,    13,
            13,  1678,   732,  4640,    13,  1678,  6364,  4533,  1653,  1043,
         29898,  2677,  3030,  2597,    13,  4706,   736,   716,  1976, 14977,
          3453, 29898,  4703,   416,    13,  1678,   500,    13,    13,  1678,
           732,  4640,    13,  1678,   970,  1459,  2232,  2061,  1653,  9629,
         29898,  2677,  3030,  2597,    13,  4706,   736,   716,  1976, 14977,
         26476, 29898,  4703,   416,    13,  1678,   500,    13, 29913,    13],
        [    1,  3883, 29889, 26500,   353,  1996,   877,  6904,   949,   519,
          2824, 13372,    13,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 470, 32000]) tensor([[[-8.0312, -1.2568, -0.5439,  ..., -4.2266, -5.7031, -4.6328],
         [-9.4219, -6.3438, -5.2227,  ..., -4.3828, -6.0469, -5.9453],
         [-6.6172, -2.1816,  1.9678,  ..., -3.2715, -3.0449, -2.6719],
         ...,
         [-3.7656,  3.1992, 12.2500,  ..., -1.2344, -3.2715, -1.7998],
         [-3.3477,  4.1680, 13.7031,  ..., -0.9561, -0.8467,  0.8574],
         [-0.5854,  3.0078, 24.0469,  ..., -0.4988, -0.1000, -1.5400]],

        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]],
       device='cuda:0')
torch.Size([2, 470, 1]) tensor([[[29892],
         [ 7775],
         [ 7775],
         [ 7775],
         [ 7775],
         [ 4189],
         [ 4189],
         [ 7775],
         [   13],
         [  334],
         [ 1760],
         [14293],
         [22301],
         [  304],
         [ 2304],
         [  278],
         [ 1722],
         [ 2752],
         [ 7881],
         [  491],
         [ 3907],
         [  350],
         [  333],
         [ 4007],
         [ 3625],
         [   13],
         [   13],
         [14187],
         [ 1266],
         [  313],
         [29907],
         [29897],
         [29871],
         [29906],
         [19379],
         [29896],
         [29955],
         [ 3446],
         [30488],
         [  319],
         [29906],
         [29929],
         [28873],
         [29892],
         [  263],
         [12444],
         [ 1760],
         [30488],
         [29889],
         [ 2178],
         [10462],
         [21676],
         [29889],
         [   13],
         [10413],
         [21144],
         [ 1090],
         [  278],
         [  341],
         [30488],
         [19245],
         [  293],
         [30488],
         [  313],
         [ 1552],
         [  376],
         [29931],
         [  293],
         [ 1947],
         [ 1496],
         [  366],
         [ 1122],
         [  451],
         [  671],
         [  445],
         [  934],
         [ 5174],
         [  297],
         [  752],
         [13036],
         [  411],
         [  411],
         [  278],
         [19245],
         [29889],
         [  887],
         [ 1122],
         [ 4017],
         [ 2408],
         [  263],
         [ 3509],
         [  310],
         [  278],
         [19245],
         [  472],
         [   13],
         [ 1732],
         [ 1732],
         [  597],
         [ 2390],
         [30488],
         [29889],
         [  990],
         [29914],
         [  506],
         [11259],
         [29914],
         [26349],
         [   13],
         [   13],
         [25870],
         [ 3734],
         [  491],
         [22903],
         [ 4307],
         [  470],
         [15502],
         [  304],
         [  297],
         [ 5007],
         [29892],
         [ 7047],
         [13235],
         [ 1090],
         [  278],
         [19245],
         [   13],
         [   13],
         [13235],
         [  373],
         [  385],
         [  376],
         [ 3289],
         [ 8519],
         [29908],
         [  350],
         [ 3289],
         [ 3235],
         [29892],
         [  399],
         [ 1806],
         [ 8187],
         [ 2692],
         [  399],
         [ 1718],
         [29934],
         [13566],
         [29059],
         [ 6323],
         [ 8707],
         [29928],
         [22122],
         [29903],
         [ 8079],
         [13764],
         [29979],
         [  476],
         [22255],
         [29892],
         [ 2845],
         [ 4653],
         [  470],
         [ 2411],
         [ 2411],
         [ 2957],
         [29889],
         [ 2823],
         [  278],
         [19245],
         [  363],
         [  278],
         [ 2702],
         [ 4086],
         [14765],
         [ 1076],
         [11239],
         [  322],
         [27028],
         [ 1090],
         [  278],
         [19245],
         [19245],
         [29889],
         [   13],
         [  334],
         [ 7775],
         [ 7775],
         [ 7775],
         [ 7775],
         [ 7775],
         [ 7775],
         [ 1068],
         [ 3877],
         [   13],
         [ 3577],
         [ 1638],
         [29889],
         [30879],
         [ 1760],
         [ 9274],
         [30488],
         [  333],
         [30488],
         [29889],
         [ 3221],
         [ 4299],
         [   13],
         [   13],
         [ 5215],
         [ 1442],
         [29889],
         [ 3051],
         [29889],
         [ 2677],
         [29936],
         [   13],
         [ 5215],
         [ 1442],
         [29889],
         [ 5924],
         [29889],
         [ 1043],
         [ 4782],
         [   13],
         [ 5215],
         [ 1442],
         [29889],
         [ 1493],
         [29889],
         [ 4308],
         [14977],
         [ 3453],
         [29936],
         [ 5363],
         [ 5215],
         [ 5215],
         [ 1442],
         [29889],
         [  841],
         [ 1760],
         [29889],
         [ 2390],
         [  333],
         [ 1493],
         [29889],
         [29934],
         [29889],
         [29934],
         [14977],
         [ 3453],
         [29936],
         [   13],
         [ 5215],
         [  419],
         [24366],
         [  841],
         [ 1760],
         [29889],
         [ 2390],
         [  333],
         [29893],
         [29889],
         [ 3207],
         [29889],
         [26476],
         [29936],
         [29936],
         [   13],
         [ 5215],
         [  419],
         [29889],
         [  841],
         [ 1760],
         [29889],
         [ 2390],
         [30879],
         [30488],
         [29889],
         [ 3207],
         [29889],
         [11726],
         [14977],
         [ 3453],
         [11726],
         [29936],
         [   13],
         [ 5215],
         [  419],
         [29889],
         [  841],
         [ 1760],
         [29889],
         [ 2390],
         [  333],
         [30488],
         [29889],
         [16680],
         [29889],
         [11726],
         [  481],
         [  333],
         [ 1043],
         [29936],
         [29936],
         [   13],
         [ 5215],
         [ 5215],
         [   13],
         [  334],
         [ 6760],
         [23607],
         [  978],
         [  333],
         [ 4920],
         [14977],
         [ 3453],
         [   13],
         [  334],
         [  732],
         [29933],
         [29871],
         [  234],
         [30879],
         [31263],
         [30806],
         [30210],
         [14977],
         [ 3453],
         [31195],
         [  334],
         [  732],
         [  334],
         [  732],
         [30488],
         [24510],
         [30488],
         [ 4096],
         [11895],
         [   13],
         [  334],
         [  732],
         [30488],
         [29871],
         [29906],
         [29900],
         [29896],
         [29955],
         [30470],
         [29900],
         [29906],
         [29889],
         [29906],
         [29947],
         [   13],
         [  334],
         [   13],
         [ 3597],
         [  770],
         [16866],
         [  333],
         [ 4920],
         [14977],
         [ 3453],
         [ 4988],
         [ 1976],
         [  333],
         [ 1043],
         [  426],
         [  426],
         [10703],
         [   13],
         [   13],
         [ 1678],
         [ 2024],
         [16866],
         [  333],
         [ 4920],
         [14977],
         [ 3453],
         [29898],
         [   13],
         [   13],
         [   13],
         [ 1678],
         [  970],
         [ 4640],
         [   13],
         [ 1678],
         [  970],
         [ 1459],
         [  333],
         [11726],
         [ 2061],
         [ 6088],
         [11726],
         [ 2061],
         [   13],
         [ 4706],
         [  736],
         [  716],
         [ 1976],
         [14977],
         [ 3453],
         [11726],
         [  890],
         [   13],
         [ 1678],
         [  500],
         [   13],
         [   13],
         [ 1678],
         [  732],
         [ 4640],
         [   13],
         [ 1678],
         [ 6364],
         [ 1459],
         [ 4782],
         [ 1043],
         [29898],
         [ 2677],
         [ 3030],
         [29892],
         [   13],
         [ 4706],
         [  736],
         [  716],
         [ 1976],
         [14977],
         [ 3453],
         [29898],
         [ 4703],
         [  416],
         [   13],
         [ 1678],
         [  500],
         [   13],
         [   13],
         [ 1678],
         [  732],
         [ 4640],
         [   13],
         [ 1678],
         [ 6364],
         [ 1459],
         [ 2232],
         [ 2061],
         [  679],
         [ 9629],
         [ 2061],
         [ 2677],
         [ 3030],
         [ 2597],
         [   13],
         [ 4706],
         [  736],
         [  716],
         [ 1459],
         [14977],
         [26476],
         [29898],
         [ 4703],
         [  416],
         [   13],
         [ 1678],
         [  500],
         [   13],
         [   13],
         [   13],
         [    2]],

        [[    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0],
         [    0]]], device='cuda:0')
torch.Size([2, 470, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 7775,  8778, 17943,  ...,   315,   382, 29871],
         [ 7775,  4189,  2328,  ..., 29914,   518, 14187],
         ...,
         [   13, 29913,  1678,  ..., 29871,   500,  5515],
         [   13,     2, 29871,  ..., 29947, 29874, 29896],
         [    2,    13, 29871,  ...,  1678,    12,   458]],

        [[    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         ...,
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9]]], device='cuda:0')
Batch 11, 23.5% of total tokens
encoded shape: torch.Size([2, 1755])
torch.Size([2, 1755]) tensor([[    1,   426,    13,  ...,   500,    13, 29913],
        [    1,   396,  5920,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1755, 32000]) tensor([[[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-5.3555, -4.1367, -0.8452,  ..., -2.7676, -0.3655, -1.9971],
         [-3.9219, -0.7129, -4.3750,  ..., -1.4131, -2.1094,  2.6465],
         ...,
         [-0.3562,  2.4004,  7.2422,  ...,  0.3545,  1.5498, -1.3730],
         [-4.2109, -1.1133,  2.1270,  ..., -3.2617, -4.0469, -3.0176],
         [-2.0215,  0.2700, 11.8984,  ..., -1.8262,  2.4883, -1.6006]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-7.3203, -6.8555, -1.7881,  ..., -2.7773, -2.7988, -6.3867],
         [-4.6094, -5.9219,  0.3918,  ..., -0.4250, -0.9941, -7.8750],
         ...,
         [-8.9297,  7.9727, -1.9473,  ..., -5.8047, -5.2227, -5.5469],
         [-9.1094,  7.6953, -2.0273,  ..., -5.8711, -5.2109, -5.6289],
         [-9.0234,  8.0469, -2.3262,  ..., -5.6680, -4.8398, -5.4102]]],
       device='cuda:0')
torch.Size([2, 1755, 1]) tensor([[[29892],
         [11680],
         [ 3257],
         ...,
         [   13],
         [29892],
         [    2]],

        [[29892],
         [29871],
         [29916],
         ...,
         [29871],
         [29871],
         [ 7228]]], device='cuda:0')
torch.Size([2, 1755, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [11680,  7776,   380,  ...,  4303,  6224,   376],
         [ 3257,  1678, 29871,  ...,   418,  4706,  1897],
         ...,
         [   13,   500,  2981,  ..., 24278,  2604, 29871],
         [29892, 29871,    13,  ..., 29899, 31147, 29914],
         [    2,    13,   500,  ...,   421,  4514,  1919]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,   319,   476,  ...,   350,   349,   405],
         [29916,  8626,  1879,  ...,  3488,   316,  1737],
         ...,
         [29871,  7228,     1,  ...,   448,    13, 29892],
         [29871,  7228,     1,  ...,   448,    13, 29892],
         [ 7228, 29871,     1,  ...,   448,    13, 29892]]], device='cuda:0')
Batch 12, 25.6% of total tokens
encoded shape: torch.Size([2, 2315])
torch.Size([2, 2315]) tensor([[    1,   849, 14187,  ...,    13, 29913,    13],
        [    1,   396,  2856,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2315, 32000]) tensor([[[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-5.9453, -2.6719,  2.6543,  ..., -1.0781, -3.1855,  5.7383],
         [-5.2148, -8.8047,  1.0020,  ..., -3.6680, -1.8701,  0.8081],
         ...,
         [-3.5508,  1.6602,  6.2930,  ..., -0.1031, -1.1240,  0.1555],
         [ 0.5259,  2.4219, 11.4609,  ...,  2.9043,  0.3906,  0.3831],
         [ 0.7954,  3.4707, 12.1719,  ...,  2.2207, -0.5942,  1.1279]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-7.3203, -6.8555, -1.7881,  ..., -2.7773, -2.7988, -6.3867],
         [ 2.4844,  4.1992,  8.6562,  ...,  3.0430,  3.6348,  3.7012],
         ...,
         [-8.0703,  6.5508,  7.0039,  ..., -4.6680, -6.6328, -3.3379],
         [-7.9258,  6.5312,  7.0234,  ..., -4.6211, -6.5195, -3.2695],
         [-7.8555,  6.1367,  7.4102,  ..., -4.6328, -6.4531, -3.2559]]],
       device='cuda:0')
torch.Size([2, 2315, 1]) tensor([[[29892],
         [ 5920],
         [ 1266],
         ...,
         [29913],
         [    2],
         [   13]],

        [[29892],
         [29871],
         [  529],
         ...,
         [29879],
         [29879],
         [29879]]], device='cuda:0')
torch.Size([2, 2315, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 1266,  3539,   322,  ...,   669,  8966,  7341],
         ...,
         [29913,    12,    13,  ...,  1836,  5003,  1012],
         [    2,    13, 23196,  ..., 27581, 26077, 24626],
         [   13,  9891,     2,  ..., 29952,  3075,  6348]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,   319,   476,  ...,   350,   349,   405],
         [  529,   376, 29966,  ...,  5591,   320, 13218],
         ...,
         [29879, 29889, 29899,  ..., 29892, 29896, 29898],
         [29879, 29889, 29899,  ..., 29892, 29896, 29898],
         [29879, 29889, 29899,  ..., 29892, 29898, 29896]]], device='cuda:0')
Batch 13, 27.9% of total tokens
encoded shape: torch.Size([2, 697])
torch.Size([2, 697]) tensor([[    1,  6319,  3134,  ...,  1420, 29958,    13],
        [    1,   849, 14187,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 697, 32000]) tensor([[[-8.0312, -1.1523, -0.5342,  ..., -4.1953, -5.6719, -4.5938],
         [-7.0703, -4.4648,  0.6255,  ..., -2.1191, -3.4863, -3.7598],
         [-4.5781, -6.8438,  0.4475,  ..., -3.8984, -1.9229, -4.7109],
         ...,
         [-0.8267, -1.2158,  4.6367,  ..., -0.8867,  2.2930,  0.6743],
         [ 0.4995,  4.4961, 12.4766,  ..., -0.5596,  1.9160,  1.4453],
         [-0.0258,  5.6094, 13.3984,  ..., -1.3770,  2.0801,  2.8125]],

        [[-8.0312, -1.1523, -0.5342,  ..., -4.1953, -5.6719, -4.5938],
         [-5.9492, -2.6719,  2.6504,  ..., -1.0771, -3.1816,  5.7461],
         [-5.2070, -8.7969,  1.0000,  ..., -3.6621, -1.8604,  0.8120],
         ...,
         [-1.5801,  9.2422, -2.9082,  ...,  0.4407,  0.8945,  0.6377],
         [-1.7158,  9.3828, -2.9375,  ...,  0.3442,  0.7939,  0.5869],
         [-1.7109,  9.4844, -2.9082,  ...,  0.3494,  0.7998,  0.6416]]],
       device='cuda:0')
torch.Size([2, 697, 1]) tensor([[[29892],
         [ 1961],
         [ 1873],
         ...,
         [29958],
         [   13],
         [    2]],

        [[29892],
         [ 5920],
         [ 1266],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 697, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1961,  3134, 25446,  ...,  6080,   565,  2916],
         [ 1873, 10079,  6910,  ...,  2643,   518,  2322],
         ...,
         [29958,  1405, 16299,  ..., 23625,  5299, 15513],
         [   13,     2, 10341,  ..., 25145, 21172,   529],
         [    2, 29905,    13,  ...,  1769, 15945, 29908]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 1266,  3539,   322,  ...,   669,  8966,  7341],
         ...,
         [    1,  7228, 31779,  ..., 25528, 26502, 18627],
         [    1,  7228, 31779,  ..., 25528, 26502, 18627],
         [    1,  7228, 31779,  ..., 24708, 26502, 24426]]], device='cuda:0')
Batch 14, 28.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  3577,  8635,  ..., 12277, 29889,  3782],
        [    1, 11474,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.8945,  -5.4062,  -6.1211,  ...,  -6.4648,  -5.0703,  -6.7930],
         [ -4.3984, -10.2891,   5.8242,  ...,  -4.5859,   0.5415,  -2.3027],
         ...,
         [ -1.5146,  -6.2266,   1.3457,  ...,   1.3906,   2.6484,   0.1114],
         [  2.7148,   1.3018,  -2.9023,  ...,   3.7949,   4.4414,   0.8135],
         [ -0.9023,  -3.9375,   0.3179,  ...,   0.6504,   1.5156,  -1.2402]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -4.3828,   3.3477,   5.5898,  ...,  -1.9590,  -5.9844,  -1.4531],
         [ -1.5225,  -1.7930,  -2.4043,  ...,   0.2106,  -1.1865,   0.8462],
         ...,
         [ -7.7461,   9.4688,   1.3281,  ...,  -3.0742,  -5.5586,  -2.7402],
         [ -7.5898,   9.4453,   1.7480,  ...,  -2.9492,  -5.4531,  -2.6875],
         [ -7.4844,   9.0625,   2.2676,  ...,  -2.7402,  -5.3242,  -2.6270]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [  419],
         [  359],
         ...,
         [29889],
         [ 3782],
         [ 2392]],

        [[29892],
         [   13],
         [ 3257],
         ...,
         [29879],
         [29879],
         [29879]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  419,  1638,   592,  ...,  5796,  2393,   274],
         [  359,    13, 29918,  ..., 19594, 29936,  1057],
         ...,
         [29889,  1860,   358,  ..., 25207, 19212, 27823],
         [ 3782, 27823,  2392,  ..., 20434,  8140, 26521],
         [ 2392,  4829,  1059,  ..., 29923,  2624,  4436]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [   13, 30004, 29992,  ...,  6805, 26833, 22415],
         [ 3257,  3611,  2680,  ...,   358,  7030,  1725],
         ...,
         [29879, 29900, 29896,  ..., 29899, 29947, 29955],
         [29879, 29900, 29896,  ..., 29899, 29947, 29955],
         [29879, 29900, 29896,  ..., 29871, 29947, 29955]]], device='cuda:0')
Batch 15, 33.3% of total tokens
encoded shape: torch.Size([2, 1310])
torch.Size([2, 1310]) tensor([[    1,  3925,  9921,  ...,     2,     2,     2],
        [    1,  7762,    13,  ..., 29937, 15224,    13]], device='cuda:0')
torch.Size([2, 1310, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.7539,  -4.0312,  -0.4199,  ...,  -1.3340,  -0.4751,  -0.4690],
         [ -9.6328, -10.7891,  -5.4570,  ...,  -8.3281,  -6.5898,  -8.8984],
         ...,
         [-13.1875,  -5.8398,  -2.3496,  ...,  -7.9688,  -7.2031,  -8.7266],
         [-13.1719,  -5.8281,  -2.3770,  ...,  -7.9805,  -7.2031,  -8.7344],
         [-13.1562,  -5.8242,  -2.4316,  ...,  -7.9609,  -7.1875,  -8.7266]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.2422,  -0.8477,   3.0000,  ...,  -2.6660,  -5.1641,   1.6953],
         [ -2.2422,   0.1150,  -2.9004,  ...,   0.6396,  -2.4473,   4.8477],
         ...,
         [ -2.7305,  -2.8145,   2.1934,  ...,  -1.4482,  -0.4832,   3.1992],
         [ -0.8228,   1.4600,  10.5078,  ...,  -2.0098,   2.5996,   0.8198],
         [  1.6523,   6.0742,  20.1719,  ...,  -3.6016,  -1.2461,   0.5781]]],
       device='cuda:0')
torch.Size([2, 1310, 1]) tensor([[[29892],
         [25217],
         [ 3120],
         ...,
         [29924],
         [29924],
         [29924]],

        [[29892],
         [   13],
         [  334],
         ...,
         [15224],
         [  849],
         [    2]]], device='cuda:0')
torch.Size([2, 1310, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [25217,   457,   326,  ...,   292,   905,  1160],
         [ 3120,  3740,   338,  ..., 29871, 16046, 14059],
         ...,
         [29924, 29896,  4345,  ..., 29929,   341, 29903],
         [29924, 29896,  4345,  ..., 29929,   341, 29938],
         [29924, 29896,  4345,  ..., 29929,   341, 29938]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [   13,   732, 30004,  ...,   910,   796,   319],
         [  334,  1678,  3579,  ..., 29722,  6658, 29930],
         ...,
         [15224,   361,  2856,  ...,  4529,   565, 28436],
         [  849,  4949,   402,  ..., 29871, 12729, 29954],
         [    2,    13,   458,  ...,  5515,   259, 29936]]], device='cuda:0')
Batch 16, 35.7% of total tokens
encoded shape: torch.Size([2, 621])
torch.Size([2, 621]) tensor([[    1,  1192, 18267,  ...,    13, 15091, 29991],
        [    1,  3577,  6361,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 621, 32000]) tensor([[[ -8.0312,  -1.1094,  -0.5273,  ...,  -4.1836,  -5.6641,  -4.5781],
         [ -5.4805,  -3.2012,  -0.9326,  ...,  -0.5347,  -4.0703,  -2.4414],
         [ -2.7578,  -1.6748,   1.6504,  ...,  -4.4453,  -5.2969,  -5.6445],
         ...,
         [ -6.9297, -10.9844,   3.7520,  ...,  -2.0410,  -1.3672,  -1.2676],
         [ -3.1953,  -0.9741,   7.6289,  ...,  -1.9795,  -1.4209,  -1.0205],
         [ -0.4666,  -1.2041,  11.6562,  ...,  -1.2334,   2.5879,   0.6558]],

        [[ -8.0312,  -1.1094,  -0.5273,  ...,  -4.1836,  -5.6641,  -4.5781],
         [ -6.8906,  -5.3984,  -6.1133,  ...,  -6.4609,  -5.0625,  -6.7930],
         [ -3.5273,  -6.4844,   4.8438,  ...,  -5.4180,   1.7188,  -2.0723],
         ...,
         [  0.5796,   7.0977,  -1.7529,  ...,   2.0742,   2.8516,   1.9658],
         [  0.5024,   7.3789,  -1.7646,  ...,   2.0449,   2.8223,   1.9619],
         [  0.4941,   7.5430,  -1.7666,  ...,   2.0547,   2.8379,   1.9834]]],
       device='cuda:0')
torch.Size([2, 621, 1]) tensor([[[29892],
         [ 8999],
         [20170],
         ...,
         [10717],
         [29991],
         [   13]],

        [[29892],
         [  419],
         [29889],
         ...,
         [25145],
         [25145],
         [    1]]], device='cuda:0')
torch.Size([2, 621, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 8999,   891,   450,  ...,   940, 18267,  4911],
         [20170,   383,   489,  ...,  3497,  4214, 24080],
         ...,
         [10717,  5594, 14035,  ...,  4176,  6359, 29900],
         [29991, 21520, 29889,  ...,  1738, 29892, 29973],
         [   13,     2, 10717,  ...,  1273,  4176, 17248]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  419,  1638,   592,  ...,  5796,  2393,   274],
         [29889,    13,   482,  ...,  2974,   356,   585],
         ...,
         [25145, 18627, 24366,  ..., 31779, 21209, 19838],
         [25145, 18627,     1,  ..., 31779, 21209, 19838],
         [    1, 25145, 18627,  ..., 31779, 21209, 19838]]], device='cuda:0')
Batch 17, 36.4% of total tokens
encoded shape: torch.Size([2, 918])
torch.Size([2, 918]) tensor([[    1, 29871,    12,  ..., 29889,   355,    13],
        [    1,   525,  1509,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 918, 32000]) tensor([[[ -8.0312,  -1.1514,  -0.5337,  ...,  -4.1953,  -5.6719,  -4.5977],
         [ -8.3984,   0.6187,  -1.6689,  ...,   2.6641,   0.4221,   0.0743],
         [ -6.4180,  -5.2852,  -2.6074,  ...,  -4.3242,  -3.9062,  -2.2617],
         ...,
         [  0.3811,  -5.5938,  -7.4961,  ...,   0.6167,   2.1680,   2.6211],
         [ -3.8789,  -1.8018,   1.9648,  ...,  -3.4160,  -4.0430,  -2.5527],
         [  2.1387,   1.6709,  20.2656,  ...,   1.0996,   1.5830,   0.9185]],

        [[ -8.0312,  -1.1514,  -0.5337,  ...,  -4.1953,  -5.6719,  -4.5977],
         [ -7.2734,  -4.8242,   0.2349,  ...,  -3.1914,  -3.0312,  -5.6797],
         [ -5.2070, -10.5391,  -0.1044,  ...,  -5.5078,  -1.7148,  -3.9727],
         ...,
         [ -5.5273,   7.9805,  -4.4648,  ...,  -2.8184,  -1.7578,  -1.4102],
         [ -6.0820,   7.9609,  -4.6328,  ...,  -3.2461,  -2.1270,  -1.7344],
         [ -6.5977,   7.8516,  -4.7812,  ...,  -3.6641,  -2.4844,  -2.0547]]],
       device='cuda:0')
torch.Size([2, 918, 1]) tensor([[[29892],
         [29896],
         [29966],
         ...,
         [ 1742],
         [30488],
         [    2]],

        [[29892],
         [29902],
         [ 9406],
         ...,
         [    1],
         [ 7228],
         [ 7228]]], device='cuda:0')
torch.Size([2, 918, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29966,    12,   334,  ...,  8169,  1177, 29915],
         ...,
         [ 1742, 10389,   355,  ...,  3425,   990,  3706],
         [30488, 30879, 31147,  ..., 29871,   313, 31488],
         [    2,    13,    12,  ..., 29879, 29914,   732]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29902,  1576,  2604,  ..., 29879,  4806,   718],
         [ 9406,   289, 29899,  ...,  3767,  6514,  1002],
         ...,
         [    1,  7228,  4345,  ..., 31440,  8132,    10],
         [ 7228,     1,  4345,  ...,  8132, 31440, 29871],
         [ 7228,     1,  4345,  ...,  8132,  1516, 31779]]], device='cuda:0')
Batch 18, 37.5% of total tokens
encoded shape: torch.Size([2, 4021])
torch.Size([2, 4021]) tensor([[    1, 18787,  2109,  ...,     2,     2,     2],
        [    1,   849,    13,  ..., 29992,   355,    13]], device='cuda:0')
torch.Size([2, 4021, 32000]) tensor([[[-8.0312e+00, -1.1055e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [ 9.0547e+00,  9.5078e+00, -1.2766e+01,  ...,  1.1195e+01,
           8.1172e+00,  1.1188e+01],
         [-3.8984e+00, -2.4258e+00, -7.1436e-01,  ..., -4.6914e+00,
          -3.6699e+00, -4.1289e+00],
         ...,
         [-9.3359e+00,  6.8398e+00, -5.3314e-02,  ..., -5.3750e+00,
          -5.3203e+00, -4.8438e+00],
         [-9.4062e+00,  6.7383e+00, -4.3945e-02,  ..., -5.4453e+00,
          -5.3164e+00, -4.9062e+00],
         [-9.5859e+00,  6.4219e+00, -1.3232e-01,  ..., -5.6055e+00,
          -5.3750e+00, -5.0781e+00]],

        [[-8.0312e+00, -1.1055e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-5.9453e+00, -2.6719e+00,  2.6543e+00,  ..., -1.0781e+00,
          -3.1855e+00,  5.7383e+00],
         [-5.3438e+00, -4.8398e+00, -6.0449e-01,  ..., -2.3086e+00,
          -2.4980e+00,  1.8711e+00],
         ...,
         [-3.5684e+00, -1.7148e+00,  1.2295e+00,  ..., -3.2695e+00,
          -3.8086e+00, -2.5605e+00],
         [ 3.2959e-01,  2.4375e+00,  1.0164e+01,  ..., -6.4575e-02,
           2.1113e+00, -1.7729e-03],
         [ 6.5771e-01,  2.5781e+00,  1.1781e+01,  ..., -9.4873e-01,
           3.1582e+00,  4.4702e-01]]], device='cuda:0')
torch.Size([2, 4021, 1]) tensor([[[29892],
         [ 4855],
         [29914],
         ...,
         [29900],
         [29900],
         [29900]],

        [[29892],
         [ 5920],
         [ 5215],
         ...,
         [30488],
         [    2],
         [    2]]], device='cuda:0')
torch.Size([2, 4021, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 4855,  2109,  5184,  ...,  4691, 13067,  7070],
         [29914,  3017, 13067,  ...,   845,  4691, 10891],
         ...,
         [29900, 29896,   229,  ..., 29871, 29929, 29945],
         [29900, 29896,   229,  ..., 29871, 29929, 29945],
         [29900, 29896,   229,  ..., 29929, 29945, 29903]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 5215,   458,  3075,  ...,  4746,  1707,   970],
         ...,
         [30488, 30879, 31147,  ..., 30186, 31256, 29892],
         [    2,    13, 23196,  ..., 27581,  7683, 12879],
         [    2,    13,  3059,  ..., 29475,  6530,   732]]], device='cuda:0')
Batch 19, 42.8% of total tokens
encoded shape: torch.Size([2, 262])
torch.Size([2, 262]) tensor([[    1,  4949, 10937, 29928, 29990, 29899, 29931,   293,  1947, 29899,
         12889, 29901,   402,  7390, 29899, 29906, 29889, 29900,  3776,    13,
          5515,    13,   334, 14187,  1266,   313, 29907, 29897,   751,   399,
           264,   582, 29877, 29871, 29906, 29900, 29896, 29955, 29889, 29871,
          2178, 10462, 21676, 29889,    13,  3776,    13,    13, 29937,   361,
           299,  1389,   350,  5659,  9998, 29918, 29911, 21661, 29918,  3210,
         16658,  1001, 29918, 29950,    13, 29937,  7922,   350,  5659,  9998,
         29918, 29911, 21661, 29918,  3210, 16658,  1001, 29918, 29950,    13,
            13, 29937,  2856,   376,   312,   929, 29889, 29882, 29908,    13,
         29937,  2856,   376,  1062,   296, 29918,   601, 29889, 29882, 29908,
            13,    13,  5515,    13,   334,   422,  1457, 29882,  6270, 20447,
          1423,   261, 29889,    13,   334,  2811,  1423,   451,   871,   278,
          2944, 12589, 29892,   541,   884,  1432,  1950,  4509,    13,   334,
           297,  2944,   848, 29889,    13,  3776,    13,   524,   289,   509,
          5847, 29918,  3198, 29918, 29500, 29918,  8159, 29898,  4984, 15834,
         29918,  9040,   334, 29500,   416,    13,    13,  5515,    13,   334,
         27898,  9406, 20447,  1423,   261, 29889,    13,   334,  2811,   871,
          1423,  2944, 12589, 29892,   451,  5183,  2944,   848, 29889,    13,
          3776,    13,   524,   289,   509,  5847, 29918,  3198, 29918, 29500,
         29918, 27480,   287, 29898,  4984, 15834, 29918,  9040,   334, 29500,
           416,    13,   524,   289,   509,  5847, 29918,  3198, 29918,  3177,
         29898,  4984, 15834, 29918,  9040,   334,  3177,   416,    13,    13,
           524,   289,   509,  5847, 29918,  3198, 29918, 29812, 29918,  3084,
         29898,  4984, 15834, 29918,  9040,   334, 29500, 29892,    13,    12,
            12,    12,  1678,  2281,   289,   509,  5847, 29918, 29812,   334,
         29812, 29892,   318, 29953, 29946, 16667,   416,    13,    13, 29937,
         15224,    13],
        [    1, 11474,    13,  7312, 29901,   525,  1124,   597,  7312, 29889,
           666,  5847, 29889,   601, 22208,    13,  3292, 29901, 10377,  5847,
         29914,   666,  5847,    13,  3608, 11242, 29901,   525,   991,   597,
         11242, 29889,  3608, 29889,   510, 29914, 29896, 29900, 29947, 29953,
         29941, 29947, 29953, 29947, 29946, 29906, 29946, 29945, 29947, 29929,
         29946, 29955, 29946, 29929, 29947, 29955, 29929, 29915,    13,  1188,
          1148,   392,   280, 29901, 10377,  5847,   601,    13,  6605, 29901,
         10377,  5847,    13,  3257, 29901,  5641,  9998,    13, 24946, 29901,
         10377,  5847,  7451,    13, 22942, 29901,   525,   991,   597,   666,
          5847, 29889,   601, 22208,    13,  6011, 29901,   525,   991,   597,
           264, 29889,  6011, 29889,   990, 29914,  4594, 29914,  4074, 20334,
           300,   653, 29918,  2283, 29918,  3924, 29915,    13, 19567, 29901,
           525,   991,   597, 19567, 29889,   510, 29914, 12719, 29914, 23129,
         29881,  1315, 29965, 29990, 29967, 29941, 29984,  1450, 29968, 29946,
         29949, 29945, 29931, 29896, 29895, 24349,   344, 29893, 29915,    13,
          5634,    13,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 262, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -8.9062,  -7.6641,  -0.7886,  ...,  -5.9688,  -6.3516,  -1.2373],
         [ -5.8633, -12.8828,  -0.7173,  ...,  -0.3354,  -0.7285,  -2.8809],
         ...,
         [ -3.0449,  -6.0430,   3.1973,  ...,  -0.3579,  -0.1479,   0.2986],
         [ -1.7100,  -0.9141,   4.0039,  ...,  -0.3035,   2.7422,  -1.4434],
         [ -0.8789,  -1.8584,  10.9844,  ...,  -2.0801,  -2.3711,  -2.1738]],

        [[ -8.0234,  -1.1396,  -0.5400,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -4.4023,   3.3301,   5.5625,  ...,  -1.9619,  -5.9883,  -1.4629],
         [ -1.4463,  -1.6709,  -2.4219,  ...,   0.2759,  -1.0967,   0.9385],
         ...,
         [ -3.2363,  -1.3975,   1.0908,  ...,  -3.0703,  -3.7539,  -2.4648],
         [ -3.2363,  -1.3975,   1.0898,  ...,  -3.0703,  -3.7539,  -2.4629],
         [ -3.2383,  -1.3975,   1.0918,  ...,  -3.0723,  -3.7559,  -2.4648]]],
       device='cuda:0')
torch.Size([2, 262, 1]) tensor([[[29892],
         [ 9166],
         [29928],
         [29990],
         [29899],
         [29931],
         [  293],
         [ 1947],
         [29899],
         [12889],
         [29901],
         [13380],
         [ 7390],
         [29899],
         [29906],
         [29889],
         [29900],
         [29899],
         [   13],
         [29937],
         [14187],
         [  334],
         [14187],
         [ 1266],
         [  313],
         [29907],
         [29897],
         [29871],
         [15440],
         [30488],
         [  582],
         [  529],
         [  529],
         [29906],
         [    1],
         [29906],
         [29929],
         [  529],
         [ 2178],
         [29906],
         [10462],
         [21676],
         [29889],
         [   13],
         [  334],
         [   13],
         [   13],
         [29937],
         [ 2856],
         [  299],
         [ 1389],
         [ 4770],
         [29889],
         [ 9998],
         [29918],
         [ 9998],
         [21661],
         [14262],
         [ 9094],
         [16658],
         [25021],
         [29918],
         [29950],
         [   13],
         [29937],
         [ 7922],
         [  350],
         [ 5659],
         [  282],
         [ 1789],
         [29911],
         [21661],
         [29918],
         [ 3210],
         [16658],
         [ 1001],
         [29918],
         [29950],
         [   13],
         [   13],
         [29937],
         [ 2856],
         [  529],
         [ 5847],
         [  929],
         [29889],
         [29882],
         [ 1789],
         [   13],
         [29937],
         [ 2856],
         [  529],
         [ 8336],
         [  296],
         [29918],
         [ 1958],
         [ 2003],
         [29882],
         [29908],
         [   13],
         [29937],
         [ 4984],
         [   13],
         [  334],
         [ 5399],
         [ 2139],
         [29882],
         [ 6270],
         [ 1423],
         [ 1423],
         [  261],
         [29889],
         [   13],
         [  334],
         [   13],
         [ 1423],
         [  599],
         [  871],
         [  278],
         [20447],
         [ 1423],
         [29892],
         [  541],
         [  884],
         [  278],
         [20447],
         [20447],
         [  310],
         [  334],
         [  310],
         [  278],
         [12589],
         [29889],
         [   13],
         [  334],
         [   13],
         [ 4984],
         [ 5447],
         [  509],
         [ 5847],
         [  312],
         [29500],
         [29918],
         [29500],
         [29898],
         [  667],
         [29898],
         [ 4984],
         [15834],
         [29918],
         [ 9040],
         [  334],
         [29500],
         [  416],
         [   13],
         [   13],
         [ 5515],
         [   13],
         [  334],
         [ 5399],
         [15171],
         [ 1423],
         [ 1423],
         [  261],
         [29889],
         [   13],
         [  334],
         [ 2811],
         [ 1423],
         [ 1423],
         [ 2944],
         [12589],
         [29889],
         [  541],
         [ 2944],
         [ 2944],
         [  848],
         [29889],
         [   13],
         [  334],
         [   13],
         [  524],
         [  289],
         [  509],
         [ 5847],
         [29918],
         [ 3198],
         [29918],
         [29500],
         [29918],
         [  667],
         [  287],
         [29898],
         [ 4984],
         [15834],
         [29918],
         [ 9040],
         [  334],
         [29500],
         [  416],
         [   13],
         [   13],
         [  289],
         [  509],
         [ 5847],
         [29918],
         [ 3198],
         [29918],
         [29500],
         [29918],
         [ 4984],
         [15834],
         [29918],
         [ 9040],
         [  334],
         [ 3177],
         [  416],
         [   13],
         [  524],
         [29937],
         [  289],
         [  509],
         [ 5847],
         [29918],
         [ 3198],
         [29918],
         [  667],
         [29918],
         [ 8336],
         [  537],
         [ 4984],
         [15834],
         [29918],
         [ 9040],
         [  334],
         [29812],
         [  416],
         [  318],
         [   12],
         [   12],
         [   12],
         [  268],
         [ 2281],
         [15834],
         [  509],
         [ 5847],
         [29918],
         [  667],
         [  334],
         [29812],
         [  416],
         [  938],
         [29953],
         [29946],
         [19875],
         [29918],
         [   13],
         [  524],
         [  524],
         [15224],
         [   12],
         [    2]],

        [[29892],
         [   13],
         [ 3257],
         [  914],
         [ 1565],
         [29906],
         [  597],
         [ 7312],
         [29889],
         [29926],
         [ 1656],
         [29889],
         [  601],
         [22208],
         [   13],
         [ 5184],
         [29901],
         [  525],
         [ 5847],
         [29914],
         [  666],
         [ 5847],
         [29899],
         [  666],
         [ 2972],
         [29901],
         [ 2045],
         [  991],
         [  597],
         [11242],
         [29889],
         [ 3608],
         [29889],
         [30488],
         [29914],
         [29896],
         [29900],
         [29947],
         [29955],
         [29947],
         [29945],
         [29947],
         [29947],
         [29947],
         [29947],
         [29946],
         [29946],
         [29953],
         [29946],
         [29953],
         [29929],
         [29953],
         [29929],
         [29947],
         [29947],
         [29953],
         [29914],
         [   13],
         [24946],
         [30488],
         [ 1141],
         [ 1358],
         [29901],
         [10377],
         [ 5847],
         [29899],
         [   13],
         [24946],
         [29901],
         [  525],
         [ 5847],
         [29899],
         [ 5634],
         [29901],
         [ 5641],
         [ 9998],
         [   13],
         [ 5634],
         [29901],
         [10377],
         [ 5847],
         [   13],
         [   13],
         [ 5634],
         [29901],
         [ 2045],
         [  991],
         [  597],
         [  666],
         [ 5847],
         [29889],
         [  601],
         [22208],
         [   13],
         [ 5634],
         [29901],
         [ 5641],
         [  991],
         [  597],
         [  264],
         [29889],
         [ 6011],
         [29889],
         [  990],
         [29914],
         [ 4594],
         [29914],
         [ 5690],
         [29899],
         [  300],
         [  653],
         [29918],
         [ 2283],
         [29918],
         [ 3924],
         [29915],
         [   13],
         [ 5634],
         [29901],
         [10377],
         [  991],
         [  597],
         [ 1636],
         [29889],
         [  510],
         [29914],
         [12719],
         [29914],
         [23129],
         [30488],
         [30488],
         [29990],
         [29939],
         [29999],
         [29990],
         [29999],
         [29990],
         [29990],
         [29893],
         [29929],
         [29979],
         [29990],
         [29999],
         [29900],
         [29939],
         [29990],
         [29909],
         [29915],
         [   13],
         [ 5634],
         [   13],
         [   13],
         [    1],
         [    1],
         [    1],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [ 1576],
         [29896],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [ 1576],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 262, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [29928,   360, 29924,  ...,  8353,  1806, 29950],
         ...,
         [15224,  7922,   361,  ..., 23681, 28436, 17645],
         [   12,  4949, 14844,  ...,  2880, 21124,  2550],
         [    2, 29937,  1789,  ...,  7959,   893,  2200]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [   13, 30004, 29992,  ...,  6805, 26833, 22415],
         [ 3257,  3611,  2680,  ...,   358,  7030,  1725],
         ...,
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307]]], device='cuda:0')
Batch 20, 43.2% of total tokens
encoded shape: torch.Size([2, 971])
torch.Size([2, 971]) tensor([[    1,   722,  3667,  ...,     2,     2,     2],
        [    1,  4770,  3259,  ..., 29882, 29897,    13]], device='cuda:0')
torch.Size([2, 971, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.1016,  -9.0938,  -4.9453,  ...,  -7.9062,  -4.7812,  -5.8320],
         [ -6.3438, -11.6016,  -2.8301,  ...,  -3.2324,  -2.0410,  -4.1523],
         ...,
         [ -8.0859,   6.4062,  -3.6680,  ...,  -4.1953,  -3.6543,  -2.7930],
         [ -8.4219,   6.2461,  -3.7129,  ...,  -4.4336,  -3.8828,  -2.9980],
         [ -8.6484,   6.1836,  -3.7754,  ...,  -4.6055,  -4.0469,  -3.1172]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.3789,  -5.2031,  -2.2539,  ...,  -3.3535,  -4.1953,  -4.2656],
         [ -3.3789, -10.5156,  -1.8652,  ...,   3.4375,  -0.3320,  -2.8594],
         ...,
         [ -4.3281,   0.2439,   4.4688,  ...,  -1.8584,  -1.8408,  -2.0449],
         [ -0.5269,   3.5469,  17.0938,  ...,  -0.1543,   1.8564,  -2.7715],
         [  0.0473,   4.0977,  18.2656,  ...,   1.9795,   2.2559,   0.2859]]],
       device='cuda:0')
torch.Size([2, 971, 1]) tensor([[[29892],
         [  903],
         [29879],
         ...,
         [ 7228],
         [ 7228],
         [ 7228]],

        [[29892],
         [  506],
         [ 1649],
         ...,
         [29897],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 971, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  903, 19476,   330,  ..., 18920,  9537,  4770],
         [29879,   353,  1907,  ...,   418,  3388, 29901],
         ...,
         [ 7228,     1,  4345,  ...,  8132, 29900,   278],
         [ 7228,     1,  4345,  ..., 29900,  8132,   263],
         [ 7228,     1,  4345,  ..., 29900,   263,  8132]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  506,  8552,  1514,  ...,  3259,  1457,   276],
         [ 1649,  4830,  3888,  ..., 13869,  8948, 21355],
         ...,
         [29897, 29892,   467,  ...,   470,  1846, 29918],
         [   13,     2,   268,  ...,   396,   632,   418],
         [   13,     2,  1678,  ...,   842, 21707,   632]]], device='cuda:0')
Batch 21, 44.5% of total tokens
encoded shape: torch.Size([2, 3812])
torch.Size([2, 3812]) tensor([[    1,   444, 10682,  ...,     2,     2,     2],
        [    1,  3645, 29871,  ...,  7971,   416,    13]], device='cuda:0')
torch.Size([2, 3812, 32000]) tensor([[[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-4.5664, -0.2336,  1.5947,  ..., -0.5298, -1.4482, -4.1328],
         [-7.0938, -5.6836,  2.6660,  ..., -4.7344, -5.6094, -3.4395],
         ...,
         [-3.5762,  6.1602, 10.4141,  ..., -0.3994, -2.9219, -0.5527],
         [-2.7441,  5.9961, 10.7812,  ...,  0.4011, -2.2598,  0.0577],
         [-2.9531,  6.0820, 10.7734,  ...,  0.3850, -2.4043, -0.0197]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-7.7969, -9.2266, -4.1211,  ..., -5.5273, -5.9453, -5.9609],
         [-5.5898, -3.8672, -2.5508,  ...,  2.3516,  0.7065, -0.7188],
         ...,
         [-3.0781, -8.3594,  6.8398,  ...,  0.9102,  2.2754, -0.7979],
         [ 1.9062,  3.0723, 15.9766,  ...,  2.4805,  3.0938,  0.3501],
         [-4.3398, -3.3340, 11.6875,  ...,  1.0039,  0.8843, -1.1670]]],
       device='cuda:0')
torch.Size([2, 3812, 1]) tensor([[[29892],
         [11162],
         [  261],
         ...,
         [   13],
         [   13],
         [   13]],

        [[29892],
         [  278],
         [29896],
         ...,
         [  416],
         [   13],
         [  938]]], device='cuda:0')
torch.Size([2, 3812, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [11162,  2216, 18416,  ...,   826, 10783,  1551],
         [  261,   292,   414,  ...,   263,   596,    13],
         ...,
         [   13, 29871, 29879,  ..., 29899,   229, 29946],
         [   13, 29871, 29879,  ...,   229, 29899, 29898],
         [   13, 29871, 29879,  ..., 29899,   229, 29898]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  278, 29871,   263,  ..., 29901,   967,   385],
         [29896, 29906, 29941,  ..., 29947, 29929, 29900],
         ...,
         [  416, 29892, 29897,  ...,  4770, 29961,   976],
         [   13,     2,    12,  ..., 29871,  3776, 25380],
         [  938, 29974, 25380,  ...,   732,    13,   524]]], device='cuda:0')
Batch 22, 48.5% of total tokens
encoded shape: torch.Size([2, 1407])
torch.Size([2, 1407]) tensor([[    1,  3883,  8045,  ...,     2,     2,     2],
        [    1, 18252, 21300,  ...,  1420, 29958,    13]], device='cuda:0')
torch.Size([2, 1407, 32000]) tensor([[[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [ -8.0781, -11.9453,  -7.1445,  ...,  -5.4336,  -5.3750,  -6.6133],
         [ -5.8672,  -9.9922,   0.0827,  ...,  -2.7988,  -1.4463,  -7.9883],
         ...,
         [ -4.8047,   9.9297,  -3.9863,  ...,  -1.9922,  -1.3682,  -0.9331],
         [ -4.8984,  10.0078,  -3.9785,  ...,  -2.0742,  -1.4971,  -0.9702],
         [ -4.9453,  10.0469,  -3.9746,  ...,  -2.0996,  -1.5527,  -0.9912]],

        [[ -8.0000,  -1.0967,  -0.5269,  ...,  -4.1719,  -5.6445,  -4.5625],
         [ -5.2695,  -4.0039,  -1.2725,  ...,  -0.6450,  -3.0430,  -1.6514],
         [ -3.3633,   0.6016,   5.0703,  ...,  -1.3340,  -3.4043,  -4.6289],
         ...,
         [ -0.5029,  -1.7725,   4.2109,  ...,   0.9258,   1.9873,   0.6982],
         [ -0.4753,   1.9531,  12.6562,  ...,  -1.7275,   2.2793,  -1.3711],
         [  0.8281,   4.2930,  15.7500,  ...,  -2.9648,   1.6426,   0.3608]]],
       device='cuda:0')
torch.Size([2, 1407, 1]) tensor([[[29892],
         [29889],
         [ 2841],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [21300],
         [ 3472],
         ...,
         [29958],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 1407, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29889,   360,  4241,  ...,   383,   341,  2563],
         [ 2841,   495,  2139,  ..., 12121, 15126, 28746],
         ...,
         [    1,  7228, 29871,  ...,   891, 17687,   229],
         [    1,  7228, 29871,  ...,   891, 17687,   229],
         [    1,  7228, 29871,  ...,   891,   229, 17687]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [21300,  1867,  5634,  ..., 30003, 22158,  1961],
         [ 3472,  4544, 29958,  ...,  1420,   856,   349],
         ...,
         [29958,  5299, 23625,  ..., 13885, 15513, 16871],
         [   13,     2, 10341,  ...,  6319,    12, 25145],
         [    2,    13, 29871,  ...,  8169,   268,   529]]], device='cuda:0')
Batch 23, 50.2% of total tokens
encoded shape: torch.Size([2, 2703])
torch.Size([2, 2703]) tensor([[    1,  4949, 14187,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13,  3400,    13]], device='cuda:0')
torch.Size([2, 2703, 32000]) tensor([[[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-8.9141, -7.6758, -0.7969,  ..., -5.9844, -6.3711, -1.2461],
         [-4.1328, -9.6406,  2.2891,  ..., -1.2949,  0.8462,  1.3486],
         ...,
         [-5.1836, -0.2693,  1.1807,  ..., -3.4746, -3.9746, -2.9590],
         [-5.5430,  0.0920,  1.0889,  ..., -3.5078, -3.9414, -3.0156],
         [-6.3594,  0.8394,  0.6885,  ..., -3.5781, -3.8555, -3.1719]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-8.9141, -7.6758, -0.7969,  ..., -5.9844, -6.3711, -1.2461],
         [-6.2188, -7.0859, -3.5312,  ..., -2.5137, -0.8354,  3.2246],
         ...,
         [ 0.2150,  1.7070,  7.5391,  ...,  2.2051,  1.4570,  1.0342],
         [ 1.7256,  3.5645, 13.0000,  ...,  0.6924,  1.6992,  1.6201],
         [ 1.4131,  2.5879,  8.5000,  ...,  1.0479,  1.2959,  0.9224]]],
       device='cuda:0')
torch.Size([2, 2703, 1]) tensor([[[29892],
         [ 9166],
         [ 1266],
         ...,
         [29892],
         [29892],
         [29892]],

        [[29892],
         [ 9166],
         [  334],
         ...,
         [ 3400],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 2703, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [ 1266,  3539,  1377,  ..., 29893,   322,   278],
         ...,
         [29892, 29889, 29871,  ..., 29924, 29914, 29906],
         [29892, 29889, 29871,  ...,   313, 29906, 29914],
         [29892, 29924,   341,  ..., 29899, 29900,   322]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [  334,  5215,    12,  ...,  9891,  7959,  3776],
         ...,
         [ 3400,    13,    12,  ...,  3680,  1118,  1769],
         [   13,     2,  3776,  ...,  1769,  4949,   500],
         [   13,  3400, 29913,  ..., 23196, 25145, 26077]]], device='cuda:0')
Batch 24, 55.2% of total tokens
encoded shape: torch.Size([2, 3398])
torch.Size([2, 3398]) tensor([[    1,   849, 14187,  ...,     2,     2,     2],
        [    1,  1053,   426,  ...,  9591, 29936,    13]], device='cuda:0')
torch.Size([2, 3398, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.9453,  -2.6719,   2.6543,  ...,  -1.0781,  -3.1855,   5.7383],
         [ -5.2148,  -8.8047,   1.0020,  ...,  -3.6680,  -1.8701,   0.8081],
         ...,
         [ -7.7500,   6.3164,   8.0234,  ...,  -1.5742,  -6.1094,  -1.4004],
         [ -7.6289,   6.3203,   8.1953,  ...,  -1.5107,  -6.0352,  -1.3096],
         [ -7.8047,   6.2812,   8.0312,  ...,  -1.6182,  -6.1406,  -1.4346]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.4805,  -6.6719,  -4.0117,  ...,  -5.3516,  -5.2695,  -1.5977],
         [ -5.3008, -10.0547,  -1.2129,  ...,  -1.8896,  -2.7090,  -2.3203],
         ...,
         [  0.3037,  -3.6504,  13.2812,  ...,  -0.4014,   0.0841,   0.2098],
         [  0.0651,   4.2148,  14.2891,  ...,  -0.0312,   1.6338,  -0.9707],
         [  0.7661,   0.6704,  17.8750,  ...,  -1.9775,   1.7070,   0.4529]]],
       device='cuda:0')
torch.Size([2, 3398, 1]) tensor([[[29892],
         [ 5920],
         [ 1266],
         ...,
         [   13],
         [   13],
         [   13]],

        [[29892],
         [  426],
         [29170],
         ...,
         [29936],
         [   13],
         [    2]]], device='cuda:0')
torch.Size([2, 3398, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 1266,  3539,   322,  ...,   669,  8966,  7341],
         ...,
         [   13, 29896, 29871,  ..., 29889, 29892, 29898],
         [   13, 29896, 29871,  ..., 29889, 29892, 29898],
         [   13, 29896, 29871,  ..., 29889, 29892, 29898]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  426, 10606,  9537,  ...,  2115,  3740, 15877],
         [29170, 15924,   512,  ..., 28329,   306, 15591],
         ...,
         [29936, 29898,   408,  ...,   877, 29924, 29892],
         [   13,     2,   849,  ...,  5609,  3532,  3830],
         [    2,    13, 15843,  ...,  2220,   361,  5453]]], device='cuda:0')
Batch 25, 58.8% of total tokens
encoded shape: torch.Size([2, 544])
torch.Size([2, 544]) tensor([[    1,   849, 14187,  ...,     2,     2,     2],
        [    1, 29871,  3577,  ...,    13,   500,    13]], device='cuda:0')
torch.Size([2, 544, 32000]) tensor([[[-8.0312, -1.1484, -0.5361,  ..., -4.1953, -5.6719, -4.5938],
         [-5.9531, -2.6719,  2.6523,  ..., -1.0811, -3.1895,  5.7344],
         [-5.2109, -8.7969,  0.9956,  ..., -3.6660, -1.8633,  0.8149],
         ...,
         [-3.3301, -1.2363,  0.9639,  ..., -3.0996, -3.7363, -2.4883],
         [-3.3887, -1.1992,  0.9634,  ..., -3.1270, -3.7441, -2.5078],
         [-3.4414, -1.1387,  0.9575,  ..., -3.1465, -3.7422, -2.5195]],

        [[-8.0312, -1.1484, -0.5361,  ..., -4.1953, -5.6719, -4.5938],
         [-8.3906,  0.6279, -1.6699,  ...,  2.6660,  0.4204,  0.0735],
         [-9.7500, -9.2031, -5.2578,  ..., -9.1484, -6.4570, -7.6992],
         ...,
         [ 1.2197,  0.1350, 10.4141,  ...,  3.5059,  1.5645,  3.7207],
         [-2.0020,  2.6055, 19.0156,  ...,  0.0436, -2.1523, -1.3350],
         [-2.6621, -2.3926, 15.3047,  ..., -2.1504, -3.7969,  0.1439]]],
       device='cuda:0')
torch.Size([2, 544, 1]) tensor([[[29892],
         [ 5920],
         [ 1266],
         ...,
         [30488],
         [30488],
         [30488]],

        [[29892],
         [29896],
         [  419],
         ...,
         [  500],
         [   13],
         [29871]]], device='cuda:0')
torch.Size([2, 544, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 1266,  3539,   322,  ...,   669,  8966,  7341],
         ...,
         [30488, 30879, 31147,  ..., 31256, 29889, 31575],
         [30488, 30879, 31147,  ..., 29889, 31256, 31575],
         [30488, 30879, 31147,  ..., 29889, 31256, 31575]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [  419,  1638,   592,  ..., 21385, 11317, 18293],
         ...,
         [  500, 29871,   259,  ...,  4970,  3980,   849],
         [   13,     2, 29871,  ...,   500,  1678,    12],
         [29871,    13,     2,  ..., 30004, 29913,  3776]]], device='cuda:0')
Batch 26, 59.8% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  3577,  1667,  ..., 29879, 12975,   718],
        [    1, 18252, 21300,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.8945,  -5.4062,  -6.1211,  ...,  -6.4648,  -5.0703,  -6.7930],
         [ -0.5806,   0.8608,  11.7969,  ...,  -1.1836,   1.3193,   0.2769],
         ...,
         [ -0.6934,  -4.2656,   1.6719,  ...,   0.6113,   2.6074,  -1.7881],
         [ -1.3174,  -2.0293,   0.1366,  ...,  -0.5068,   1.9062,  -0.7627],
         [ -1.5625,  -2.6660,   0.7090,  ...,  -0.8408,   1.0938,  -0.9072]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.2773,  -4.0117,  -1.2666,  ...,  -0.6592,  -3.0547,  -1.6572],
         [ -3.3516,   0.6182,   5.0781,  ...,  -1.3223,  -3.3965,  -4.6172],
         ...,
         [ -9.1641,   3.5469,  11.9375,  ...,  -3.8848,  -7.5898,  -2.9395],
         [-10.0078,   4.4805,  10.3906,  ...,  -4.6211,  -8.2109,  -3.6094],
         [-10.4219,   5.7773,   8.5000,  ...,  -5.0195,  -8.4688,  -3.9570]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [  419],
         [   13],
         ...,
         [12975],
         [  718],
         [ 1178]],

        [[29892],
         [21300],
         [ 3472],
         ...,
         [   13],
         [   13],
         [29879]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  419,  1638,   592,  ...,  5796,  2393,   274],
         [   13, 29889, 30004,  ...,  1212, 29906,  5461],
         ...,
         [12975, 22584, 29914,  ...,  6160, 29908, 13401],
         [  718, 29974, 13578,  ..., 15691, 24035, 11793],
         [ 1178,  3142,  6031,  ...,  4175,   274,   333]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [21300,  1867,  5634,  ..., 30003, 22158,  1961],
         [ 3472,  4544, 29958,  ...,  1420,   856,   349],
         ...,
         [   13, 29871, 29879,  ..., 29973, 29900, 29892],
         [   13, 29871, 29879,  ..., 29973, 29892, 29900],
         [29879, 29871,    13,  ..., 29900, 29973, 29892]]], device='cuda:0')
Batch 27, 64.1% of total tokens
encoded shape: torch.Size([2, 2151])
torch.Size([2, 2151]) tensor([[   1, 4363,  916,  ...,    2,    2,    2],
        [   1, 6319, 3134,  ...,   13,  462,  268]], device='cuda:0')
torch.Size([2, 2151, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -9.7891,  -4.4102,  -0.4165,  ...,  -4.9141,  -8.3047,  -0.4612],
         [-10.9062, -13.9297,  -6.2461,  ...,  -9.1953,  -9.1016,  -9.5391],
         ...,
         [-11.9141,  -3.1055,  -1.1143,  ...,  -7.3281,  -4.9453,  -5.9844],
         [-11.9375,  -3.1523,  -1.1182,  ...,  -7.3359,  -4.9766,  -5.9883],
         [-12.0078,  -3.2129,  -1.1338,  ...,  -7.3828,  -5.0508,  -6.0430]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.0742,  -4.4766,   0.6255,  ...,  -2.1152,  -3.4844,  -3.7578],
         [ -4.5781,  -6.8438,   0.4534,  ...,  -3.8945,  -1.9180,  -4.7148],
         ...,
         [ -2.6445,   0.1453,   7.7109,  ...,  -0.6250,   0.7046,   0.2568],
         [ -3.2344,  -1.6582,   3.4004,  ...,   0.2115,   3.2773,   1.1475],
         [ -1.9170,   1.4814,   5.2578,  ...,   1.6777,   2.0547,   1.6904]]],
       device='cuda:0')
torch.Size([2, 2151, 1]) tensor([[[29892],
         [  529],
         [ 1135],
         ...,
         [29900],
         [29900],
         [29900]],

        [[29892],
         [ 1961],
         [ 1873],
         ...,
         [ 1678],
         [  462],
         [ 1533]]], device='cuda:0')
torch.Size([2, 2151, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  529,   732, 29966,  ..., 10413,  7562, 29992],
         [ 1135,  4072,  2712,  ...,  2066,  3838, 29918],
         ...,
         [29900, 29924, 29929,  ..., 29946, 29947, 29945],
         [29900, 29924, 29929,  ..., 29946, 29947, 29945],
         [29900, 29924, 29929,  ..., 29946, 29947, 29945]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1961,  3134, 25446,  ...,  6080,   565,  2916],
         [ 1873, 10079,  6910,  ...,  2643,   518,  2322],
         ...,
         [ 1678,   829,     2,  ...,  8169, 16871, 25982],
         [  462,  9651, 18884,  ...,   308,  1533, 24426],
         [ 1533,  6756, 29722,  ..., 21275,    12, 29588]]], device='cuda:0')
Batch 28, 67.6% of total tokens
encoded shape: torch.Size([2, 824])
torch.Size([2, 824]) tensor([[    1,  6319,  1961,  ...,     2,     2,     2],
        [    1,  1053,  9537,  ...,    13, 29897,    13]], device='cuda:0')
torch.Size([2, 824, 32000]) tensor([[[-8.0312, -1.1074, -0.5288,  ..., -4.1836, -5.6602, -4.5781],
         [-7.0703, -4.4648,  0.6235,  ..., -2.1152, -3.4883, -3.7539],
         [ 1.0127,  2.7949,  9.4609,  ..., -2.4648,  1.9971,  1.2783],
         ...,
         [-0.8457,  4.5898, -1.1924,  ...,  0.9980,  2.3223,  0.9141],
         [-0.9048,  4.5781, -1.2148,  ...,  0.9614,  2.2891,  0.8770],
         [-0.9756,  4.5625, -1.2490,  ...,  0.9165,  2.2598,  0.8262]],

        [[-8.0312, -1.1074, -0.5288,  ..., -4.1836, -5.6602, -4.5781],
         [-5.4766, -6.6680, -4.0156,  ..., -5.3555, -5.2656, -1.5996],
         [-3.4844, -4.8164,  2.5293,  ..., -4.3906,  0.4119, -3.8438],
         ...,
         [-4.7773, -4.9609, 10.4531,  ..., -2.0586, -2.9844,  0.4182],
         [-1.6680, -1.9326, 21.0938,  ..., -2.6934, -3.4824, -1.0361],
         [ 3.3750,  4.5391, 25.7188,  ...,  2.2949,  0.6978,  3.5098]]],
       device='cuda:0')
torch.Size([2, 824, 1]) tensor([[[29892],
         [ 1961],
         [   13],
         ...,
         [24366],
         [24366],
         [24366]],

        [[29892],
         [  426],
         [  515],
         ...,
         [29897],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 824, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1961,  3134, 25446,  ...,  6080,   565,  2916],
         [   13,  7397,  3342,  ...,  3160,  9607,  4867],
         ...,
         [24366, 18627, 14262,  ..., 31779,  6610, 23795],
         [24366, 18627, 14262,  ..., 31779,  6610, 23795],
         [24366, 18627, 14262,  ..., 31779,  6610, 23795]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  426, 10606,  9537,  ...,  2115,  3740, 15877],
         [  515, 29892, 22141,  ..., 11096,  9802, 11024],
         ...,
         [29897, 29871,   467,  ...,  3569, 29913,  8443],
         [   13,     2,   849,  ...,   353, 29871,   313],
         [   13,     2, 15843,  ...,  6185,   424,  1252]]], device='cuda:0')
Batch 29, 68.9% of total tokens
encoded shape: torch.Size([2, 791])
torch.Size([2, 791]) tensor([[    1,   849, 14187,  ...,    13, 29913,    13],
        [    1,   444, 29871,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 791, 32000]) tensor([[[-8.0312, -1.1064, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-5.9531, -2.6758,  2.6484,  ..., -1.0840, -3.1895,  5.7383],
         [-5.2148, -8.8125,  0.9961,  ..., -3.6680, -1.8623,  0.8154],
         ...,
         [-1.3291, -0.7012,  2.5215,  ...,  0.4006, -0.9702,  0.5469],
         [ 0.6309,  0.9473,  7.0273,  ...,  0.2900, -0.2854, -0.2130],
         [-1.1055, -2.3223,  5.1211,  ..., -1.2021, -0.9292, -0.2981]],

        [[-8.0312, -1.1064, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-4.5703, -0.2256,  1.6055,  ..., -0.5254, -1.4482, -4.1250],
         [-6.0508, -6.0508,  1.3945,  ...,  2.7207,  0.6143,  2.2246],
         ...,
         [-5.5078,  1.5859,  1.4463,  ..., -2.9883, -0.1697, -2.4551],
         [-5.5898,  1.6211,  1.4404,  ..., -3.0156, -0.2166, -2.4629],
         [-5.4727,  1.6572,  1.5596,  ..., -2.9551, -0.1785, -2.3633]]],
       device='cuda:0')
torch.Size([2, 791, 1]) tensor([[[29892],
         [ 5920],
         [ 1266],
         ...,
         [29913],
         [25145],
         [  458]],

        [[29892],
         [11162],
         [29896],
         ...,
         [29900],
         [29900],
         [29900]]], device='cuda:0')
torch.Size([2, 791, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 1266,  3539,   322,  ...,   669,  8966,  7341],
         ...,
         [29913,  3400,  1836,  ..., 19327,  3680,   930],
         [25145, 24366, 26312,  ..., 31650, 21209, 18182],
         [  458, 17662, 11713,  ..., 23196, 15843,    13]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [11162,  2216, 18416,  ...,   826, 10783,  1551],
         [29896, 29900, 29906,  ..., 31789,   232,    13],
         ...,
         [29900, 29896,   448,  ..., 29901, 29941, 29946],
         [29900, 29896,   448,  ..., 29901, 29941,    13],
         [29900, 29896,   448,  ..., 29901, 29941,    13]]], device='cuda:0')
Batch 30, 70.3% of total tokens
encoded shape: torch.Size([2, 2009])
torch.Size([2, 2009]) tensor([[    1,  3577, 21385,  ...,    13, 29913,    13],
        [    1,  6319,  3134,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2009, 32000]) tensor([[[-8.0312e+00, -1.1055e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-6.8945e+00, -5.4062e+00, -6.1211e+00,  ..., -6.4648e+00,
          -5.0703e+00, -6.7930e+00],
         [-2.1172e+00, -4.5156e+00,  1.0773e+01,  ...,  3.7769e-01,
           3.0664e-01,  2.4980e+00],
         ...,
         [-1.6631e+00,  5.4297e-01,  7.6602e+00,  ..., -2.7905e-01,
          -1.1562e+00,  3.3911e-01],
         [-8.3203e-01,  2.3047e+00,  8.9219e+00,  ..., -6.1475e-01,
           1.0020e+00, -3.1787e-01],
         [-9.4238e-01,  7.9785e-01,  1.4766e+01,  ..., -1.0283e+00,
          -7.7576e-02, -1.0071e-02]],

        [[-8.0312e+00, -1.1055e+00, -5.2832e-01,  ..., -4.1836e+00,
          -5.6602e+00, -4.5781e+00],
         [-7.0742e+00, -4.4766e+00,  6.2549e-01,  ..., -2.1152e+00,
          -3.4844e+00, -3.7578e+00],
         [-4.5781e+00, -6.8438e+00,  4.5337e-01,  ..., -3.8945e+00,
          -1.9180e+00, -4.7148e+00],
         ...,
         [-8.6484e+00,  9.0156e+00, -3.1816e+00,  ..., -4.5820e+00,
          -3.4023e+00, -5.2578e+00],
         [-9.7969e+00,  7.6328e+00, -2.3809e+00,  ..., -5.7500e+00,
          -4.6680e+00, -6.3672e+00],
         [-1.0367e+01,  6.3867e+00, -1.5684e+00,  ..., -6.4453e+00,
          -5.4883e+00, -6.9648e+00]]], device='cuda:0')
torch.Size([2, 2009, 1]) tensor([[[29892],
         [  419],
         [   13],
         ...,
         [29913],
         [   13],
         [    2]],

        [[29892],
         [ 1961],
         [ 1873],
         ...,
         [    1],
         [ 7228],
         [29871]]], device='cuda:0')
torch.Size([2, 2009, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  419,  1638,   592,  ...,  5796,  2393,   274],
         [   13, 29889, 29936,  ...,  3032,   849, 24376],
         ...,
         [29913,    13, 29871,  ...,   355, 10162, 28296],
         [   13,     2, 26077,  ..., 18029,  2183, 30252],
         [    2,    13,  3318,  ..., 29871,  8394,    29]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1961,  3134, 25446,  ...,  6080,   565,  2916],
         [ 1873, 10079,  6910,  ...,  2643,   518,  2322],
         ...,
         [    1,  7228, 29871,  ...,    13,   313, 29879],
         [ 7228, 29871,     1,  ..., 29879,  4345, 29889],
         [29871,  7228,    13,  ...,     1, 29879, 29892]]], device='cuda:0')
Batch 31, 72.8% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[   1,  396,  448,  ...,  634,  351,   13],
        [   1, 9995, 1576,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -7.3203,  -6.8555,  -1.7881,  ...,  -2.7773,  -2.7988,  -6.3867],
         [ -7.5859,  -4.4062,   1.3213,  ...,  -1.2656,  -5.3164,  -5.2461],
         ...,
         [  0.0280,   0.8525,   0.9668,  ...,   0.6641,   3.6953,   0.7930],
         [ -3.4531,  -1.0693,   2.4199,  ...,  -3.3750,  -4.0117,  -2.6152],
         [ -0.1666,   2.3262,   5.1328,  ...,   2.1523,   2.3184,   0.6924]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.7500,  -8.6641,   0.6714,  ...,  -1.4502,  -4.4336,   1.1055],
         [-10.7031, -14.0391,  -7.3516,  ...,  -7.8477,  -8.1875,  -6.7031],
         ...,
         [-12.0156,   2.3086,  -0.1151,  ...,  -6.8008,  -6.0508,  -6.8984],
         [-12.0391,   2.3105,   0.0293,  ...,  -6.8516,  -6.0664,  -6.9336],
         [-11.9375,   2.5117,   0.1680,  ...,  -6.8086,  -6.0078,  -6.8477]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [29871],
         [29930],
         ...,
         [  351],
         [   13],
         [   13]],

        [[29892],
         [   13],
         [ 2967],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,   319,   476,  ...,   350,   349,   405],
         [29930, 29877,  2683,  ..., 10457, 29895, 29896],
         ...,
         [  351, 20189, 23196,  ..., 25145, 14262, 26077],
         [   13, 29889, 30488,  ..., 30555, 30186, 29961],
         [   13, 23196,   268,  ...,   308, 23681,   339]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [   13, 24376,  4013,  ..., 29909,  1576,  3206],
         [ 2967,  1667,  1243,  ...,  6055,  1494,  2295],
         ...,
         [29871, 29896, 29900,  ..., 29906,   313, 29901],
         [29871, 29896, 29900,  ...,   450, 29901,   313],
         [29871, 29896, 29900,  ..., 29901, 29946,   313]]], device='cuda:0')
Batch 32, 77.9% of total tokens
encoded shape: torch.Size([2, 88])
torch.Size([2, 88]) tensor([[    1,   334,   584,  1514, 18078, 29914, 29264, 29918,  2962,   287,
         29914,  6252,   362, 29952,    13, 29930,   584,  1514, 18078, 29914,
         29264, 29918,  2962,   287, 29914,   786,  5105,   292, 29952,    13,
         29930,   584,  1514, 18078, 29914, 29264, 29918,  2962,   287, 29914,
         12857, 29918,  4773, 29952,    13,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2],
        [    1,  4321,  3692, 21501, 10174,  9200, 20673,   297,   278,  1959,
          1797, 29889,    13,    13,  2951,  2551, 29892,   366,   674,  1074,
           263,  3652,   310,   376, 25711, 29908,  7191, 29892,  5643,   491,
           376, 18267,  4810,  3580, 18476,  1642,    13,    13, 25711, 11640,
          2792,   338,   376, 29886,  2548, 29908,    13, 25711, 11640,  2792,
           338,   376, 29886,  2548, 29908,    13, 25711, 11640,  2792,   338,
           376,  1319, 26940, 29908,    13, 25711, 11640,  3591,   338,   376,
         12199, 29908,    13, 25711,  8472, 29925,  1503,   287,   338,  1565,
            13,    13, 18267,  4810,  3580, 18476,    13,    13]],
       device='cuda:0')
torch.Size([2, 88, 32000]) tensor([[[ -8.0312,  -1.1094,  -0.5273,  ...,  -4.1836,  -5.6641,  -4.5781],
         [-10.8828,  -8.7891,  -3.1816,  ...,  -5.0586,  -7.5703,  -5.9297],
         [ -7.7305,  -9.3984,  -1.8408,  ...,  -3.2246,  -2.1836,  -3.4121],
         ...,
         [ -3.3613,  -1.2998,   1.1162,  ...,  -3.1133,  -3.7656,  -2.5156],
         [ -3.3281,  -1.2793,   1.1143,  ...,  -3.0977,  -3.7539,  -2.5020],
         [ -3.7500,  -0.9209,   1.2568,  ...,  -3.2715,  -3.7910,  -2.6445]],

        [[ -8.0312,  -1.1094,  -0.5273,  ...,  -4.1836,  -5.6641,  -4.5781],
         [-11.5234, -11.8438,  -7.0859,  ...,  -9.9062,  -9.5938,  -8.8516],
         [ -8.5078,  -8.9531,  -4.3398,  ...,  -6.0430,  -7.1445,  -6.3906],
         ...,
         [  0.4341,   2.8945,  13.4766,  ...,  -1.9600,  -1.5674,  -2.8691],
         [ -6.8555,  -4.2812,  10.3594,  ...,  -4.4766,  -4.6562,  -3.3926],
         [ -8.7891, -11.0391,   5.3164,  ...,  -3.9023,  -4.0547,  -2.8750]]],
       device='cuda:0')
torch.Size([2, 88, 1]) tensor([[[29892],
         [  334],
         [ 1057],
         [29901],
         [29961],
         [12631],
         [29899],
         [ 2962],
         [  287],
         [29914],
         [ 6252],
         [  362],
         [29889],
         [   13],
         [29930],
         [  584],
         [  999],
         [18078],
         [29914],
         [29264],
         [29918],
         [ 2962],
         [30488],
         [29914],
         [13305],
         [30488],
         [30488],
         [29952],
         [   13],
         [29930],
         [  584],
         [ 1514],
         [18078],
         [29914],
         [29264],
         [29918],
         [ 2962],
         [  287],
         [29914],
         [13305],
         [30488],
         [21125],
         [29952],
         [   13],
         [29930],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [ 1576],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [ 1576],
         [ 1576],
         [ 1576],
         [29892],
         [30488],
         [30488],
         [30488]],

        [[29892],
         [20170],
         [  263],
         [  338],
         [  526],
         [20673],
         [  297],
         [ 8943],
         [ 1959],
         [ 1797],
         [29889],
         [   13],
         [18571],
         [ 1678],
         [  278],
         [29892],
         [  278],
         [  881],
         [ 1074],
         [  263],
         [ 2643],
         [  310],
         [ 3694],
         [10994],
         [29908],
         [ 7191],
         [29889],
         [  322],
         [  491],
         [  263],
         [ 4519],
         [  349],
         [ 3580],
         [18476],
         [ 1642],
         [   13],
         [   13],
         [ 2277],
         [29901],
         [29896],
         [29901],
         [  278],
         [ 1319],
         [ 2548],
         [29908],
         [   13],
         [25711],
         [11640],
         [ 2792],
         [  338],
         [  376],
         [ 1319],
         [ 2548],
         [29908],
         [   13],
         [25711],
         [11640],
         [ 2792],
         [  338],
         [  376],
         [ 1319],
         [26940],
         [29908],
         [   13],
         [25711],
         [11640],
         [ 2792],
         [  338],
         [  376],
         [29896],
         [ 3186],
         [   13],
         [25711],
         [11640],
         [19356],
         [ 2548],
         [  287],
         [  338],
         [  376],
         [   13],
         [25711],
         [25711],
         [ 4810],
         [ 3580],
         [18476],
         [   13],
         [   13],
         [25711]]], device='cuda:0')
torch.Size([2, 88, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  334,  2328,   450,  ..., 29903,  4013, 29902],
         [ 1057,   518,  8552,  ...,   450, 29930,  3579],
         ...,
         [30488, 30879, 31147,  ..., 31256, 29889, 31575],
         [30488, 30879, 31147,  ..., 31256, 31575, 31307],
         [30488, 30879, 31147,  ..., 30555, 29892, 31256]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [20170, 15664,   326,  ..., 10253, 29877,   310],
         [  263,   278,   596,  ...,   372,   727,   445],
         ...,
         [   13, 29889, 29991,  ...,   313,   518,  3850],
         [   13, 28956, 25711,  ..., 25512, 29908, 29952],
         [25711,  2277,  2951,  ...,  3644,  1576,  4013]]], device='cuda:0')
Batch 33, 78.0% of total tokens
encoded shape: torch.Size([2, 3093])
torch.Size([2, 3093]) tensor([[   1,  396,  448,  ..., 7700,   13,   13],
        [   1, 4949,  232,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 3093, 32000]) tensor([[[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-7.3203, -6.8555, -1.7881,  ..., -2.7773, -2.7988, -6.3867],
         [-7.5859, -4.4062,  1.3213,  ..., -1.2656, -5.3164, -5.2461],
         ...,
         [ 2.0801,  5.0625, 21.0156,  ...,  0.3308,  1.2715, -0.9453],
         [-0.7593,  3.8398, 21.5938,  ..., -0.8110,  1.8096, -0.7837],
         [ 2.6445,  7.3477, 16.6719,  ...,  0.0592,  5.8789,  2.1152]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-8.9141, -7.6758, -0.7969,  ..., -5.9844, -6.3711, -1.2461],
         [12.5234, 13.5938, -4.5859,  ..., 11.5781, 10.0859, 12.9844],
         ...,
         [-7.9727,  9.1875, -0.4636,  ..., -4.5898, -5.8438, -3.9922],
         [-8.1016,  9.4688, -0.4756,  ..., -4.6758, -5.8672, -4.0977],
         [-8.0703,  9.5938, -0.5273,  ..., -4.6484, -5.8281, -4.0938]]],
       device='cuda:0')
torch.Size([2, 3093, 1]) tensor([[[29892],
         [29871],
         [29930],
         ...,
         [   13],
         [   13],
         [   13]],

        [[29892],
         [ 9166],
         [  193],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 3093, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,   319,   476,  ...,   350,   349,   405],
         [29930, 29877,  2683,  ..., 10457, 29895, 29896],
         ...,
         [   13,     2,   396,  ...,  1678,   308,   259],
         [   13,  9651,  4706,  ...,   462, 29871,   396],
         [   13, 29937,  1678,  ...,   361,     2,  9651]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [  193,   147,   177,  ...,   194,   165,   139],
         ...,
         [    1, 29900, 29889,  ..., 29906,   448, 29915],
         [    1, 29900, 29889,  ..., 29906,   448,   229],
         [    1, 29889, 29900,  ..., 29906,   448, 29915]]], device='cuda:0')
Batch 34, 81.9% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   528, 29874,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,   376, 29878, 11490]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-8.3984,  0.6221, -1.6709,  ...,  2.6641,  0.4211,  0.0731],
         [-5.4297, -0.6924, -2.2090,  ..., -0.5454, -0.5952,  1.4268],
         ...,
         [-4.4531, -5.9922, -2.2461,  ..., -0.2793,  0.5176, -0.3337],
         [-3.5312, -1.7305,  1.1611,  ..., -3.3145, -3.9414, -2.5312],
         [-1.1592, -0.7915, -0.4189,  ...,  0.0278,  1.4805, -0.0283]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[    0],
         [    0],
         [    0],
         ...,
         [    0],
         [    0],
         [    0]],

        [[29892],
         [29896],
         [29871],
         ...,
         [29939],
         [30488],
         [29899]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         ...,
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9],
         [    7,     6,     4,  ...,     3,     8,     9]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [29871,  1678,   462,  ...,    12, 16595,    13],
         ...,
         [29939, 29879, 29878,  ..., 29894, 29891, 29916],
         [30488, 30879, 31147,  ..., 31256, 31488, 29892],
         [29899, 18627,  6610,  ..., 14672,   776,  1680]]], device='cuda:0')
Batch 35, 86.0% of total tokens
encoded shape: torch.Size([2, 858])
torch.Size([2, 858]) tensor([[    1, 29871, 30143,  ...,    13,  1678,    13],
        [    1,   934,  5809,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 858, 32000]) tensor([[[-8.0078e+00, -1.2354e+00, -5.3906e-01,  ..., -4.2148e+00,
          -5.6875e+00, -4.6211e+00],
         [-8.3984e+00,  6.2207e-01, -1.6670e+00,  ...,  2.6621e+00,
           4.1895e-01,  6.7627e-02],
         [-1.0070e+01, -3.7188e+00, -2.2812e+00,  ..., -4.9062e+00,
          -5.4844e+00, -4.2109e+00],
         ...,
         [ 4.3677e-01,  7.5312e+00,  2.2656e+01,  ..., -2.5293e+00,
           2.2900e-01,  2.0547e+00],
         [-1.8726e-01,  6.1875e+00,  1.1672e+01,  ..., -9.6777e-01,
           1.4600e-01,  1.9873e+00],
         [ 6.6992e-01,  4.1758e+00,  1.7922e+01,  ..., -1.8076e+00,
           1.0488e+00,  2.2363e+00]],

        [[-8.0078e+00, -1.2354e+00, -5.3906e-01,  ..., -4.2148e+00,
          -5.6875e+00, -4.6211e+00],
         [-5.5273e+00, -1.2344e+01, -3.0449e+00,  ..., -2.9434e+00,
          -5.5000e+00, -4.7617e+00],
         [-6.8477e+00, -1.2062e+01, -3.2598e+00,  ..., -5.8086e+00,
          -5.3086e+00, -6.4414e+00],
         ...,
         [-2.7949e+00,  1.2242e+01, -3.0586e+00,  ..., -2.0630e-01,
           1.2207e+00,  2.9106e-03],
         [-2.9023e+00,  1.2250e+01, -3.0859e+00,  ..., -2.9395e-01,
           1.1504e+00, -7.3486e-02],
         [-2.9980e+00,  1.2219e+01, -3.1074e+00,  ..., -3.6499e-01,
           1.1006e+00, -1.4099e-01]]], device='cuda:0')
torch.Size([2, 858, 1]) tensor([[[29892],
         [29896],
         [ 4746],
         ...,
         [    2],
         [ 7397],
         [    2]],

        [[29892],
         [29881],
         [29901],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 858, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29896, 29906, 29941,  ..., 29955, 29929, 29953],
         [ 4746, 22377, 29992,  ..., 29966,  1888, 29914],
         ...,
         [    2,    13,   268,  ..., 22377,  1678, 30143],
         [ 7397,   970,  4363,  ...,   773,  1533,   376],
         [    2,  1678,    13,  ...,  4706, 22377,   462]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29881,   471, 29918,  ..., 29901,  1090,   338],
         [29901,   353,   338,  ...,   584,  1746,  1762],
         ...,
         [    1,  7228, 31779,  ..., 25528,    10,  4345],
         [    1,  7228, 31779,  ...,    10, 25528,  4345],
         [    1,  7228, 31779,  ...,    10,  4345, 25528]]], device='cuda:0')
Batch 36, 87.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[   1,  934, 5809,  ...,    2,    2,    2],
        [   1, 3577,  269,  ...,   12,   12,   12]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.5273, -12.3281,  -3.0352,  ...,  -2.9395,  -5.5117,  -4.7500],
         [ -6.8477, -12.0625,  -3.2695,  ...,  -5.8047,  -5.3086,  -6.4297],
         ...,
         [ -8.1172,   6.0078,   9.1328,  ...,  -4.1289,  -6.8672,  -2.9316],
         [ -7.8828,   5.6445,   9.7500,  ...,  -3.9023,  -6.7656,  -2.7148],
         [ -8.1016,   6.3906,   8.8672,  ...,  -4.0273,  -6.8320,  -2.8457]],

        [[ -8.0312,  -1.1055,  -0.5283,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -6.8945,  -5.4062,  -6.1211,  ...,  -6.4648,  -5.0703,  -6.7930],
         [ -5.3125,  -5.5469,  -1.2041,  ...,  -0.7656,  -4.7148,  -2.3242],
         ...,
         [ -3.0820,   1.5459,   0.4863,  ...,   1.7871,  -0.5898,  -1.2715],
         [ -3.1582,   2.5039,   1.6846,  ...,  -0.3472,  -2.6094,  -1.7080],
         [ -2.4277,  -2.4629,  -2.0293,  ...,   0.6294,  -1.6650,  -0.1327]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [29881],
         [29901],
         ...,
         [   13],
         [   13],
         [   13]],

        [[29892],
         [  419],
         [ 2364],
         ...,
         [   12],
         [   12],
         [ 7850]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29881,   471, 29918,  ..., 29901,  1090,   338],
         [29901,   353,   338,  ...,   584,  1762,  1746],
         ...,
         [   13, 29889, 29899,  ..., 29918, 29900, 29871],
         [   13, 29889, 29899,  ..., 29896, 29900, 29871],
         [   13, 29889, 29879,  ..., 29918, 29900, 29898]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [  419,  1638,   592,  ...,  5796,  2393,   274],
         [ 2364, 14569,  8181,  ..., 29941,  1516, 21040],
         ...,
         [   12,   597,  1118,  ...,  1881, 19258,  6982],
         [   12,  1118, 19345,  ...,   597,  4451, 20462],
         [ 7850,  8434,  1469,  ...,  3089, 19345,  6982]]], device='cuda:0')
Batch 37, 91.2% of total tokens
encoded shape: torch.Size([2, 828])
torch.Size([2, 828]) tensor([[    1,  4949,    13,  ...,    13, 29913,    13],
        [    1,   849, 29991,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 828, 32000]) tensor([[[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -8.9141,  -7.6797,  -0.7905,  ...,  -5.9766,  -6.3633,  -1.2363],
         [ -6.2227,  -7.0898,  -3.5254,  ...,  -2.5117,  -0.8398,   3.2266],
         ...,
         [ -3.2422,  -0.6577,   4.3906,  ...,   0.9224,  -0.4968,   0.2081],
         [ -0.7095,   1.6689,   9.5156,  ...,   0.3091,   0.1195,  -0.4624],
         [  1.3691,   4.4375,  21.5156,  ...,   2.4980,  -1.3516,   0.4648]],

        [[ -8.0312,  -1.1074,  -0.5288,  ...,  -4.1836,  -5.6602,  -4.5781],
         [ -5.9531,  -2.6758,   2.6484,  ...,  -1.0840,  -3.1895,   5.7383],
         [-10.2344,  -9.9922,  -0.9629,  ...,  -5.0664,  -6.1836,  -1.9512],
         ...,
         [ -2.9434,  12.6094,   7.5703,  ...,  -0.3435,  -0.2267,  -2.4102],
         [ -0.7920,  14.4219,   4.8008,  ...,   1.1260,   1.4746,  -0.5400],
         [ -1.9629,  13.8672,   4.1914,  ...,   0.0688,   0.0406,  -0.5957]]],
       device='cuda:0')
torch.Size([2, 828, 1]) tensor([[[29892],
         [ 9166],
         [  334],
         ...,
         [29913],
         [   13],
         [   13]],

        [[29892],
         [ 5920],
         [  910],
         ...,
         [    1],
         [    1],
         [    1]]], device='cuda:0')
torch.Size([2, 828, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [  334,  5215,    12,  ...,  9891,  7959,  3776],
         ...,
         [29913,    12,    13,  ...,  8117, 10114,  5003],
         [   13,     2, 23196,  ...,   849, 24366, 18627],
         [   13,     2,  9891,  ...,  2220, 29952,  3877]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [  910,   319,   320,  ...,   530,  4321,   518],
         ...,
         [    1, 29900,   396,  ..., 29873, 29962, 29955],
         [    1, 18383, 25145,  ..., 23795, 10477, 31681],
         [    1, 29900, 29879,  ...,  2495,  1127,   336]]], device='cuda:0')
Batch 38, 92.8% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   396, 29991,  ...,     2,     2,     2],
        [    1,  6319,  3134,  ...,   179,   181,   227]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-7.3203, -6.8555, -1.7881,  ..., -2.7773, -2.7988, -6.3867],
         [-4.3516, -0.6943, -0.8838,  ..., -4.9609, -5.3867, -0.6060],
         ...,
         [-7.1719, 10.7344,  1.0068,  ..., -3.5020, -5.1289, -3.1211],
         [-7.2891, 10.4531,  1.0264,  ..., -3.5312, -5.2109, -3.2051],
         [-7.4648, 10.1562,  1.0713,  ..., -3.6016, -5.3086, -3.3438]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-7.0742, -4.4766,  0.6255,  ..., -2.1152, -3.4844, -3.7578],
         [-4.5781, -6.8438,  0.4534,  ..., -3.8945, -1.9180, -4.7148],
         ...,
         [ 8.7656,  7.8828, -4.4141,  ...,  7.3281,  8.6016, 11.2656],
         [-2.5176, -2.6543,  2.5957,  ..., -0.3801,  2.7422,  0.5767],
         [ 7.1875,  9.4453, -2.6230,  ...,  7.5312,  7.9961,  6.4961]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [29871],
         [ 3017],
         ...,
         [    1],
         [    1],
         [    1]],

        [[29892],
         [ 1961],
         [ 1873],
         ...,
         [  181],
         [  227],
         [  180]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [29871,   319,   476,  ...,   350,   349,   405],
         [ 3017, 22032,  4691,  ...,  1207,  5675,  9016],
         ...,
         [    1, 29900, 29879,  ..., 29889, 29929, 29955],
         [    1, 29900, 29879,  ..., 29946, 29929, 29955],
         [    1, 29900, 29879,  ..., 29946, 29892, 29929]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1961,  3134, 25446,  ...,  6080,   565,  2916],
         [ 1873, 10079,  6910,  ...,  2643,   518,  2322],
         ...,
         [  181,   154,   171,  ...,   187,   177,   164],
         [  227, 29871, 31807,  ..., 30140, 29908, 29915],
         [  180,   179,   181,  ...,   177,   176,   183]]], device='cuda:0')
Batch 39, 97.5% of total tokens
encoded shape: torch.Size([2, 120])
torch.Size([2, 120]) tensor([[    1,   849,    13,   458,  6760,   630,   491, 21488,  4271, 29886,
          3028,   513,   373, 29871, 29941, 29914, 29896, 29941, 29914, 29896,
         29955, 29889,    13,   458,    13,    13, 29937,   361,   299,  1389,
           438, 29906, 29918, 29949, 29906, 17080, 29949, 29954,  1307, 29918,
         29950,    13, 29937,  7922,   438, 29906, 29918, 29949, 29906, 17080,
         29949, 29954,  1307, 29918, 29950,    13,    13, 29937,  2856,   376,
         29877, 29906, 29889, 29882, 29908,    13,    13,  1990,   438, 29906,
         14207,   584,   970,   438, 29906,   426,    13,  1678,   660, 29918,
         14824, 17637,    13,  3597, 29901,    13,  1678,  6261,   438, 29906,
         14207, 29898, 29984,  2061,   334,  3560,   353, 29871, 29900,   416,
            13,  3400,    13,    13,    13, 29937, 15224,   849, 29949, 29906,
         29918, 29949, 29906, 17080, 29949, 29954,  1307, 29918, 29950,    13],
        [    1,  4949,  3497,   584,  1342, 29889, 29883,  3776,    13,    13,
           524,   437, 29918,   459, 29898,   524,   263, 29892,   938,   289,
         29892,   938,  3070,   459,  5033,   524, 29892,   524,   876,   426,
            13, 29871,   736,  3070,   459,  5033, 29874, 29892, 29890,   416,
            13, 29913,    13,    13,   524,   788, 29898,   524,   263, 29892,
           938,   289, 29897,   426,    13, 29871,   736,   263, 29974, 29890,
         29936,    13, 29913,    13,    13,   524,  1014, 29898,   524,   263,
         29892,   938,   289, 29897,   426,    13, 29871,   736,   263, 29899,
         29890, 29936,    13, 29913,    13,    13,   524, 15065, 29898,   524,
           263, 29892,   938,   289, 29897,   426,    13, 29871,   736,   263,
         29930, 29890, 29936,    13, 29913,    13,    13,   524,  3070,  9891,
          1707,  5033,   524, 29892,   524, 29897,   353,   788, 29936,    13]],
       device='cuda:0')
torch.Size([2, 120, 32000]) tensor([[[ -8.0234,  -1.1396,  -0.5381,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -5.9453,  -2.6699,   2.6562,  ...,  -1.0781,  -3.1816,   5.7461],
         [ -5.3242,  -4.8398,  -0.5718,  ...,  -2.2617,  -2.4355,   1.9355],
         ...,
         [ -2.8828,  -6.3477,   9.9688,  ...,  -2.2598,  -2.9883,  -1.1221],
         [ -0.8394,  -0.1045,  20.9375,  ...,  -0.5884,  -2.3730,  -2.1055],
         [ -0.5376,   6.6680,  19.4219,  ...,   2.0723,   0.0657,   0.6240]],

        [[ -8.0234,  -1.1396,  -0.5381,  ...,  -4.1914,  -5.6680,  -4.5898],
         [ -8.9062,  -7.6719,  -0.7881,  ...,  -5.9766,  -6.3594,  -1.2373],
         [ -5.4414, -11.0391,  -2.8887,  ...,  -2.6465,  -3.1328,  -1.7119],
         ...,
         [ -2.0410,  -6.6250,   5.2109,  ...,   4.2500,  -1.5400,   1.7295],
         [  2.4375,   2.2148,  12.7812,  ...,   1.1680,   1.9395,   2.2207],
         [  4.1914,   1.5400,  16.2031,  ...,   3.3184,   2.0156,   4.7656]]],
       device='cuda:0')
torch.Size([2, 120, 1]) tensor([[[29892],
         [ 5920],
         [ 5215],
         [29871],
         [  630],
         [  491],
         [ 3159],
         [ 4271],
         [  373],
         [  373],
         [30488],
         [  373],
         [29871],
         [29906],
         [29914],
         [29906],
         [29945],
         [29914],
         [29896],
         [29955],
         [29889],
         [   13],
         [  458],
         [   13],
         [   13],
         [ 5215],
         [  361],
         [  299],
         [ 1389],
         [ 4770],
         [ 1783],
         [ 7390],
         [ 3217],
         [29906],
         [29918],
         [ 1964],
         [ 8452],
         [ 1307],
         [29918],
         [29950],
         [   13],
         [29937],
         [ 7922],
         [  438],
         [29906],
         [29918],
         [29949],
         [29906],
         [17080],
         [29949],
         [29954],
         [ 1307],
         [29918],
         [29950],
         [   13],
         [   13],
         [29937],
         [ 2856],
         [  529],
         [29877],
         [29906],
         [ 3221],
         [29882],
         [29908],
         [   13],
         [29937],
         [22377],
         [  438],
         [29906],
         [14207],
         [  426],
         [  970],
         [  438],
         [29906],
         [  426],
         [   13],
         [ 9053],
         [  970],
         [29918],
         [14824],
         [17637],
         [   13],
         [ 3597],
         [29901],
         [   13],
         [ 1678],
         [ 6261],
         [  438],
         [29906],
         [14207],
         [29898],
         [29984],
         [ 2061],
         [  334],
         [ 3560],
         [  353],
         [ 1870],
         [29900],
         [  416],
         [   13],
         [ 1678],
         [   13],
         [   13],
         [29937],
         [29937],
         [15224],
         [  849],
         [  438],
         [29906],
         [29918],
         [29949],
         [29906],
         [17080],
         [29949],
         [29954],
         [ 1307],
         [29918],
         [29950],
         [   13],
         [    2]],

        [[29892],
         [ 9166],
         [ 4408],
         [ 1667],
         [29918],
         [29883],
         [ 3776],
         [   13],
         [ 5515],
         [29937],
         [ 1667],
         [29918],
         [14481],
         [29898],
         [  524],
         [ 1852],
         [29892],
         [  938],
         [  289],
         [29892],
         [  938],
         [  334],
         [29888],
         [ 5033],
         [  524],
         [29892],
         [  938],
         [  876],
         [  426],
         [   13],
         [ 1678],
         [  736],
         [ 1015],
         [  459],
         [ 5033],
         [29874],
         [29892],
         [29890],
         [  416],
         [   13],
         [29913],
         [   13],
         [   13],
         [  524],
         [ 1667],
         [29898],
         [  524],
         [  263],
         [29892],
         [  938],
         [  289],
         [29897],
         [  426],
         [  736],
         [29871],
         [  736],
         [  263],
         [  718],
         [29890],
         [29936],
         [   13],
         [29913],
         [   13],
         [   13],
         [  524],
         [ 1014],
         [29898],
         [  524],
         [  263],
         [29892],
         [  938],
         [  289],
         [29897],
         [  426],
         [   13],
         [29871],
         [  736],
         [  263],
         [29899],
         [29890],
         [29936],
         [   13],
         [29913],
         [   13],
         [   13],
         [  524],
         [15065],
         [29898],
         [  524],
         [  263],
         [29892],
         [  938],
         [  289],
         [29897],
         [  426],
         [   13],
         [29871],
         [  736],
         [  263],
         [29930],
         [29890],
         [29936],
         [   13],
         [29913],
         [   13],
         [   13],
         [  524],
         [ 1933],
         [  459],
         [23076],
         [ 9601],
         [  524],
         [29892],
         [  524],
         [  416],
         [  353],
         [ 1014],
         [29936],
         [   13],
         [   13]]], device='cuda:0')
torch.Size([2, 120, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 5920, 18610, 19511,  ...,  2683, 22029,  2045],
         [ 5215,   458,  3075,  ...,   334,  1707,   970],
         ...,
         [29950,  3954, 29984,  ..., 29963, 29924, 29907],
         [   13,     2, 29918,  ...,   438,   849, 29914],
         [    2,    13,   458,  ...,  5515,   268,  3059]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 9166,   831, 14187,  ...,   910, 17067,   426],
         [ 4408,  1024,  5759,  ..., 10663,   512,  2825],
         ...,
         [29936, 29892,  2056,  ..., 29898, 29888, 15458],
         [   13,  4949,   849,  ...,   418,   268,   462],
         [   13,   524,  5405,  ...,  3090,   735,  1867]]], device='cuda:0')
Batch 40, 97.8% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 18252, 21300,  ..., 29878,  2176, 29946],
        [    1,   376,  1509,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-5.2773, -4.0117, -1.2666,  ..., -0.6592, -3.0547, -1.6572],
         [-3.3516,  0.6182,  5.0781,  ..., -1.3223, -3.3965, -4.6172],
         ...,
         [-1.6348,  0.3511,  2.6953,  ...,  0.1517,  1.4014, -0.3828],
         [-4.9180, -5.9844,  3.9004,  ..., -3.3789,  1.5283, -1.5186],
         [-2.9082, -2.8145,  2.5938,  ..., -1.9648,  0.8945,  1.4668]],

        [[-8.0312, -1.1055, -0.5283,  ..., -4.1836, -5.6602, -4.5781],
         [-7.6016, -5.0391, -0.5879,  ..., -2.9238, -3.3652, -2.4707],
         [-3.7812, -5.7734,  0.0931,  ..., -1.2412, -0.5649, -2.2520],
         ...,
         [-8.0156,  5.9297,  5.3867,  ..., -2.6680, -6.1992, -3.1875],
         [-8.3438,  6.0352,  5.2578,  ..., -2.8867, -6.4258, -3.3984],
         [-8.6484,  6.2344,  4.9688,  ..., -3.0996, -6.6250, -3.5957]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29892],
         [21300],
         [ 3472],
         ...,
         [ 2176],
         [29946],
         [29926]],

        [[29892],
         [ 1576],
         [ 9406],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [21300,  1867,  5634,  ..., 30003, 22158,  1961],
         [ 3472,  4544, 29958,  ...,  1420,   856,   349],
         ...,
         [ 2176,  4037,  1289,  ...,   299, 30617,  1288],
         [29946, 29953,   618,  ...,  1049, 20949, 30379],
         [29926, 29967,   261,  ..., 21452,   823, 29884]],

        [[29892, 29889,   313,  ..., 30010, 29896, 29899],
         [ 1576, 29902,  7690,  ..., 29933,  3112,  2900],
         [ 9406,  1319, 26742,  ...,  6514,  3724,  9513],
         ...,
         [29871, 29896, 29879,  ..., 29945, 29929, 29889],
         [29871, 29896, 29879,  ..., 29889, 29945, 29929],
         [29871, 29896, 29879,  ..., 29889, 29945, 29929]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 891])
torch.Size([2, 891]) tensor([[    1, 11474,    13,  ...,     2,     2,     2],
        [    1,  6319,  3134,  ...,   829,  9700, 29958]], device='cuda:0')
torch.Size([2, 891, 32000]) tensor([[[-9.0156,  0.8428,  0.8081,  ..., -3.0449, -5.3750, -2.3594],
         [-4.5508, -3.0508,  1.9414,  ..., -3.4062, -4.0625, -3.0254],
         [-5.8438,  3.2188,  6.0781,  ..., -0.1276, -2.0547,  0.7603],
         ...,
         [-6.2773,  1.2578, -3.2969,  ..., -2.5449, -3.6973, -2.4863],
         [-6.2617,  1.2881, -3.2949,  ..., -2.5430, -3.6973, -2.4785],
         [-6.1836,  1.2998, -3.3145,  ..., -2.5293, -3.6699, -2.4648]],

        [[-9.0156,  0.8428,  0.8081,  ..., -3.0449, -5.3750, -2.3594],
         [-4.6875, -2.9609,  2.2520,  ..., -3.3125, -4.3047, -3.0781],
         [-4.6758, -3.3750,  2.1719,  ..., -3.4277, -3.8867, -3.0625],
         ...,
         [-5.7891, -4.4609,  2.2188,  ..., -3.9082, -4.2070, -3.5488],
         [-6.3359, -6.2617,  2.5059,  ..., -4.4805, -4.5820, -3.8672],
         [-6.5078, -6.2227,  2.6895,  ..., -4.5586, -4.7148, -4.0117]]],
       device='cuda:0')
torch.Size([2, 891, 1]) tensor([[[29918],
         [29889],
         [   13],
         ...,
         [30010],
         [30010],
         [30010]],

        [[29918],
         [29871],
         [29899],
         ...,
         [29892],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 891, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 30488,  ...,   313,   856, 31147],
         [   13,   313,    12,  ..., 29918, 29915, 30024],
         ...,
         [30010, 29915,   313,  ...,   392, 30140,   306],
         [30010, 29915,   313,  ...,   392, 30140, 29987],
         [30010, 29915,   313,  ...,   392, 30140, 29987]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29899, 29874, 29889,  ..., 29875, 30488, 29915],
         ...,
         [29892, 29871, 29889,  ..., 29896,   349, 29915],
         [29871, 29899, 29892,  ..., 29896, 29875,   856],
         [29871, 29899, 29892,  ..., 29896,   313, 29875]]], device='cuda:0')
Batch 1, 0.9% of total tokens
encoded shape: torch.Size([2, 562])
torch.Size([2, 562]) tensor([[    1,  4949, 29991,  ...,  3954, 29925,    13],
        [    1,   525,  1509,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 562, 32000]) tensor([[[ -9.0156,   0.8452,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.4336,  -2.8066,   2.1680,  ...,  -3.4434,  -4.0625,  -2.8242],
         [ -4.9883,  -3.3867,   2.3691,  ...,  -3.5371,  -4.2500,  -3.2207],
         ...,
         [-11.1172, -17.3125,  -0.4805,  ...,  -6.4297,  -2.2754,  -7.1211],
         [-12.5703, -16.0156,   0.9175,  ...,  -7.6211,  -5.3242,  -8.1016],
         [ -7.2656,  -7.1406,   2.7266,  ...,  -4.5742,  -5.2031,  -3.8145]],

        [[ -9.0156,   0.8452,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.9609,  -5.5000,   4.4492,  ...,  -4.3164,  -4.7734,  -3.9980],
         [ -8.2578,  -8.6484,   3.0547,  ...,  -4.7852,  -4.8711,  -4.4102],
         ...,
         [ -4.1875,   0.2161,  -1.9355,  ...,  -2.6523,  -3.2285,  -2.5703],
         [ -4.3125,   0.2362,  -2.0566,  ...,  -2.6582,  -3.2363,  -2.5977],
         [ -4.5156,   0.3877,  -2.3105,  ...,  -2.6445,  -3.2148,  -2.6152]]],
       device='cuda:0')
torch.Size([2, 562, 1]) tensor([[[29918],
         [30488],
         [29892],
         ...,
         [29874],
         [29874],
         [29871]],

        [[29918],
         [29871],
         [29874],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 562, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [29892, 29889, 29899,  ..., 29915,   315,   349],
         ...,
         [29874, 29871, 29875,  ..., 29879, 29892, 29877],
         [29874, 29871, 29899,  ..., 29928, 29882,   294],
         [29871, 29899, 29892,  ...,   856, 29933,   313]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ...,   315, 29874,   349],
         [29874, 29899, 29875,  ...,   262, 29898,   294],
         ...,
         [30488, 30879, 31147,  ...,   376, 29915,   349],
         [30488, 30879, 31147,  ..., 29915, 30186,   349],
         [30488, 30879, 31147,  ..., 29915, 30010, 30140]]], device='cuda:0')
Batch 2, 1.5% of total tokens
encoded shape: torch.Size([2, 1902])
torch.Size([2, 1902]) tensor([[    1,   444, 16155,  ..., 29920,  1412,    13],
        [    1,   426,  2048,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1902, 32000]) tensor([[[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [ -4.9961,  -3.4004,   2.1465,  ...,  -3.4277,  -3.8730,  -3.1777],
         [ -8.7578,  -9.0234,   4.0039,  ...,  -5.5703,  -4.9570,  -5.0039],
         ...,
         [ -8.8438, -14.0156,  -0.1567,  ...,  -5.5625,  -3.7402,  -7.4453],
         [ -6.3945,  -5.8086,   1.5107,  ...,  -4.7383,  -4.0430,  -4.3477],
         [ -6.2070,  -5.5781,   2.0781,  ...,  -4.6211,  -4.3789,  -4.0859]],

        [[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [ -4.5195,  -2.8008,   2.1953,  ...,  -3.3750,  -4.0039,  -2.9629],
         [ -5.3828,  -3.8770,   2.6113,  ...,  -3.4844,  -4.5312,  -3.3984],
         ...,
         [ -7.1133,  -0.7822,  -3.8965,  ...,  -2.6113,  -3.3262,  -2.9590],
         [ -7.1367,  -0.7852,  -3.9004,  ...,  -2.6016,  -3.3281,  -2.9570],
         [ -7.1562,  -0.8149,  -3.9102,  ...,  -2.5996,  -3.3281,  -2.9629]]],
       device='cuda:0')
torch.Size([2, 1902, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [29924],
         [29874],
         [29892]],

        [[29918],
         [29889],
         [29892],
         ...,
         [29915],
         [29915],
         [29915]]], device='cuda:0')
torch.Size([2, 1902, 10]) tensor([[[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29899, 29892,  ..., 29915,   262, 29896],
         [29871, 29899, 29892,  ...,    13,   315, 29915],
         ...,
         [29924,   557, 29903,  ..., 29950,  1131,   392],
         [29874, 29911, 29899,  ..., 29903, 29933, 29909],
         [29892,   313, 29899,  ..., 29874, 29915, 29898]],

        [[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29889, 29892, 29871,  ..., 31147, 30879,   315],
         [29892, 29871, 29899,  ...,   315,    13, 29874],
         ...,
         [29915, 30010, 30057,  ...,   229, 29987, 29879],
         [29915, 30010, 30057,  ...,   229, 29987, 29879],
         [29915, 30010, 30057,  ...,   229, 29987,  1068]]], device='cuda:0')
Batch 3, 3.7% of total tokens
encoded shape: torch.Size([2, 110])
torch.Size([2, 110]) tensor([[    1,  1996, 29918, 17588, 29898, 12194, 29918, 29999, 29943, 29950,
           416,    13, 12277, 29918, 18091, 29936,    13,  2695,  7411, 29918,
         29878, 12449,  6818,   353,   390, 29924, 29936,    13, 16365, 29918,
         15860, 29928, 29898,  1481, 29941, 29906, 29918,   517, 29918, 29888,
         29896, 29953,  3552, 13470, 29941, 29906, 29918, 29873, 29897, 12445,
         29896,  2483,    13,   842, 29918, 18091, 29918, 11739, 29879, 29936,
            13,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1,  3577,   419, 29889, 24911,   675, 29889, 23106, 29889,  4530,
          2490, 29889, 11739, 29936,    13,    13, 29992, 20182,  1253, 29956,
          2753,   886,   703, 15550,  1159,    13,  3597,  9846,   770,   438,
          6444,  2451,  4988,  8960,   426,    13,    13,  1678,   970,   438,
          6444,  2451, 29898,  1231,  2643, 29897,   426,    13,  4706,  2428,
         29898,  4906,   416,    13,  1678,   500,    13,    13,  1678,   970,
           438,  6444,  2451, 29898, 29473,   519,  4556, 29897,   426,    13,
          4706,  2428, 29898, 29883,  1071,   416,    13,  1678,   500,    13,
            13,  1678,   970,   438,  6444,  2451, 29898,  1231,  2643, 29892,
           498,   798,   519,  4556, 29897,   426,    13,  4706,  2428, 29898,
          4906, 29892,  4556,   416,    13,  1678,   500,    13, 29913,    13]],
       device='cuda:0')
torch.Size([2, 110, 32000]) tensor([[[ -9.0156,   0.8486,   0.8081,  ...,  -3.0469,  -5.3750,  -2.3613],
         [ -4.8281,  -3.5859,   2.6133,  ...,  -3.3965,  -3.9512,  -2.8828],
         [ -9.2578,  -9.4688,   3.8223,  ...,  -5.8555,  -5.0391,  -6.0664],
         ...,
         [ -4.9570,  -3.5703,   2.6562,  ...,  -3.6973,  -4.2812,  -3.2168],
         [ -5.0469,  -3.7324,   2.7266,  ...,  -3.7227,  -4.3242,  -3.2539],
         [ -5.4375,  -4.2266,   3.0625,  ...,  -3.8574,  -4.4297,  -3.4004]],

        [[ -9.0156,   0.8486,   0.8081,  ...,  -3.0469,  -5.3750,  -2.3613],
         [ -6.2344,  -5.0000,   2.5352,  ...,  -3.9082,  -3.2910,  -3.4980],
         [ -9.8672, -15.2422,  -0.1523,  ...,  -5.4492,  -2.2441,  -7.6484],
         ...,
         [ -8.7969,  -9.9297,   8.6953,  ...,  -3.8184,  -1.7939,  -5.4961],
         [ -5.9805,  -4.8828,   1.8486,  ...,  -3.8418,  -4.6758,  -3.6641],
         [ -6.7070,  -6.2578,   2.8223,  ...,  -4.6211,  -5.5117,  -4.1016]]],
       device='cuda:0')
torch.Size([2, 110, 1]) tensor([[[29918],
         [29899],
         [29892],
         [29874],
         [29892],
         [29874],
         [29892],
         [29874],
         [  370],
         [29924],
         [29871],
         [   13],
         [29871],
         [29892],
         [  376],
         [29899],
         [29871],
         [29899],
         [29899],
         [29892],
         [29871],
         [29899],
         [29874],
         [29871],
         [29871],
         [  376],
         [29892],
         [29871],
         [29899],
         [29871],
         [29874],
         [29879],
         [29892],
         [29871],
         [29906],
         [29874],
         [29892],
         [29874],
         [29892],
         [29941],
         [29906],
         [29874],
         [  313],
         [29896],
         [29906],
         [  300],
         [29871],
         [29874],
         [  313],
         [29871],
         [29874],
         [29874],
         [29892],
         [29874],
         [29892],
         [  376],
         [14131],
         [  313],
         [  370],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871]],

        [[29918],
         [29892],
         [29874],
         [10266],
         [29871],
         [29871],
         [29889],
         [29871],
         [29892],
         [29874],
         [29874],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [29892],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29892],
         [29933],
         [29874],
         [  856],
         [29933],
         [29933],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29871],
         [29933],
         [29933],
         [29874],
         [29874],
         [29874],
         [  498],
         [29874],
         [29874],
         [29924],
         [29874],
         [29924],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29903],
         [30488],
         [30488],
         [30488],
         [  392],
         [29874],
         [30488],
         [29874],
         [29874],
         [29874],
         [  498],
         [  519],
         [  262],
         [29874],
         [29924],
         [29874],
         [29924],
         [ 9136],
         [29874],
         [29892],
         [29871],
         [29874],
         [29874],
         [29924],
         [29874],
         [29874],
         [    2],
         [29875],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  498],
         [29874],
         [  519],
         [  262],
         [29874],
         [29924],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29883],
         [29874],
         [29874],
         [29903],
         [29933],
         [29874],
         [    2],
         [29889],
         [29871]]], device='cuda:0')
torch.Size([2, 110, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29899, 29892, 29871,  ...,   856,   313, 31147],
         [29892, 29933, 29908,  ..., 29911, 29874, 29903],
         ...,
         [29871, 29889, 29892,  ...,   349, 29874,   315],
         [29871, 29889, 29892,  ..., 29874,   349, 29915],
         [29871, 29892, 29899,  ..., 29874, 29915,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29898,  ...,   262, 29915,   856],
         [29874,   392, 29950,  ..., 29924,   300, 29871],
         ...,
         [    2, 29903, 29933,  ..., 29956,   481,   262],
         [29889, 29899, 29874,  ..., 29875, 29915, 29898],
         [29871,    13, 29899,  ...,   856,   315, 29875]]], device='cuda:0')
Batch 4, 3.9% of total tokens
encoded shape: torch.Size([2, 973])
torch.Size([2, 973]) tensor([[    1,   313,  2220,  ...,     2,     2,     2],
        [    1,   849, 10937,  ...,    13,  3400,    13]], device='cuda:0')
torch.Size([2, 973, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -7.3086,  -6.2109,   4.5938,  ...,  -4.7070,  -4.8750,  -4.0977],
         [ -6.2148,  -4.8047,   3.3672,  ...,  -4.1680,  -4.0820,  -3.6523],
         ...,
         [ -6.2148,  -4.6328,   2.7305,  ...,  -4.3242,  -4.6172,  -3.7891],
         [ -6.2695,  -4.6914,   2.7598,  ...,  -4.3516,  -4.6367,  -3.8184],
         [ -6.3320,  -4.7578,   2.7949,  ...,  -4.3828,  -4.6523,  -3.8477]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.6055,  -3.9805,   3.0234,  ...,  -3.8086,  -4.3789,  -3.0312],
         [ -8.2109,  -8.0547,   2.8223,  ...,  -3.9121,  -4.4688,  -4.4023],
         ...,
         [ -8.7422, -14.1797,  -1.2090,  ...,  -5.6328,  -2.8965,  -6.1719],
         [-11.0312, -12.2734,   2.3262,  ...,  -5.6875,  -5.9336,  -6.1211],
         [ -7.3672,  -6.9688,   2.8574,  ...,  -4.5859,  -5.4883,  -4.3398]]],
       device='cuda:0')
torch.Size([2, 973, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29874],
         [29871]]], device='cuda:0')
torch.Size([2, 973, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   315, 29915,   349],
         [29874, 29899, 29898,  ..., 29871, 29896, 29889],
         ...,
         [29871, 29892,   313,  ...,   349,   315, 29915],
         [29871, 29892,   313,  ...,   349,   315, 29915],
         [29871, 29892,   313,  ...,   349,   315, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29874, 29899, 29871,  ..., 29882,   313, 29898],
         ...,
         [29874, 29875,   376,  ...,  3400,   747,   300],
         [29874, 29933, 29899,  ..., 29943,   262, 29903],
         [29871, 29899, 29892,  ...,   856,   349,   315]]], device='cuda:0')
Batch 5, 5.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  7762,    13,  ...,   565,  5384, 29898],
        [    1,  3577,   419,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.9492,  -3.4141,   2.8105,  ...,  -3.5234,  -4.2227,  -3.1270],
         [ -8.4219,   0.7622,   7.4570,  ...,  -2.6797,  -4.8125,  -0.6802],
         ...,
         [-11.1641, -13.0781,   1.7559,  ...,  -5.0820,  -5.8242,  -6.1562],
         [ -9.7578, -15.0156,  -1.7295,  ...,  -7.0312,  -3.4355,  -8.1953],
         [-10.2500, -15.3594,  -0.9663,  ...,  -7.1758,  -3.8770,  -7.9688]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.2266,  -4.9922,   2.5352,  ...,  -3.9062,  -3.2910,  -3.4961],
         [ -9.8672, -15.2578,  -0.1614,  ...,  -5.4609,  -2.2578,  -7.6562],
         ...,
         [ -7.3164,   1.9639,  -1.6631,  ...,  -2.6523,  -4.6602,  -2.3359],
         [ -7.3633,   1.9219,  -1.6299,  ...,  -2.6797,  -4.6953,  -2.3613],
         [ -7.3281,   1.9805,  -1.6201,  ...,  -2.6504,  -4.6719,  -2.3301]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [29874],
         [  313],
         [29892]],

        [[29918],
         [29892],
         [29874],
         ...,
         [29915],
         [29915],
         [29915]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   315, 29882],
         [   13,   313, 29871,  ...,   306,  1346,   373],
         ...,
         [29874,   262, 29888,  ..., 29875, 29909,   294],
         [  313, 29892, 29874,  ..., 29875, 29915, 30010],
         [29892,   445,   313,  ..., 29871,   376, 29875]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29898,  ...,   262, 29915,   856],
         [29874,   392, 29950,  ..., 29924,   300, 29871],
         ...,
         [29915, 30010, 29918,  ...,   363,   229,   376],
         [29915, 30010, 29918,  ...,   363, 29892,   376],
         [29915, 30010, 29918,  ...,   363,   229,   376]]], device='cuda:0')
Batch 6, 9.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  7762,    13,  ...,     2,     2,     2],
        [    1,   396, 14187,  ..., 29277, 29901,   263]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.9492,  -3.4141,   2.8105,  ...,  -3.5234,  -4.2227,  -3.1270],
         [ -8.4219,   0.7622,   7.4570,  ...,  -2.6797,  -4.8125,  -0.6802],
         ...,
         [ -7.2031,   2.1172,  -1.8086,  ...,  -2.5391,  -4.5469,  -2.2266],
         [ -7.2266,   2.1426,  -1.7432,  ...,  -2.5332,  -4.5586,  -2.2051],
         [ -7.2188,   2.1035,  -1.8096,  ...,  -2.5469,  -4.5586,  -2.2344]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.7344,  -4.8047,   3.3887,  ...,  -4.3633,  -4.1172,  -3.7773],
         [ -7.6641,  -7.2500,   3.8066,  ...,  -4.5352,  -4.7344,  -4.1133],
         ...,
         [ -9.9688, -12.6016,   3.4219,  ...,  -6.7656,  -3.9141,  -6.6445],
         [ -7.7656,  -7.8555,   0.7573,  ...,  -5.5039,  -2.8066,  -4.6289],
         [ -6.8672,  -5.5391,   1.4189,  ...,  -4.4844,  -2.8281,  -3.3613]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [29915],
         [29915],
         [29915]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29874],
         [29874],
         [29909]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   315, 29882],
         [   13,   313, 29871,  ...,   306,  1346,   373],
         ...,
         [29915, 30010,   313,  ...,   376,   363,   891],
         [29915, 30010,   313,  ...,   363,   376,   891],
         [29915, 30010,   313,  ...,   376,   363,   891]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ...,   349, 29896, 29915],
         [29871, 29899, 29874,  ..., 29915, 29875,   262],
         ...,
         [29874, 29899, 29871,  ..., 29901, 29875, 29906],
         [29874,   263, 29909,  ..., 29876,   313,   273],
         [29909,   392, 29874,  ...,   262, 29950, 29881]]], device='cuda:0')
Batch 7, 14.1% of total tokens
encoded shape: torch.Size([2, 184])
torch.Size([2, 184]) tensor([[    1, 29871,   233,   191,   194,    13,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2],
        [    1,  4949,  9166,  9166,  9166,  9166,  4936,  2751, 29922,    13,
          1678, 14187,  1266,   313, 29883, 29897, 29871, 29906, 29900, 29900,
         29896, 29899, 29906, 29900, 29896, 29896,  3650,   295,   316,  2088,
         29920,  1171,    13,    13,  1678,  6652,  7541,  1090,   278,  1952,
           520, 18540, 19245, 29892, 10079, 29871, 29896, 29889, 29900, 29889,
           313, 13393, 10259,  1384,   292,    13,  1678,   934,   365,  2965,
          1430,  1660, 29918, 29896, 29918, 29900, 29889,  3945,   470,  3509,
           472,  1732,   597,  1636, 29889, 17079, 29889,   990, 29914, 27888,
          1430,  1660, 29918, 29896, 29918, 29900, 29889,  3945, 29897,    13,
          9166,  9166,  9166,  9166,  4936,  2751,  1360,  3877,    13, 29937,
           361,  1738, 12119, 29898,  8456,  3718, 29918, 29943,  3308,  2725,
         29918, 29903,  4897, 15082, 29918, 24898,  1367, 29918, 29906, 29900,
         29900, 29955, 29900, 29955, 29900, 29953, 29918, 29906, 29896, 29906,
         29945, 29897,    13, 29937,  7922, 16437,  3718, 29918, 29943,  3308,
          2725, 29918, 29903,  4897, 15082, 29918, 24898,  1367, 29918, 29906,
         29900, 29900, 29955, 29900, 29955, 29900, 29953, 29918, 29906, 29896,
         29906, 29945,    13,    13, 22377, 14505,   426,  7397, 21736,    13,
         29912,    13,  1678,  2281,  1780, 29918, 15739,    13,   930,    13,
            13, 29937, 15224,    13]], device='cuda:0')
torch.Size([2, 184, 32000]) tensor([[[-9.0156,  0.8467,  0.8081,  ..., -3.0449, -5.3750, -2.3574],
         [-5.7188, -4.3672,  3.1602,  ..., -3.7773, -4.3516, -3.3789],
         [-5.5430, -4.0898,  2.4219,  ..., -3.8340, -4.2188, -3.2266],
         ...,
         [-6.3125, -5.3320,  3.4258,  ..., -4.2109, -4.6758, -3.9062],
         [-6.2891, -5.2695,  3.4141,  ..., -4.2031, -4.6602, -3.8945],
         [-6.3164, -5.1875,  3.4434,  ..., -4.2266, -4.6406, -3.9043]],

        [[-9.0156,  0.8467,  0.8081,  ..., -3.0449, -5.3750, -2.3574],
         [-4.4336, -2.8086,  2.1680,  ..., -3.4434, -4.0586, -2.8242],
         [-6.2578, -5.1289,  3.4395,  ..., -4.0820, -4.4102, -3.6309],
         ...,
         [-5.4023, -4.0234,  3.1953,  ..., -3.7539, -4.4531, -3.4668],
         [-5.3164, -4.1758,  2.0137,  ..., -3.6367, -4.3984, -3.1934],
         [-6.5508, -6.2031,  2.5352,  ..., -4.3086, -5.2852, -3.7207]]],
       device='cuda:0')
torch.Size([2, 184, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29871],
         [29871],
         [  313],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871]],

        [[29918],
         [30488],
         [29871],
         [29874],
         [29871],
         [29871],
         [29899],
         [29874],
         [29871],
         [   13],
         [29899],
         [29871],
         [30488],
         [29871],
         [29874],
         [29889],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [30488],
         [29889],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [30488],
         [29931],
         [29874],
         [  262],
         [29924],
         [29871],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [29909],
         [29874],
         [29871],
         [29933],
         [29892],
         [29924],
         [29931],
         [  376],
         [  376],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29933],
         [29924],
         [29909],
         [29874],
         [29924],
         [29889],
         [29871],
         [29924],
         [29924],
         [29874],
         [29874],
         [  376],
         [29874],
         [29874],
         [29871],
         [29874],
         [29871],
         [29874],
         [29915],
         [29874],
         [29874],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [29933],
         [29874],
         [29933],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29871],
         [ 1457],
         [29874],
         [29892],
         [  680],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29871],
         [29933],
         [29933],
         [29874],
         [29874],
         [  383],
         [  375],
         [  376],
         [29874],
         [  317],
         [29871],
         [29874],
         [29874],
         [29892],
         [29874],
         [29899],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29871],
         [29896],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29933],
         [29874],
         [29933],
         [29875],
         [29874],
         [29871],
         [29871],
         [29871],
         [29933],
         [29909],
         [29874],
         [29892],
         [29874],
         [    2],
         [29871],
         [29871],
         [29871],
         [29892],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 184, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29892, 29889,  ..., 29874,   315,   349],
         ...,
         [29871, 29892,    13,  ...,   856, 29915,   349],
         [29871, 29892, 29899,  ...,   856, 29915,   349],
         [29871, 29892, 29899,  ...,   856, 29915,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [29871, 29899, 29874,  ..., 29915,   315, 29896],
         ...,
         [29892, 29889, 29871,  ..., 29933, 29874,   349],
         [29871, 29899, 29889,  ..., 29933,   262, 29915],
         [29871, 29899,    13,  ...,   856,   349,   315]]], device='cuda:0')
Batch 8, 14.2% of total tokens
encoded shape: torch.Size([2, 3081])
torch.Size([2, 3081]) tensor([[   1, 6319, 1961,  ...,    2,    2,    2],
        [   1,  849,  910,  ...,  323,  416,   13]], device='cuda:0')
torch.Size([2, 3081, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.6914,  -2.9648,   2.2539,  ...,  -3.3125,  -4.3047,  -3.0781],
         [ -7.5781,  -5.9297,   2.9141,  ...,  -4.7539,  -3.4824,  -4.1992],
         ...,
         [ -7.2500,   2.0449,  -1.7344,  ...,  -2.5449,  -4.5625,  -2.2793],
         [ -7.3281,   2.0156,  -1.6309,  ...,  -2.5664,  -4.6133,  -2.2910],
         [ -7.3281,   2.0117,  -1.6299,  ...,  -2.5703,  -4.6133,  -2.2930]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.6055,  -3.9805,   3.0234,  ...,  -3.8086,  -4.3789,  -3.0312],
         [ -7.2266,  -6.5117,   3.9336,  ...,  -3.7012,  -3.5488,  -4.2383],
         ...,
         [-10.6094, -18.0625,  -0.5547,  ...,  -7.4922,  -2.7266,  -8.8438],
         [-11.7031, -18.2031,  -0.1600,  ...,  -9.1719,  -3.8535,  -8.5156],
         [ -7.4727, -13.3516,   1.0371,  ...,  -7.2695,  -2.4473,  -4.9219]]],
       device='cuda:0')
torch.Size([2, 3081, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29915],
         [29915],
         [29915]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29899],
         [29874],
         [29892]]], device='cuda:0')
torch.Size([2, 3081, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29874, 29924, 29875,  ..., 29903, 29907, 29893],
         ...,
         [29915, 30010, 29918,  ..., 29973, 29892,   363],
         [29915, 30010, 29918,  ..., 29973, 29892,   363],
         [29915, 30010, 29918,  ..., 29973, 29892,   363]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29874, 29875, 29915,  ..., 29933,   262, 29895],
         ...,
         [29899, 29874, 29896,  ..., 29924, 29871, 29902],
         [29874, 29899, 29875,  ..., 29902, 29909, 29896],
         [29892,    13, 29899,  ...,  4326,   281,   379]]], device='cuda:0')
Batch 9, 17.5% of total tokens
encoded shape: torch.Size([2, 290])
torch.Size([2, 290]) tensor([[    1,   396,  2856,   376, 29920,  5461, 29889, 29882, 29908,    13,
         29937,  2856,   529,   755, 29889, 29882, 29958,    13, 29937,  2856,
           529,  4172,  1982, 29889, 29882, 29958,    13, 29937,  2856,   529,
         29875,  2480,   666, 29889, 29882, 29958,    13,    13,  5405,  1667,
           580,   426,    13,  1678,  1373,   298, 29961, 29906, 29945, 29953,
         29962,   353,   376, 10994,  1769,    13,  1678,  1373, 29930,   330,
           353,   376, 18420, 26966,  1769,    13,  1678,   288, 29920,  5461,
           714,   703,  7382, 29889, 18828,  1496,    13,  1678,   714,   529,
           376,  4013,  1736,  1532, 29908,   529,   298,   529,   330, 29936,
            13,  1678,   714, 29889,  5358,   890,    13,    13,  1678,  5951,
          5461,   297,   703,  7382, 29889, 18828,  1496,   849,  1303,   372,
          1250,    13,  1678,  1373,   334, 29916,   353,  1303, 29918,  1807,
         29898,   262,   511,   334, 29891,   353,   716,  1373, 29961, 29906,
         29945, 29953,  1402,   503, 29961, 29906, 29945, 29953,  1385,    13,
          1678,   297,  1405,   343,  1405,   503, 29936,    13,  1678,   297,
         29889,  5358,   890,    13,  1678, 11196,  3532,   921,  3532, 18659,
          3532,   343,  3532, 18659,  3532,   503,  3532, 18659, 29936,    13,
            13,  1678,   714, 29889,  3150,   703,  7382, 29889, 18828,  1496,
           849,  1018,   408, 18869,  1962, 29936,   503,  4117,  5694, 29889,
         18828,   304,  1074,   278,  2582,    13,  1678,   714,  3532,   731,
         29893, 29898, 29945, 29900, 29897,  3532,   731,  5589, 14237,  1495,
          3532,   731, 17990,  2459, 29898, 29906, 29900, 29897,  3532,   921,
          3532, 18659,  3532,   343,  3532, 18659,  3532,   503,  3532, 18659,
         29936,    13,  1678,   714,  3532,   503,  3532, 18659,  3532,   343,
          3532, 18659,  3532,   921,  3532, 18659, 29936,    13,  1678,   714,
          3532, 29871, 29896, 29889, 29896, 29906, 29941, 29946, 29945, 29953,
         29955, 29947, 29929, 29900, 29896, 29906, 29941, 29946, 29945, 29953,
         29955, 29947, 29929,  3532, 18659, 29936,    13,    13,  1678,  5217,
          2636,   921, 29936,  5217,  2636,   343, 29936,    13, 29913,    13],
        [    1, 29871,    13,   458, 29912,  1271,  1024,   543, 27852, 29914,
           546, 13390, 29914,  1493, 29914,  3396, 29914,  9910, 29918,  3827,
         29918, 20673, 29908,  9773, 29913,    13,  5647, 29889,  7922,   877,
          2713,   459,  2519, 29889, 13371, 29889,  5894, 13390, 29889,  1493,
         29889,  3396, 29889, 29954,  6758,   653,   742,   426,    13,  1678,
          5712, 29901,   525,  2713,   459,  2519, 29889, 13371, 29889,  5894,
         13390, 29889,  1493, 29889,  3396, 29889, 15329,  3089, 26249,   742,
            13,    13,  1678,  2069,  5308, 29901,   740,   580,   426,    13,
          4706,   445, 29889,  1202, 14470,  4297, 29898,    13,  9651,   426,
            13, 18884,  2847,  1626, 29901,   525, 29954,  6758,   653, 24295,
           742,    13, 18884,  6728,  1626, 29901,   525, 29961, 29900, 29962,
           310,   518, 29896, 29962,  3144,  2209,   653, 24295,   742,    13,
         18884,  2009,  5983, 29901, 22372,  2271,  4701, 29922,  3820,  2209,
           653,  3158, 29922, 17158,  2008, 29877,  5983, 10162,    13,  9651,
          2981,    13,  9651,   525,  3820,  2209,   653,   742,    13,  9651,
           525,   344, 29877, 29915,    13,  4706,  3482,    13,    13,  4706,
           445, 29889,  4804,  9780, 29898, 25699,   416,    13,  1678,   500,
            13,  3680,    13,   458, 29912, 29914,  1271, 29913,    13,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 290, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -6.7461,  -4.8164,   3.3945,  ...,  -4.3672,  -4.1172,  -3.7832],
         [ -5.5703,  -3.1465,   3.5059,  ...,  -3.6738,  -3.3340,  -3.0117],
         ...,
         [ -6.6602,  -7.6055,   3.5391,  ...,  -4.4727,  -0.3696,  -3.7930],
         [ -8.3359,  -7.6641,   2.3965,  ...,  -5.7188,  -5.1914,  -4.8555],
         [-10.0547, -11.2656,   3.7871,  ...,  -7.3125,  -6.8086,  -5.5586]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7754,  -4.3477,  -3.3770],
         [ -5.5117,   3.1660,   6.0781,  ...,  -0.4026,  -1.1689,   0.2034],
         ...,
         [ -4.2188,  -2.6328,   1.8643,  ...,  -3.4453,  -4.0742,  -2.8789],
         [ -4.1719,  -2.5527,   1.8184,  ...,  -3.4258,  -4.0508,  -2.8555],
         [ -4.1211,  -2.4863,   1.7773,  ...,  -3.4082,  -4.0312,  -2.8320]]],
       device='cuda:0')
torch.Size([2, 290, 1]) tensor([[[29918],
         [29871],
         [29933],
         [29892],
         [29871],
         [29899],
         [   13],
         [29889],
         [29874],
         [29871],
         [29892],
         [29933],
         [29892],
         [  262],
         [29908],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [30488],
         [29889],
         [29908],
         [29924],
         [29874],
         [29937],
         [29924],
         [29966],
         [14131],
         [29871],
         [29933],
         [29874],
         [29915],
         [29871],
         [29874],
         [29937],
         [29892],
         [29930],
         [  313],
         [29933],
         [29871],
         [29899],
         [29924],
         [  262],
         [29896],
         [29871],
         [29945],
         [29953],
         [29900],
         [29874],
         [  262],
         [29892],
         [29874],
         [29874],
         [29875],
         [29874],
         [29930],
         [  262],
         [29896],
         [29874],
         [29892],
         [11147],
         [29872],
         [29909],
         [29875],
         [29874],
         [29874],
         [29879],
         [29966],
         [29896],
         [29892],
         [29896],
         [29892],
         [29924],
         [29874],
         [29899],
         [29892],
         [29874],
         [29871],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29966],
         [29899],
         [  386],
         [29874],
         [29875],
         [29892],
         [29874],
         [29892],
         [29874],
         [29874],
         [29875],
         [29892],
         [29899],
         [29871],
         [  297],
         [29896],
         [29892],
         [29889],
         [29892],
         [29874],
         [29874],
         [29892],
         [29874],
         [  262],
         [  297],
         [  856],
         [29889],
         [29930],
         [29892],
         [29896],
         [  313],
         [  313],
         [29892],
         [29898],
         [29892],
         [29874],
         [29930],
         [29892],
         [29896],
         [29874],
         [29899],
         [  262],
         [  313],
         [29945],
         [29953],
         [29930],
         [29930],
         [29896],
         [29871],
         [29945],
         [29953],
         [29924],
         [29874],
         [29875],
         [29874],
         [29874],
         [29899],
         [29874],
         [29899],
         [29896],
         [29909],
         [ 1678],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [ 1678],
         [29874],
         [ 3532],
         [29874],
         [29874],
         [  262],
         [29874],
         [29874],
         [ 3532],
         [  262],
         [ 3532],
         [29874],
         [ 3532],
         [29931],
         [29931],
         [29874],
         [29913],
         [29892],
         [29874],
         [29874],
         [29892],
         [29874],
         [ 7382],
         [29906],
         [29892],
         [29906],
         [ 2308],
         [  392],
         [ 8718],
         [29874],
         [29874],
         [29924],
         [29915],
         [29871],
         [29915],
         [29889],
         [29987],
         [29874],
         [29874],
         [29874],
         [ 2308],
         [29874],
         [29875],
         [29874],
         [ 1405],
         [29896],
         [29892],
         [29898],
         [29871],
         [29896],
         [29874],
         [29931],
         [29896],
         [  376],
         [29898],
         [29874],
         [ 3532],
         [29896],
         [  376],
         [29924],
         [29898],
         [29871],
         [29896],
         [29896],
         [ 3532],
         [29896],
         [ 3532],
         [29931],
         [ 3532],
         [29909],
         [ 3532],
         [29931],
         [ 3532],
         [29874],
         [ 3532],
         [29931],
         [  386],
         [29874],
         [29875],
         [29874],
         [29874],
         [29874],
         [29879],
         [29896],
         [ 3532],
         [29874],
         [ 3532],
         [  392],
         [ 3532],
         [  262],
         [ 3532],
         [  392],
         [ 3532],
         [29909],
         [29913],
         [29874],
         [ 3532],
         [29874],
         [29896],
         [29906],
         [29896],
         [29906],
         [29941],
         [29946],
         [29945],
         [29953],
         [29955],
         [29947],
         [29929],
         [29900],
         [29896],
         [29906],
         [29941],
         [29946],
         [29945],
         [29953],
         [29955],
         [29947],
         [29929],
         [29900],
         [29896],
         [ 3532],
         [ 2308],
         [ 1678],
         [29892],
         [29874],
         [29899],
         [29874],
         [29892],
         [  392],
         [29874],
         [29874],
         [29874],
         [ 4926],
         [29913],
         [29874],
         [29871]],

        [[29918],
         [29871],
         [   13],
         [30488],
         [30488],
         [30488],
         [30488],
         [29892],
         [  856],
         [29892],
         [29874],
         [29874],
         [29892],
         [29874],
         [29892],
         [29924],
         [29892],
         [29899],
         [29909],
         [29874],
         [29892],
         [29896],
         [29933],
         [29874],
         [29892],
         [29871],
         [29889],
         [29892],
         [29874],
         [29892],
         [29871],
         [29871],
         [29889],
         [29892],
         [29874],
         [29892],
         [29871],
         [29874],
         [29892],
         [29874],
         [29892],
         [29871],
         [29892],
         [29874],
         [29874],
         [14131],
         [29889],
         [29871],
         [29892],
         [29871],
         [  856],
         [29892],
         [29892],
         [29871],
         [29871],
         [29889],
         [29892],
         [29874],
         [29892],
         [29874],
         [29874],
         [29892],
         [29874],
         [29892],
         [29874],
         [29892],
         [  370],
         [26249],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29892],
         [29874],
         [29871],
         [29892],
         [29871],
         [ 4297],
         [  271],
         [29892],
         [29875],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29915],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29903],
         [29874],
         [29896],
         [29874],
         [29874],
         [  402],
         [29871],
         [29900],
         [29874],
         [29874],
         [29896],
         [29900],
         [29874],
         [29874],
         [ 2722],
         [  667],
         [29903],
         [29874],
         [29903],
         [29915],
         [  272],
         [29896],
         [29915],
         [29871],
         [29871],
         [29874],
         [29892],
         [29871],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29875],
         [29874],
         [29892],
         [29874],
         [29896],
         [29875],
         [29915],
         [29892],
         [29874],
         [  653],
         [29899],
         [29915],
         [29875],
         [29915],
         [29892],
         [29874],
         [ 2271],
         [29874],
         [29875],
         [29874],
         [29874],
         [29874],
         [29875],
         [29874],
         [29871],
         [29892],
         [29899],
         [29874],
         [29892],
         [29874],
         [29874],
         [29924],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 290, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ..., 29896,   349, 29915],
         [29933, 29903, 29924,  ..., 29874,   262,   392],
         ...,
         [29913, 30057,  2112,  ...,  2482,   262,   974],
         [29874, 29933, 29899,  ..., 29875, 29889, 29924],
         [29871, 29899, 29892,  ..., 29874, 29896,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [   13, 29871,   313,  ..., 30010,    12,   891],
         ...,
         [30488, 30879, 29889,  ...,   313,   856, 29899],
         [30488, 30879, 31147,  ...,   313,   856, 29899],
         [30488, 30879, 31147,  ...,   313,   856, 29899]]], device='cuda:0')
Batch 10, 17.9% of total tokens
encoded shape: torch.Size([2, 936])
torch.Size([2, 936]) tensor([[    1,  6319,  3134,  ...,  3225, 29958,    13],
        [    1, 29871,   669,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 936, 32000]) tensor([[[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.6875,  -2.9609,   2.2520,  ...,  -3.3125,  -4.3047,  -3.0781],
         [ -4.6758,  -3.3750,   2.1719,  ...,  -3.4277,  -3.8867,  -3.0625],
         ...,
         [ -8.2891,  -8.5938,   2.1504,  ...,  -5.1172,  -5.1211,  -4.6250],
         [ -6.1562,  -5.4297,   2.3770,  ...,  -4.1484,  -4.4688,  -3.6211],
         [ -6.5625,  -5.8477,   2.5820,  ...,  -4.3281,  -4.9883,  -3.7520]],

        [[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -5.7266,  -4.3750,   3.1660,  ...,  -3.7793,  -4.3516,  -3.3809],
         [ -4.9023,  -3.4395,   2.1191,  ...,  -3.4238,  -4.2617,  -3.0781],
         ...,
         [ -7.9570, -10.8828,  -6.4570,  ...,  -5.9219,  -2.3223,  -6.6484],
         [ -8.0078, -10.9609,  -6.3867,  ...,  -5.8906,  -2.2305,  -6.6367],
         [ -8.0938, -11.1094,  -6.2617,  ...,  -5.9141,  -2.1816,  -6.6797]]],
       device='cuda:0')
torch.Size([2, 936, 1]) tensor([[[29918],
         [29871],
         [29899],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29879],
         [29879],
         [29879]]], device='cuda:0')
torch.Size([2, 936, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29899, 29874, 29889,  ..., 29875, 30488, 29915],
         ...,
         [29871, 29874, 29899,  ..., 29915,   262, 29896],
         [29871, 29899, 29892,  ..., 29875, 29882, 29915],
         [29871, 29899, 29892,  ..., 29915,   856,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29892, 29889,  ...,   349, 30488,    13],
         ...,
         [29879, 30010, 23333,  ..., 29892,   313, 12254],
         [29879, 30010, 23333,  ..., 30057,   313,   376],
         [29879, 30010, 29892,  ...,   313, 30057,   376]]], device='cuda:0')
Batch 11, 19.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  7762,    13,  ..., 20969,   278,  4663],
        [    1,   822,   679,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.9492,  -3.4141,   2.8105,  ...,  -3.5234,  -4.2227,  -3.1270],
         [ -8.4219,   0.7622,   7.4570,  ...,  -2.6797,  -4.8125,  -0.6802],
         ...,
         [ -9.0078, -10.7500,  -2.1504,  ...,  -4.3398,  -1.7354,  -5.3086],
         [ -8.5234,  -8.7188,   0.4758,  ...,  -3.4570,  -1.9746,  -4.2227],
         [ -7.9492,  -9.4297,  -2.3535,  ...,  -5.6953,  -2.2188,  -5.9062]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.9258,  -3.6387,   2.2793,  ...,  -3.3633,  -4.1133,  -2.9180],
         [ -7.9336, -15.4922,  -1.5859,  ...,  -6.5117,  -2.5762,  -6.7734],
         ...,
         [ -5.0898,   1.6357,  -3.9238,  ...,  -2.1914,  -3.5176,  -2.3613],
         [ -5.1250,   1.6377,  -3.9121,  ...,  -2.1934,  -3.5352,  -2.3633],
         [ -5.1875,   1.6914,  -3.8828,  ...,  -2.1836,  -3.5527,  -2.3535]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [29874],
         [29909],
         [29925]],

        [[29918],
         [29892],
         [29874],
         ...,
         [30140],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   315, 29882],
         [   13,   313, 29871,  ...,   306,  1346,   373],
         ...,
         [29874, 29915,   370,  ..., 29903, 29890, 29928],
         [29909, 29874, 29924,  ..., 29915, 29902, 29875],
         [29925, 29874, 29886,  ..., 29909,   376,  2933]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29871,  ...,   856,   315,   262],
         [29874, 29899, 29871,  ..., 29918,   262, 29909],
         ...,
         [30140, 30010, 29915,  ..., 29987,   392,   525],
         [30010, 30140, 29915,  ..., 29987,   392,   525],
         [30010, 29915, 30140,  ..., 29987,   392,   525]]], device='cuda:0')
Batch 12, 23.6% of total tokens
encoded shape: torch.Size([2, 3888])
torch.Size([2, 3888]) tensor([[    1, 29871, 30143,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 3888, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7734,  -4.3477,  -3.3750],
         [ -4.0234,  -2.2539,   1.7109,  ...,  -3.1738,  -3.9629,  -2.6895],
         ...,
         [ -4.9414,   1.6445,  -4.0312,  ...,  -2.2578,  -3.5547,  -2.3379],
         [ -4.9688,   1.6123,  -4.0312,  ...,  -2.2734,  -3.5723,  -2.3535],
         [ -4.9766,   1.6143,  -4.0273,  ...,  -2.2754,  -3.5742,  -2.3535]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.4453,  -2.8223,   2.1699,  ...,  -3.4512,  -4.0703,  -2.8320],
         [ -9.0234,   0.0874,   5.8203,  ...,  -3.7910,  -4.9961,  -1.0352],
         ...,
         [ -9.3047, -10.2344,   2.8906,  ...,  -5.2812,  -5.0625,  -7.0859],
         [ -7.7266,  -7.3867,   2.4258,  ...,  -4.8516,  -4.8789,  -4.6562],
         [-10.8516, -12.5156,   3.9258,  ...,  -6.9844,  -6.6172,  -6.2422]]],
       device='cuda:0')
torch.Size([2, 3888, 1]) tensor([[[29918],
         [29871],
         [30488],
         ...,
         [29915],
         [29915],
         [29915]],

        [[29918],
         [30488],
         [  313],
         ...,
         [29871],
         [29874],
         [29871]]], device='cuda:0')
torch.Size([2, 3888, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [30488, 31147, 30879,  ...,   313, 29899,   856],
         ...,
         [29915, 30010, 30140,  ...,   229,   392, 29987],
         [29915, 30010, 30140,  ...,   229,   392, 29987],
         [29915, 30010, 30140,  ...,   229,   392, 29987]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ..., 30879,   856, 30282],
         [  313,    13,   306,  ...,   891,   376,  1346],
         ...,
         [29871, 29896, 29875,  ...,   392, 29902,   355],
         [29874, 29899, 29889,  ..., 29909, 29950, 29903],
         [29871, 29899, 29892,  ..., 29915,   315, 29896]]], device='cuda:0')
Batch 13, 27.8% of total tokens
encoded shape: torch.Size([2, 984])
torch.Size([2, 984]) tensor([[    1,  4949,   910,  ...,     2,     2,     2],
        [    1,   396,   315,  ..., 29901,    13,    13]], device='cuda:0')
torch.Size([2, 984, 32000]) tensor([[[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [ -4.4336,  -2.8066,   2.1680,  ...,  -3.4434,  -4.0586,  -2.8242],
         [ -6.2891,  -5.0234,   3.3047,  ...,  -3.3516,  -3.6035,  -3.6191],
         ...,
         [ -7.3281,  -9.6719,  -7.1992,  ...,  -4.7656,  -1.8135,  -5.5664],
         [ -7.3594,  -9.7578,  -7.1875,  ...,  -4.8125,  -1.8311,  -5.6172],
         [ -7.3711,  -9.8203,  -7.1797,  ...,  -4.8438,  -1.8301,  -5.6484]],

        [[ -8.9844,   0.8760,   0.7637,  ...,  -3.0312,  -5.3516,  -2.3477],
         [ -6.7461,  -4.8125,   3.3984,  ...,  -4.3672,  -4.1133,  -3.7812],
         [-10.0859, -15.4453,   0.4270,  ...,  -7.9922,  -3.7344,  -8.4062],
         ...,
         [ -7.1562,  -7.1250,   2.2344,  ...,  -4.3398,  -4.5195,  -4.0781],
         [ -5.2578,  -4.1133,   2.0059,  ...,  -3.8730,  -4.5508,  -3.3438],
         [ -4.9453,  -3.6934,   2.0195,  ...,  -3.7383,  -4.2812,  -3.2207]]],
       device='cuda:0')
torch.Size([2, 984, 1]) tensor([[[29918],
         [30488],
         [29874],
         ...,
         [23333],
         [23333],
         [23333]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29874],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 984, 10]) tensor([[[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [29874, 29882, 29875,  ..., 29871,   262, 29888],
         ...,
         [23333, 14131, 30057,  ..., 30119,  1131,  2650],
         [23333, 14131, 30057,  ..., 30119,  1131,   785],
         [23333, 14131, 30057,  ..., 30119,  1131,   785]],

        [[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29892,   313,  ...,   349, 29896, 29915],
         [29871, 29899, 29892,  ..., 29896,   349, 29873],
         ...,
         [29874, 29892, 29871,  ..., 29899,   313, 29875],
         [29871, 29892, 29889,  ...,   315,   349, 29915],
         [29871, 29892, 29889,  ...,   315,   349, 29915]]], device='cuda:0')
Batch 14, 29.0% of total tokens
encoded shape: torch.Size([2, 550])
torch.Size([2, 550]) tensor([[    1,  7762,    13,  ...,    13, 29913,    13],
        [    1,   330,  7283,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 550, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -4.9414,  -3.4023,   2.8066,  ...,  -3.5195,  -4.2188,  -3.1211],
         [ -8.4844,   0.6880,   7.4961,  ...,  -2.7266,  -4.8672,  -0.7285],
         ...,
         [-10.6875, -14.2969,   0.9238,  ...,  -7.5156,  -5.9219,  -7.4648],
         [ -5.4961,  -4.5469,   1.6924,  ...,  -3.9180,  -4.4219,  -3.3789],
         [ -6.3398,  -5.8867,   2.6211,  ...,  -4.4766,  -5.2383,  -3.8672]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -6.2305,  -5.2812,   3.3184,  ...,  -4.0156,  -4.4531,  -3.8027],
         [ -7.0781,  -6.3047,   3.1641,  ...,  -4.0469,  -4.3789,  -4.0352],
         ...,
         [ -6.3203,   0.3298,  -3.3457,  ...,  -2.7402,  -3.1777,  -2.9473],
         [ -6.6758,   0.3660,  -3.5684,  ...,  -2.7402,  -3.1855,  -2.9668],
         [ -6.8086,   0.4629,  -3.6523,  ...,  -2.7148,  -3.1777,  -2.9375]]],
       device='cuda:0')
torch.Size([2, 550, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [29875],
         [29889],
         [29871]],

        [[29918],
         [29871],
         [29871],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 550, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   315, 29882],
         [   13,   313, 29871,  ...,   306,  1346,   373],
         ...,
         [29875, 29874,   262,  ..., 29896,   326, 29923],
         [29889, 29871, 29892,  ..., 29898, 29933,   313],
         [29871,    13, 29899,  ..., 29874,   315,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ..., 29896, 29915,   315],
         [29871, 29899,   313,  ...,   315,   376,   856],
         ...,
         [30010, 29915, 30057,  ...,   341,   349, 29892],
         [30010, 30057, 29915,  ...,   341,   392, 29892],
         [30010, 30057, 29915,  ...,   306,   229,   392]]], device='cuda:0')
Batch 15, 29.6% of total tokens
encoded shape: torch.Size([2, 624])
torch.Size([2, 624]) tensor([[    1,  4949,  3251,  ...,  1807, 29962,    13],
        [    1,   317, 15374,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 624, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.4453,  -2.8203,   2.1680,  ...,  -3.4492,  -4.0703,  -2.8320],
         [ -8.8438,  -7.9297,   3.8750,  ...,  -5.0820,  -5.2891,  -5.2734],
         ...,
         [ -9.5078, -15.6016,  -1.0518,  ...,  -6.1133,  -2.1094,  -6.1406],
         [-12.2188, -17.0781,  -0.4695,  ...,  -8.6406,  -5.7539,  -8.3672],
         [ -5.9922,  -5.0625,   2.2031,  ...,  -4.4180,  -4.6602,  -3.4746]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [-10.3438, -14.7188,   1.5459,  ...,  -7.5352,  -3.7930,  -8.4688],
         [ -9.1016, -14.7656,  -2.2910,  ...,  -6.6445,  -1.8232,  -7.0586],
         ...,
         [ -7.0273,  -7.5781,  -5.2422,  ...,  -5.2930,  -1.1201,  -5.6367],
         [ -7.0156,  -7.5586,  -5.2578,  ...,  -5.2695,  -1.1113,  -5.6172],
         [ -7.0039,  -7.5625,  -5.2891,  ...,  -5.2773,  -1.1514,  -5.6055]]],
       device='cuda:0')
torch.Size([2, 624, 1]) tensor([[[29918],
         [30488],
         [29874],
         ...,
         [29874],
         [29874],
         [29871]],

        [[29918],
         [29871],
         [29874],
         ...,
         [23333],
         [23333],
         [23333]]], device='cuda:0')
torch.Size([2, 624, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ..., 30879,   856, 30282],
         [29874, 29871,   315,  ...,   313,   349, 29899],
         ...,
         [29874, 29924, 29933,  ...,   294, 29899, 29931],
         [29874, 29933, 29875,  ..., 29924, 29902, 29925],
         [29871, 29892, 29899,  ..., 29896, 29874, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ..., 29915, 29889,   341],
         [29874, 29871, 29899,  ...,   392, 29882, 29915],
         ...,
         [23333, 14131, 12254,  ..., 30010,   538, 30119],
         [23333, 14131, 12254,  ..., 30010,   538, 30119],
         [23333, 14131, 12254,  ..., 30010,   538, 30119]]], device='cuda:0')
Batch 16, 30.4% of total tokens
encoded shape: torch.Size([2, 859])
torch.Size([2, 859]) tensor([[    1, 29871, 30143,  ...,     2,     2,     2],
        [    1,  6319,  3134,  ...,  4836,  3238,    13]], device='cuda:0')
torch.Size([2, 859, 32000]) tensor([[[-8.9531,  0.8716,  0.6504,  ..., -3.0312, -5.3398, -2.3652],
         [-5.7148, -4.3633,  3.1621,  ..., -3.7754, -4.3477, -3.3750],
         [-4.0234, -2.2520,  1.7109,  ..., -3.1758, -3.9629, -2.6895],
         ...,
         [-6.8086,  1.0010, -3.3633,  ..., -2.4648, -3.5078, -2.6660],
         [-6.8672,  1.0840, -3.2910,  ..., -2.4648, -3.5508, -2.6484],
         [-7.0312,  1.0996, -3.2012,  ..., -2.4707, -3.6035, -2.6387]],

        [[-8.9531,  0.8716,  0.6504,  ..., -3.0312, -5.3398, -2.3652],
         [-4.6914, -2.9707,  2.2520,  ..., -3.3164, -4.3086, -3.0820],
         [-4.6797, -3.3809,  2.1738,  ..., -3.4277, -3.8867, -3.0645],
         ...,
         [-5.5430, -4.7305,  1.6709,  ..., -4.0273, -4.1719, -3.4258],
         [-4.1875, -2.7148,  1.8340,  ..., -3.3340, -3.9688, -2.8945],
         [-6.3906, -6.3477,  2.4805,  ..., -4.2812, -4.7266, -3.7207]]],
       device='cuda:0')
torch.Size([2, 859, 1]) tensor([[[29918],
         [29871],
         [30488],
         ...,
         [30010],
         [30010],
         [30010]],

        [[29918],
         [29871],
         [29899],
         ...,
         [29874],
         [30488],
         [29899]]], device='cuda:0')
torch.Size([2, 859, 10]) tensor([[[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [30488, 31147, 30879,  ...,   313, 29899,   856],
         ...,
         [30010, 29915,   313,  ...,   376, 29879, 29987],
         [30010, 29915,   313,  ..., 29879,   376, 29987],
         [30010, 29915,   313,  ..., 29879, 29930, 29987]],

        [[29918, 29879,   313,  ..., 29973,   363, 29871],
         [29871, 29889, 29892,  ..., 30488, 29874,   349],
         [29899, 29874, 29889,  ..., 29875, 30488, 29915],
         ...,
         [29874, 29899, 29871,  ..., 29896, 29909, 29924],
         [30488, 30879, 31147,  ...,   856, 29899,   313],
         [29899, 29871, 29892,  ..., 29875,   313,   262]]], device='cuda:0')
Batch 17, 31.4% of total tokens
encoded shape: torch.Size([2, 2443])
torch.Size([2, 2443]) tensor([[    1,  6319,  1961,  ...,     2,     2,     2],
        [    1,  6319,  3134,  ...,  1420, 29958,    13]], device='cuda:0')
torch.Size([2, 2443, 32000]) tensor([[[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-4.6914, -2.9648,  2.2539,  ..., -3.3125, -4.3047, -3.0781],
         [-7.5781, -5.9297,  2.9141,  ..., -4.7539, -3.4824, -4.1992],
         ...,
         [-8.6406, -6.8984,  3.0430,  ..., -5.6406, -5.0742, -5.1250],
         [-8.5391, -6.7109,  2.9805,  ..., -5.5742, -5.0352, -5.0508],
         [-8.5000, -6.6484,  2.9551,  ..., -5.5469, -5.0273, -5.0273]],

        [[-9.0156,  0.8447,  0.8071,  ..., -3.0449, -5.3750, -2.3574],
         [-4.6914, -2.9648,  2.2539,  ..., -3.3125, -4.3047, -3.0781],
         [-4.6797, -3.3750,  2.1719,  ..., -3.4277, -3.8867, -3.0625],
         ...,
         [-6.0898, -5.7422,  1.9131,  ..., -4.2969, -4.2773, -3.8965],
         [-6.5508, -6.1133,  2.0605,  ..., -4.3086, -4.5156, -3.9766],
         [-5.7773, -5.0703,  2.0977,  ..., -4.1367, -4.6758, -3.4336]]],
       device='cuda:0')
torch.Size([2, 2443, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29892],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29899],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 2443, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29874, 29924, 29875,  ..., 29903, 29907, 29893],
         ...,
         [29892, 29871,   313,  ...,   315, 29889, 29896],
         [29892, 29871,   313,  ...,   315, 29889, 29896],
         [29892, 29871,   313,  ...,   315, 29889, 29896]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29899, 29874, 29889,  ..., 29875, 30488, 29915],
         ...,
         [29871, 29874, 29899,  ...,   856, 29892, 29889],
         [29871, 29899, 29874,  ..., 29896, 29882,    13],
         [29871, 29899, 29892,  ..., 29874,   349,   315]]], device='cuda:0')
Batch 18, 35.3% of total tokens
encoded shape: torch.Size([2, 536])
torch.Size([2, 536]) tensor([[    1,  9995,  3057,  ..., 14868,   580,    13],
        [    1,  4949,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 536, 32000]) tensor([[[ -9.0156,   0.8477,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -7.7422,  -6.0469,   3.4043,  ...,  -4.4531,  -4.1250,  -3.8066],
         [ -8.5547, -11.9688,   1.2764,  ...,  -3.1582,   0.6880,  -4.4688],
         ...,
         [ -8.7188,  -9.6172,   2.6504,  ...,  -4.8828,  -4.7773,  -5.5547],
         [-11.1328, -14.2031,   1.8652,  ...,  -6.4570,  -5.5586,  -7.7031],
         [ -8.5156, -14.3906,  -2.1211,  ...,  -8.3203,  -4.2109,  -8.1016]],

        [[ -9.0156,   0.8477,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.4336,  -2.8047,   2.1660,  ...,  -3.4414,  -4.0586,  -2.8242],
         [ -9.0078,   0.0883,   5.4453,  ...,  -3.8086,  -4.9453,  -1.0830],
         ...,
         [ -6.2617,  -4.5195,   2.9531,  ...,  -4.3555,  -4.5625,  -3.8008],
         [ -6.3906,  -4.6328,   3.0156,  ...,  -4.4102,  -4.5859,  -3.8535],
         [ -6.5703,  -4.7891,   3.1035,  ...,  -4.4883,  -4.6133,  -3.9297]]],
       device='cuda:0')
torch.Size([2, 536, 1]) tensor([[[29918],
         [29892],
         [  292],
         ...,
         [29874],
         [29874],
         [29871]],

        [[29918],
         [30488],
         [  313],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 536, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29899, 29874,  ...,   317, 29898,   262],
         [  292, 29874,   294,  ...,   267,   271, 29909],
         ...,
         [29874,   262, 29882,  ...,    13,   392,   265],
         [29874, 29882, 29871,  ..., 29933, 29899,   262],
         [29871,    13, 29892,  ..., 29889,   260, 29874]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [  313,   306,    13,  ...,   373,   376,  1346],
         ...,
         [29871, 29892,   313,  ...,   349, 29915,   315],
         [29871, 29892,   313,  ...,   349, 29915,   315],
         [29871, 29892,   313,  ...,   349, 29915,   315]]], device='cuda:0')
Batch 19, 36.1% of total tokens
encoded shape: torch.Size([2, 2784])
torch.Size([2, 2784]) tensor([[    1, 29871,    13,  ...,     2,     2,     2],
        [    1,  4949,  5534,  ...,    13,  3680,    13]], device='cuda:0')
torch.Size([2, 2784, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7734,  -4.3477,  -3.3750],
         [ -5.5742,   3.1094,   6.1836,  ...,  -0.4592,  -1.2529,   0.1636],
         ...,
         [ -6.1523,   2.0703,  -3.2773,  ...,  -2.3203,  -4.0273,  -2.3496],
         [ -6.1250,   2.0918,  -3.2891,  ...,  -2.3066,  -4.0039,  -2.3359],
         [ -6.1250,   2.0918,  -3.2852,  ...,  -2.3086,  -4.0039,  -2.3379]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.4453,  -2.8223,   2.1699,  ...,  -3.4512,  -4.0703,  -2.8320],
         [ -6.0469,  -4.5430,   2.2344,  ...,  -3.7344,  -4.2070,  -3.0840],
         ...,
         [ -9.7734, -11.2422,   2.0371,  ...,  -6.9492,  -4.1602,  -6.3281],
         [ -5.2227,  -3.9961,   1.6221,  ...,  -3.7051,  -4.2578,  -3.3535],
         [ -4.8945,  -3.7207,   1.9053,  ...,  -3.7207,  -4.4219,  -3.1797]]],
       device='cuda:0')
torch.Size([2, 2784, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [30010],
         [30010],
         [30010]],

        [[29918],
         [30488],
         [29874],
         ...,
         [ 3680],
         [29889],
         [29871]]], device='cuda:0')
torch.Size([2, 2784, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [   13, 29871,   313,  ..., 30010, 29915,    12],
         ...,
         [30010, 29915,   313,  ..., 30140,   376, 29987],
         [30010, 29915,   313,  ..., 29918,   376, 29987],
         [30010, 29915,   313,  ..., 29918,   376, 29987]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ..., 30879,   856, 30282],
         [29874, 29899, 29892,  ..., 29882,   262, 29915],
         ...,
         [ 3680,   856, 29933,  ...,  7690, 30057,   481],
         [29889, 29892, 29899,  ..., 29875, 29909, 29896],
         [29871, 29889, 29892,  ...,   315,   349, 29874]]], device='cuda:0')
Batch 20, 39.0% of total tokens
encoded shape: torch.Size([2, 554])
torch.Size([2, 554]) tensor([[    1, 29871,    13,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,   416,    13,  3680]], device='cuda:0')
torch.Size([2, 554, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7754,  -4.3477,  -3.3770],
         [ -5.5117,   3.1660,   6.0781,  ...,  -0.4026,  -1.1689,   0.2034],
         ...,
         [ -4.8477,  -3.2402,   2.2012,  ...,  -3.7461,  -4.2734,  -3.2012],
         [ -4.8164,  -3.2129,   2.1875,  ...,  -3.7285,  -4.2617,  -3.1875],
         [ -4.7852,  -3.1914,   2.1680,  ...,  -3.7148,  -4.2539,  -3.1777]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -4.4336,  -2.8086,   2.1680,  ...,  -3.4434,  -4.0625,  -2.8242],
         [ -9.0078,   0.0853,   5.4453,  ...,  -3.8125,  -4.9453,  -1.0869],
         ...,
         [-11.3047, -17.4688,   2.1934,  ...,  -8.6016,  -3.5410,  -8.8281],
         [-10.8203, -16.4219,  -1.0088,  ...,  -7.6016,  -4.5898,  -7.6016],
         [ -7.9023,  -7.5703,   3.1738,  ...,  -5.5078,  -5.2969,  -4.9727]]],
       device='cuda:0')
torch.Size([2, 554, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [29889],
         [29889],
         [29889]],

        [[29918],
         [30488],
         [  313],
         ...,
         [29874],
         [29874],
         [29874]]], device='cuda:0')
torch.Size([2, 554, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [   13, 29871,   313,  ..., 30010,    12,   891],
         ...,
         [29889, 29892, 29871,  ...,   349,   315, 30488],
         [29889, 29892, 29871,  ...,   349, 30488,   315],
         [29889, 29892, 29871,  ..., 30488,   349,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [  313,   306,    13,  ...,   891,   376,  1346],
         ...,
         [29874, 29909, 29928,  ..., 29924, 29950, 29896],
         [29874, 29875, 29903,  ..., 29933, 29924,   295],
         [29874, 29871, 29933,  ...,    13, 29924, 29928]]], device='cuda:0')
Batch 21, 39.9% of total tokens
encoded shape: torch.Size([2, 1985])
torch.Size([2, 1985]) tensor([[    1,   515,  5386,  ...,     2,     2,     2],
        [    1,   529, 21993,  ..., 21367, 29958,    13]], device='cuda:0')
torch.Size([2, 1985, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.2031,  -3.2617,   1.7168,  ...,  -3.5684,  -3.4727,  -2.9668],
         [ -7.2578,  -5.7148,   2.8418,  ...,  -4.1602,  -4.4336,  -4.3789],
         ...,
         [ -7.4805,  -0.1642,  -3.5195,  ...,  -2.5273,  -3.4746,  -2.6465],
         [ -7.4648,  -0.1307,  -3.5039,  ...,  -2.5176,  -3.4727,  -2.6348],
         [ -7.4844,  -0.1372,  -3.5020,  ...,  -2.5273,  -3.4824,  -2.6387]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.2148,  -3.7051,   2.7812,  ...,  -3.8164,  -4.2148,  -3.3145],
         [ -5.3438,  -4.2539,   1.9355,  ...,  -3.5684,  -4.3594,  -3.3945],
         ...,
         [-10.3125, -12.3438,   1.7686,  ...,  -6.5938,  -4.2148,  -6.2539],
         [ -7.3984,  -7.2695,   2.6016,  ...,  -4.6523,  -4.6641,  -4.5117],
         [ -6.5938,  -6.0664,   2.5957,  ...,  -4.2734,  -4.7812,  -3.8652]]],
       device='cuda:0')
torch.Size([2, 1985, 1]) tensor([[[29918],
         [29892],
         [29871],
         ...,
         [29915],
         [29915],
         [29915]],

        [[29918],
         [29871],
         [29899],
         ...,
         [29882],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 1985, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29874,   262,  ..., 29915, 29896, 29871],
         [29871, 29874, 29899,  ..., 29915, 29903,   315],
         ...,
         [29915, 30010, 30057,  ..., 30140,   353, 29987],
         [29915, 30010, 30057,  ..., 30140,   353, 29987],
         [29915, 30010, 30057,  ..., 30140,   353, 29987]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29889,  ..., 29915,   349,   315],
         [29899, 29871, 29892,  ..., 29896, 29915, 29901],
         ...,
         [29882, 29874, 29933,  ..., 29899, 29871, 29875],
         [29871, 29899, 29892,  ...,   856,    13,   313],
         [29871, 29899, 29892,  ...,   856,   315, 29915]]], device='cuda:0')
Batch 22, 42.3% of total tokens
encoded shape: torch.Size([2, 289])
torch.Size([2, 289]) tensor([[    1,  4949,  3251,   630,   491, 24875, 21537, 29889,    13,  3776,
            13,    13, 29992, 20464,   382, 29968,  2624,  6103,  1043, 11494,
           529,  3059,  2061, 29958,    13,    13, 29992, 12403,    13,    13,
         29899,   313,  5405, 29897,  3696,  6103,  6917,  5919, 29923, 29968,
          2624,  6103,  6917,  4748,  1191, 29896,  1258, 17813,  3047,  4276,
          5919,  5426,  1472, 29897,  1191, 29906, 29936,    13,    13, 29992,
         25253,    13,    13, 29899,   313, 29923, 29968, 17447,  4748,  3696,
          6103,  6917,  4592, 17447,  2831,  4373, 13634,  5919, 29923, 29968,
          2624,  6103,  6917,  4748,  1191, 29896, 29936,    13,    13, 29992,
           355,    13,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1, 13756, 29911,  1164, 29918,  5348, 29922, 29900, 29889, 29955,
            13,  8618, 29911,  1164, 29918,  9464, 29922, 29939,  5935, 29899,
           771,   880, 29899, 12330,  8618, 29911,  1164, 29918,  5348, 29897,
            13,  8618, 29911,  1164, 29918, 29911,  1718, 29933,  9818, 19758,
          8618, 29911,  1164, 29918,  9464,   467, 12637, 29889, 18828,    13,
          8618, 29911,  1164, 29918,  4219, 29922,  1124,   597,  1636, 29889,
         11038,   729,  5509, 29889,   990, 29914, 16315, 29914, 23102, 29889,
          4288, 29889,   990, 29914, 29939,  5935, 29914,   771,   880, 29914,
         12330,  8618, 29911,  1164, 29918,  5348,  6802, 12330,  8618, 29911,
          1164, 29918, 29911,  1718, 29933,  9818, 29897,    13,    13, 29889,
         19689,  1164, 29979, 29901,  1243,    13,    13,  1688, 29901,  2048,
         29914,  1982,    13,    12,   424,  1243,    13,    13,  4282, 29914,
          1982, 29901,  2427,  8618, 29911,  1164, 29918, 29911,  1718, 29933,
          9818, 29897,    13,    12, 11256,  3972,   448, 29886,  2048, 29914,
          7050,    13,    12, 12637,   921, 29894, 29920,   448, 29907,  2048,
         29914,  7050,   448, 29888,  2427,  8618, 29911,  1164, 29918, 29911,
          1718, 29933,  9818, 29897,    13,    12,  2252,  2048, 29914,  7050,
         29914, 12330,  8618, 29911,  1164, 29918,  9464,  6802,   771,   880,
         29899, 29926,  2607,   286, 18564,  3577,    13,    12, 11256,  3972,
           448, 29886,  2048, 29914,  1982,    13,    12,  6814,  2048, 29914,
          7050, 29914, 12330,  8618, 29911,  1164, 29918,  9464,  6802,   771,
           880, 29899, 29926, 29914,  5182, 29914,   771,   880, 29899, 29926,
         29899, 12330,  8618, 29911,  1164, 29918,  5348,   467,  4758,  2048,
         29914,  1982,    13,    12,  6814, 29772,  1982, 29899,  1645,  5515,
         29889,  4758,  2048, 29914,  1982,    13,    13, 14941, 29901,    13,
            12,  1758,   448,  9600,  2048,  2427,  8618, 29911,  1164, 29918,
         29911,  1718, 29933,  9818, 29897,    13,    13, 12330,  8618, 29911,
          1164, 29918, 29911,  1718, 29933,  9818,  1125,    13,    12, 29893,
           657,  2427,  8618, 29911,  1164, 29918,  4219, 29897,    13]],
       device='cuda:0')
torch.Size([2, 289, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -4.4336,  -2.8047,   2.1660,  ...,  -3.4414,  -4.0586,  -2.8223],
         [ -8.8438,  -7.9297,   3.8730,  ...,  -5.0820,  -5.2891,  -5.2734],
         ...,
         [ -9.1016, -11.6172,  -3.4180,  ...,  -6.8984,  -2.1934,  -7.0703],
         [ -9.0469, -11.5156,  -3.6406,  ...,  -6.8789,  -2.2168,  -7.0195],
         [ -8.9844, -11.3750,  -3.8633,  ...,  -6.8164,  -2.1934,  -6.9336]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -9.6328, -13.5859,  -0.4539,  ...,  -6.3438,  -4.6992,  -8.0781],
         [ -8.9766, -15.1484,  -2.2949,  ...,  -7.1523,  -3.8281,  -7.4102],
         ...,
         [-10.2109, -17.8125,  -0.3403,  ...,  -6.5000,  -2.5586,  -8.4844],
         [-10.0312, -16.2031,  -2.6191,  ...,  -6.8516,  -3.5000,  -8.1172],
         [-10.0625, -16.2656,  -2.3145,  ...,  -8.0547,  -5.4219,  -8.6016]]],
       device='cuda:0')
torch.Size([2, 289, 1]) tensor([[[29918],
         [30488],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [  313],
         [29899],
         [29889],
         [29899],
         [29899],
         [30488],
         [29874],
         [29874],
         [29874],
         [29874],
         [  292],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29892],
         [29874],
         [29874],
         [29899],
         [29874],
         [  333],
         [29874],
         [29892],
         [ 5628],
         [  292],
         [ 1131],
         [29899],
         [29874],
         [29874],
         [29874],
         [  292],
         [29874],
         [29871],
         [29896],
         [29874],
         [  370],
         [29874],
         [  262],
         [29874],
         [29899],
         [29924],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29924],
         [29924],
         [29892],
         [29874],
         [29874],
         [29899],
         [29874],
         [  333],
         [29874],
         [29874],
         [  370],
         [14131],
         [ 5628],
         [  292],
         [29874],
         [23392],
         [ 1454],
         [29875],
         [ 2624],
         [  680],
         [29892],
         [29874],
         [29874],
         [29874],
         [  292],
         [29874],
         [29874],
         [29896],
         [29874],
         [29874],
         [29924],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29871],
         [29874],
         [29892],
         [29874],
         [29892],
         [29871],
         [  313],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [14131],
         [29874],
         [  315],
         [29871],
         [29950],
         [29892],
         [29874],
         [29874],
         [  315],
         [29892],
         [29874],
         [29874],
         [29874],
         [ 1798],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [ 8813],
         [  272],
         [29933],
         [29874],
         [  991],
         [29892],
         [29874],
         [29874],
         [29874],
         [ 9464],
         [29874],
         [29892],
         [  370],
         [29890],
         [29874],
         [  323],
         [29874],
         [29874],
         [29874],
         [ 8813],
         [29874],
         [  285],
         [29874],
         [29871],
         [30488],
         [29892],
         [30488],
         [30488],
         [29889],
         [29892],
         [29924],
         [29892],
         [29871],
         [29871],
         [29899],
         [29892],
         [29874],
         [  376],
         [29874],
         [29871],
         [29871],
         [29899],
         [29892],
         [29874],
         [29899],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [ 1798],
         [29874],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [  323],
         [29874],
         [29933],
         [  497],
         [29874],
         [29874],
         [29892],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [29915],
         [29874],
         [29892],
         [29892],
         [29874],
         [29874],
         [29899],
         [29892],
         [29899],
         [29892],
         [29892],
         [29899],
         [29874],
         [29871],
         [29892],
         [29899],
         [29892],
         [29899],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [ 3972],
         [29874],
         [29933],
         [29874],
         [29874],
         [29874],
         [29892],
         [29892],
         [29933],
         [29933],
         [  282],
         [  392],
         [29874],
         [29892],
         [29874],
         [29892],
         [  281],
         [  370],
         [29888],
         [29888],
         [29888],
         [  315],
         [29874],
         [29914],
         [ 7050],
         [29874],
         [29888],
         [29894],
         [29874],
         [29874],
         [29874],
         [29874],
         [  323],
         [29874],
         [29933],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29914],
         [29892],
         [29874],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [ 1798],
         [29874],
         [29892],
         [29874],
         [29874],
         [  376],
         [29924],
         [29874],
         [29871],
         [29893],
         [29874],
         [29892],
         [29874],
         [29892],
         [  448],
         [29874],
         [29874],
         [29914],
         [29892],
         [29899],
         [29892],
         [29874],
         [29874],
         [29899],
         [29892],
         [29914],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29899],
         [29892],
         [29874],
         [29892],
         [29874],
         [29892],
         [29874],
         [29899],
         [29892],
         [29899],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29892],
         [29924],
         [29892],
         [29874],
         [29874],
         [29892],
         [29899],
         [29892],
         [29899],
         [29874],
         [29892],
         [29874],
         [29899],
         [29892],
         [29874],
         [29892],
         [29892],
         [29899],
         [29874],
         [29892],
         [29899],
         [  448],
         [ 1424],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [  323],
         [29874],
         [29933],
         [29874],
         [29874],
         [29874],
         [29892],
         [29892],
         [29892],
         [29874],
         [29874],
         [29874],
         [  323],
         [29874],
         [29933],
         [  497],
         [29874],
         [29874],
         [29892],
         [  281],
         [29924],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892]]], device='cuda:0')
torch.Size([2, 289, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [29874, 29871,   315,  ...,   313,   349, 29899],
         ...,
         [29892, 29871,   313,  ..., 29899,   317,   349],
         [29892, 29871,   313,  ...,   317, 29899,   349],
         [29892, 29871,   313,  ...,   317,   349, 29899]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ..., 29890,   323,   315],
         [29871, 29874, 29899,  ..., 29892, 29883, 29885],
         ...,
         [29874,   262, 29875,  ..., 29879, 29950,   370],
         [29874, 29875, 29924,  ...,   448, 29903, 29915],
         [29892, 29871, 29899,  ..., 29915, 29943, 29875]]], device='cuda:0')
Batch 23, 42.7% of total tokens
encoded shape: torch.Size([2, 1125])
torch.Size([2, 1125]) tensor([[    1,   396,  2856,  ..., 11625,  1159,    13],
        [    1,   518,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1125, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -6.7500,  -4.8203,   3.3984,  ...,  -4.3711,  -4.1172,  -3.7852],
         [ -5.5664,  -3.1445,   3.5059,  ...,  -3.6738,  -3.3359,  -3.0098],
         ...,
         [-11.6094, -19.1094,  -0.7827,  ...,  -8.0000,  -3.7324,  -9.8047],
         [-14.1953, -20.3750,   3.5781,  ...,  -9.0000,  -4.5820,  -9.4297],
         [-12.6094, -19.8594,   2.0605,  ...,  -9.7188,  -6.4453,  -9.3750]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -6.7500,  -6.0977,   4.1641,  ...,  -4.1172,  -4.5859,  -4.0195],
         [ -8.1250,   1.0791,   1.8506,  ...,  -2.4961,  -4.4375,  -1.7734],
         ...,
         [ -8.5234, -11.2109,  -4.5391,  ...,  -6.3398,  -1.7764,  -6.9375],
         [ -8.5469, -11.2031,  -4.4961,  ...,  -6.2891,  -1.7256,  -6.9023],
         [ -8.5391, -11.1875,  -4.5000,  ...,  -6.2734,  -1.7178,  -6.8906]]],
       device='cuda:0')
torch.Size([2, 1125, 1]) tensor([[[29918],
         [29871],
         [29933],
         ...,
         [29874],
         [29874],
         [29871]],

        [[29918],
         [29871],
         [  306],
         ...,
         [29892],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 1125, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ..., 29896,   349, 29915],
         [29933, 29903, 29924,  ..., 29874,   262,   392],
         ...,
         [29874, 29899, 29892,  ..., 29924,   313, 29875],
         [29874, 29899, 29871,  ..., 29909, 29875, 29903],
         [29871, 29899,    13,  ...,   319, 29901, 29874]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ..., 29874,   315,   349],
         [  306,   313,  1346,  ...,   373, 10266,   891],
         ...,
         [29892, 29879, 29871,  ...,   313,   376,   263],
         [29892, 29879, 29871,  ...,   313,   376,   263],
         [29892, 29879, 29871,  ...,   313,   376,   263]]], device='cuda:0')
Batch 24, 44.3% of total tokens
encoded shape: torch.Size([2, 568])
torch.Size([2, 568]) tensor([[    1,   849, 25512,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,  3954, 29925,    13]], device='cuda:0')
torch.Size([2, 568, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -5.6172,  -3.9980,   3.0312,  ...,  -3.8164,  -4.3867,  -3.0391],
         [ -6.3672,  -5.1719,   2.9805,  ...,  -3.9746,  -4.5352,  -3.3086],
         ...,
         [ -8.2656, -10.3281,  -4.7422,  ...,  -5.8672,  -1.8594,  -6.2539],
         [ -8.2734, -10.3594,  -4.6641,  ...,  -5.8594,  -1.8330,  -6.2617],
         [ -8.2656, -10.3203,  -4.6523,  ...,  -5.8438,  -1.8037,  -6.2500]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.4453,  -2.8203,   2.1680,  ...,  -3.4492,  -4.0703,  -2.8320],
         [ -9.0234,   0.0891,   5.8203,  ...,  -3.7891,  -4.9961,  -1.0322],
         ...,
         [-11.0391, -17.7969,  -0.3955,  ...,  -7.3047,  -3.4180,  -8.0703],
         [-11.5391, -16.1406,  -1.0947,  ...,  -7.5273,  -4.7266,  -8.0156],
         [-11.7656, -13.4688,   2.8848,  ...,  -7.1875,  -7.2266,  -6.6992]]],
       device='cuda:0')
torch.Size([2, 568, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [29892],
         [29892],
         [29892]],

        [[29918],
         [30488],
         [  313],
         ...,
         [29874],
         [29874],
         [29871]]], device='cuda:0')
torch.Size([2, 568, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29871, 29899, 29892,  ...,   315,   856,   349],
         ...,
         [29892,   313, 29915,  ...,   448,   306,   317],
         [29892,   313, 29915,  ...,   448,   306,   317],
         [29892,   313, 29915,  ...,   448,   306,   317]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ..., 30879,   856, 30282],
         [  313,    13,   306,  ...,   891,   376,  1346],
         ...,
         [29874, 29875, 29871,  ..., 29899, 29892,   376],
         [29874, 29933, 29924,  ...,   294,   262, 29909],
         [29871, 29899, 29874,  ...,   349,   856, 29933]]], device='cuda:0')
Batch 25, 45.1% of total tokens
encoded shape: torch.Size([2, 617])
torch.Size([2, 617]) tensor([[    1,  3577,   419,  ...,    13, 29913,    13],
        [    1,   849, 14187,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 617, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -6.2305,  -4.9922,   2.5332,  ...,  -3.9043,  -3.2871,  -3.4941],
         [ -9.8594, -15.2500,  -0.1564,  ...,  -5.4492,  -2.2422,  -7.6484],
         ...,
         [-10.0156, -14.2109,  -1.1650,  ...,  -6.9922,  -2.8379,  -7.0508],
         [ -7.5859,  -7.0000,   1.5605,  ...,  -4.6094,  -4.8242,  -4.5508],
         [-11.0312, -12.6172,   3.0645,  ...,  -7.1680,  -6.8008,  -7.2695]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -5.6172,  -3.9980,   3.0312,  ...,  -3.8164,  -4.3867,  -3.0391],
         [ -7.5977,  -7.1328,   3.5801,  ...,  -4.6836,  -4.0195,  -3.3320],
         ...,
         [ -7.7031,  -9.4141,  -7.1172,  ...,  -5.6367,  -2.7832,  -6.0195],
         [ -7.6367,  -9.4453,  -7.1016,  ...,  -5.5898,  -2.6875,  -5.9883],
         [ -7.5859,  -9.3359,  -7.1445,  ...,  -5.5000,  -2.6152,  -5.9141]]],
       device='cuda:0')
torch.Size([2, 617, 1]) tensor([[[29918],
         [29892],
         [29874],
         ...,
         [29875],
         [29874],
         [29899]],

        [[29918],
         [29871],
         [29874],
         ...,
         [30057],
         [23333],
         [23333]]], device='cuda:0')
torch.Size([2, 617, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29898,  ...,   262, 29915,   856],
         [29874,   392, 29950,  ..., 29924,   300, 29871],
         ...,
         [29875, 29874,   392,  ..., 29879, 29899, 29923],
         [29874, 29899, 29892,  ..., 29889,   856,   392],
         [29899, 29871, 29874,  ..., 29915,   856,   313]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29874, 29871, 29899,  ...,   856, 29882, 29903],
         ...,
         [30057, 23333, 14131,  ...,   785,   313,  1131],
         [23333, 14131, 30057,  ...,   785,   313,  1131],
         [23333, 14131, 30057,  ...,   785,  1131, 29879]]], device='cuda:0')
Batch 26, 45.8% of total tokens
encoded shape: torch.Size([2, 1021])
torch.Size([2, 1021]) tensor([[    1,  6319,  1961,  ...,    13, 29913,    13],
        [    1,   722,  2967,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1021, 32000]) tensor([[[ -9.0156,   0.8442,   0.8052,  ...,  -3.0469,  -5.3750,  -2.3613],
         [ -4.6836,  -2.9629,   2.2480,  ...,  -3.3145,  -4.3047,  -3.0781],
         [ -7.5781,  -5.9297,   2.9062,  ...,  -4.7578,  -3.4863,  -4.1992],
         ...,
         [ -5.8477,  -4.7148,   2.8320,  ...,  -3.8555,  -4.6641,  -3.6973],
         [ -4.7930,  -3.4883,   1.6416,  ...,  -3.5391,  -4.1523,  -3.0723],
         [ -5.0234,  -3.9805,   1.9326,  ...,  -3.7246,  -4.5117,  -3.2188]],

        [[ -9.0156,   0.8442,   0.8052,  ...,  -3.0469,  -5.3750,  -2.3613],
         [ -4.8867,  -3.3750,   1.9355,  ...,  -3.4492,  -3.7930,  -2.7227],
         [ -9.0547, -13.4688,   0.2266,  ...,  -7.0039,  -4.1641,  -8.2969],
         ...,
         [ -7.4531,  -9.2969,  -7.2344,  ...,  -4.8711,  -1.9600,  -5.6641],
         [ -7.4375,  -9.2656,  -7.2578,  ...,  -4.8633,  -1.9658,  -5.6641],
         [ -7.4102,  -9.1250,  -7.2969,  ...,  -4.8203,  -1.9727,  -5.6250]]],
       device='cuda:0')
torch.Size([2, 1021, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29899],
         [29889],
         [29871]],

        [[29918],
         [29892],
         [29874],
         ...,
         [23333],
         [23333],
         [23333]]], device='cuda:0')
torch.Size([2, 1021, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29874, 29924, 29875,  ..., 29903, 29907, 29893],
         ...,
         [29899,   856, 29892,  ..., 29875,    13, 29915],
         [29889, 29892,   856,  ..., 31147, 30879,   313],
         [29871, 29889, 29892,  ..., 29874, 29915,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29899,  ...,   313, 29896, 29898],
         [29874, 29899,   315,  ..., 29896,   271,   262],
         ...,
         [23333, 14131, 30057,  ..., 30119,  1131, 29879],
         [23333, 14131, 30057,  ..., 30119,  1131, 29879],
         [23333, 14131, 30057,  ...,   514,  1131,   538]]], device='cuda:0')
Batch 27, 47.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 18252, 21300,  ..., 16113,   517, 29914],
        [    1,   396,   361,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.5312,  -2.1426,   2.1641,  ...,  -3.1152,  -4.0117,  -3.1406],
         [ -6.5664,  -4.7500,   3.6270,  ...,  -3.6406,  -3.9883,  -3.8965],
         ...,
         [ -5.9883,  -5.0078,   2.1406,  ...,  -3.9082,  -4.4805,  -3.6816],
         [ -9.4844, -11.3359,   2.8906,  ...,  -6.4492,  -4.5703,  -6.0547],
         [ -6.8203,  -5.9648,   3.2402,  ...,  -4.6484,  -4.8633,  -4.1016]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.7344,  -4.8047,   3.3887,  ...,  -4.3633,  -4.1172,  -3.7773],
         [ -6.4609,  -4.3594,   3.7598,  ...,  -3.3145,  -3.9141,  -3.4258],
         ...,
         [ -4.8125,   1.3047,  -3.8262,  ...,  -2.1777,  -3.2207,  -2.2930],
         [ -4.8125,   1.3154,  -3.8281,  ...,  -2.1758,  -3.2188,  -2.2910],
         [ -4.7930,   1.3408,  -3.8262,  ...,  -2.1621,  -3.2031,  -2.2754]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29889],
         [29874],
         ...,
         [29871],
         [29874],
         [  297]],

        [[29918],
         [29871],
         [29924],
         ...,
         [30140],
         [30140],
         [30140]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 31147,  ...,   856,   313,   349],
         [29874, 29875, 29933,  ..., 29873,   294, 29911],
         ...,
         [29871, 29892, 29899,  ..., 29915, 29896,   349],
         [29874, 29914, 29871,  ..., 29909, 29896, 29933],
         [  297, 29892, 29889,  ..., 29915,   349,   319]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ...,   349, 29896, 29915],
         [29924, 29933, 29950,  ...,   262, 29931, 29903],
         ...,
         [30140, 30488, 30057,  ..., 31147,   229,   313],
         [30140, 30488, 30057,  ..., 31147,   229,   313],
         [30140, 30488, 30057,  ..., 31147,   229,   313]]], device='cuda:0')
Batch 28, 51.8% of total tokens
encoded shape: torch.Size([2, 318])
torch.Size([2, 318]) tensor([[    1,  1235,   318,   333,   353,  4712, 29889,  3707,   580,    13,
            13, 15843,  1040,   679, 29965,   333,   353,  3861,  1149,   426,
            13, 29871,   318,   333,  4619, 29896,    13, 29871,   736,   318,
           333,    13, 29913,    13,    13, 15843,  1040,   679, 29965,   333,
          1231,   353,  3861,  1149,   426,    13, 29871,   736,   679, 29965,
           333,  2141,  7711, 29898, 29941, 29953, 29897,    13, 29913,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2],
        [    1,  5877,   353,   376, 17529, 29941,  1769,    13,    13,  5215,
           376,  2974, 29899,  4645, 29914,  6004,  3481,   845,  1296, 29889,
         17529,  1769,    13,  5215,   376, 12366, 29914, 29925,   292, 29889,
         17529,  1769,    13,  5215,   376,  2974, 29899,  4645, 29914,  6004,
          3728, 29889, 17529,  1769,    13,  5215,   376,  2974, 29899,  4645,
         29914,  9075,  6422, 29889, 17529,  1769,    13,  5215,   376, 12366,
         29914,  9075,  1469, 29889, 17529,  1769,    13,  5215,   376, 12366,
         29914, 19346,  1469, 29889, 17529,  1769,    13,  5215,   376, 12366,
         29914,  1451,   271, 29889, 17529,  1769,    13,    13,  4906,  5656,
          4032,   426,    13, 29871, 14115,  7777,  1542,   426,    13,  1678,
          8291, 29968,  6632, 16048,   353, 29871, 29900, 29936,    13,  1678,
           379,  9468, 23498,  6059,   353, 29871, 29906, 29936,    13,  1678,
           349,  4214,   353, 29871, 29941, 29936,    13,  1678, 26996,  5348,
         29918,  2303,  1799, 10461,   353, 29871, 29946, 29936,    13,  1678,
           349, 18799,  1001, 29918, 24360, 29918, 14474,   353, 29871, 29945,
         29936,    13,  1678,   349, 18799,  1001, 29918, 14474,   353, 29871,
         29953, 29936,    13,  1678,   349, 18799,  1001, 29918, 14573,   353,
         29871, 29896, 29906, 29947, 29936,    13,  1678,   341,  2544, 29909,
         29918, 14573,   353, 29871, 29896, 29906, 29929, 29936,    13,  1678,
          5868,  1299,   353, 29871, 29896, 29941, 29900, 29936,    13, 29871,
           500,    13, 29871,  7777,  1542,  2643, 29918,  1853,   353, 29871,
         29896, 29936,    13, 29871,   697,   974,  2643,   426,    13,  1678,
          5656,  3481,   845,  1296,  1361,   845,  1296,   353, 29871, 29906,
         29936,    13,  1678,   349,   292, 24543,   353, 29871, 29941, 29936,
            13,  1678,  5656,  3728,  1923, 29918,  4906,   353, 29871, 29946,
         29936,    13,  1678, 14574,  1293,  6422,  4847, 29918,  1761, 29918,
          5504,   353, 29871, 29945, 29936,    13,  1678, 14574,  6422,  4847,
         29918,  5504,   353, 29871, 29953, 29936,    13,  1678, 14574,  1469,
          4847, 29918,  1272,   353, 29871, 29896, 29906, 29947, 29936,    13,
          1678, 20553,  1469, 12700, 29918,  1272,   353, 29871, 29896, 29906,
         29929, 29936,    13,  1678,   678,   271, 13563,   353, 29871, 29896,
         29941, 29900, 29936,    13, 29871,   500,    13, 29913]],
       device='cuda:0')
torch.Size([2, 318, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -4.7969,  -3.2441,   2.1113,  ...,  -3.3887,  -3.8203,  -2.8047],
         [ -5.7305,  -4.9922,   2.2480,  ...,  -3.7070,  -4.6445,  -3.6230],
         ...,
         [ -9.2734, -12.8750,  -2.4043,  ...,  -7.3711,  -2.3965,  -7.6055],
         [ -9.3359, -12.6719,  -2.4316,  ...,  -7.1328,  -2.1621,  -7.3789],
         [ -9.2891, -12.3516,  -2.4219,  ...,  -6.8359,  -1.9170,  -7.1172]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -4.6484,  -3.4961,   2.0508,  ...,  -3.3496,  -4.1172,  -3.0547],
         [ -6.9922,  -5.6836,   3.1973,  ...,  -4.3828,  -4.1289,  -3.6973],
         ...,
         [ -9.9531, -11.3438,   3.8379,  ...,  -6.1758,  -5.7500,  -5.9102],
         [-11.2578, -17.0781,   1.4268,  ...,  -8.2969,  -5.6445,  -7.5820],
         [-11.6406, -14.4453,   2.8340,  ...,  -7.8320,  -6.1055,  -6.9922]]],
       device='cuda:0')
torch.Size([2, 318, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29899],
         [29871],
         [29874],
         [10266],
         [29874],
         [29874],
         [29892],
         [29871],
         [29874],
         [29909],
         [29874],
         [  333],
         [  392],
         [29874],
         [ 1149],
         [29933],
         [29874],
         [29871],
         [29874],
         [29871],
         [29933],
         [29896],
         [29900],
         [29928],
         [29924],
         [29874],
         [29871],
         [ 1351],
         [29950],
         [29874],
         [29871],
         [29899],
         [29924],
         [29909],
         [29965],
         [  333],
         [  392],
         [29874],
         [29874],
         [ 1149],
         [29924],
         [29874],
         [29871],
         [29933],
         [29874],
         [  501],
         [29871],
         [  392],
         [30488],
         [29874],
         [29896],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29899],
         [29892],
         [29871],
         [29899],
         [29899],
         [   13],
         [29871],
         [29874],
         [29871],
         [29899],
         [29899],
         [29899],
         [29892],
         [29874],
         [  845],
         [29924],
         [29874],
         [29892],
         [29871],
         [29871],
         [29871],
         [29874],
         [29892],
         [29871],
         [29892],
         [29871],
         [29874],
         [29892],
         [29871],
         [29899],
         [29871],
         [29874],
         [29892],
         [29899],
         [29892],
         [29914],
         [14131],
         [14131],
         [29874],
         [29892],
         [29924],
         [29874],
         [29871],
         [29874],
         [29892],
         [29899],
         [ 3132],
         [29899],
         [29892],
         [29874],
         [29874],
         [29892],
         [29871],
         [29874],
         [29871],
         [29874],
         [29892],
         [29899],
         [29892],
         [  333],
         [29874],
         [29892],
         [29924],
         [29874],
         [29871],
         [29874],
         [29892],
         [29899],
         [29892],
         [29874],
         [29874],
         [29892],
         [29871],
         [29874],
         [29871],
         [29874],
         [29892],
         [29899],
         [29892],
         [29874],
         [  370],
         [29892],
         [29871],
         [29874],
         [29871],
         [29871],
         [29874],
         [ 3728],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [  519],
         [29874],
         [29874],
         [29874],
         [29874],
         [  465],
         [  776],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [  262],
         [ 9468],
         [  845],
         [  276],
         [  370],
         [29896],
         [29896],
         [29874],
         [29874],
         [ 1678],
         [ 4345],
         [  886],
         [  957],
         [29871],
         [29871],
         [29874],
         [29874],
         [ 1678],
         [ 4345],
         [29909],
         [ 4345],
         [10888],
         [12062],
         [29874],
         [29903],
         [29871],
         [29871],
         [29874],
         [29874],
         [ 1678],
         [ 9106],
         [ 4847],
         [ 1001],
         [29918],
         [14474],
         [  292],
         [14474],
         [29881],
         [29871],
         [29871],
         [29874],
         [29874],
         [ 1678],
         [ 9106],
         [ 4847],
         [ 1001],
         [29918],
         [14474],
         [29881],
         [29871],
         [29871],
         [    2],
         [29871],
         [ 1678],
         [ 9106],
         [  292],
         [ 1001],
         [29918],
         [  848],
         [  294],
         [29871],
         [29871],
         [29896],
         [29874],
         [29874],
         [29874],
         [ 1678],
         [29874],
         [26833],
         [29909],
         [29918],
         [  848],
         [29874],
         [29896],
         [29871],
         [29906],
         [29929],
         [    2],
         [29874],
         [ 1678],
         [29874],
         [29874],
         [30057],
         [29896],
         [29871],
         [29941],
         [29896],
         [    2],
         [    2],
         [  262],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [ 1542],
         [29892],
         [29874],
         [  262],
         [29871],
         [29874],
         [29909],
         [29871],
         [29874],
         [29899],
         [29874],
         [29874],
         [29899],
         [29871],
         [29874],
         [29874],
         [  845],
         [29871],
         [29874],
         [  845],
         [  845],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29871],
         [29874],
         [  292],
         [  292],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29918],
         [29892],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29892],
         [29874],
         [ 1761],
         [29874],
         [29874],
         [ 1761],
         [ 1761],
         [29918],
         [29892],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [ 5504],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [29871],
         [29871],
         [29906],
         [29871],
         [29871],
         [29874],
         [29892],
         [29874],
         [29871],
         [29874],
         [29899],
         [29871],
         [29871],
         [29941],
         [29900],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 318, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29899,  ..., 30488, 29898, 31147],
         [29892, 29871, 29874,  ..., 29896,   349,    13],
         ...,
         [29892, 29871, 29899,  ..., 29879,   297,   315],
         [29892, 29871, 29899,  ..., 29879,   315,   297],
         [29892, 29871,   313,  ..., 29879,   315,   297]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 31147, 29874, 29915],
         [29899, 29871, 29892,  ..., 29889, 29898, 29915],
         ...,
         [29874, 29899, 29871,  ..., 29933, 29915,    13],
         [29871, 29874, 29909,  ..., 29924, 29915, 29933],
         [29871, 29874, 29899,  ..., 29909, 29875, 29896]]], device='cuda:0')
Batch 29, 52.1% of total tokens
encoded shape: torch.Size([2, 550])
torch.Size([2, 550]) tensor([[    1,   849,    13,  ..., 29992,   355,    13],
        [    1,   770, 13679,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 550, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -5.6172,  -3.9980,   3.0293,  ...,  -3.8164,  -4.3867,  -3.0391],
         [ -6.2461,   3.5742,   7.4180,  ...,  -1.0469,  -3.0840,   0.6992],
         ...,
         [ -8.3359,  -7.5977,   3.0020,  ...,  -5.0156,  -5.0859,  -5.4492],
         [-11.3906, -13.2266,   3.6211,  ...,  -7.0820,  -5.3242,  -6.4141],
         [-11.6641, -18.2188,   0.8213,  ...,  -8.9375,  -4.9141,  -8.2656]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -5.2227,  -3.3965,   2.4688,  ...,  -3.5293,  -3.7305,  -2.8066],
         [ -8.0859,  -8.2188,   3.8770,  ...,  -4.8281,  -4.4102,  -4.8672],
         ...,
         [ -4.3047,   0.8877,  -2.8320,  ...,  -2.4688,  -3.0742,  -2.4531],
         [ -4.7617,   1.2002,  -3.1934,  ...,  -2.4648,  -3.1152,  -2.4805],
         [ -5.3008,   1.4893,  -3.3594,  ...,  -2.4844,  -3.2324,  -2.4961]]],
       device='cuda:0')
torch.Size([2, 550, 1]) tensor([[[29918],
         [29871],
         [   13],
         ...,
         [  355],
         [29874],
         [29871]],

        [[29918],
         [29874],
         [29874],
         ...,
         [30488],
         [30488],
         [30010]]], device='cuda:0')
torch.Size([2, 550, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [   13,   313, 29871,  ..., 29973,   891, 30010],
         ...,
         [  355, 29892, 29924,  ..., 29915, 29899, 29925],
         [29874, 29933, 29871,  ..., 29928, 29896, 29903],
         [29871, 29899, 29892,  ..., 29889, 29933, 29896]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29874,   262, 29899,  ..., 29915,   856, 29909],
         [29874, 29871, 29899,  ..., 29898, 29875,    13],
         ...,
         [30488, 30879, 31147,  ..., 29915, 30186,   376],
         [30488, 30879, 30010,  ..., 30282,   376,   313],
         [30010, 30140, 29915,  ...,   306, 29987,   392]]], device='cuda:0')
Batch 30, 52.7% of total tokens
encoded shape: torch.Size([2, 122])
torch.Size([2, 122]) tensor([[    1,  1192,    13,   489, 20561,  1591,  3829,   363,   770,   304,
           788,   278,   770, 29889,  7165,    13,   489,    13,    13,  1964,
          4945, 10911,   770,    13, 29871, 27827,   421,  7165, 29952, 15236,
         29898, 29906, 29945, 29945, 29897,  2322, 29871, 29900, 23844,  4945,
         17659, 29918, 19145,    13, 29936,    13,    13,   489,    13,   489,
         20561,  1591,  3829,   363,   770,   304,   788,   278,   770, 29889,
         29894,  5358,  3986,    13,   489,    13,    13,  1964,  4945, 10911,
           770,    13, 29871, 27827,   421, 29894,  5358, 29952,   938, 29898,
         29896, 29896, 29897, 23844,  4945,   421,  7165, 29952,    13, 29936,
            13,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,   934,  5809,  6594, 29901, 29871, 29906,    13,  2543,   333,
         29901,   263, 29947, 29929, 19385,   287, 29953, 29872, 29945, 29881,
         29946, 29946, 29890, 29946, 29953, 29890, 29941, 29896, 29955, 29900,
         29896, 29888, 29945, 29953, 29883, 29929, 29947, 29946, 29947, 29953,
            13,  2230, 20399, 29901, 29871, 29896, 29946, 29947, 29941, 29945,
         29946, 29900, 29900, 29955, 29929,    13,   506,  1947,  1542, 29901,
          1019,    13, 29924,  3231, 24192,  9555, 29901,    13, 29871,  7797,
          1891,  6594, 29901, 29871, 29906,    13, 29871,  2322,  1123, 10662,
         29901,  5159,    13, 29871,  8225,  7514, 29901, 29871, 29900,    13,
         29871,  9849, 29901,   426,  8758,  1367, 29901, 29871, 29900, 29913,
            13, 29871,  1404,  1469, 29901, 29871,    13, 29871, 24342,  9534,
          1170, 29901, 29871,    13, 29871, 24342,  9534, 10444,   424, 29901,
         29871,    13]], device='cuda:0')
torch.Size([2, 122, 32000]) tensor([[[ -9.0156,   0.8423,   0.8091,  ...,  -3.0469,  -5.3750,  -2.3594],
         [ -4.8555,  -3.2910,   2.2852,  ...,  -3.4492,  -4.1445,  -3.1074],
         [ -6.9570,   2.2070,   6.3789,  ...,  -0.7256,  -2.5098,  -0.2013],
         ...,
         [ -9.0078, -13.5547,   2.1250,  ...,  -7.7227,  -4.9336,  -6.9219],
         [ -8.2812, -13.2344,   1.0449,  ...,  -7.6016,  -4.5391,  -6.8516],
         [ -7.7539, -13.0547,   0.2228,  ...,  -7.5195,  -4.2344,  -6.7852]],

        [[ -9.0156,   0.8423,   0.8091,  ...,  -3.0469,  -5.3750,  -2.3594],
         [ -4.1406,  -2.6348,   1.6924,  ...,  -3.1641,  -4.0078,  -2.7793],
         [ -8.8750,  -9.2812,   5.1016,  ...,  -4.9062,  -4.9453,  -4.9062],
         ...,
         [-11.1875, -15.9219,  -0.4236,  ...,  -5.1484,  -3.0957,  -6.8711],
         [-10.9688, -18.0781,   1.7930,  ...,  -5.9766,  -1.2910,  -7.3672],
         [ -7.7227,  -8.3984,   3.1562,  ...,  -4.3672,  -5.2578,  -4.1367]]],
       device='cuda:0')
torch.Size([2, 122, 1]) tensor([[[29918],
         [29892],
         [   13],
         [29889],
         [29871],
         [29874],
         [29874],
         [29924],
         [29909],
         [ 1129],
         [29874],
         [29874],
         [  333],
         [29892],
         [29874],
         [29899],
         [29892],
         [29871],
         [29892],
         [29874],
         [29874],
         [29874],
         [29924],
         [14131],
         [29874],
         [ 1131],
         [29892],
         [29874],
         [  392],
         [29898],
         [29906],
         [29945],
         [29945],
         [29924],
         [ 2142],
         [  370],
         [29871],
         [29874],
         [  747],
         [29909],
         [29874],
         [29892],
         [29924],
         [  370],
         [29874],
         [29871],
         [29871],
         [29874],
         [29871],
         [29928],
         [  287],
         [29909],
         [29874],
         [29909],
         [  304],
         [29928],
         [  278],
         [29924],
         [29915],
         [29892],
         [ 1160],
         [29874],
         [29871],
         [29892],
         [29874],
         [  509],
         [21332],
         [29874],
         [29924],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29894],
         [29907],
         [29952],
         [  996],
         [29898],
         [29896],
         [29896],
         [29924],
         [ 2142],
         [29874],
         [29909],
         [29892],
         [29874],
         [ 2142],
         [  370],
         [29874],
         [29871],
         [29924],
         [29924],
         [29874],
         [29933],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871]],

        [[29918],
         [30488],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [30488],
         [30488],
         [29889],
         [29871],
         [29874],
         [29874],
         [29871],
         [29899],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29899],
         [29871],
         [29892],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29899],
         [29874],
         [29871],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [29874],
         [29892],
         [29871],
         [29874],
         [29871],
         [29871],
         [29874],
         [29899],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 122, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29871,  ..., 29915,   315,    13],
         [   13,   313, 29871,  ...,   363,   297,   304],
         ...,
         [29871, 29892,    13,  ..., 29896,   315,   349],
         [29871, 29892,    13,  ..., 29896,   315,   376],
         [29871, 29892,    13,  ..., 29896,   315,   263]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 31147, 30879,  ...,   313, 29899,   856],
         [29874, 29871, 29899,  ..., 29875,   392, 29903],
         ...,
         [29874, 29915, 29896,  ..., 30010, 29892, 29909],
         [29871, 29874, 29899,  ..., 29900, 29903, 29896],
         [29871, 29892, 29899,  ..., 29896,   856,   315]]], device='cuda:0')
Batch 31, 52.9% of total tokens
encoded shape: torch.Size([2, 1054])
torch.Size([2, 1054]) tensor([[    1,  3577, 18778,  ..., 23684,   293,    13],
        [    1,   847,  5205,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1054, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -6.2266,  -4.9883,   2.5332,  ...,  -3.9023,  -3.2871,  -3.4922],
         [ -6.6992,  -5.5312,   3.0938,  ...,  -3.8164,  -4.6289,  -3.5117],
         ...,
         [-11.7188, -17.5469,  -1.7930,  ...,  -7.6133,  -4.8555,  -8.2969],
         [-10.4688, -16.9688,  -1.5605,  ...,  -7.8477,  -4.3555,  -8.1797],
         [-10.6797, -15.5469,  -1.1689,  ...,  -8.7266,  -6.9453,  -8.9375]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -5.3867,  -3.7109,   2.4160,  ...,  -3.6348,  -4.2305,  -3.2832],
         [ -5.3359,  -4.1367,   2.2734,  ...,  -3.6133,  -4.2578,  -3.1582],
         ...,
         [ -5.0195,   1.4658,  -3.5352,  ...,  -2.2344,  -3.2324,  -2.2871],
         [ -5.0742,   1.4912,  -3.5312,  ...,  -2.2402,  -3.2500,  -2.2891],
         [ -5.1484,   1.5332,  -3.5176,  ...,  -2.2500,  -3.2793,  -2.2891]]],
       device='cuda:0')
torch.Size([2, 1054, 1]) tensor([[[29918],
         [29892],
         [29871],
         ...,
         [29871],
         [   13],
         [29892]],

        [[29918],
         [29892],
         [29871],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 1054, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29898,  ...,   262, 29915,   856],
         [29871, 29892,   313,  ...,    13, 29915, 29874],
         ...,
         [29871, 29903, 29933,  ..., 29924, 29943,   349],
         [   13, 29874, 29871,  ..., 29875,   376, 29915],
         [29892, 29899, 29871,  ..., 29875,   315, 29934]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29871, 29889,  ...,   856,   349, 29915],
         [29871, 29899,   313,  ...,   315,   349,   856],
         ...,
         [30010, 30140, 29915,  ...,   392,   229, 29987],
         [30010, 30140, 29915,  ...,   392,   229, 29987],
         [30010, 30140, 29915,  ...,   392, 30488, 29987]]], device='cuda:0')
Batch 32, 54.0% of total tokens
encoded shape: torch.Size([2, 56])
torch.Size([2, 56]) tensor([[    1,   518,  4282, 29899,  5205, 29962,    13,   276,   339,  2658,
           353,   518,    13,  1678,   376,   842, 21245,  8789, 18572, 29946,
         29941,   613,    13,  1678,   376, 29893, 10552,   613,    13,  1678,
           376, 24830,   613,    13,  1678,   376,  6327,  6832, 29908,    13,
         29962,    13,  4282, 29899, 27852,   353,   376,   842, 21245,  8789,
         29889,  4282, 29918,  7299, 29908,    13],
        [    1,   448, 29883, 20159,   448, 29875,  1243,  3069, 29901, 29906,
         29906, 29906, 29929, 29946,    13,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 56, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -6.7578,  -6.1094,   4.1680,  ...,  -4.1211,  -4.5859,  -4.0234],
         [ -6.5742,  -6.1016,   2.6699,  ...,  -4.1211,  -4.7812,  -3.9668],
         ...,
         [ -8.3125, -14.5156,  -1.8408,  ...,  -3.8867,  -1.3711,  -6.9141],
         [-11.6875, -17.7656,  -2.2422,  ...,  -7.9102,  -4.5312,  -8.8438],
         [ -8.8281,  -8.6562,   2.6680,  ...,  -5.8008,  -5.5000,  -5.2148]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -8.3984,  -7.4297,   3.7520,  ...,  -4.8203,  -4.8828,  -4.6211],
         [ -6.1367,  -5.0117,   2.6758,  ...,  -3.8516,  -4.2656,  -3.7168],
         ...,
         [-10.9844, -13.7969,   2.6270,  ...,  -7.0547,  -3.8516,  -7.6953],
         [-10.9922, -13.4297,   2.7793,  ...,  -6.9766,  -3.8867,  -7.6016],
         [-10.5859, -13.7578,   1.4883,  ...,  -6.9766,  -3.3965,  -7.8477]]],
       device='cuda:0')
torch.Size([2, 56, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29892],
         [29874],
         [29915],
         [   13],
         [29899],
         [29879],
         [29874],
         [29899],
         [29892],
         [29871],
         [29874],
         [29892],
         [29899],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29875],
         [29874],
         [29892],
         [29871],
         [29924],
         [29874],
         [29875],
         [29874],
         [29892],
         [29874],
         [29874],
         [29875],
         [29874],
         [29892],
         [29871],
         [ 1131],
         [29874],
         [29896],
         [29874],
         [29871],
         [29899],
         [29892],
         [29899],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29908],
         [29924],
         [29924],
         [29924],
         [29874],
         [29871]],

        [[29918],
         [29899],
         [29871],
         [29874],
         [29892],
         [29871],
         [29896],
         [29896],
         [29871],
         [29871],
         [29874],
         [29906],
         [29874],
         [29874],
         [29871],
         [29874],
         [29889],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29871],
         [29871],
         [30488],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874]]], device='cuda:0')
torch.Size([2, 56, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ..., 29874,   315,   349],
         [29871, 29899, 29892,  ..., 29915, 29889,   315],
         ...,
         [29924, 29874, 29925,  ..., 29909, 29928,  2142],
         [29874, 29924, 29871,  ..., 29896, 29899, 29931],
         [29871, 29892, 29899,  ..., 29874,   349,   341]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29899, 29892, 29871,  ..., 29875, 29889,   262],
         [29871, 29892, 29899,  ...,   315,   856, 29915],
         ...,
         [29874, 29871, 29899,  ..., 29924, 29883, 29909],
         [29874, 29871, 29899,  ..., 29883, 29924, 29909],
         [29874, 29871, 29899,  ..., 29924, 29883, 29909]]], device='cuda:0')
Batch 33, 54.1% of total tokens
encoded shape: torch.Size([2, 1072])
torch.Size([2, 1072]) tensor([[    1,  6319,  1961,  ...,    13, 29913,    13],
        [    1,  6319,  3134,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1072, 32000]) tensor([[[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.6875,  -2.9609,   2.2520,  ...,  -3.3125,  -4.3047,  -3.0781],
         [ -7.5547,  -5.9023,   2.9023,  ...,  -4.7422,  -3.4844,  -4.1875],
         ...,
         [-10.7891, -11.7188,   4.4141,  ...,  -6.7656,  -5.6172,  -7.4883],
         [ -7.3164,  -6.7617,   2.1055,  ...,  -4.8008,  -5.2617,  -4.2812],
         [ -6.4727,  -5.9492,   2.5742,  ...,  -4.5352,  -5.1094,  -3.8809]],

        [[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.6875,  -2.9609,   2.2520,  ...,  -3.3125,  -4.3047,  -3.0781],
         [ -4.6758,  -3.3750,   2.1719,  ...,  -3.4277,  -3.8867,  -3.0625],
         ...,
         [ -8.1641, -10.7578,  -5.3125,  ...,  -5.4219,  -1.2871,  -6.3516],
         [ -8.1484, -10.7500,  -5.3516,  ...,  -5.3945,  -1.2734,  -6.3320],
         [ -8.1172, -10.7734,  -5.4492,  ...,  -5.4219,  -1.3242,  -6.3555]]],
       device='cuda:0')
torch.Size([2, 1072, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29874],
         [29871]],

        [[29918],
         [29871],
         [29899],
         ...,
         [29879],
         [29879],
         [29879]]], device='cuda:0')
torch.Size([2, 1072, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29874, 29924, 29875,  ..., 29903, 29907, 29893],
         ...,
         [29874, 29875,   262,  ..., 29896, 29906,   856],
         [29874, 29933, 29889,  ..., 29871, 29875, 29896],
         [29871, 29899, 29892,  ...,   313, 29915, 29896]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29899, 29874, 29889,  ..., 29875, 30488, 29915],
         ...,
         [29879, 29892, 29915,  ..., 30057,   306,   313],
         [29879, 29892, 29871,  ..., 30057,   306, 23333],
         [29879, 29892, 29871,  ..., 30057, 23333,   306]]], device='cuda:0')
Batch 34, 55.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   426,    13,  ...,     2,     2,     2],
        [    1,   396,    13,  ..., 29937,    12, 29931]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.5117,  -2.7910,   2.1934,  ...,  -3.3711,  -3.9980,  -2.9590],
         [ -5.3984,   3.7949,   4.4414,  ...,   0.1442,  -1.6377,   0.8726],
         ...,
         [ -8.5625,   1.8398,   1.3926,  ...,  -2.8281,  -5.3555,  -2.0840],
         [ -8.5703,   1.8477,   1.4697,  ...,  -2.8223,  -5.3516,  -2.0645],
         [ -8.5234,   1.8877,   1.3711,  ...,  -2.8027,  -5.3203,  -2.0566]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.7344,  -4.8047,   3.3887,  ...,  -4.3633,  -4.1172,  -3.7773],
         [ -6.0469,   2.6406,   6.5820,  ...,  -0.6870,  -1.6689,  -0.3325],
         ...,
         [ -7.3984,  -7.5664,   3.0605,  ...,  -4.5703,  -4.9375,  -4.6641],
         [ -8.2109, -14.1250,  -3.4082,  ...,  -6.3320,  -3.7148,  -7.6602],
         [ -9.6094, -15.2344,  -2.4688,  ...,  -6.0000,  -2.3633,  -7.8164]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29889],
         [   13],
         ...,
         [29918],
         [29918],
         [29918]],

        [[29918],
         [29871],
         [   13],
         ...,
         [29892],
         [  365],
         [  376]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 29871,  ..., 31147, 30879,   315],
         [   13, 10266,   891,  ...,   376,  2880,   304],
         ...,
         [29918, 29915, 29879,  ..., 29973, 29892,   363],
         [29918, 29915, 29879,  ..., 29973, 29892,   363],
         [29918, 29915, 29879,  ..., 29973, 29892,   363]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ...,   349, 29896, 29915],
         [   13, 29871,   313,  ...,   363,   891, 30010],
         ...,
         [29892, 29899, 29871,  ..., 29896,   856, 29875],
         [  365,   317,   376,  ..., 29874,   390,   360],
         [  376, 29871, 29933,  ...,   315,   294, 29873]]], device='cuda:0')
Batch 35, 60.0% of total tokens
encoded shape: torch.Size([2, 224])
torch.Size([2, 224]) tensor([[    1,   313, 12262,  1207, 29899, 11249, 29899, 10184, 29899, 18082,
          1237, 29899,   262, 29899,  1990,  5159,    13, 29871,   313,  1026,
         15974, 25232,   584, 29918,   333, 29913,   313, 29881, 29914,   657,
         29899,  1990, 29899,  1609, 29899,   978,   376, 29906, 29900, 29896,
         29946, 29899, 29906, 29900, 29896, 29945, 13531,    13,  1678,   313,
          2585, 29914, 11236,   403, 29899,  1990,   274,   333, 29897,    13,
          1678,   313,  1026,   518, 29879,   313, 29881, 29914,  5675, 29899,
         18945,   376, 29926,   326, 29906,  1159,    13,  3986,   426, 29879,
           333,   584, 29918,   333, 29913,   269,    13,  3986,  1121, 12365,
          1990, 29918,   333,   274,   333,   584, 18945, 29918,  4841,   518,
         29879,   333, 29962,  6525,    13,   418,   313, 29881, 29914,  1202,
         29899, 18945, 29899,   517, 29899,  1990, 25349,   274,   333, 29897,
            13,   418,   313,  1026,   518, 29879,   313, 29881, 29914,  5675,
         29899, 18945,   376,  1655,   345, 29906,  1159,    13,  9651,   426,
         29879,   333,   584, 29918,   333, 29913,   269,    13,  9651,  1121,
           313,  5504, 29899,   262,  1121, 20840, 18945, 29918,  4841, 29962,
           313,  9144,   518, 29879,  4841, 29962,   313,   535, 29926,   269,
          4841, 25349,   876,  4638,    13,  4706,   313, 29881, 29914,  1202,
         29899, 18945, 29899,   517, 29899,  1990, 25349,   274,   333, 29897,
            13,  4706,  1121, 13697,    13,    13,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2],
        [    1,   891,   334, 19215,   334,   891,   334,  1917, 29930,   462,
          3986,   891,    13, 29989, 18981,   268,   891, 29772, 29896, 29900,
         29918, 19238, 29914,  9435, 29889,   307,  7451,   308,   891,    13,
         29989, 18981,   268,   891, 29772, 29896, 29900, 29918, 19238, 29914,
          4993, 29889,   307,  7451,   308,   891,    13, 29989, 18981,   268,
           891, 29772, 29896, 29900, 29918, 19238, 29914, 19238,   300, 29889,
           307,  7451,  4706,   891,    13, 29989, 18981,   268,   891, 29772,
         29896, 29900, 29918, 19238, 29914,   267, 29889,   307,  7451,   632,
           891,    13,    13, 29989,   334,  3057,   315,  2129, 29930,  1678,
           891,   462, 29871,   891,   632,   891,   462,   462,  3986,   891,
           462,  1678,   891,    13, 29989,  6204,   263,  2752,   891,   462,
         29871,   891,   632,   891,   462,   462,  3986,   891,   462,  1678,
           891,    13, 29989,   462,   891,   518, 28089, 29962,   965,   891,
          1653,   418,   891,  1653, 29918,  4993,   462,  9651,   891,   462,
          1678,   891,    13, 29989,   462,   891, 13103,  3789,   786,   268,
           891,   632,   891,   462,   462,  3986,   891,   462,  1678,   891,
            13, 29989,   462,   891,  6204,  2752,  1678,   891,  1158, 29922,
          1445,   891,  1418, 23179, 29922, 10140,  3698,  2066,   297,  9913,
         18871,   891,   934, 23339, 28283, 17101, 29918,  7724, 29913,   891,
            13,    13, 29989,  6204,   263,  6865,   300,   891,   518, 28089,
         29962,   308,   891,  1653,   891,  1653, 29918, 19238,   300,   891,
            13, 29989,   462, 29871,   891,  6204,  6865,   300,   891,  4706,
           891, 18884,   891,    13]], device='cuda:0')
torch.Size([2, 224, 32000]) tensor([[[ -9.0547,   0.7935,   0.8057,  ...,  -3.0742,  -5.4062,  -2.3906],
         [ -7.2891,  -6.1875,   4.5781,  ...,  -4.6953,  -4.8672,  -4.0859],
         [ -5.5352,  -4.3242,   2.0273,  ...,  -3.6289,  -4.0859,  -3.1973],
         ...,
         [-10.6094, -15.8516,   1.3574,  ...,  -8.3594,  -5.0664,  -8.0859],
         [-10.6953, -15.9531,   1.2979,  ...,  -8.3750,  -5.1094,  -8.1328],
         [-10.7656, -16.0469,   1.2002,  ...,  -8.3984,  -5.1445,  -8.1797]],

        [[ -9.0547,   0.7935,   0.8057,  ...,  -3.0742,  -5.4062,  -2.3906],
         [ -5.0234,  -3.5469,   2.5664,  ...,  -3.5781,  -4.1211,  -3.1484],
         [-10.4688, -13.2500,   4.6406,  ...,  -5.9805,  -5.4727,  -7.2070],
         ...,
         [ -9.1562,  -9.9453,   3.0918,  ...,  -5.5117,  -4.7344,  -5.5898],
         [ -9.9844, -12.9766,   1.5020,  ...,  -5.7305,  -4.5312,  -6.1055],
         [-10.7266, -17.4844,  -1.6309,  ...,  -8.4688,  -5.7070,  -8.0469]]],
       device='cuda:0')
torch.Size([2, 224, 1]) tensor([[[29918],
         [29871],
         [29899],
         [29899],
         [29892],
         [29899],
         [29892],
         [29899],
         [29879],
         [29879],
         [29899],
         [29879],
         [29899],
         [29879],
         [29899],
         [29874],
         [   13],
         [29874],
         [29892],
         [29924],
         [29901],
         [29896],
         [  315],
         [  333],
         [29896],
         [29909],
         [29892],
         [29903],
         [29892],
         [29899],
         [29892],
         [29899],
         [29892],
         [29899],
         [29892],
         [29896],
         [29892],
         [29900],
         [29896],
         [29874],
         [29874],
         [29896],
         [29900],
         [29896],
         [29871],
         [29874],
         [29874],
         [  856],
         [29874],
         [  270],
         [29899],
         [29892],
         [29871],
         [29899],
         [29892],
         [29899],
         [29896],
         [29909],
         [29874],
         [  392],
         [29874],
         [29892],
         [29924],
         [  313],
         [29896],
         [29892],
         [29914],
         [29892],
         [29899],
         [29892],
         [29899],
         [29906],
         [ 6547],
         [29896],
         [29896],
         [29874],
         [29892],
         [29874],
         [29892],
         [29896],
         [29896],
         [29874],
         [  333],
         [29896],
         [29874],
         [    2],
         [29892],
         [29987],
         [29896],
         [29892],
         [  333],
         [  333],
         [29883],
         [29896],
         [30057],
         [30057],
         [29896],
         [  333],
         [  392],
         [  269],
         [  333],
         [  392],
         [30057],
         [29874],
         [29875],
         [29874],
         [  270],
         [29914],
         [29892],
         [29899],
         [  304],
         [29874],
         [  304],
         [29899],
         [ 2385],
         [29874],
         [29883],
         [29896],
         [29950],
         [29874],
         [29875],
         [29874],
         [  270],
         [29874],
         [  269],
         [29906],
         [  270],
         [29871],
         [29892],
         [29899],
         [29879],
         [29899],
         [ 2858],
         [  345],
         [29906],
         [29874],
         [29924],
         [29874],
         [29987],
         [  269],
         [  333],
         [29906],
         [29892],
         [  333],
         [29874],
         [  392],
         [    2],
         [29882],
         [29874],
         [29906],
         [  270],
         [29874],
         [29892],
         [29874],
         [29874],
         [30057],
         [29899],
         [  333],
         [29874],
         [29909],
         [  285],
         [29899],
         [29874],
         [29896],
         [29896],
         [29874],
         [29874],
         [29909],
         [29874],
         [29896],
         [29874],
         [29933],
         [29874],
         [29874],
         [29874],
         [29874],
         [  270],
         [29899],
         [29892],
         [29899],
         [29892],
         [29899],
         [  304],
         [29899],
         [29892],
         [29874],
         [29883],
         [29896],
         [29924],
         [29874],
         [29875],
         [29874],
         [29924],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892]],

        [[29918],
         [29871],
         [29871],
         [29874],
         [29871],
         [29874],
         [29871],
         [29930],
         [29899],
         [29874],
         [29871],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29871],
         [29871],
         [29892],
         [29899],
         [29892],
         [29899],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29896],
         [29871],
         [29874],
         [29871],
         [29871],
         [29871],
         [29892],
         [29914],
         [29892],
         [29899],
         [29892],
         [29903],
         [29924],
         [29874],
         [29874],
         [29871],
         [29874],
         [29896],
         [29899],
         [29874],
         [29896],
         [30488],
         [29899],
         [29892],
         [29874],
         [29892],
         [29874],
         [29896],
         [29892],
         [29933],
         [29924],
         [29871],
         [29874],
         [29871],
         [29874],
         [29896],
         [29874],
         [29896],
         [29896],
         [29871],
         [29899],
         [29892],
         [29914],
         [29892],
         [29871],
         [29892],
         [29933],
         [29924],
         [29874],
         [29874],
         [29871],
         [29871],
         [29874],
         [29874],
         [29930],
         [29896],
         [29930],
         [29874],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [  891],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [  271],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29892],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [  300],
         [29896],
         [29871],
         [29874],
         [29896],
         [29871],
         [29874],
         [29874],
         [29896],
         [29874],
         [29874],
         [29874],
         [29874],
         [29892],
         [29871],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [  886],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871],
         [29874],
         [29892],
         [29871],
         [29899],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29896],
         [29874],
         [29874],
         [29896],
         [29892],
         [29874],
         [29874],
         [29879],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [ 1279],
         [29874],
         [29874],
         [29874],
         [29892],
         [29874],
         [  300],
         [ 2084],
         [29874],
         [29874],
         [29874],
         [29899],
         [29871],
         [29874],
         [29874],
         [19238],
         [  300],
         [29909],
         [29874],
         [28089],
         [29874],
         [  891],
         [29874],
         [29874],
         [29874],
         [29874],
         [29918],
         [ 6865],
         [  300],
         [29896],
         [29874],
         [29871],
         [29874],
         [29874],
         [29871],
         [29874],
         [ 1131],
         [  300],
         [29874],
         [29874],
         [29871],
         [29874],
         [29874],
         [29874],
         [29871]]], device='cuda:0')
torch.Size([2, 224, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   315, 29915,   349],
         [29899, 29892, 29871,  ..., 29909,   262,   313],
         ...,
         [29892, 29871, 29899,  ...,   313, 29896,   315],
         [29892, 29871, 29899,  ...,   313, 29896,   315],
         [29892, 29871, 29899,  ...,   313, 29896,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29889,  ..., 29915,   262,   315],
         [29871, 29899, 29874,  ...,   262,   376, 29915],
         ...,
         [29874, 29899, 29871,  ..., 29889, 29875, 29885],
         [29874, 29899, 29896,  ..., 29898,   262, 29875],
         [29871, 29899, 29874,  ..., 29875, 29873,   348]]], device='cuda:0')
Batch 36, 60.4% of total tokens
encoded shape: torch.Size([2, 626])
torch.Size([2, 626]) tensor([[    1,   319,  2058,  ...,     2,     2,     2],
        [    1,   444, 24162,  ...,    13, 28956,    13]], device='cuda:0')
torch.Size([2, 626, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [-10.1641, -14.0312,  -0.2440,  ...,  -6.8203,  -2.0000,  -8.5156],
         [ -9.1797, -11.3125,  -1.3252,  ...,  -5.5117,  -1.7168,  -7.0273],
         ...,
         [ -5.7344,   0.2961,  -2.9199,  ...,  -2.7324,  -3.2520,  -2.8906],
         [ -5.8828,   0.5269,  -3.1074,  ...,  -2.6875,  -3.2402,  -2.8613],
         [ -6.0039,   0.6357,  -3.1992,  ...,  -2.6816,  -3.2559,  -2.8633]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.9883,  -3.3945,   2.1445,  ...,  -3.4258,  -3.8730,  -3.1758],
         [ -5.7188,  -4.8242,  -0.0598,  ...,  -2.1914,  -2.6074,  -2.9727],
         ...,
         [ -6.9336,  -6.6484,   4.1602,  ...,  -4.7344,  -5.1953,  -4.5625],
         [-12.0078, -16.2031,  -0.7910,  ...,  -9.1719,  -5.2852,  -9.6641],
         [ -8.5000,  -9.5156,   1.1631,  ...,  -7.2109,  -5.1523,  -6.2656]]],
       device='cuda:0')
torch.Size([2, 626, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [30010],
         [30010],
         [30010]],

        [[29918],
         [29871],
         [29903],
         ...,
         [29899],
         [29899],
         [29899]]], device='cuda:0')
torch.Size([2, 626, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29874,  ...,   349, 29875,   315],
         [29874, 29924, 29909,  ..., 29902, 29934,  1129],
         ...,
         [30010, 29915,   313,  ..., 30488, 29892,   341],
         [30010, 29915, 30057,  ...,   392, 29892,   341],
         [30010, 29915, 30057,  ...,   392, 29892,   341]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   262, 29896],
         [29903, 29874,   317,  ...,   392, 29899, 29873],
         ...,
         [29899, 29892, 29871,  ..., 29915,   315, 29874],
         [29899, 29871, 29874,  ..., 29896, 29909, 29889],
         [29899, 29892,    13,  ...,   376,   315,   323]]], device='cuda:0')
Batch 37, 61.1% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 18252, 21300,  ...,  1335, 29914,  1990],
        [    1,   849, 29871,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.5312,  -2.1426,   2.1641,  ...,  -3.1152,  -4.0117,  -3.1406],
         [ -6.5664,  -4.7500,   3.6270,  ...,  -3.6406,  -3.9883,  -3.8965],
         ...,
         [ -9.7891, -10.7500,   2.9844,  ...,  -6.0625,  -5.3711,  -5.9258],
         [ -7.3672, -12.4766,  -3.6172,  ...,  -7.0859,  -3.1836,  -7.2148],
         [-10.7422, -16.0781,  -1.8623,  ...,  -7.9297,  -4.8281,  -7.5938]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.6055,  -3.9805,   3.0234,  ...,  -3.8086,  -4.3789,  -3.0312],
         [-10.0469, -12.3906,   0.2815,  ...,  -6.4062,  -3.6621,  -5.3906],
         ...,
         [-10.6797, -12.3281,   2.8281,  ...,  -7.5938,  -5.0547,  -7.1953],
         [-10.6953, -12.3438,   2.8594,  ...,  -7.5938,  -5.0508,  -7.1758],
         [-10.7344, -12.4688,   2.7930,  ...,  -7.6523,  -5.0430,  -7.2344]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29889],
         [29874],
         ...,
         [29874],
         [29892],
         [29871]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29874],
         [29874],
         [29874]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 31147,  ...,   856,   313,   349],
         [29874, 29875, 29933,  ..., 29873,   294, 29911],
         ...,
         [29874, 29871, 29899,  ..., 29896, 29914,    13],
         [29892,   376,   349,  ...,   297, 29879, 29889],
         [29871, 29874, 29899,  ..., 29924, 29879, 29933]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29871, 29874, 29915,  ..., 29892, 29924, 29933],
         ...,
         [29874, 29871, 29899,  ...,   376, 29915,   392],
         [29874, 29871, 29899,  ...,   376, 29915,   392],
         [29874, 29871, 29899,  ...,   376, 29915,   392]]], device='cuda:0')
Batch 38, 68.3% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 29807,    13,  ..., 29900, 29896,    12],
        [    1,   396,  5293,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-9.0156e+00,  8.4473e-01,  8.0713e-01,  ..., -3.0449e+00,
          -5.3750e+00, -2.3574e+00],
         [-6.3438e+00, -5.8398e+00,  2.6992e+00,  ..., -4.0742e+00,
          -4.3438e+00, -3.7852e+00],
         [-9.1641e+00,  3.9038e-01,  4.4414e+00,  ..., -3.3633e+00,
          -4.0391e+00, -1.5605e+00],
         ...,
         [-9.3438e+00, -1.0141e+01,  3.3809e+00,  ..., -6.1406e+00,
          -5.3828e+00, -5.3945e+00],
         [-5.9727e+00, -5.5078e+00,  2.3496e+00,  ..., -4.1016e+00,
          -4.4023e+00, -3.6348e+00],
         [-9.0156e+00, -8.7188e+00,  3.5156e+00,  ..., -5.5703e+00,
          -5.5469e+00, -5.4453e+00]],

        [[-9.0156e+00,  8.4473e-01,  8.0713e-01,  ..., -3.0449e+00,
          -5.3750e+00, -2.3574e+00],
         [-6.7344e+00, -4.8047e+00,  3.3887e+00,  ..., -4.3633e+00,
          -4.1172e+00, -3.7773e+00],
         [-9.2031e+00, -1.4992e+01, -8.8348e-03,  ..., -7.0742e+00,
          -2.8086e+00, -7.1602e+00],
         ...,
         [-4.5664e+00,  1.2529e+00, -3.5469e+00,  ..., -2.1387e+00,
          -3.1230e+00, -2.2578e+00],
         [-4.6016e+00,  1.2666e+00, -3.5566e+00,  ..., -2.1406e+00,
          -3.1348e+00, -2.2598e+00],
         [-4.6367e+00,  1.3330e+00, -3.5742e+00,  ..., -2.1250e+00,
          -3.1348e+00, -2.2402e+00]]], device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29871],
         [  313],
         ...,
         [29896],
         [29899],
         [29871]],

        [[29918],
         [29871],
         [29874],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915, 29889,   856],
         [  313,   306,   363,  ...,    12,    13,   304],
         ...,
         [29896, 29871, 29892,  ..., 29882,   856, 29875],
         [29899, 29892, 29871,  ...,    13, 29915, 29882],
         [29871, 29892, 29899,  ..., 29874,   315, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ...,   349, 29896, 29915],
         [29874, 29871, 29899,  ..., 29875,   392,   262],
         ...,
         [30488, 30879, 31147,  ..., 30282, 29915,   392],
         [30488, 30879, 31147,  ..., 29915, 30282,   392],
         [30488, 30879, 30140,  ..., 29915,   392,   313]]], device='cuda:0')
Batch 39, 73.2% of total tokens
encoded shape: torch.Size([2, 1697])
torch.Size([2, 1697]) tensor([[   1,  376, 1509,  ...,    2,    2,    2],
        [   1,  444,  694,  ...,   13,   13,   13]], device='cuda:0')
torch.Size([2, 1697, 32000]) tensor([[[-8.9844,  0.8760,  0.7637,  ..., -3.0312, -5.3516, -2.3477],
         [-7.4141, -5.8125,  5.1094,  ..., -4.5586, -4.6836, -4.3516],
         [-6.0156, -5.1172,  2.4609,  ..., -3.6484, -4.4414, -3.3691],
         ...,
         [-5.3008,  0.4053, -3.5215,  ..., -2.3984, -3.3145, -2.6641],
         [-5.3125,  0.4338, -3.5312,  ..., -2.3945, -3.3145, -2.6562],
         [-5.2891,  0.4646, -3.5312,  ..., -2.3867, -3.3164, -2.6465]],

        [[-8.9844,  0.8760,  0.7637,  ..., -3.0312, -5.3516, -2.3477],
         [-4.9961, -3.4004,  2.1465,  ..., -3.4277, -3.8730, -3.1777],
         [-5.4180, -4.5820,  2.7344,  ..., -3.5098, -4.2852, -3.2480],
         ...,
         [-5.5156, -4.5625,  1.2803,  ..., -3.9082, -4.2031, -3.8594],
         [-6.3867, -5.9336,  1.9639,  ..., -5.2695, -4.1406, -4.3594],
         [-6.8438, -6.6367,  2.1934,  ..., -4.8633, -4.3945, -4.3008]]],
       device='cuda:0')
torch.Size([2, 1697, 1]) tensor([[[29918],
         [29892],
         [29899],
         ...,
         [29915],
         [29915],
         [29915]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29892],
         [29930],
         [29899]]], device='cuda:0')
torch.Size([2, 1697, 10]) tensor([[[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29892, 29871,   313,  ..., 29874,   376,   315],
         [29899, 29874, 29892,  ..., 29915,   392, 29896],
         ...,
         [29915, 30010,   313,  ...,   306,   856,   392],
         [29915, 30010,   313,  ...,   306,   856,   392],
         [29915, 30010,   313,  ...,   306,   856,   392]],

        [[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29899, 29892,  ..., 29915,   262, 29896],
         [29871, 29899, 29892,  ..., 29915,   349, 29896],
         ...,
         [29892,   392, 29889,  ..., 29871,   262,   317],
         [29930, 29899, 29892,  ..., 29871, 29889,   349],
         [29899, 29892,   313,  ..., 29915,   376,   315]]], device='cuda:0')
Batch 40, 75.1% of total tokens
encoded shape: torch.Size([2, 902])
torch.Size([2, 902]) tensor([[    1,   849, 14187,  ...,  1800,   890,    13],
        [    1,   773,  2184,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 902, 32000]) tensor([[[-9.0156,  0.8442,  0.8076,  ..., -3.0449, -5.3750, -2.3594],
         [-5.6094, -3.9844,  3.0273,  ..., -3.8086, -4.3789, -3.0312],
         [-7.6016, -7.1445,  3.5781,  ..., -4.6836, -4.0195, -3.3320],
         ...,
         [-3.7305, -2.3965,  1.2461,  ..., -3.1504, -3.8887, -2.7324],
         [-5.3281, -4.2891,  1.9951,  ..., -3.9238, -4.2773, -3.5332],
         [-6.2422, -5.1680,  3.4746,  ..., -4.3789, -4.8477, -3.8691]],

        [[-9.0156,  0.8442,  0.8076,  ..., -3.0449, -5.3750, -2.3594],
         [-5.1680, -3.9180,  2.3418,  ..., -3.4570, -3.8730, -3.1172],
         [-7.3438, -6.6875,  4.5078,  ..., -3.4941, -4.3633, -4.2930],
         ...,
         [-7.1953, -9.1328, -7.1641,  ..., -4.7773, -1.9570, -5.3945],
         [-7.1836, -9.0938, -7.1680,  ..., -4.7383, -1.9189, -5.3633],
         [-7.1758, -9.0625, -7.1680,  ..., -4.7227, -1.9102, -5.3516]]],
       device='cuda:0')
torch.Size([2, 902, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [30488],
         [29889],
         [29871]],

        [[29918],
         [29892],
         [29874],
         ...,
         [14131],
         [14131],
         [14131]]], device='cuda:0')
torch.Size([2, 902, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29874, 29871, 29899,  ...,   856, 29903, 29882],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [29889, 29871, 29892,  ...,   313, 29915, 29896],
         [29871,    13, 29892,  ...,   315, 29874, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29874, 29889,  ..., 29915, 29882,   313],
         [29874,   262, 29881,  ..., 29896, 29903, 29933],
         ...,
         [14131, 23333, 30057,  ..., 30010, 22752,  1131],
         [14131, 23333, 30057,  ..., 30010, 22752,  1131],
         [14131, 23333, 30057,  ..., 30010, 22752,  1131]]], device='cuda:0')
Batch 41, 76.2% of total tokens
encoded shape: torch.Size([2, 1351])
torch.Size([2, 1351]) tensor([[    1,  4949,    13,  ...,    13, 29913,    13],
        [    1, 29871, 30143,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1351, 32000]) tensor([[[-8.9844,  0.8760,  0.7637,  ..., -3.0312, -5.3516, -2.3477],
         [-4.4336, -2.8066,  2.1680,  ..., -3.4434, -4.0586, -2.8242],
         [-9.0156,  0.1042,  5.9102,  ..., -3.7754, -4.9883, -1.0078],
         ...,
         [-5.7891, -4.7031,  2.6602,  ..., -3.9082, -4.7383, -3.6523],
         [-6.2383, -5.2930,  2.1484,  ..., -4.3281, -4.6875, -3.8711],
         [-6.7188, -5.6172,  3.2070,  ..., -4.6523, -5.2852, -4.0391]],

        [[-8.9844,  0.8760,  0.7637,  ..., -3.0312, -5.3516, -2.3477],
         [-5.7227, -4.3711,  3.1621,  ..., -3.7773, -4.3516, -3.3789],
         [-4.0273, -2.2617,  1.7119,  ..., -3.1777, -3.9668, -2.6914],
         ...,
         [-5.6641, -4.0195,  2.4473,  ..., -4.0820, -4.4570, -3.5957],
         [-5.6328, -4.0000,  2.4375,  ..., -4.0664, -4.4492, -3.5781],
         [-5.6016, -3.9766,  2.4258,  ..., -4.0508, -4.4414, -3.5625]]],
       device='cuda:0')
torch.Size([2, 1351, 1]) tensor([[[29918],
         [30488],
         [  313],
         ...,
         [29892],
         [29889],
         [29871]],

        [[29918],
         [29871],
         [30488],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 1351, 10]) tensor([[[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [  313,    13,   306,  ...,   891,   376,  1346],
         ...,
         [29892, 29889, 29871,  ...,   313,    13,   315],
         [29889, 29899, 29892,  ...,    13, 29933,   262],
         [29871, 29892,    13,  ..., 29915,   315,   349]],

        [[29918, 29879, 29915,  ..., 29973,   363, 29871],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [30488, 31147, 30879,  ...,   313, 29899,   856],
         ...,
         [29871, 29892, 29889,  ...,   315, 29915,   349],
         [29871, 29892, 29889,  ..., 29915,   315,   349],
         [29871, 29892, 29889,  ..., 29915,   315,   349]]], device='cuda:0')
Batch 42, 78.4% of total tokens
encoded shape: torch.Size([2, 1137])
torch.Size([2, 1137]) tensor([[    1,  6319,  3134,  ..., 11010, 29958,    13],
        [    1,   529,  6510,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1137, 32000]) tensor([[[-9.0156,  0.8442,  0.8076,  ..., -3.0449, -5.3750, -2.3594],
         [-4.6875, -2.9629,  2.2520,  ..., -3.3125, -4.3047, -3.0781],
         [-4.6797, -3.3770,  2.1719,  ..., -3.4277, -3.8867, -3.0625],
         ...,
         [-6.1797, -5.6719,  1.5166,  ..., -4.1094, -4.1328, -3.7168],
         [-5.7852, -5.1133,  1.9209,  ..., -3.9004, -4.5078, -3.5293],
         [-5.4102, -4.5039,  2.0469,  ..., -3.8594, -4.5234, -3.2422]],

        [[-9.0156,  0.8442,  0.8076,  ..., -3.0449, -5.3750, -2.3594],
         [-5.2188, -3.7051,  2.7812,  ..., -3.8164, -4.2148, -3.3145],
         [-4.6953, -3.2578,  2.0332,  ..., -3.4453, -3.9375, -3.1543],
         ...,
         [-7.7031,  0.4587, -3.1602,  ..., -2.3535, -3.5703, -2.6680],
         [-7.6133,  0.4917, -3.1816,  ..., -2.3711, -3.5684, -2.6758],
         [-7.5703,  0.4500, -3.2480,  ..., -2.3809, -3.5469, -2.6934]]],
       device='cuda:0')
torch.Size([2, 1137, 1]) tensor([[[29918],
         [29871],
         [29899],
         ...,
         [29899],
         [29899],
         [29871]],

        [[29918],
         [29871],
         [29899],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 1137, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29899, 29874, 29889,  ..., 29875, 30488, 29915],
         ...,
         [29899, 29874, 29871,  ..., 29896, 29882, 29924],
         [29899, 29871, 29889,  ..., 29933, 29896, 29875],
         [29871, 29899, 29892,  ..., 29874, 29875,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29889,  ..., 29874,   349,   315],
         [29899, 29889, 29871,  ..., 29874, 29915,   315],
         ...,
         [30010, 29915,   891,  ..., 30140,   353, 29987],
         [30010, 29915,   229,  ..., 30140, 29987,   353],
         [30010, 29915,   229,  ..., 30140, 29987,   353]]], device='cuda:0')
Batch 43, 79.6% of total tokens
encoded shape: torch.Size([2, 908])
torch.Size([2, 908]) tensor([[   1, 4949,  402,  ..., 1649, 3776,   13],
        [   1, 4949,   13,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 908, 32000]) tensor([[[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.4336,  -2.8066,   2.1660,  ...,  -3.4414,  -4.0586,  -2.8242],
         [ -9.8125, -12.5625,   1.4502,  ...,  -6.5977,  -4.3164,  -7.3711],
         ...,
         [-10.6328, -13.0312,   1.4297,  ...,  -6.2500,  -5.2227,  -6.3008],
         [-10.2188, -11.3047,   2.8145,  ...,  -5.6641,  -5.7227,  -5.6055],
         [ -9.9688, -11.1875,   3.2031,  ...,  -6.1836,  -6.1758,  -5.6484]],

        [[ -9.0156,   0.8428,   0.8081,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.4336,  -2.8066,   2.1660,  ...,  -3.4414,  -4.0586,  -2.8242],
         [ -9.0078,   0.0878,   5.4492,  ...,  -3.8086,  -4.9453,  -1.0830],
         ...,
         [ -8.3750,  -7.6680,   3.3496,  ...,  -5.3281,  -4.9414,  -4.9141],
         [ -8.5547,  -7.8711,   3.3418,  ...,  -5.4180,  -4.9492,  -5.0156],
         [ -8.8438,  -8.2266,   3.3477,  ...,  -5.5781,  -4.9922,  -5.1914]]],
       device='cuda:0')
torch.Size([2, 908, 1]) tensor([[[29918],
         [30488],
         [29899],
         ...,
         [29874],
         [29899],
         [29871]],

        [[29918],
         [30488],
         [  313],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 908, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [29899, 29871, 29892,  ..., 29915,   376,   341],
         ...,
         [29874, 29899, 29933,  ...,   262,   294, 29875],
         [29899, 29874, 29933,  ..., 29882, 29896,   262],
         [29871, 29899,    13,  ...,   349, 29875,   313]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [  313,   306,    13,  ...,   373,   376,  1346],
         ...,
         [29871, 29899,    13,  ..., 29915,   349,   856],
         [29871, 29899,    13,  ..., 29915,   349, 29898],
         [29871, 29899,    13,  ..., 29915,   349, 29898]]], device='cuda:0')
Batch 44, 81.4% of total tokens
encoded shape: torch.Size([2, 545])
torch.Size([2, 545]) tensor([[    1,   396,  3450,  ...,  2752,  6507,    13],
        [    1, 29871, 29896,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 545, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -6.7461,  -4.8164,   3.3945,  ...,  -4.3672,  -4.1172,  -3.7832],
         [-10.5469, -13.1328,   3.9805,  ...,  -5.6484,  -4.5742,  -5.9414],
         ...,
         [ -6.3711, -10.3438,  -4.2695,  ...,  -1.8438,   1.2002,  -2.1738],
         [ -6.3750, -10.2578,  -0.8711,  ...,  -3.9023,  -0.0219,  -3.0137],
         [-11.5625, -15.2578,   2.3984,  ...,  -8.8906,  -6.4688,  -7.9883]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7754,  -4.3477,  -3.3770],
         [ -6.7656,  -4.9258,   3.0273,  ...,  -3.6562,  -4.2461,  -4.0078],
         ...,
         [ -7.2344,  -0.9517,  -4.7148,  ...,  -3.0488,  -3.7363,  -3.1406],
         [ -7.2383,  -0.9194,  -4.7148,  ...,  -3.0410,  -3.7344,  -3.1328],
         [ -7.2891,  -0.8242,  -4.6484,  ...,  -3.0547,  -3.7617,  -3.1152]]],
       device='cuda:0')
torch.Size([2, 545, 1]) tensor([[[29918],
         [29871],
         [29871],
         ...,
         [29894],
         [29894],
         [29899]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29915],
         [29915],
         [29915]]], device='cuda:0')
torch.Size([2, 545, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ..., 29896,   349, 29915],
         [29871, 29899, 29874,  ..., 29915,   392, 29882],
         ...,
         [29894, 29909,   276,  ...,   287, 29950,   519],
         [29894, 29924, 29909,  ..., 21490,  5062, 29872],
         [29899, 29892, 29874,  ..., 29889,   313, 29915]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [29871, 29874, 29899,  ...,   376,   313,   856],
         ...,
         [29915, 30010, 30057,  ...,   891,   785,   376],
         [29915, 30010, 30057,  ...,   891,   785,   376],
         [29915, 30010, 30057,  ..., 29987,   785,   376]]], device='cuda:0')
Batch 45, 82.0% of total tokens
encoded shape: torch.Size([2, 342])
torch.Size([2, 342]) tensor([[    1,   849,  2045,   597,  1636, 29889,  1639,  1493,  2966, 29889,
           510, 29914, 17199, 29879, 29914,   326,  2037, 29899, 13519, 29899,
          2220, 29914,    13,    13,   524, 24380,  1057, 12248, 29898,   524,
           921, 29892,   938,   302, 29892,   938,   270, 29897,   426,    13,
          1678,   849,  1938,   451,  2436,  1667,   580,   740, 29889,    13,
          1678,   849,  1938,   451,  1303,  1881, 29892,  2012,   671,   278,
          6273,   304,   278,   740, 29889,    13,  1678,   849,  1938,   451,
          1596,   278,  1962, 29892,  2012,   736,  1819,   408,  6790,    13,
          1678,   849, 12074,   505,   263,  7404, 29889,  5399,   449,  7821,
         29889,  1639,  1493,  2966, 29889,   510, 29914, 12292, 29914, 11249,
         29918, 18137, 29914,   363,   901,  4902,    13,    13,  1678,  1472,
          1472,   938,  1083,   353, 29871, 29896, 29936,    13,  1678,   938,
          1423,   353, 29871, 29900, 29936,    13,   268,    13,  1678,   565,
         29898, 29916,  1275, 29871, 29900,  2597,    13,  4706,   736, 29871,
         29900, 29936,    13,  1678,   500,    13,  1678,   565, 29898, 29876,
          1275, 29871, 29900,  2597,    13,  4706,   736, 29871, 29896, 29936,
            13,  1678,   500,    13,   268,    13,  1678,   565, 29898, 29916,
           529, 29871, 29900,  2597,    13,  4706,   921,   353,  6425, 29898,
         29916,   416,    13,  4706,   565, 29898, 29876, 29995, 29906,  2804,
         29871, 29900,  2597,    13,  9651,  1423,   353, 29871, 29896, 29936,
            13,  4706,   500,    13,  1678,   500,    13,   268,    13,  1678,
          1472,  1472,   938,  5694,   353,   921, 29995, 29881, 29936,    13,
           268,    13,  1678,  1550, 29898, 29876,  2804, 29871, 29900,  2597,
            13,  4706,   565, 29898, 29876, 29995, 29906,  2804, 29871, 29900,
          2597,    13,  9651,  1083,   353,   313,  1745, 29930,  7382, 29897,
         29995, 29881, 29936,    13,  4706,   500,    13,   308,    13,  4706,
          5694,   353,  5694, 29930,  7382, 29936,    13,  4706,  5694,   353,
          5694, 29995, 29881, 29936,    13,   308,    13,  4706,   302,   353,
           302, 29914, 29906, 29936,    13,  4706,   565, 29898,  1745,  1405,
           270,  2597,    13,  9651,  1083,   353,  1083, 29995, 29881, 29936,
            13,  4706,   500,    13,  1678,   500,    13,   268,    13,  1678,
           565, 29898,  3198,  1275, 29871, 29896,  2597,    13,  4706,   736,
           270, 17722,   524, 29897,  1745, 29936,    13,  1678,   500,    13,
           268,    13,  1678,   736,   313,   524, 29897,  1745, 29936,    13,
         29913,    13],
        [    1,  1996,   525,  8690,  3149, 29918,  4645, 29915,    13,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 342, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -5.6133,  -3.9941,   3.0273,  ...,  -3.8145,  -4.3867,  -3.0371],
         [ -4.7617,  -3.4375,   2.6094,  ...,  -3.5312,  -4.2695,  -3.0488],
         ...,
         [-10.0859, -14.2891,  -2.1875,  ...,  -6.2461,  -4.1250,  -7.2266],
         [-11.4141, -14.1172,   1.1660,  ...,  -7.1875,  -6.0391,  -8.0469],
         [ -8.3438,  -8.8203,   2.5215,  ...,  -5.3164,  -5.5859,  -4.8633]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -4.8164,  -3.5664,   2.6074,  ...,  -3.3867,  -3.9414,  -2.8730],
         [ -7.9102,  -7.7031,   4.0312,  ...,  -5.4688,  -4.6992,  -4.7188],
         ...,
         [ -7.5039,  -7.7539,  -7.4336,  ...,  -4.5703,  -1.7236,  -5.1602],
         [ -7.6875,  -7.9531,  -7.4961,  ...,  -4.8242,  -2.1328,  -5.3516],
         [ -7.8828,  -7.6719,  -7.5625,  ...,  -4.8633,  -2.3945,  -5.3672]]],
       device='cuda:0')
torch.Size([2, 342, 1]) tensor([[[29918],
         [29871],
         [29871],
         [29871],
         [30488],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [29889],
         [30488],
         [29899],
         [29892],
         [29899],
         [29892],
         [29874],
         [29889],
         [29871],
         [29871],
         [29874],
         [29874],
         [30488],
         [  313],
         [29892],
         [29909],
         [29874],
         [  262],
         [29874],
         [29871],
         [29875],
         [29874],
         [29899],
         [29874],
         [29871],
         [29899],
         [29874],
         [29892],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [  262],
         [29874],
         [29874],
         [29874],
         [29874],
         [  262],
         [29874],
         [29874],
         [29874],
         [29875],
         [29875],
         [29874],
         [29899],
         [29874],
         [29874],
         [29899],
         [  262],
         [29874],
         [29874],
         [29933],
         [29874],
         [29874],
         [ 1457],
         [29874],
         [29874],
         [29875],
         [  262],
         [29899],
         [29874],
         [  856],
         [  262],
         [29874],
         [29874],
         [29874],
         [  262],
         [29899],
         [29874],
         [29871],
         [29892],
         [29874],
         [29874],
         [29924],
         [29874],
         [  262],
         [29892],
         [29874],
         [29892],
         [29899],
         [29924],
         [29875],
         [29892],
         [29874],
         [29924],
         [29874],
         [29899],
         [29899],
         [29874],
         [29874],
         [29874],
         [29909],
         [  392],
         [29898],
         [29871],
         [29874],
         [29875],
         [29875],
         [29874],
         [29924],
         [  261],
         [29896],
         [29871],
         [29875],
         [29874],
         [ 1678],
         [29871],
         [29875],
         [29874],
         [29898],
         [  270],
         [29995],
         [29896],
         [29900],
         [29931],
         [29874],
         [29875],
         [29874],
         [29898],
         [29896],
         [29931],
         [29874],
         [29874],
         [29871],
         [29898],
         [29903],
         [29874],
         [29898],
         [  270],
         [29995],
         [29900],
         [29871],
         [ 1131],
         [29874],
         [29875],
         [29874],
         [29896],
         [29896],
         [29931],
         [29874],
         [29874],
         [29874],
         [29903],
         [  268],
         [29871],
         [29875],
         [29874],
         [29898],
         [  270],
         [29995],
         [29900],
         [29900],
         [ 1131],
         [29874],
         [29875],
         [29874],
         [29875],
         [29875],
         [29898],
         [30010],
         [29950],
         [29909],
         [29895],
         [29881],
         [29898],
         [  270],
         [29995],
         [29906],
         [ 1131],
         [29900],
         [29871],
         [ 1131],
         [29881],
         [29903],
         [29881],
         [  891],
         [29896],
         [29896],
         [29900],
         [29874],
         [ 2236],
         [29874],
         [29903],
         [29895],
         [29874],
         [29903],
         [  268],
         [29871],
         [29875],
         [29874],
         [29874],
         [  524],
         [ 4704],
         [29896],
         [29898],
         [29875],
         [  270],
         [29896],
         [29874],
         [29903],
         [29871],
         [29875],
         [29874],
         [29898],
         [  270],
         [29995],
         [29900],
         [29900],
         [ 1131],
         [29874],
         [29875],
         [29874],
         [29898],
         [  270],
         [29995],
         [29906],
         [ 1131],
         [29900],
         [29871],
         [ 1131],
         [29874],
         [29875],
         [29874],
         [29930],
         [  392],
         [  270],
         [29930],
         [ 7382],
         [29995],
         [29995],
         [  270],
         [29874],
         [29874],
         [ 2236],
         [29874],
         [29903],
         [29895],
         [29871],
         [29934],
         [29874],
         [29930],
         [29898],
         [29930],
         [  270],
         [29995],
         [29875],
         [29875],
         [29881],
         [29995],
         [29898],
         [29995],
         [  270],
         [29936],
         [29874],
         [29895],
         [29871],
         [29875],
         [29874],
         [  370],
         [29898],
         [ 6778],
         [29871],
         [29874],
         [29874],
         [29903],
         [29874],
         [29898],
         [  270],
         [29995],
         [29874],
         [29930],
         [29874],
         [29875],
         [29874],
         [29995],
         [29881],
         [29995],
         [  270],
         [29936],
         [29874],
         [29906],
         [29874],
         [29874],
         [29903],
         [29874],
         [29874],
         [29875],
         [29871],
         [29875],
         [29874],
         [29898],
         [  270],
         [29995],
         [29896],
         [29896],
         [ 1131],
         [29874],
         [29875],
         [29874],
         [29898],
         [29930],
         [  313],
         [29874],
         [  313],
         [29875],
         [29874],
         [29903],
         [29874],
         [29903],
         [29903],
         [29871],
         [29875],
         [29874],
         [29881],
         [  313],
         [29874],
         [  313],
         [29896],
         [29874],
         [29875],
         [29874],
         [29871]],

        [[29918],
         [29899],
         [29892],
         [29871],
         [29899],
         [29909],
         [29899],
         [29874],
         [   13],
         [29871],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [    2],
         [    2],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29874],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29899],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29889],
         [29889],
         [29889],
         [29889],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29892],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [23333],
         [23333],
         [29871],
         [29871],
         [29871],
         [29871],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [29892],
         [29892],
         [29892],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29871],
         [29892],
         [29892],
         [29892],
         [29892],
         [30010],
         [30010],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [29871],
         [29892],
         [29892],
         [29871],
         [30010],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333],
         [10266],
         [10266],
         [10266],
         [10266],
         [23333],
         [23333],
         [23333],
         [23333],
         [23333]]], device='cuda:0')
torch.Size([2, 342, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29871, 29889, 29892,  ...,    13,   315,   349],
         ...,
         [29875, 29874,   370,  ..., 29895,   300,   295],
         [29874, 29875, 29871,  ..., 29899, 29903, 29898],
         [29871, 29899, 29892,  ...,    13, 29875, 29898]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29899, 29892, 29871,  ...,   856,   313, 31147],
         [29892, 29889, 29871,  ..., 29896,   349,   376],
         ...,
         [23333, 10266, 14131,  ...,   538,  4345, 30010],
         [23333, 10266, 30057,  ...,   891, 30010,  4345],
         [23333, 10266, 30057,  ..., 30119,  4345,  1131]]], device='cuda:0')
Batch 46, 82.4% of total tokens
encoded shape: torch.Size([2, 551])
torch.Size([2, 551]) tensor([[   1, 3577, 1226,  ...,    2,    2,    2],
        [   1, 1053,  426,  ...,   13, 3400,   13]], device='cuda:0')
torch.Size([2, 551, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -6.2266,  -4.9883,   2.5332,  ...,  -3.9023,  -3.2871,  -3.4941],
         [ -7.7891,  -6.3398,   3.6895,  ...,  -4.5859,  -5.1875,  -4.7930],
         ...,
         [ -5.8594,  -4.2969,   2.9160,  ...,  -4.1445,  -4.4297,  -3.5664],
         [ -5.8750,  -4.3125,   2.9258,  ...,  -4.1562,  -4.4336,  -3.5762],
         [ -5.8672,  -4.3086,   2.9199,  ...,  -4.1562,  -4.4336,  -3.5742]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0469,  -5.3789,  -2.3613],
         [ -5.2773,  -3.7891,   1.9150,  ...,  -3.6289,  -4.0312,  -2.8594],
         [ -9.3047, -10.5859,   1.8877,  ...,  -6.3711,  -4.5195,  -5.0859],
         ...,
         [-10.4688, -15.5703,   0.0222,  ...,  -6.5547,  -4.3398,  -8.3438],
         [-12.3828, -15.1797,   2.8574,  ...,  -7.5508,  -6.1719,  -7.9102],
         [-13.0703, -18.8594,   2.9062,  ...,  -9.0938,  -7.4609,  -8.8594]]],
       device='cuda:0')
torch.Size([2, 551, 1]) tensor([[[29918],
         [29892],
         [29871],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29918],
         [29899],
         [29892],
         ...,
         [29906],
         [29874],
         [29899]]], device='cuda:0')
torch.Size([2, 551, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29898,  ...,   262, 29915,   856],
         [29871,   313, 29892,  ...,   315, 29915, 29889],
         ...,
         [29871, 29892, 29899,  ..., 29915, 29874,   349],
         [29871, 29892, 29899,  ..., 29915, 29874,   349],
         [29871, 29892, 29899,  ..., 29915, 29874,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29899, 29892, 29889,  ...,   313, 29896,   856],
         [29892, 29874, 29899,  ...,   262, 29909, 29898],
         ...,
         [29906, 29896, 29924,  ..., 29950, 29903, 29909],
         [29874, 29899, 29875,  ..., 29924,    13, 29950],
         [29899, 29871,    13,  ..., 29875,   315, 29915]]], device='cuda:0')
Batch 47, 83.3% of total tokens
encoded shape: torch.Size([2, 3323])
torch.Size([2, 3323]) tensor([[    1,   849,   448,  ..., 15224, 29871,    13],
        [    1, 29871, 30143,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3323, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.6055,  -3.9805,   3.0234,  ...,  -3.8086,  -4.3789,  -3.0312],
         [-10.0938, -10.7812,   3.7402,  ...,  -5.1758,  -5.3281,  -5.7031],
         ...,
         [ -7.0234,  -6.9922,   1.9316,  ...,  -4.3945,  -4.6094,  -4.0195],
         [-12.1406, -15.2344,   0.9243,  ...,  -8.2344,  -4.6914,  -7.3750],
         [ -9.4375, -10.6094,   3.1895,  ...,  -6.4688,  -6.4727,  -4.8008]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.7188,  -4.3633,   3.1621,  ...,  -3.7734,  -4.3477,  -3.3750],
         [ -4.0234,  -2.2539,   1.7109,  ...,  -3.1738,  -3.9629,  -2.6895],
         ...,
         [ -6.0977,   2.0293,  -3.2910,  ...,  -2.3457,  -4.0078,  -2.3594],
         [ -6.0508,   2.0254,  -3.3320,  ...,  -2.3379,  -3.9863,  -2.3613],
         [ -6.0234,   2.0312,  -3.3496,  ...,  -2.3281,  -3.9648,  -2.3555]]],
       device='cuda:0')
torch.Size([2, 3323, 1]) tensor([[[29918],
         [29871],
         [29930],
         ...,
         [29933],
         [29871],
         [29871]],

        [[29918],
         [29871],
         [30488],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 3323, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29930, 29899, 29874,  ..., 30010,   313,   315],
         ...,
         [29933, 29924,   262,  ..., 29911, 29903, 29896],
         [29871, 29874, 29899,  ..., 29909, 29907, 29931],
         [29871, 29899,    13,  ..., 29896,   856,   313]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ..., 29915,   856, 29896],
         [30488, 31147, 30879,  ...,   313, 29899,   856],
         ...,
         [30010, 29915,   313,  ..., 29918,   376,   306],
         [30010, 29915,   313,  ..., 29918,   376,   306],
         [30010, 29915,   313,  ...,   376, 29918,   306]]], device='cuda:0')
Batch 48, 86.7% of total tokens
encoded shape: torch.Size([2, 740])
torch.Size([2, 740]) tensor([[    1,   849, 14187,  ...,  8259,   416,    13],
        [    1,   395,  6779,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 740, 32000]) tensor([[[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -5.6133,  -3.9941,   3.0273,  ...,  -3.8145,  -4.3867,  -3.0371],
         [ -7.5977,  -7.1367,   3.5762,  ...,  -4.6836,  -4.0195,  -3.3340],
         ...,
         [ -9.2422, -14.2734,  -1.1592,  ...,  -7.2148,  -3.3066,  -8.1094],
         [-10.1016, -16.3906,  -3.7871,  ...,  -7.9844,  -2.8379,  -7.3828],
         [ -5.7227, -11.6641,  -4.3984,  ...,  -7.2031,  -2.9590,  -5.9648]],

        [[ -9.0156,   0.8428,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -8.1953,  -7.5000,   4.8516,  ...,  -4.8750,  -5.1836,  -4.5703],
         [ -8.2812,  -7.8594,   3.2578,  ...,  -4.5273,  -5.1016,  -4.2734],
         ...,
         [ -8.6562, -11.6562,  -3.2188,  ...,  -6.7344,  -2.1309,  -7.0938],
         [ -8.6328, -11.5234,  -3.2246,  ...,  -6.6094,  -2.0156,  -6.9766],
         [ -8.6172, -11.3906,  -3.1133,  ...,  -6.4492,  -1.8467,  -6.8398]]],
       device='cuda:0')
torch.Size([2, 740, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29874],
         [29874],
         [  285]],

        [[29918],
         [29871],
         [29899],
         ...,
         [29892],
         [29892],
         [29892]]], device='cuda:0')
torch.Size([2, 740, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29874, 29871, 29899,  ...,   856, 29903, 29882],
         ...,
         [29874, 29875, 29882,  ...,   517,   392,   376],
         [29874, 29909, 29875,  ..., 29950, 29934, 29906],
         [  285, 29892,  2169,  ...,  2308, 29879,   260]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ..., 29889,   315,   376],
         [29899, 29874, 29871,  ..., 29915,   376,   349],
         ...,
         [29892, 29915,   376,  ..., 30010,   263,   448],
         [29892, 29915,   376,  ..., 30010,   263,   448],
         [29892, 29915, 29879,  ..., 30010,   448,   263]]], device='cuda:0')
Batch 49, 87.8% of total tokens
encoded shape: torch.Size([2, 1027])
torch.Size([2, 1027]) tensor([[    1,  4949,    13,  ...,     2,     2,     2],
        [    1,   529,  4563,  ...,   829,  4563, 29958]], device='cuda:0')
torch.Size([2, 1027, 32000]) tensor([[[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.4336,  -2.8047,   2.1660,  ...,  -3.4434,  -4.0625,  -2.8242],
         [ -9.0078,   0.0879,   5.4492,  ...,  -3.8086,  -4.9453,  -1.0830],
         ...,
         [ -8.0078, -10.9766,  -5.5977,  ...,  -6.1836,  -2.2656,  -6.7266],
         [ -7.9883, -10.9062,  -5.6523,  ...,  -6.1289,  -2.2207,  -6.6836],
         [ -8.0000, -10.8438,  -5.6484,  ...,  -6.0430,  -2.1172,  -6.6250]],

        [[ -9.0156,   0.8442,   0.8076,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -5.2188,  -3.7051,   2.7812,  ...,  -3.8164,  -4.2148,  -3.3145],
         [ -7.2930,  -6.7930,   3.2148,  ...,  -4.1328,  -4.1016,  -4.6484],
         ...,
         [ -7.7930,  -7.1992,   2.7422,  ...,  -5.1680,  -5.0625,  -4.7656],
         [ -6.5195,  -6.6836,   2.0469,  ...,  -4.4531,  -4.4609,  -4.0742],
         [-11.3047, -14.0156,   2.2891,  ...,  -7.3906,  -5.3125,  -7.2266]]],
       device='cuda:0')
torch.Size([2, 1027, 1]) tensor([[[29918],
         [30488],
         [  313],
         ...,
         [29892],
         [14131],
         [14131]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29892],
         [29874],
         [29874]]], device='cuda:0')
torch.Size([2, 1027, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ...,   313,   856, 30282],
         [  313,   306,    13,  ...,   373,   376,  1346],
         ...,
         [29892, 29879, 14131,  ...,   306,   313,   315],
         [14131, 29892, 29879,  ...,   306,   313, 23333],
         [14131, 29879, 29892,  ...,   306,   313, 23333]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29889,  ..., 29874,   349,   315],
         [29874, 29899, 29896,  ...,   262, 29909, 29933],
         ...,
         [29892, 29871, 29899,  ..., 29915,   856, 29896],
         [29874, 29871, 29899,  ..., 29924, 29882, 29950],
         [29874, 29908, 29871,  ..., 29875, 29892, 29903]]], device='cuda:0')
Batch 50, 89.3% of total tokens
encoded shape: torch.Size([2, 1043])
torch.Size([2, 1043]) tensor([[    1,  6319,  3134,  ...,  2042, 29958,    13],
        [    1,  3883,  4321,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1043, 32000]) tensor([[[-9.0156,  0.8442,  0.8076,  ..., -3.0449, -5.3750, -2.3594],
         [-4.6875, -2.9629,  2.2520,  ..., -3.3125, -4.3047, -3.0781],
         [-4.6797, -3.3770,  2.1719,  ..., -3.4277, -3.8867, -3.0625],
         ...,
         [-5.7617, -4.9609,  1.8545,  ..., -4.0000, -4.5938, -3.5547],
         [-6.0156, -5.3867,  1.9756,  ..., -3.9238, -4.5469, -3.9023],
         [-5.0898, -4.0312,  1.7959,  ..., -3.5977, -4.5078, -3.2520]],

        [[-9.0156,  0.8442,  0.8076,  ..., -3.0449, -5.3750, -2.3594],
         [-6.6719, -5.8477,  2.3516,  ..., -3.0996, -3.1953, -3.2148],
         [-8.5234, -9.6016,  3.1191,  ..., -4.1914, -3.9160, -5.5391],
         ...,
         [-5.0820,  1.2949, -3.5176,  ..., -2.4023, -3.4648, -2.3594],
         [-5.0547,  1.2725, -3.5137,  ..., -2.4004, -3.4570, -2.3594],
         [-5.0078,  1.2588, -3.5059,  ..., -2.3867, -3.4316, -2.3496]]],
       device='cuda:0')
torch.Size([2, 1043, 1]) tensor([[[29918],
         [29871],
         [29899],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29918],
         [29874],
         [29871],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 1043, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29889, 29892,  ..., 29915, 29874,   349],
         [29899, 29874, 29889,  ..., 29875, 30488, 29915],
         ...,
         [29871, 29899, 29892,  ...,    13,   856, 29882],
         [29871, 29899, 29892,  ...,    13,   349, 29896],
         [29871, 29899, 29892,  ...,   349, 29874,   315]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29874,   262,   392,  ..., 29909, 29882, 29896],
         [29871, 29874,   262,  ..., 29892,   315,   349],
         ...,
         [30010, 29915,   313,  ...,   392,   306, 30879],
         [30010, 29915,   313,  ...,   392, 30879,   306],
         [30010, 30488, 29915,  ...,   392, 30879,   306]]], device='cuda:0')
Batch 51, 90.4% of total tokens
encoded shape: torch.Size([2, 1465])
torch.Size([2, 1465]) tensor([[    1,  4949,  5804,  ...,    13, 29913,    13],
        [    1,   396, 29941,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1465, 32000]) tensor([[[ -9.0156,   0.8423,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -4.4414,  -2.8203,   2.1680,  ...,  -3.4512,  -4.0703,  -2.8320],
         [ -8.9453, -10.1250,   2.8691,  ...,  -5.4688,  -4.6211,  -4.7461],
         ...,
         [ -9.9922, -12.5625,  -2.0078,  ...,  -6.1445,  -2.9766,  -7.2734],
         [-10.6719, -11.4922,   1.9785,  ...,  -8.0469,  -5.2305,  -6.3789],
         [ -8.1250,  -8.9766,  -0.1250,  ...,  -6.8828,  -4.6523,  -4.4219]],

        [[ -9.0156,   0.8423,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -6.7461,  -4.8164,   3.3965,  ...,  -4.3672,  -4.1172,  -3.7832],
         [ -6.6406,  -5.3008,   2.7695,  ...,  -3.7793,  -4.0039,  -3.8867],
         ...,
         [ -5.4336,   1.8945,  -3.4863,  ...,  -2.2910,  -3.5957,  -2.3125],
         [ -5.3555,   1.8662,  -3.5176,  ...,  -2.2832,  -3.5586,  -2.3086],
         [ -5.3086,   1.8799,  -3.5254,  ...,  -2.2715,  -3.5293,  -2.2910]]],
       device='cuda:0')
torch.Size([2, 1465, 1]) tensor([[[29918],
         [30488],
         [29871],
         ...,
         [29950],
         [29874],
         [29892]],

        [[29918],
         [29871],
         [29871],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 1465, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ..., 30879,   856, 30282],
         [29871, 29899, 29874,  ..., 29909, 29882,   262],
         ...,
         [29950,   355, 29875,  ..., 29896,   262, 29903],
         [29874, 29903, 29899,  ..., 29871, 29909,    13],
         [29892, 29874, 29899,  ...,   263, 29914,   349]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ..., 29896,   349, 29915],
         [29871, 29892, 29899,  ...,   856,   349, 29915],
         ...,
         [30010, 29915,   313,  ...,   229, 29987, 29879],
         [30010, 29915,   313,  ...,   229, 29987, 29879],
         [30010, 29915,   313,  ...,   229, 29987,   363]]], device='cuda:0')
Batch 52, 91.9% of total tokens
encoded shape: torch.Size([2, 1279])
torch.Size([2, 1279]) tensor([[   1,  525, 1509,  ...,   13, 3400,   13],
        [   1,  732, 5215,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 1279, 32000]) tensor([[[ -9.0156,   0.8433,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -6.9570,  -5.4961,   4.4453,  ...,  -4.3164,  -4.7734,  -3.9961],
         [ -8.2578,  -8.6484,   3.0566,  ...,  -4.7852,  -4.8672,  -4.4102],
         ...,
         [-10.0000, -10.3203,   1.9004,  ...,  -6.3633,  -4.9453,  -6.5156],
         [ -5.7422,  -4.6914,   1.9248,  ...,  -3.9980,  -4.4766,  -3.5977],
         [ -7.0000,  -6.4531,   3.1504,  ...,  -4.8164,  -5.4648,  -4.1992]],

        [[ -9.0156,   0.8433,   0.8076,  ...,  -3.0449,  -5.3789,  -2.3613],
         [ -5.5586,  -4.0820,   2.9531,  ...,  -3.8672,  -4.4258,  -3.3809],
         [ -4.3438,  -2.5605,   2.0117,  ...,  -3.2637,  -3.8105,  -2.7363],
         ...,
         [ -6.0352,   1.1494,  -3.3965,  ...,  -2.4492,  -3.4258,  -2.5586],
         [ -6.0312,   1.1562,  -3.3984,  ...,  -2.4395,  -3.4121,  -2.5488],
         [ -6.0156,   1.1172,  -3.4160,  ...,  -2.4434,  -3.4082,  -2.5605]]],
       device='cuda:0')
torch.Size([2, 1279, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29933],
         [29889],
         [29871]],

        [[29918],
         [29871],
         [30488],
         ...,
         [30010],
         [30010],
         [30010]]], device='cuda:0')
torch.Size([2, 1279, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ...,   315, 29874,   349],
         [29874, 29899, 29875,  ...,   262, 29898, 29882],
         ...,
         [29933, 29924, 29909,  ..., 29956, 29896, 29925],
         [29889, 29871, 29892,  ..., 29915, 29875,    13],
         [29871, 29899, 29892,  ...,   856, 29915, 29874]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892,   313,  ..., 29915,   315,   856],
         [30488, 31147, 29889,  ...,   856, 29876, 29898],
         ...,
         [30010, 29915,   313,  ..., 29987,   306,   891],
         [30010, 29915, 30057,  ..., 29987,   306,   891],
         [30010, 29915, 30057,  ..., 29987,   306,   392]]], device='cuda:0')
Batch 53, 93.3% of total tokens
encoded shape: torch.Size([2, 504])
torch.Size([2, 504]) tensor([[    1,   849, 17157,  ...,     2,     2,     2],
        [    1,  1591, 29889,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 504, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.6055,  -3.9805,   3.0234,  ...,  -3.8086,  -4.3789,  -3.0312],
         [ -8.5625,  -8.9375,   2.1973,  ...,  -4.5469,  -4.5312,  -4.5234],
         ...,
         [ -9.7969, -13.2812,  -1.4414,  ...,  -7.3555,  -2.8730,  -7.4531],
         [ -9.7734, -13.3438,  -1.5488,  ...,  -7.4688,  -2.9883,  -7.5547],
         [ -9.7422, -13.3672,  -1.6289,  ...,  -7.5508,  -3.0703,  -7.6211]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.4609,  -2.9395,   1.9863,  ...,  -3.2227,  -3.9590,  -2.9922],
         [ -9.1094,  -1.6885,   6.6094,  ...,  -2.1699,  -4.7070,  -1.9502],
         ...,
         [ -8.6016, -10.3906,   2.3301,  ...,  -3.5723,  -2.1758,  -6.1484],
         [-12.2969, -17.6719,  -1.2314,  ..., -10.5391,  -4.8125,  -9.1562],
         [ -7.6328,  -9.8906,  -2.8652,  ...,  -8.2031,  -3.5273,  -5.7969]]],
       device='cuda:0')
torch.Size([2, 504, 1]) tensor([[[29918],
         [29871],
         [29874],
         ...,
         [29892],
         [29892],
         [29892]],

        [[29918],
         [30488],
         [   13],
         ...,
         [29913],
         [29874],
         [  534]]], device='cuda:0')
torch.Size([2, 504, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29874, 29899, 29875,  ..., 29896, 29909,   294],
         ...,
         [29892, 29871, 29899,  ...,   376, 30010, 29874],
         [29892, 29871, 29899,  ...,   376, 29874, 30010],
         [29892, 29871, 29899,  ...,   263, 29874, 30010]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 31147, 30879,  ...,   856, 30282,   313],
         [   13,   313, 29871,  ...,   376,   373,   304],
         ...,
         [29913, 30057, 29896,  ..., 29882,  1131,   262],
         [29874, 29899, 29924,  ..., 29892, 29909,    13],
         [  534, 29992,   509,  ...,   689,  6008, 29874]]], device='cuda:0')
Batch 54, 94.1% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  1738,   645,  ...,     2,     2,     2],
        [    1,   849, 25512,  ...,  7508,   976,  6647]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.6445,  -3.1113,   2.3203,  ...,  -3.4785,  -4.2148,  -3.0762],
         [ -4.8477,  -3.4805,   2.0254,  ...,  -3.4473,  -4.2383,  -3.0410],
         ...,
         [ -9.0312,   1.4814,   2.1250,  ...,  -3.0762,  -5.6953,  -2.1914],
         [ -9.0781,   1.4502,   2.3887,  ...,  -3.0762,  -5.7344,  -2.1543],
         [ -9.0938,   1.4297,   2.4395,  ...,  -3.0859,  -5.7461,  -2.1543]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -5.6055,  -3.9805,   3.0234,  ...,  -3.8086,  -4.3789,  -3.0312],
         [ -6.3711,  -5.1758,   2.9824,  ...,  -3.9766,  -4.5391,  -3.3086],
         ...,
         [-10.4062, -17.8594,   2.2793,  ...,  -7.1367,  -2.0508,  -7.6523],
         [ -7.2656, -12.0938,  -1.7480,  ...,  -6.7148,  -2.5430,  -6.6719],
         [-12.8672, -17.9844,   1.5645,  ...,  -8.7266,  -5.4805,  -8.6797]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [29889],
         [29871],
         ...,
         [29918],
         [29918],
         [29918]],

        [[29918],
         [29871],
         [29871],
         ...,
         [29874],
         [29892],
         [29874]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29889, 29892, 29871,  ..., 31147, 30488, 29874],
         [29871, 29892, 29899,  ..., 29874, 29915,   349],
         ...,
         [29918, 29879, 29915,  ..., 29930, 29973, 29892],
         [29918, 29879, 29915,  ..., 29973, 29930, 29892],
         [29918, 29879, 29915,  ..., 29973, 29930, 29892]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29899,  ...,   856, 29896,   315],
         [29871, 29899, 29892,  ...,   315,   856,   349],
         ...,
         [29874, 29899, 29875,  ...,   294, 29915,   271],
         [29892, 29899, 30010,  ...,   313,   319,   349],
         [29874, 29871, 29899,  ..., 29882,   315, 29915]]], device='cuda:0')
Batch 55, 98.2% of total tokens
encoded shape: torch.Size([2, 564])
torch.Size([2, 564]) tensor([[    1,  1134, 29901,  ...,     2,     2,     2],
        [    1,   529,  1420,  ...,  1420, 29958,    13]], device='cuda:0')
torch.Size([2, 564, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -4.5547,  -3.2852,   2.1523,  ...,  -3.2305,  -3.7559,  -2.8223],
         [ -5.0352,  -3.7480,   2.7129,  ...,  -3.4492,  -4.1797,  -3.0039],
         ...,
         [-11.6875, -12.0938,   2.9102,  ...,  -8.0938,  -5.6445,  -7.3945],
         [-11.6172, -11.8906,   2.9590,  ...,  -8.0000,  -5.6406,  -7.2969],
         [-11.6250, -11.8906,   2.8418,  ...,  -8.0156,  -5.6250,  -7.3125]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3594],
         [ -5.2188,  -3.7070,   2.7832,  ...,  -3.8184,  -4.2148,  -3.3164],
         [ -5.0547,  -4.0000,   2.3086,  ...,  -3.4883,  -3.9004,  -3.4023],
         ...,
         [ -6.1172,  -5.8086,   2.0977,  ...,  -4.1602,  -4.5742,  -3.7754],
         [ -6.5273,  -6.2305,   2.2363,  ...,  -4.1758,  -4.7344,  -3.8691],
         [ -5.4414,  -4.4570,   2.0352,  ...,  -3.7969,  -4.5234,  -3.2949]]],
       device='cuda:0')
torch.Size([2, 564, 1]) tensor([[[29918],
         [29871],
         [29892],
         ...,
         [29871],
         [29871],
         [29871]],

        [[29918],
         [29871],
         [29874],
         ...,
         [29871],
         [29871],
         [29871]]], device='cuda:0')
torch.Size([2, 564, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29899, 29892,  ...,   856, 29915, 29898],
         [29892, 29889, 29899,  ..., 29915, 29898,   262],
         ...,
         [29871, 29892, 29899,  ..., 29896,   856,   262],
         [29871, 29892, 29899,  ...,   856, 29896,   262],
         [29871, 29892, 29899,  ...,   856, 29896,   262]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29871, 29892, 29889,  ..., 29915,   349,   315],
         [29874, 29899, 29875,  ..., 29882, 29871, 29933],
         ...,
         [29871, 29899, 29874,  ...,   313,   262,   856],
         [29871, 29899, 29892,  ...,   313, 29896,   856],
         [29871, 29892, 29899,  ...,   349,   315, 29874]]], device='cuda:0')
Batch 56, 99.1% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  4949,    13,  ..., 29907, 29898, 29906],
        [    1,  3577, 29898,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -4.4453,  -2.8223,   2.1699,  ...,  -3.4512,  -4.0703,  -2.8320],
         [ -9.0234,   0.0874,   5.8203,  ...,  -3.7910,  -4.9961,  -1.0352],
         ...,
         [-10.2422, -17.9375,  -1.0059,  ...,  -7.3945,  -2.7910,  -7.9492],
         [-11.0156, -18.1094,  -0.4846,  ...,  -7.2305,  -3.3789,  -9.0234],
         [-11.5000, -16.2188,  -1.0469,  ...,  -6.5859,  -3.3926,  -8.5000]],

        [[ -9.0156,   0.8447,   0.8071,  ...,  -3.0449,  -5.3750,  -2.3574],
         [ -6.2266,  -4.9922,   2.5352,  ...,  -3.9062,  -3.2910,  -3.4961],
         [ -5.3164,  -3.6973,   2.5586,  ...,  -3.6973,  -4.4531,  -3.3594],
         ...,
         [ -4.2031,   1.2080,  -3.9805,  ...,  -2.1387,  -3.0840,  -2.3301],
         [ -4.2109,   1.2100,  -3.9805,  ...,  -2.1406,  -3.0879,  -2.3340],
         [ -4.2109,   1.2158,  -3.9785,  ...,  -2.1387,  -3.0840,  -2.3301]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[29918],
         [30488],
         [  313],
         ...,
         [29874],
         [29871],
         [29874]],

        [[29918],
         [29892],
         [29892],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[29918, 29879,   313,  ..., 29973, 29871,   363],
         [30488, 29889, 29871,  ..., 30879,   856, 30282],
         [  313,    13,   306,  ...,   891,   376,  1346],
         ...,
         [29874, 29871,   313,  ..., 29875,   315, 29896],
         [29871, 29906, 29892,  ..., 29941, 29896,   315],
         [29874, 29871, 29929,  ..., 29879, 29933, 29909]],

        [[29918, 29879,   313,  ..., 29973, 29871,   363],
         [29892, 29889, 29898,  ...,   262, 29915,   856],
         [29892, 29871, 29889,  ...,   315, 29915,   349],
         ...,
         [30488, 31147, 30879,  ..., 29915,   376, 30186],
         [30488, 31147, 30879,  ..., 29915,   376, 30186],
         [30488, 31147, 30879,  ..., 29915,   376, 30186]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 93])
torch.Size([2, 93]) tensor([[    1,   934,  5809,  6594, 29901, 29871, 29906,    13,  2543,   333,
         29901, 29871, 29947, 29890, 29947, 29946, 29945, 29890, 29896, 29906,
         29941,   370, 29946, 29896, 29947, 29946, 29946, 29947, 29874, 29947,
           915, 29906, 29929, 29941, 29945,  5444, 29947, 29900, 29946, 29872,
         29900,    13, 22400, 14683, 24192,  9555, 29901,    13, 29871,  7029,
         12724, 29901,  6571,    13, 29871,  1404,  1469, 29901, 29871,    13,
         29871, 24342,  9534,  1170, 29901, 29871,    13, 29871, 24342,  9534,
         10444,   424, 29901, 29871,    13,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1, 29871, 30143, 29966,  4873,    13,  1678,   921, 29901,  2385,
           543, 13579, 29918, 23145,   267, 29889,  2052, 29908,    13,  1678,
          9463,   543,  1124,   597, 11993, 29889,  4994, 29889,   510, 29914,
          5080, 11093, 29914, 29906, 29900, 29900, 29953, 29914, 29510, 29914,
         26081, 29908,    13,  1678,  9463, 29901, 29916,   543,  1124,   597,
         11993, 29889,  4994, 29889,   510, 29914,  5080, 11093, 29914, 29906,
         29900, 29900, 29953, 29914, 29510, 29908,    13,  1678,  9463, 29901,
          2997,   543,  4746, 29901, 13579, 29918, 23145,   267, 29908,    13,
          1678, 10729,   287, 17693,   543, 20769,  1013,    13,    13,   829,
          4873, 29958,    13]], device='cuda:0')
torch.Size([2, 93, 32000]) tensor([[[-2.7734, -0.5366, -2.4902,  ..., -2.0957, -2.9941, -2.1152],
         [-3.8496, -2.3027,  0.3191,  ..., -2.9785, -3.8438, -2.6621],
         [-3.9727, -2.4512,  0.3618,  ..., -3.0312, -3.8340, -2.7285],
         ...,
         [-3.8184, -2.0918,  0.5259,  ..., -3.0059, -3.8105, -2.6406],
         [-3.8242, -2.0938,  0.5215,  ..., -3.0020, -3.8027, -2.6367],
         [-3.8359, -2.1074,  0.5195,  ..., -3.0039, -3.8047, -2.6426]],

        [[-2.7734, -0.5366, -2.4902,  ..., -2.0957, -2.9941, -2.1152],
         [-4.0117, -2.3887,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-3.8398, -2.2031,  0.4392,  ..., -2.9922, -3.8301, -2.6367],
         ...,
         [-3.8086, -2.2812,  0.3313,  ..., -2.9941, -3.8223, -2.6797],
         [-3.8848, -2.3086,  0.4370,  ..., -3.0391, -3.8496, -2.7109],
         [-3.8379, -2.2656,  0.5439,  ..., -3.0488, -3.8672, -2.6445]]],
       device='cuda:0')
torch.Size([2, 93, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30879],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 93, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892, 31488,   313],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856]]], device='cuda:0')
Batch 1, 0.2% of total tokens
encoded shape: torch.Size([2, 1093])
torch.Size([2, 1093]) tensor([[    1,   740,   270,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1093, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.8809, -2.3047,  0.3628,  ..., -3.0117, -3.7852, -2.6328],
         [-3.9922, -2.5527,  0.3008,  ..., -3.0430, -3.7910, -2.7617],
         ...,
         [-3.8125, -2.0781,  0.3604,  ..., -2.9785, -3.7832, -2.6426],
         [-3.8066, -2.0703,  0.3591,  ..., -2.9746, -3.7793, -2.6387],
         [-3.8105, -2.0781,  0.3608,  ..., -2.9785, -3.7832, -2.6426]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.8828, -2.2852,  0.4751,  ..., -3.0508, -3.8066, -2.6523],
         [-2.4785,  0.0337, -4.4102,  ..., -1.6445, -2.4297, -1.7930],
         ...,
         [-3.9844, -2.4277,  0.3638,  ..., -3.0234, -3.8711, -2.7598],
         [-3.9648, -2.3926,  0.2396,  ..., -2.9824, -3.7910, -2.7051],
         [-3.9785, -2.4453,  0.4939,  ..., -3.0820, -3.8945, -2.7363]]],
       device='cuda:0')
torch.Size([2, 1093, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1093, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856,   349],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]]], device='cuda:0')
Batch 2, 1.5% of total tokens
encoded shape: torch.Size([2, 781])
torch.Size([2, 781]) tensor([[    1,  1053,   426,  ...,     2,     2,     2],
        [    1,  4949,  1275,  ..., 17038,   416,    13]], device='cuda:0')
torch.Size([2, 781, 32000]) tensor([[[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.8750, -2.3047,  0.3665,  ..., -3.0215, -3.7910, -2.5996],
         [-3.9727, -2.4043,  0.3821,  ..., -3.0391, -3.8418, -2.6738],
         ...,
         [-3.8691, -2.0879,  0.4172,  ..., -3.0117, -3.8105, -2.6582],
         [-3.8691, -2.0879,  0.4163,  ..., -3.0117, -3.8086, -2.6582],
         [-3.8711, -2.0918,  0.4153,  ..., -3.0117, -3.8086, -2.6582]],

        [[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.8848, -2.2852,  0.4749,  ..., -3.0508, -3.8066, -2.6523],
         [-3.9355, -2.3828,  0.2532,  ..., -2.9883, -3.7754, -2.6602],
         ...,
         [-3.9062, -2.3320,  0.1726,  ..., -2.9551, -3.7969, -2.6992],
         [-3.8555, -2.2148,  0.3267,  ..., -3.0059, -3.8320, -2.6973],
         [-3.8945, -2.2832,  0.4680,  ..., -3.0684, -3.8828, -2.7266]]],
       device='cuda:0')
torch.Size([2, 781, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 781, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 3, 2.6% of total tokens
encoded shape: torch.Size([2, 3816])
torch.Size([2, 3816]) tensor([[    1, 29871,    13,  ...,   829,  1420, 29958],
        [    1,  3577,  4390,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3816, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-2.4590,  0.4312, -5.0547,  ..., -1.4912, -2.2754, -1.8203],
         ...,
         [-3.8457, -2.2773,  0.3062,  ..., -2.9941, -3.8105, -2.6641],
         [-3.8770, -2.3652,  0.3894,  ..., -3.0332, -3.8125, -2.7188],
         [-3.8848, -2.3535,  0.4673,  ..., -3.0352, -3.8203, -2.7148]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8672, -2.2930,  0.3989,  ..., -3.0312, -3.7461, -2.6602],
         [-4.0664, -2.6465,  0.3406,  ..., -3.0430, -3.7637, -2.7031],
         ...,
         [-3.9355, -2.2871,  0.4504,  ..., -3.0352, -3.8516, -2.7246],
         [-3.9336, -2.2852,  0.4502,  ..., -3.0352, -3.8516, -2.7227],
         [-3.9355, -2.2871,  0.4509,  ..., -3.0352, -3.8516, -2.7246]]],
       device='cuda:0')
torch.Size([2, 3816, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 3816, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [31147, 30488, 30879,  ..., 30331, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ...,   856,   349, 30555],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186]]], device='cuda:0')
Batch 4, 9.3% of total tokens
encoded shape: torch.Size([2, 1209])
torch.Size([2, 1209]) tensor([[    1,   849,    13,  ...,    13, 29913,    13],
        [    1, 23708,  8695,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1209, 32000]) tensor([[[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.8496, -2.2402,  0.5137,  ..., -3.0273, -3.8262, -2.5977],
         [-2.4492,  0.5010, -5.2227,  ..., -1.4121, -2.2168, -1.7432],
         ...,
         [-4.0703, -2.5625,  0.3352,  ..., -3.0996, -3.8828, -2.7266],
         [-3.9629, -2.4121,  0.3962,  ..., -3.1055, -3.8652, -2.6992],
         [-4.0078, -2.4805,  0.6133,  ..., -3.1621, -3.9199, -2.7305]],

        [[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.9766, -2.3770,  0.2627,  ..., -3.0723, -3.7812, -2.7207],
         [-4.0273, -2.4961,  0.2993,  ..., -3.0566, -3.7500, -2.7578],
         ...,
         [-3.8555, -2.1074,  0.3608,  ..., -2.9941, -3.7930, -2.6621],
         [-3.8555, -2.1074,  0.3604,  ..., -2.9941, -3.7930, -2.6602],
         [-3.8477, -2.0977,  0.3579,  ..., -2.9902, -3.7891, -2.6562]]],
       device='cuda:0')
torch.Size([2, 1209, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [31147],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1209, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [31147, 30488, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29871]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         ...,
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856]]], device='cuda:0')
Batch 5, 10.8% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   849, 10937,  ...,  5277,   525, 29955],
        [    1,  9995, 24376,  ...,  9621, 29892, 15068]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8477, -2.2402,  0.5132,  ..., -3.0293, -3.8262, -2.5957],
         [-3.9355, -2.4004,  0.1821,  ..., -2.9219, -3.7793, -2.6895],
         ...,
         [-3.8633, -2.3008,  0.3164,  ..., -2.9531, -3.7910, -2.6738],
         [-3.9824, -2.4395,  0.2798,  ..., -2.9922, -3.8691, -2.7754],
         [-3.9590, -2.4883,  0.2216,  ..., -2.9277, -3.8691, -2.7812]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8711, -2.2422,  0.4299,  ..., -2.9863, -3.7812, -2.6074],
         [-3.9609, -2.3574,  0.2671,  ..., -2.9434, -3.6777, -2.6914],
         ...,
         [-3.9980, -2.4785,  0.4675,  ..., -3.1250, -3.9043, -2.7930],
         [-3.8223, -2.2285,  0.4531,  ..., -3.0195, -3.7949, -2.6523],
         [-3.9258, -2.4316,  0.3728,  ..., -3.0508, -3.8594, -2.7344]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30186, 29892,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ...,   313, 30186,   856]]], device='cuda:0')
Batch 6, 19.0% of total tokens
encoded shape: torch.Size([2, 3058])
torch.Size([2, 3058]) tensor([[    1, 29871, 30143,  ...,     2,     2,     2],
        [    1,  6317,   903,  ...,  2272, 29952,    13]], device='cuda:0')
torch.Size([2, 3058, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-3.8398, -2.2012,  0.4397,  ..., -2.9902, -3.8301, -2.6367],
         ...,
         [-3.8477, -2.1055,  0.3354,  ..., -2.9883, -3.7773, -2.6582],
         [-3.8477, -2.1055,  0.3342,  ..., -2.9863, -3.7773, -2.6582],
         [-3.8516, -2.1094,  0.3320,  ..., -2.9902, -3.7793, -2.6602]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9922, -2.3789,  0.4038,  ..., -3.0508, -3.8047, -2.7129],
         [-3.9668, -2.4160,  0.3835,  ..., -3.0195, -3.8242, -2.7285],
         ...,
         [-4.0156, -2.5625,  0.4165,  ..., -3.0625, -3.8008, -2.8262],
         [-4.0664, -2.5488,  0.5410,  ..., -3.1152, -3.8379, -2.8262],
         [-4.0391, -2.4766,  0.4941,  ..., -3.0938, -3.8281, -2.7832]]],
       device='cuda:0')
torch.Size([2, 3058, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 3058, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892, 30555, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29871]]], device='cuda:0')
Batch 7, 23.3% of total tokens
encoded shape: torch.Size([2, 871])
torch.Size([2, 871]) tensor([[    1, 10341,    13,  ..., 29945, 29952,    13],
        [    1,   773,  2184,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 871, 32000]) tensor([[[-2.7793, -0.5444, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-3.8379, -2.2246,  0.4397,  ..., -3.0156, -3.8027, -2.6367],
         [-2.3906,  0.7051, -5.4297,  ..., -1.3291, -2.1230, -1.6943],
         ...,
         [-4.0234, -2.6016,  0.2673,  ..., -3.0684, -3.8066, -2.8086],
         [-4.0078, -2.4297,  0.4065,  ..., -3.0859, -3.8145, -2.8164],
         [-3.9219, -2.4023,  0.6123,  ..., -3.1309, -3.8984, -2.8125]],

        [[-2.7793, -0.5444, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-3.8457, -2.3008,  0.3352,  ..., -2.9746, -3.7734, -2.6465],
         [-3.9043, -2.4004,  0.2190,  ..., -2.9336, -3.8184, -2.6895],
         ...,
         [-3.7637, -2.0371,  0.3098,  ..., -2.9590, -3.7695, -2.6250],
         [-3.7695, -2.0430,  0.3135,  ..., -2.9609, -3.7695, -2.6250],
         [-3.7695, -2.0430,  0.3120,  ..., -2.9590, -3.7695, -2.6250]]],
       device='cuda:0')
torch.Size([2, 871, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [31147],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 871, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [31147, 30488, 30879,  ..., 30331, 30154, 30300],
         ...,
         [31147, 30488, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 29899]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 31488, 29892],
         [30488, 31147, 30879,  ...,   313, 31488, 29892],
         [30488, 31147, 30879,  ...,   313, 31488, 29892]]], device='cuda:0')
Batch 8, 24.3% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   525,  1509,  ...,     2,     2,     2],
        [    1,  1053, 10606,  ...,  2159, 29901,  8446]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9922, -2.3594,  0.4192,  ..., -3.0430, -3.8398, -2.7266],
         [-3.9355, -2.4160,  0.1580,  ..., -2.9980, -3.7969, -2.6953],
         ...,
         [-3.4648, -1.6699, -0.1094,  ..., -2.8008, -3.6211, -2.5098],
         [-3.4629, -1.6680, -0.1188,  ..., -2.7988, -3.6191, -2.5078],
         [-3.4648, -1.6689, -0.1267,  ..., -2.7969, -3.6191, -2.5098]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8789, -2.3105,  0.3672,  ..., -3.0254, -3.7930, -2.6035],
         [-3.9023, -2.2852,  0.3889,  ..., -2.9980, -3.8223, -2.7266],
         ...,
         [-3.8418, -2.2891,  0.2783,  ..., -3.0039, -3.7949, -2.6836],
         [-3.7441, -2.1426,  0.3286,  ..., -2.9277, -3.7734, -2.6133],
         [-3.8691, -2.3203,  0.1688,  ..., -2.9824, -3.8223, -2.7188]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ..., 30186,   856,   313],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 31488, 29892,   313],
         [30488, 31147, 30879,  ...,   313, 29892,   856]]], device='cuda:0')
Batch 9, 29.2% of total tokens
encoded shape: torch.Size([2, 514])
torch.Size([2, 514]) tensor([[    1,   849, 14187,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 514, 32000]) tensor([[[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8477, -2.2402,  0.5132,  ..., -3.0293, -3.8262, -2.5957],
         [-3.9668, -2.4844,  0.1691,  ..., -3.0078, -3.7773, -2.6406],
         ...,
         [-3.8984, -2.0859,  0.4128,  ..., -3.0098, -3.8066, -2.6680],
         [-3.9102, -2.1055,  0.4148,  ..., -3.0156, -3.8145, -2.6777],
         [-3.9102, -2.1055,  0.4126,  ..., -3.0137, -3.8105, -2.6758]],

        [[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8828, -2.2852,  0.4749,  ..., -3.0508, -3.8066, -2.6523],
         [-2.4766,  0.0347, -4.4102,  ..., -1.6436, -2.4277, -1.7930],
         ...,
         [-3.9062, -2.3477,  0.3682,  ..., -2.9688, -3.8750, -2.6738],
         [-3.9727, -2.3828,  0.3198,  ..., -3.0000, -3.8223, -2.7285],
         [-3.9922, -2.4629,  0.5596,  ..., -3.0547, -3.9395, -2.7676]]],
       device='cuda:0')
torch.Size([2, 514, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 514, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 30186]]], device='cuda:0')
Batch 10, 29.9% of total tokens
encoded shape: torch.Size([2, 1145])
torch.Size([2, 1145]) tensor([[    1, 11474,    13,  ...,     2,     2,     2],
        [    1,   396,  3638,  ...,  1525, 29889,    13]], device='cuda:0')
torch.Size([2, 1145, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.8730, -2.2422,  0.4089,  ..., -2.9961, -3.8125, -2.6699],
         [-2.3906,  0.4680, -5.6250,  ..., -1.2314, -2.1074, -1.6602],
         ...,
         [-3.8340, -2.0918,  0.3811,  ..., -2.9922, -3.7949, -2.6504],
         [-3.8398, -2.0996,  0.3823,  ..., -2.9941, -3.7969, -2.6543],
         [-3.8477, -2.1152,  0.3833,  ..., -2.9980, -3.8008, -2.6582]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9941, -2.3320,  0.4214,  ..., -3.0605, -3.8086, -2.7305],
         [-3.8965, -2.3867,  0.4309,  ..., -3.0195, -3.8613, -2.6328],
         ...,
         [-3.9570, -2.4609,  0.1702,  ..., -2.9473, -3.7539, -2.7520],
         [-3.9238, -2.3887,  0.4009,  ..., -3.0273, -3.7930, -2.7070],
         [-3.9492, -2.4102,  0.6558,  ..., -3.0918, -3.8555, -2.7402]]],
       device='cuda:0')
torch.Size([2, 1145, 1]) tensor([[[30488],
         [30488],
         [30879],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1145, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30879, 31147, 30488,  ..., 30331, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   856,   313, 29892],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29871]]], device='cuda:0')
Batch 11, 31.4% of total tokens
encoded shape: torch.Size([2, 988])
torch.Size([2, 988]) tensor([[    1,   529,  4563,  ..., 29908,  6660,    13],
        [    1,  4529,  3319,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 988, 32000]) tensor([[[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-3.8906, -2.3496,  0.4419,  ..., -3.0449, -3.7988, -2.6699],
         [-3.9551, -2.4121,  0.3020,  ..., -3.0117, -3.7949, -2.7305],
         ...,
         [-3.7949, -2.1953,  0.2676,  ..., -2.9512, -3.8008, -2.6504],
         [-3.8379, -2.2734,  0.4250,  ..., -3.0117, -3.8047, -2.6953],
         [-3.8789, -2.3125,  0.5220,  ..., -3.0273, -3.8379, -2.6777]],

        [[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-3.8945, -2.3828,  0.3176,  ..., -3.0117, -3.8496, -2.6738],
         [-3.8848, -2.2871,  0.3833,  ..., -3.0020, -3.8164, -2.6992],
         ...,
         [-3.6426, -1.8887,  0.1245,  ..., -2.8828, -3.6953, -2.5801],
         [-3.6465, -1.8936,  0.1300,  ..., -2.8848, -3.6953, -2.5820],
         [-3.6504, -1.9033,  0.1301,  ..., -2.8867, -3.6992, -2.5840]]],
       device='cuda:0')
torch.Size([2, 988, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 988, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 31488,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 29889, 30331,   313],
         [30488, 31147, 30879,  ..., 29889, 30331,   313],
         [30488, 31147, 30879,  ..., 29889, 30331,   313]]], device='cuda:0')
Batch 12, 32.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  4949, 30004,  ..., 29872,   278,  3436],
        [    1, 18787,  2109,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8828, -2.2852,  0.4744,  ..., -3.0488, -3.8066, -2.6523],
         [-3.9160, -2.2520,  0.5864,  ..., -3.0410, -3.8164, -2.7051],
         ...,
         [-4.0703, -2.5039,  0.3162,  ..., -3.0605, -3.8320, -2.7578],
         [-4.0781, -2.5605,  0.2815,  ..., -3.0547, -3.7910, -2.7617],
         [-3.9941, -2.4277,  0.1938,  ..., -2.9980, -3.8164, -2.7812]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.7715, -2.1523,  0.3284,  ..., -2.9375, -3.7793, -2.6387],
         [-3.9141, -2.3145,  0.2017,  ..., -3.0234, -3.8359, -2.7285],
         ...,
         [-2.9707, -0.8096, -1.8574,  ..., -2.2871, -3.1758, -2.2266],
         [-2.9688, -0.8076, -1.8643,  ..., -2.2852, -3.1758, -2.2246],
         [-2.9785, -0.8213, -1.8652,  ..., -2.2930, -3.1836, -2.2344]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         [30488, 30879, 31147,  ..., 29892,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154]]], device='cuda:0')
Batch 13, 36.6% of total tokens
encoded shape: torch.Size([2, 1011])
torch.Size([2, 1011]) tensor([[    1,  4949,    13,  ...,     2,     2,     2],
        [    1,  4949, 29899,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1011, 32000]) tensor([[[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8848, -2.2852,  0.4744,  ..., -3.0508, -3.8066, -2.6523],
         [-2.4727,  0.0393, -4.4102,  ..., -1.6406, -2.4219, -1.7881],
         ...,
         [-3.9434, -2.1562,  0.3438,  ..., -3.0078, -3.7969, -2.6914],
         [-3.9395, -2.1504,  0.3442,  ..., -3.0020, -3.7930, -2.6875],
         [-3.9434, -2.1582,  0.3442,  ..., -3.0020, -3.7949, -2.6875]],

        [[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8848, -2.2852,  0.4744,  ..., -3.0508, -3.8066, -2.6523],
         [-3.9160, -2.2695,  0.2671,  ..., -2.9609, -3.8340, -2.6797],
         ...,
         [-3.9062, -2.3145,  0.3521,  ..., -3.0020, -3.8691, -2.6543],
         [-3.9980, -2.4121,  0.2620,  ..., -3.0020, -3.8262, -2.7188],
         [-4.0352, -2.5020,  0.4714,  ..., -3.0703, -3.9297, -2.7266]]],
       device='cuda:0')
torch.Size([2, 1011, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1011, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29871]]], device='cuda:0')
Batch 14, 38.0% of total tokens
encoded shape: torch.Size([2, 1109])
torch.Size([2, 1109]) tensor([[    1,   934,  5809,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1109, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.8496, -2.3027,  0.3188,  ..., -2.9766, -3.8438, -2.6621],
         [-3.9688, -2.4492,  0.3618,  ..., -3.0312, -3.8340, -2.7285],
         ...,
         [-3.5938, -1.8193, -0.0862,  ..., -2.8281, -3.6504, -2.5566],
         [-3.5879, -1.8135, -0.0868,  ..., -2.8242, -3.6445, -2.5527],
         [-3.5879, -1.8145, -0.0838,  ..., -2.8262, -3.6445, -2.5547]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.8828, -2.2852,  0.4751,  ..., -3.0508, -3.8066, -2.6523],
         [-2.4785,  0.0337, -4.4102,  ..., -1.6445, -2.4297, -1.7930],
         ...,
         [-3.9824, -2.4238,  0.3691,  ..., -3.0000, -3.8867, -2.7207],
         [-4.0977, -2.5625,  0.4568,  ..., -3.0781, -3.8848, -2.7871],
         [-4.0273, -2.5215,  0.6992,  ..., -3.1211, -3.9375, -2.7383]]],
       device='cuda:0')
torch.Size([2, 1109, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1109, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30331, 29889, 30300],
         [30488, 31147, 30879,  ..., 30331, 29889, 30300],
         [30488, 31147, 30879,  ..., 30331, 29889, 30300]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   856, 29871, 30555]]], device='cuda:0')
Batch 15, 39.2% of total tokens
encoded shape: torch.Size([2, 755])
torch.Size([2, 755]) tensor([[    1,  4949, 29899,  ...,    13, 29913,    13],
        [    1, 11474,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 755, 32000]) tensor([[[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8828, -2.2852,  0.4749,  ..., -3.0488, -3.8066, -2.6523],
         [-3.9160, -2.2695,  0.2676,  ..., -2.9609, -3.8340, -2.6797],
         ...,
         [-3.8164, -2.2266,  0.4192,  ..., -2.9980, -3.8477, -2.6367],
         [-3.9141, -2.3242,  0.3550,  ..., -3.0020, -3.8066, -2.6816],
         [-3.9434, -2.4082,  0.5068,  ..., -3.0566, -3.9199, -2.6836]],

        [[-2.7734, -0.5371, -2.4844,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8770, -2.2480,  0.4094,  ..., -2.9980, -3.8184, -2.6719],
         [-2.3887,  0.4653, -5.6250,  ..., -1.2314, -2.1074, -1.6602],
         ...,
         [-3.8848, -2.1035,  0.3643,  ..., -3.0000, -3.8086, -2.6621],
         [-3.8926, -2.1133,  0.3660,  ..., -3.0039, -3.8145, -2.6680],
         [-3.8906, -2.1133,  0.3657,  ..., -3.0039, -3.8125, -2.6660]]],
       device='cuda:0')
torch.Size([2, 755, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30879],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 755, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30879, 31147, 30488,  ..., 30331, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 16, 40.3% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[   1,  426,   13,  ...,    2,    2,    2],
        [   1,  396,  353,  ..., 6273, 1149,  376]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8867, -2.2520,  0.4216,  ..., -2.9844, -3.7695, -2.6504],
         [-2.4062,  0.5059, -5.2578,  ..., -1.3457, -2.2500, -1.7090],
         ...,
         [-2.9551, -0.7817, -1.9023,  ..., -2.2754, -3.1660, -2.2168],
         [-2.9551, -0.7812, -1.9023,  ..., -2.2734, -3.1660, -2.2168],
         [-2.9551, -0.7827, -1.9004,  ..., -2.2754, -3.1660, -2.2168]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9922, -2.3340,  0.4207,  ..., -3.0605, -3.8086, -2.7305],
         [-3.9297, -2.3633,  0.4260,  ..., -3.0273, -3.8379, -2.6992],
         ...,
         [-3.9023, -2.4453,  0.2703,  ..., -2.9512, -3.7812, -2.7246],
         [-3.8672, -2.3281,  0.4075,  ..., -3.0059, -3.7891, -2.6758],
         [-3.8496, -2.2793,  0.4548,  ..., -3.0371, -3.8594, -2.6758]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [31147, 30488, 30879,  ..., 30331, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186, 31488]]], device='cuda:0')
Batch 17, 44.4% of total tokens
encoded shape: torch.Size([2, 1235])
torch.Size([2, 1235]) tensor([[    1,   525,  1509,  ...,   500,    13, 29913],
        [    1,  4529, 18959,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1235, 32000]) tensor([[[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.9883, -2.3535,  0.4185,  ..., -3.0410, -3.8359, -2.7227],
         [-3.9355, -2.4160,  0.1583,  ..., -2.9980, -3.7969, -2.6953],
         ...,
         [-3.9492, -2.3594,  0.3823,  ..., -3.0742, -3.8535, -2.7754],
         [-3.9414, -2.3320,  0.3472,  ..., -3.0215, -3.8809, -2.7363],
         [-3.9590, -2.3711,  0.4788,  ..., -3.1016, -3.8535, -2.7637]],

        [[-2.7734, -0.5376, -2.4863,  ..., -2.0977, -2.9941, -2.1133],
         [-3.8945, -2.3828,  0.3179,  ..., -3.0117, -3.8496, -2.6738],
         [-3.8887, -2.3066,  0.3860,  ..., -3.0605, -3.8203, -2.6914],
         ...,
         [-3.3438, -1.4648, -0.6152,  ..., -2.6621, -3.5039, -2.4434],
         [-3.3438, -1.4609, -0.6104,  ..., -2.6641, -3.5039, -2.4434],
         [-3.3418, -1.4570, -0.6206,  ..., -2.6621, -3.5020, -2.4414]]],
       device='cuda:0')
torch.Size([2, 1235, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1235, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ..., 30186,   856,   313],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]]], device='cuda:0')
Batch 18, 45.7% of total tokens
encoded shape: torch.Size([2, 982])
torch.Size([2, 982]) tensor([[    1, 29871, 30143,  ..., 29936,    13, 29913],
        [    1,  2793,   432,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 982, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0117, -2.3867,  0.5610,  ..., -3.0332, -3.8535, -2.7090],
         [-3.8398, -2.2012,  0.4397,  ..., -2.9902, -3.8301, -2.6367],
         ...,
         [-3.9570, -2.3848,  0.6006,  ..., -3.0684, -3.8555, -2.7520],
         [-3.8809, -2.2715,  0.3848,  ..., -2.9863, -3.7969, -2.6875],
         [-3.9043, -2.2715,  0.4763,  ..., -3.0586, -3.8125, -2.7324]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9492, -2.3262,  0.3054,  ..., -3.0352, -3.7910, -2.7168],
         [-4.0156, -2.4883,  0.3284,  ..., -3.0039, -3.7773, -2.7051],
         ...,
         [-3.4941, -1.7061, -0.1505,  ..., -2.7891, -3.6133, -2.5156],
         [-3.4980, -1.7129, -0.1362,  ..., -2.7910, -3.6172, -2.5176],
         [-3.5000, -1.7178, -0.1223,  ..., -2.7949, -3.6191, -2.5195]]],
       device='cuda:0')
torch.Size([2, 982, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 982, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 29871, 30555],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 29889],
         [30488, 31147, 30879,  ..., 30331, 30300, 29889],
         [30488, 31147, 30879,  ..., 30331, 30300, 29889]]], device='cuda:0')
Batch 19, 46.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  5609, 25289,  ...,     2,     2,     2],
        [    1,  4949,    13,  ..., 29889, 17506,  9843]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8574, -2.2754,  0.4172,  ..., -3.0156, -3.8672, -2.6445],
         [-4.0117, -2.5508,  0.2644,  ..., -3.0000, -3.7988, -2.7520],
         ...,
         [-3.0215, -0.9072, -1.6729,  ..., -2.3496, -3.2363, -2.2617],
         [-3.0156, -0.8979, -1.6787,  ..., -2.3457, -3.2324, -2.2578],
         [-3.0156, -0.8960, -1.6797,  ..., -2.3457, -3.2324, -2.2559]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8828, -2.2852,  0.4744,  ..., -3.0488, -3.8066, -2.6523],
         [-2.4590,  0.0652, -4.4258,  ..., -1.6279, -2.4102, -1.7764],
         ...,
         [-3.8145, -2.2148,  0.2527,  ..., -2.9277, -3.7539, -2.7109],
         [-3.8633, -2.2715,  0.2062,  ..., -2.9102, -3.7441, -2.7012],
         [-3.8555, -2.3867,  0.3088,  ..., -2.9961, -3.8008, -2.7305]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 30186, 29892,   856]]], device='cuda:0')
Batch 20, 50.9% of total tokens
encoded shape: torch.Size([2, 1843])
torch.Size([2, 1843]) tensor([[    1,  3577,  5639,  ...,    13, 29913,    13],
        [    1,  4949,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1843, 32000]) tensor([[[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-3.8672, -2.2949,  0.3992,  ..., -3.0312, -3.7461, -2.6621],
         [-4.0000, -2.4707,  0.2710,  ..., -2.9316, -3.7930, -2.7227],
         ...,
         [-3.9668, -2.3945,  0.3374,  ..., -2.9707, -3.9004, -2.7539],
         [-3.9668, -2.3477,  0.3262,  ..., -3.0234, -3.8535, -2.7461],
         [-3.9766, -2.4082,  0.5039,  ..., -3.0352, -3.9180, -2.7617]],

        [[-2.7695, -0.5298, -2.4824,  ..., -2.0938, -2.9902, -2.1113],
         [-3.8828, -2.2852,  0.4749,  ..., -3.0488, -3.8066, -2.6523],
         [-2.4648,  0.0590, -4.4375,  ..., -1.6279, -2.4121, -1.7803],
         ...,
         [-3.8379, -2.0840,  0.1940,  ..., -2.9512, -3.7461, -2.6543],
         [-3.8438, -2.0898,  0.1907,  ..., -2.9512, -3.7480, -2.6562],
         [-3.8477, -2.0938,  0.1892,  ..., -2.9531, -3.7480, -2.6582]]],
       device='cuda:0')
torch.Size([2, 1843, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1843, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   856,   313, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856]]], device='cuda:0')
Batch 21, 53.3% of total tokens
encoded shape: torch.Size([2, 2102])
torch.Size([2, 2102]) tensor([[    1,   450,  7306,  ...,     2,     2,     2],
        [    1,   396,  2856,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 2102, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9980, -2.2812,  0.4731,  ..., -3.0430, -3.7715, -2.7246],
         [-4.0664, -2.4219,  0.2340,  ..., -3.0449, -3.7695, -2.7930],
         ...,
         [-3.2988, -1.4023, -0.7739,  ..., -2.6191, -3.4648, -2.4141],
         [-3.2988, -1.4033, -0.7700,  ..., -2.6191, -3.4648, -2.4141],
         [-3.3008, -1.4062, -0.7676,  ..., -2.6191, -3.4648, -2.4141]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9922, -2.3340,  0.4207,  ..., -3.0605, -3.8086, -2.7305],
         [-3.8418, -2.2305,  0.3225,  ..., -2.9883, -3.7285, -2.6426],
         ...,
         [-3.8945, -2.3203,  0.3884,  ..., -3.0000, -3.8516, -2.6816],
         [-3.9941, -2.4023,  0.4578,  ..., -3.0508, -3.8359, -2.7422],
         [-3.9512, -2.3945,  0.6777,  ..., -3.0820, -3.8926, -2.7285]]],
       device='cuda:0')
torch.Size([2, 2102, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 2102, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307],
         [30488, 31147, 30879,  ..., 30331, 30300, 31307]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 29871]]], device='cuda:0')
Batch 22, 55.6% of total tokens
encoded shape: torch.Size([2, 609])
torch.Size([2, 609]) tensor([[   1, 4949,   13,  ...,    2,    2,    2],
        [   1, 3577,  349,  ..., 7582,   13,   13]], device='cuda:0')
torch.Size([2, 609, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8828, -2.2852,  0.4746,  ..., -3.0508, -3.8066, -2.6523],
         [-2.4629,  0.0578, -4.4297,  ..., -1.6289, -2.4121, -1.7793],
         ...,
         [-3.9238, -2.1328,  0.3240,  ..., -3.0020, -3.8105, -2.6797],
         [-3.9238, -2.1328,  0.3250,  ..., -2.9980, -3.8066, -2.6777],
         [-3.9199, -2.1270,  0.3237,  ..., -2.9961, -3.8027, -2.6758]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8672, -2.2930,  0.3992,  ..., -3.0312, -3.7461, -2.6602],
         [-3.9375, -2.4531,  0.3105,  ..., -2.9785, -3.7578, -2.7070],
         ...,
         [-3.7871, -2.1426,  0.2264,  ..., -2.9336, -3.7383, -2.6113],
         [-3.9043, -2.3438,  0.3579,  ..., -2.9863, -3.8223, -2.7090],
         [-3.8125, -2.2090,  0.3352,  ..., -2.9531, -3.7812, -2.6426]]],
       device='cuda:0')
torch.Size([2, 609, 1]) tensor([[[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 609, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 31488,   856,   313],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 31488, 29892,   313]]], device='cuda:0')
Batch 23, 56.3% of total tokens
encoded shape: torch.Size([2, 577])
torch.Size([2, 577]) tensor([[    1,   396,   334,  ..., 29889, 11256,    13],
        [    1,   426,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 577, 32000]) tensor([[[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.9980, -2.3418,  0.4209,  ..., -3.0645, -3.8145, -2.7344],
         [-3.9121, -2.3691,  0.3735,  ..., -2.9961, -3.8320, -2.7207],
         ...,
         [-3.8359, -2.2656,  0.2822,  ..., -2.9434, -3.8086, -2.7148],
         [-3.9043, -2.3555,  0.4045,  ..., -3.0020, -3.8066, -2.7246],
         [-3.8145, -2.2266,  0.6201,  ..., -2.9980, -3.8926, -2.7129]],

        [[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.8906, -2.2617,  0.4226,  ..., -2.9883, -3.7734, -2.6562],
         [-2.4160,  0.4939, -5.2578,  ..., -1.3535, -2.2578, -1.7168],
         ...,
         [-3.7598, -1.9766,  0.2793,  ..., -2.9453, -3.7539, -2.6230],
         [-3.7520, -1.9658,  0.2776,  ..., -2.9414, -3.7500, -2.6172],
         [-3.7441, -1.9551,  0.2732,  ..., -2.9375, -3.7441, -2.6133]]],
       device='cuda:0')
torch.Size([2, 577, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 577, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892]]], device='cuda:0')
Batch 24, 57.0% of total tokens
encoded shape: torch.Size([2, 643])
torch.Size([2, 643]) tensor([[    1,   313,  1983,  ...,     2,     2,     2],
        [    1,  6319,  3134,  ..., 21529,  3453, 29958]], device='cuda:0')
torch.Size([2, 643, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.9883, -2.4160,  0.4199,  ..., -3.0312, -3.8359, -2.6934],
         [-3.8555, -2.3027,  0.2092,  ..., -2.9297, -3.7852, -2.6602],
         ...,
         [-3.8809, -2.1836,  0.4485,  ..., -3.0293, -3.7852, -2.6836],
         [-3.8770, -2.1797,  0.4495,  ..., -3.0273, -3.7852, -2.6816],
         [-3.8789, -2.1836,  0.4514,  ..., -3.0312, -3.7910, -2.6855]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.8965, -2.2910,  0.4421,  ..., -2.9648, -3.8340, -2.6934],
         [-3.8496, -2.3125,  0.3020,  ..., -3.0020, -3.7617, -2.6953],
         ...,
         [-3.8809, -2.2598,  0.1688,  ..., -2.9590, -3.7852, -2.7090],
         [-3.8965, -2.4004,  0.2295,  ..., -2.9941, -3.7520, -2.7266],
         [-3.8867, -2.2930,  0.3787,  ..., -2.9863, -3.7988, -2.7539]]],
       device='cuda:0')
torch.Size([2, 643, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 643, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856]]], device='cuda:0')
Batch 25, 58.2% of total tokens
encoded shape: torch.Size([2, 939])
torch.Size([2, 939]) tensor([[    1,   450,   848,  ...,     2,     2,     2],
        [    1,   396,   910,  ...,  2172, 29897,    13]], device='cuda:0')
torch.Size([2, 939, 32000]) tensor([[[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9922, -2.2715,  0.4722,  ..., -3.0371, -3.7656, -2.7207],
         [-4.0078, -2.4316,  0.2495,  ..., -2.9648, -3.8242, -2.7227],
         ...,
         [-3.9043, -2.2109,  0.4502,  ..., -3.0312, -3.8105, -2.6953],
         [-3.9023, -2.2031,  0.4529,  ..., -3.0273, -3.8086, -2.6934],
         [-3.9004, -2.1992,  0.4517,  ..., -3.0234, -3.8047, -2.6914]],

        [[-2.7754, -0.5454, -2.4824,  ..., -2.1016, -2.9980, -2.1172],
         [-3.9941, -2.3320,  0.4214,  ..., -3.0605, -3.8086, -2.7305],
         [-3.8906, -2.3477,  0.4622,  ..., -3.0371, -3.8359, -2.7148],
         ...,
         [-3.9141, -2.4336,  0.3264,  ..., -3.0234, -3.7520, -2.7578],
         [-3.9883, -2.4980,  0.3738,  ..., -3.0332, -3.8242, -2.7305],
         [-3.8613, -2.3438,  0.5786,  ..., -3.0332, -3.8242, -2.6738]]],
       device='cuda:0')
torch.Size([2, 939, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 939, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   313,   856, 29899],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186]]], device='cuda:0')
Batch 26, 60.0% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  1053,   534,  ...,     2,     2,     2],
        [    1,   396, 27694,  ..., 29900, 29916, 29947]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8789, -2.3105,  0.3672,  ..., -3.0254, -3.7930, -2.6035],
         [-4.0156, -2.5391,  0.3152,  ..., -3.0352, -3.9238, -2.7754],
         ...,
         [-3.7773, -2.0391,  0.4446,  ..., -2.9863, -3.7910, -2.6445],
         [-3.7734, -2.0332,  0.4438,  ..., -2.9844, -3.7871, -2.6406],
         [-3.7734, -2.0332,  0.4438,  ..., -2.9844, -3.7891, -2.6406]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9922, -2.3340,  0.4207,  ..., -3.0605, -3.8086, -2.7305],
         [-4.0312, -2.5215,  0.3831,  ..., -3.0488, -3.8613, -2.7734],
         ...,
         [-3.8320, -2.3281,  0.3542,  ..., -2.9805, -3.8086, -2.6934],
         [-3.9004, -2.3652,  0.3848,  ..., -3.0078, -3.8984, -2.7305],
         [-3.9297, -2.4004,  0.4282,  ..., -3.0215, -3.8926, -2.7676]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856,   349],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 31488, 29892],
         [30488, 31147, 30879,  ...,   313, 31488, 29892]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]]], device='cuda:0')
Batch 27, 65.8% of total tokens
encoded shape: torch.Size([2, 2080])
torch.Size([2, 2080]) tensor([[    1,  2431, 29888,  ...,     2,     2,     2],
        [    1,   849,    13,  ...,  5690, 29925,    13]], device='cuda:0')
torch.Size([2, 2080, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9688, -2.5098,  0.3701,  ..., -3.0020, -3.8359, -2.6562],
         [-4.0508, -2.5840,  0.3108,  ..., -3.0820, -3.9062, -2.7891],
         ...,
         [-3.7383, -2.0020,  0.2166,  ..., -2.9355, -3.7383, -2.6152],
         [-3.7363, -1.9990,  0.2152,  ..., -2.9355, -3.7363, -2.6133],
         [-3.7344, -1.9971,  0.2157,  ..., -2.9355, -3.7363, -2.6133]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8477, -2.2402,  0.5132,  ..., -3.0293, -3.8262, -2.5957],
         [-2.4492,  0.4900, -5.2031,  ..., -1.4189, -2.2246, -1.7471],
         ...,
         [-4.2227, -2.7344,  0.1316,  ..., -3.0098, -3.8359, -2.8457],
         [-4.1523, -2.6172,  0.1608,  ..., -3.0000, -3.8281, -2.7715],
         [-4.1172, -2.5703,  0.2737,  ..., -3.0469, -3.8828, -2.7207]]],
       device='cuda:0')
torch.Size([2, 2080, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 2080, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856,   349],
         ...,
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ...,   856,   349,   315],
         [30488, 31147, 30879,  ...,   856, 30555,   349],
         [30488, 31147, 30879,  ...,   856, 30555,   349]]], device='cuda:0')
Batch 28, 68.5% of total tokens
encoded shape: torch.Size([2, 312])
torch.Size([2, 312]) tensor([[    1,   849,    13,   458, 29871,   390, 29916,  1626, 10486, 11494,
         14048, 29889, 26792,    13,   458, 29871,   390, 29916, 29907, 22531,
            13,   458,    13,   458, 29871,  6760,   630,   491,  6667,  2236,
          1383,   352,  3249,   373, 29871, 29896, 29906, 29914, 29941, 29900,
         29914, 29896, 29945, 29889,    13,   458, 29871, 14187,  1266, 29871,
         30211, 29871, 29906, 29900, 29896, 29945,   476,  3389, 17464,   796,
           801,   261, 29889,  2178, 10462, 21676, 29889,    13,   458,    13,
            13, 29937,   361,  2897, 29898, 29875,  3267, 29897,  3830,  2897,
         29898, 12427,  3267, 29897,    13,    13,  1678,  1053,   390, 29916,
         10840,  2027,    13,  1678,  1053,  3740, 13117,    13,    13,  1678,
          6081,   405,  1254,  1062, 10486, 29901, 11699, 11494,   426,    13,
          4706,   970,  1134, 19973,   897,  6045,   353,   405,  1254,  1062,
         10486, 11494,    13,  1678,   500,    13,    13,  1678,  1722,   770,
           390, 29916,  1626, 10486, 11494, 14048,    13,  4706,   584,   897,
          6045, 14048, 29966, 29940,  1254,  1062, 10486, 29892,   405,  1254,
          1062, 10486, 11494, 29958,    13,  4706,  1919,   897,  6045, 14048,
          1542, 29871,    13,  4706,  1919,   405,  1254,  1062, 10486, 11494,
           426,    13,    13,  4706,  4363, 14213,   287,  3847,  1203, 29889,
            13,  4706,   970,  8062,  2024, 29898,   842, 29897,   722,  1426,
         10486, 29901,   405,  1254,  1062, 10486, 29973,    13,    13,  4706,
          4363,   448,  3443,  1426, 10486, 29901, 22280,  1203,   363, 13341,
         10166, 29889,    13,  4706,   970,  2069, 29898,   726, 10486, 29901,
           405,  1254,  1062, 10486, 29897,   426,    13,  9651,  1583, 29889,
           726, 10486,   353,  1426, 10486,    13,  9651,  2428, 29889,  2344,
         29898,  3560,  2061, 29901,  1426, 10486, 29892, 13341, 14048, 29901,
           390, 29916,  1626, 10486, 11494, 14048, 29889,  1311, 29897,    13,
          4706,   500,    13,    13,  4706,   849, 12577,  2998, 20240,    13,
          4706,   970,  2294,  3653,  6036, 29968, 21369,  1888,  2037,   800,
           580,   426,    13,  9651,  1583, 29889,  9573,   426,   390, 29916,
          1626, 10486, 11494, 14048, 29898,   726, 10486, 29901,   395, 29900,
         29897,   500,    13,  4706,   500,    13,  1678,   500,    13, 29937,
         15224,    13],
        [    1,   773,  2184, 29936,    13,    13, 22377, 16108, 29923,  4099,
         29889, 21741, 29889,  9203, 29889,  5971, 29907, 29889, 15801,    13,
         29912,    13,  1678,   518,  6708, 27573, 29898,  6708,  8667, 29879,
         29889,  2385,  4638,    13,  1678,   970,   770,  2216, 28329,   287,
          3047,  1168,   794,  1080,  6708, 29901, 23833,    13,  1678,   426,
            13,  1678,   500,    13, 29913,    13,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 312, 32000]) tensor([[[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.8477, -2.2402,  0.5137,  ..., -3.0293, -3.8262, -2.5957],
         [-2.4395,  0.5054, -5.2148,  ..., -1.4092, -2.2148, -1.7383],
         ...,
         [-3.7578, -2.1367,  0.3899,  ..., -2.9473, -3.8145, -2.6328],
         [-3.7656, -2.1562,  0.3569,  ..., -2.9492, -3.8145, -2.6348],
         [-3.8633, -2.3086,  0.5576,  ..., -3.0098, -3.8535, -2.6445]],

        [[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.8457, -2.3008,  0.3347,  ..., -2.9746, -3.7734, -2.6484],
         [-3.9102, -2.4082,  0.2208,  ..., -2.9375, -3.8223, -2.6934],
         ...,
         [-3.9004, -2.1133,  0.4626,  ..., -3.0195, -3.8145, -2.6836],
         [-3.9043, -2.1172,  0.4629,  ..., -3.0234, -3.8203, -2.6875],
         [-3.9004, -2.1074,  0.4617,  ..., -3.0195, -3.8145, -2.6816]]],
       device='cuda:0')
torch.Size([2, 312, 1]) tensor([[[30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 312, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ..., 31488, 29892,   313],
         [30488, 31147, 30879,  ..., 31488, 29892,   313],
         [30488, 31147, 30879,  ..., 30186,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 29, 68.8% of total tokens
encoded shape: torch.Size([2, 313])
torch.Size([2, 313]) tensor([[    1,  6319,  3134,  1873,   543, 29896, 29889, 29900, 29908,  8025,
           543, 10496, 29899, 29947, 18943,    13, 29966,  4836,  1873,   543,
         29946,  1013,    13, 29871,   529,  9700,  1024,   543,  7653,  7355,
          3260,  1013,    13,  1678,   529,  7576, 29958,    13,   418,   529,
          5453,   934,  2271,   543,  1445,   597, 29938,  8618, 17637, 29918,
          9464, 29938, 29914, 29934,  3028, 29941, 29928, 14460, 29889,   326,
         29880, 29908,   934,  2084, 18965,  8618, 17637, 29918,  9464, 29938,
         29914, 29934,  3028, 29941, 29928, 14460, 29889,   326, 29880, 29908,
          2900,    13,   418,   529,  5453,   934,  2271,   543,  1445,   597,
         29938,  8618, 17637, 29918,  9464, 29938, 29914,   932, 29914,   932,
         29889,   326, 29880, 29908,   934,  2084, 18965,  8618, 17637, 29918,
          9464, 29938, 29914,   932, 29914,   932, 29889,   326, 29880, 29908,
          2900,    13,   418,   529,  5453,   934,  2271,   543,  1445,   597,
         29938,  8618, 17637, 29918,  9464, 29938, 29914,  5258, 29914,  5258,
         29889,   326, 29880, 29908,   934,  2084, 18965,  8618, 17637, 29918,
          9464, 29938, 29914,  5258, 29914,  5258, 29889,   326, 29880, 29908,
          2900,    13,  1678,  1533,  7576, 29958,    13, 29871,  1533,  9700,
         29958,    13,   829,  4836, 29958,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2],
        [    1,  7762,    13,   334, 14187,  1266, 29871, 29906, 29900, 29900,
         29955, 29899, 29906, 29900, 29896, 29953, 29892, 13680,   834,   292,
         15025, 29889,  2178, 10462, 21676, 29889,    13,   334,    13,   334,
         10413, 21144,  1090,   278, 13380, 19245, 29892, 10079, 29871, 29906,
         29889, 29900,   313,  1552,   376, 29931,   293,  1947,  1496,    13,
           334,   366,  1122,   451,   671,   445,   934,  5174,   297,   752,
         13036,   411,   278, 19245, 29889,    13,   334,   887,  1122,  4017,
           263,  3509,   310,   278, 19245,   472,    13,   334,    13,   334,
          1732,   597,  1636, 29889,  4288, 29889,   990, 29914,   506, 11259,
         29914, 27888,  1430,  1660, 29899, 29906, 29889, 29900,    13,   334,
            13,   334, 25870,  3734,   491, 22903,  4307,   470, 15502,   304,
           297,  5007, 29892,  7047,    13,   334, 13235,  1090,   278, 19245,
           338, 13235,   373,   385,   376,  3289,  8519, 29908,   350,  3289,
          3235, 29892,    13,   334,   399,  1806,  8187,  2692,   399,  1718,
         29934, 13566, 29059,  6323,  8707, 29928, 22122, 29903,  8079, 13764,
         29979,   476, 22255, 29892,  2845,  4653,   470,  2411,  2957, 29889,
            13,   334,  2823,   278, 19245,   363,   278,  2702,  4086, 14765,
          1076, 11239,   322,    13,   334, 27028,  1090,   278, 19245, 29889,
            13,  3776,    13,  5113,  1638, 29889,  1335,   834,   292, 29889,
         17062,  1582, 29889, 21895, 29936,    13,    13,    13,  7918,    13,
           334,  1954, 14607,   310,   278, 10643,  7292, 29892,   411,  2304,
           363,   731, 29914,   657, 29889,    13,  3776,    13,  3597,   770,
          6991,  5219, 27107, 12506,  6647, 10703,  6991,  5219, 27107, 12506,
           426,    13,  1678,  2024,   938,  7292, 29936,    13,    13,  1678,
           970,  6991,  5219, 27107, 12506,  6647, 29898,   524,  7292, 29897,
           426,    13,  4706,   445, 29889, 19207,   353,  7292, 29936,    13,
          1678,   500,    13,    13,  1678,   732,  4640,    13,  1678,   970,
           938,   679, 12506,   580,   426,    13,  4706,   736,  7292, 29936,
            13,  1678,   500,    13,    13,  1678,   732,  4640,    13,  1678,
           970,  1780,   731, 12506, 29898,   524,  7292, 29897,   426,    13,
          4706,   445, 29889, 19207,   353,  7292, 29936,    13,  1678,   500,
            13, 29913,    13]], device='cuda:0')
torch.Size([2, 313, 32000]) tensor([[[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.8945, -2.2910,  0.4421,  ..., -2.9648, -3.8340, -2.6934],
         [-3.8496, -2.3125,  0.3020,  ..., -3.0039, -3.7617, -2.6953],
         ...,
         [-3.8535, -2.0977,  0.5103,  ..., -3.0254, -3.8125, -2.6680],
         [-3.8555, -2.0996,  0.5088,  ..., -3.0273, -3.8125, -2.6699],
         [-3.8613, -2.1055,  0.5083,  ..., -3.0293, -3.8164, -2.6738]],

        [[-2.7773, -0.5444, -2.4883,  ..., -2.0996, -2.9961, -2.1191],
         [-3.8848, -2.2676,  0.4661,  ..., -3.0195, -3.8242, -2.6602],
         [-2.4004,  0.3289, -4.5508,  ..., -1.5088, -2.4062, -1.8027],
         ...,
         [-3.9023, -2.2773,  0.3726,  ..., -3.0059, -3.8398, -2.7305],
         [-3.8164, -2.2129,  0.3457,  ..., -2.9902, -3.8066, -2.6777],
         [-3.8242, -2.2383,  0.5386,  ..., -3.0742, -3.8516, -2.6914]]],
       device='cuda:0')
torch.Size([2, 313, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 313, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856]]], device='cuda:0')
Batch 30, 69.3% of total tokens
encoded shape: torch.Size([2, 576])
torch.Size([2, 576]) tensor([[    1,  1192,   718,  ...,  1989, 29936,    13],
        [    1,   849, 27694,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 576, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8809, -2.2734,  0.3704,  ..., -2.9785, -3.8184, -2.6738],
         [-3.9844, -2.5098,  0.3835,  ..., -3.0430, -3.8184, -2.7285],
         ...,
         [-4.0586, -2.5449,  0.3777,  ..., -3.0586, -3.8496, -2.8262],
         [-4.0117, -2.4902,  0.4363,  ..., -3.0684, -3.8184, -2.7910],
         [-3.8848, -2.3281,  0.6118,  ..., -3.0625, -3.8750, -2.7246]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8477, -2.2402,  0.5132,  ..., -3.0293, -3.8262, -2.5957],
         [-3.9121, -2.3477,  0.1843,  ..., -2.9629, -3.7832, -2.6777],
         ...,
         [-3.8809, -2.0762,  0.3940,  ..., -3.0078, -3.8125, -2.6641],
         [-3.8848, -2.0801,  0.3943,  ..., -3.0078, -3.8125, -2.6641],
         [-3.8828, -2.0801,  0.3938,  ..., -3.0078, -3.8125, -2.6641]]],
       device='cuda:0')
torch.Size([2, 576, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 576, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ..., 30555,   856, 29899],
         [30488, 31147, 30879,  ...,   313,   856, 30186]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30186,   856, 29892],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ..., 29892, 30186,   856]]], device='cuda:0')
Batch 31, 70.1% of total tokens
encoded shape: torch.Size([2, 106])
torch.Size([2, 106]) tensor([[    1,   529, 13237, 29958,    13,  1678, 10341, 13109,  4315, 15276,
          1144, 29892,   639,   278,  5669, 12037,  1410, 10652,  1475, 29889,
          6660,    13,  1678,   529, 24702,  1024,   543, 10072, 29918, 22672,
         29918,  9264,  1013, 29896, 29953,  6099,   829, 24702, 29958,    13,
          1678,   529, 24702,  1024,   543, 10072, 29918, 18575, 29918,  9264,
          1013, 29896, 29953,  6099,   829, 24702, 29958,    13,    13,  1678,
           529, 24702,  1024,   543,  1493, 29918, 29886,  1875, 29918, 29893,
           277, 12744,  1013, 29946, 29945, 29900,  6099,   829, 24702, 29958,
            13,  1678,   529, 24702,  1024,   543,  1493, 29918, 29886,  1875,
         29918,  3545,  1013, 29896, 29945, 29900,  6099,   829, 24702, 29958,
            13,   829, 13237, 29958,    13,     2],
        [    1,   396,    13, 29937,  8561,  1445,   363,   286, 10351,  2702,
          1067, 29895,    13, 29937,    13,    13,  5415, 29899, 29891,  4619,
          1067, 29895, 29889, 29877,  1067, 29895, 29899,   572, 29880, 29889,
         29877,  1067, 29895, 29899,   999, 29889, 29877,  1067, 29895, 29899,
          4563, 29889, 29877,  1067, 29895, 29899,  1154, 29889, 29877,  1067,
         29895, 29899,   893, 29886, 29889, 29877,    13,    13,  5415, 29899,
         12330, 25903, 29918,  6156, 29907, 29918,  7833, 29990, 29906, 29941,
         29897,  4619,  1067, 29895, 29899,   326, 29916, 29906, 29941, 29889,
         29877,    13,  5415, 29899, 12330, 25903, 29918,  6156, 29907, 29918,
          7833, 29990, 29906, 29947, 29897,  4619,  1067, 29895, 29899,   326,
         29916, 29906, 29947, 29889, 29877,    13]], device='cuda:0')
torch.Size([2, 106, 32000]) tensor([[[-2.7734, -0.5366, -2.4902,  ..., -2.0957, -2.9941, -2.1152],
         [-3.8906, -2.3477,  0.4424,  ..., -3.0449, -3.7988, -2.6680],
         [-3.8848, -2.3516,  0.2495,  ..., -2.9785, -3.7773, -2.7070],
         ...,
         [-3.8828, -2.2578,  0.5122,  ..., -3.0117, -3.8125, -2.7207],
         [-3.8027, -2.2188,  0.5981,  ..., -3.0293, -3.8281, -2.6465],
         [-4.0352, -2.0488,  0.4656,  ..., -2.9980, -3.8398, -2.7168]],

        [[-2.7734, -0.5366, -2.4902,  ..., -2.0957, -2.9941, -2.1152],
         [-3.9980, -2.3398,  0.4214,  ..., -3.0645, -3.8145, -2.7363],
         [-2.4551,  0.5156, -5.5156,  ..., -1.3457, -2.1562, -1.7861],
         ...,
         [-3.8223, -2.2559,  0.4148,  ..., -3.0273, -3.8711, -2.7090],
         [-3.8926, -2.4160,  0.5605,  ..., -3.0605, -3.8379, -2.7246],
         [-3.8223, -2.2637,  0.6416,  ..., -3.0430, -3.9219, -2.6875]]],
       device='cuda:0')
torch.Size([2, 106, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 106, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856,   313],
         [30488, 31147, 30879,  ...,   313,   856, 29871]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 30331, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186]]], device='cuda:0')
Batch 32, 70.3% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   849,  9586,  ..., 29899,  1445, 29899],
        [    1, 18252, 21300,  ...,  1853,  3443,   297]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8477, -2.2402,  0.5132,  ..., -3.0293, -3.8262, -2.5957],
         [-4.0586, -2.4082,  0.1426,  ..., -3.0059, -3.8750, -2.7754],
         ...,
         [-3.8477, -2.2422,  0.4417,  ..., -2.9668, -3.8730, -2.6895],
         [-3.8633, -2.2832,  0.1520,  ..., -2.9160, -3.8105, -2.6816],
         [-3.7676, -2.1465,  0.1382,  ..., -2.8613, -3.7637, -2.6484]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8340, -2.1719,  0.2703,  ..., -2.9238, -3.7773, -2.6738],
         [-3.8535, -2.2266,  0.2671,  ..., -2.9551, -3.7695, -2.6992],
         ...,
         [-3.9102, -2.2969,  0.3096,  ..., -3.0332, -3.7656, -2.7656],
         [-3.9688, -2.3945,  0.3430,  ..., -3.0684, -3.8086, -2.7598],
         [-3.9473, -2.3711,  0.4397,  ..., -3.0234, -3.8359, -2.6934]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ..., 31488,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   856,   313],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186]]], device='cuda:0')
Batch 33, 78.5% of total tokens
encoded shape: torch.Size([2, 3107])
torch.Size([2, 3107]) tensor([[    1, 18252, 21300,  ...,     2,     2,     2],
        [    1,  1053,  4842,  ..., 29889,  5085,    13]], device='cuda:0')
torch.Size([2, 3107, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8340, -2.1719,  0.2703,  ..., -2.9238, -3.7773, -2.6738],
         [-3.8535, -2.2266,  0.2671,  ..., -2.9551, -3.7695, -2.6992],
         ...,
         [-3.7539, -2.0039,  0.3230,  ..., -2.9551, -3.7559, -2.6250],
         [-3.7500, -2.0020,  0.3228,  ..., -2.9551, -3.7559, -2.6230],
         [-3.7461, -1.9961,  0.3230,  ..., -2.9512, -3.7500, -2.6191]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8789, -2.3105,  0.3672,  ..., -3.0254, -3.7930, -2.6035],
         [-3.9941, -2.4434,  0.3293,  ..., -3.0176, -3.8672, -2.7109],
         ...,
         [-3.9492, -2.4434,  0.5522,  ..., -3.0801, -3.8770, -2.7656],
         [-4.0234, -2.5312,  0.4373,  ..., -3.0840, -3.8945, -2.8066],
         [-3.9375, -2.3320,  0.5269,  ..., -3.0684, -3.8496, -2.7754]]],
       device='cuda:0')
torch.Size([2, 3107, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 3107, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   856,   313],
         ...,
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 31488,   313, 29892]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ...,   313,   856, 30186]]], device='cuda:0')
Batch 34, 82.7% of total tokens
encoded shape: torch.Size([2, 219])
torch.Size([2, 219]) tensor([[    1,  4949,   289,  1581, 29899, 11338, 29901,  6920, 29892,  1544,
         29892,  4876,  3776,    13,  5515,   289,  1581, 29899,   384, 15204,
         29899, 12800, 29901,  1544, 29892,  3092, 29892, 10154,  1646, 29892,
         15901,  3776,    13,    13, 29890,  1581, 29889, 15204,   353, 15739,
            13,    13, 29890,  1581, 29889,  1688, 29898,   426,    13,    12,
           458,   313, 29937, 29906, 29900, 29906, 29955, 29897,    13,    12,
         29915,  1688,  1544,  3646, 29361,  2396,   740,   580,   426,    13,
            12,    12,  1707,  9225,   353,   445, 29889, 15204, 29933,   327,
         29936,    13,    13,    12,    12,  7451, 29889,   842, 10922,  3047,
         15097, 29898, 12801, 29882, 29896, 29958, 14925,   304,   529, 29874,
          2822,   543,  2549,   517, 29901,   384, 15204, 29992,  4684,  1167,
         29889,   510,  1013, 17548,  7077,  4435, 29962,   829, 29874, 29958,
         29991,   829, 29882, 29896, 16299,  3482,    13,    13,    12,    12,
          7451, 29889, 15901, 29898,   525,  2324,   742,   740, 29898,  7928,
          1723,   426,    13,    12,    12,    12, 15901, 29889,   657,  3125,
         29898,   525,   554, 29915, 13742,  3808,   890,    13,    13,    12,
            12,    12,  9294, 29889,   598, 29903,   420, 29898, 12801, 29882,
         29896, 29958, 14925,   304,   529, 29874,  2822,   543,  2549,   517,
         29901,   384, 15204, 29992,  4684,  1167, 29889,   510,  1013, 29992,
          7077,  4435,   829, 29874, 29958, 29991,   829, 29882, 29896, 29958,
           742,  9225, 29889,   657,  1469,   580,  3482,    13,    12,    12,
         29913,  3482,    13,    12, 29913,    13, 29913,  3482,    13],
        [    1, 29871, 30143, 14626,    13, 29871,   376,  3403,  3460,  1115,
          3336,    13,  1678,   376, 29419,  4421,   459,   267,  1115,  2089,
         11167,    13,  1678,   376,  3403, 10108,  1115,  3336,    13,   418,
           376,  4592,  1115,   376, 22709, 19451,    13,  1678,  4970,    13,
         29871,  4970,    13,  8117,    13,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 219, 32000]) tensor([[[-2.7793, -0.5439, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-3.8828, -2.2852,  0.4744,  ..., -3.0488, -3.8066, -2.6523],
         [-3.9844, -2.4141,  0.2401,  ..., -3.0020, -3.8105, -2.6797],
         ...,
         [-3.8184, -2.2227,  0.2942,  ..., -2.9668, -3.7773, -2.6543],
         [-3.7695, -2.1484,  0.4329,  ..., -2.9941, -3.7910, -2.6406],
         [-3.8105, -2.2207,  0.5767,  ..., -3.0469, -3.8477, -2.6602]],

        [[-2.7793, -0.5439, -2.4883,  ..., -2.0996, -2.9980, -2.1191],
         [-4.0078, -2.3809,  0.5596,  ..., -3.0293, -3.8496, -2.7051],
         [-3.8418, -2.2031,  0.4395,  ..., -2.9922, -3.8301, -2.6387],
         ...,
         [-3.8770, -2.0977,  0.4788,  ..., -3.0156, -3.8086, -2.6719],
         [-3.8770, -2.1035,  0.4814,  ..., -3.0156, -3.8105, -2.6758],
         [-3.8848, -2.1230,  0.4844,  ..., -3.0234, -3.8203, -2.6855]]],
       device='cuda:0')
torch.Size([2, 219, 1]) tensor([[[30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 219, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 31488,   313, 29892],
         [30488, 31147, 30879,  ..., 29892,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]]], device='cuda:0')
Batch 35, 83.0% of total tokens
encoded shape: torch.Size([2, 394])
torch.Size([2, 394]) tensor([[    1,   396,  2856,   529, 29879,  5461, 29958,    13,    13, 29937,
          2856,   529, 11762,   273, 29941, 29914,  3221, 29914,  1853, 29918,
          1761, 29914,  1853, 29918,  1761, 29889, 29623, 29958,    13, 29937,
          2856,   529, 11762,   273, 29941, 29914,   601, 29914,  2520,   358,
         29918,  1445, 29914,  2080, 29889, 29623, 29958,    13,    13,  6921,
          3514, 29918,  1445, 29918,  1610,   353,   390, 29908, 10394, 26124,
            12, 29963, 29940, 29901, 29896, 29889, 29953,    12,  6156, 29901,
         29302,    12, 17080, 29901,  9290,    13, 29992, 29903, 29984,    12,
         19296, 29901,   999,    12, 29931, 29940, 29901, 29946, 29945,    13,
         29878, 29900, 29900, 29896,    12, 29929, 29929,    12,   999,    12,
         29955,    12, 29941, 29900,    12, 29947, 29924, 29906, 29902, 29946,
         29924, 29896, 29928, 29941, 29924,    12, 29922,    12, 29941, 29955,
            12, 29941, 29929,    12, 29911, 16881,  1299,  6344, 10051, 29954,
          8254,  1783, 29954,    12, 29930,    13, 29878, 29900, 29900, 29941,
            12, 29900,    12,   999,    12, 29906, 29929,    12, 29941, 29900,
            12, 29945, 29903, 29953, 29924,    12, 29930,    12, 29900,    12,
         29900,    12,  8766,  1783,  6344, 29954,  1783,  6344,    12, 29930,
            12,  8132, 29901, 29999, 29901,   999, 29892, 29906, 29929,  6653,
         29892, 29953, 29950, 29945, 29924, 29892, 29896, 29955, 29892, 29900,
         29936,    13, 29878, 29900, 29900, 29941,    12, 29906, 29900, 29953,
         29946,    12,   999,    12, 29906, 29929,    12, 29896, 29955,    12,
         29953, 29950, 29945, 29924,    12, 29930,    12, 29900,    12, 29900,
            12, 16881,  8766,    12, 29930,    12,  8132, 29901, 29999, 29901,
           999, 29892, 29929, 29892, 29974, 29892, 29945, 29903, 29953, 29924,
         29892, 29941, 29900, 29892, 29896, 29936,    13, 29878, 29900, 29900,
         29896,    12, 29896, 29946, 29955,    12,   999,    12, 29906, 29941,
         29955,    12, 29941, 29900,    12, 29929, 29924,    12, 29922,    12,
         29955,    12, 29899, 29941, 29929,    12,  5454,  8766, 29954,  8766,
          1299,    12, 29930,    12, 29940, 29924, 29901, 29875, 29901, 29896,
            13, 29897,  1769,    13,    13,   524,  1667,   580,    13, 29912,
            13,  1678, 19359,   273, 29941,  1057,  2520,   358, 29918,  1445,
         29918,  2080,  1436, 29912,  4172,  1057,  2132,   292,  5461, 29912,
         13445, 29918,  1445, 29918,  1610,  1118, 19359,   273, 29941,  1057,
          4830, 29918, 13445, 29912,   930, 29936,    13,    13,  1678,  4469,
           372,   353,  1436, 29889,   463,   890,    13,    13,  1678,   849,
           278,  1494,   526,  7126, 29901,    13,  1678,  4469,   669,  1162,
         29900,   353,   334,   277, 29936,    13,  1678,  4469,   669,  1162,
         29896,   353,  1436, 29889,  8862,   890,    13,  1678,   849,  3940,
         29901,  1716,  4953,  8340,  1156, 11924,   292,   376,   277, 29908,
         29991,    13, 29913,    13],
        [    1,  3883,   383,  2713,  6834,  3057, 29896, 29946,    13,    13,
          1026,   921,   353, 29871, 29896,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 394, 32000]) tensor([[[-2.7793, -0.5449, -2.4844,  ..., -2.0996, -2.9980, -2.1191],
         [-4.0039, -2.3496,  0.4233,  ..., -3.0684, -3.8184, -2.7383],
         [-3.8418, -2.2305,  0.3223,  ..., -2.9883, -3.7285, -2.6426],
         ...,
         [-3.8223, -2.2637,  0.3813,  ..., -2.9746, -3.8223, -2.7051],
         [-3.8301, -2.1992,  0.2927,  ..., -2.9648, -3.8027, -2.6445],
         [-3.8145, -2.2441,  0.5063,  ..., -3.0293, -3.8555, -2.6855]],

        [[-2.7793, -0.5449, -2.4844,  ..., -2.0996, -2.9980, -2.1191],
         [-3.8672, -2.3164,  0.2046,  ..., -2.9199, -3.7207, -2.6270],
         [-3.9258, -2.5039,  0.2805,  ..., -2.9277, -3.7500, -2.7305],
         ...,
         [-3.8066, -2.0156,  0.4402,  ..., -2.9961, -3.7930, -2.6426],
         [-3.7949, -2.0020,  0.4365,  ..., -2.9922, -3.7910, -2.6387],
         [-3.7891, -1.9990,  0.4331,  ..., -2.9922, -3.7910, -2.6387]]],
       device='cuda:0')
torch.Size([2, 394, 1]) tensor([[[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [31147],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 394, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ..., 29892,   313,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 30879, 31147,  ..., 29892, 30186,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]]], device='cuda:0')
Batch 36, 83.4% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 18787,  2109,  ...,     2,     2,     2],
        [    1,   849,    13,  ..., 16311,  2354,  5407]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.7715, -2.1523,  0.3284,  ..., -2.9375, -3.7793, -2.6387],
         [-3.9141, -2.3145,  0.2017,  ..., -3.0234, -3.8359, -2.7285],
         ...,
         [-3.0000, -0.8643, -1.7568,  ..., -2.3203, -3.2051, -2.2441],
         [-3.0098, -0.8765, -1.7588,  ..., -2.3262, -3.2129, -2.2520],
         [-2.9980, -0.8584, -1.7715,  ..., -2.3164, -3.2012, -2.2422]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8477, -2.2402,  0.5132,  ..., -3.0293, -3.8262, -2.5957],
         [-2.4492,  0.4900, -5.2031,  ..., -1.4189, -2.2246, -1.7471],
         ...,
         [-3.9160, -2.3809,  0.3596,  ..., -3.0273, -3.7402, -2.7754],
         [-3.9512, -2.3906,  0.3176,  ..., -3.0742, -3.7461, -2.8418],
         [-3.8848, -2.2930,  0.1761,  ..., -3.0039, -3.6875, -2.7559]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   313, 31488],
         [30488, 31147, 30879,  ..., 29892, 30186,   856],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 30879, 31147,  ..., 29892,   856,   313]]], device='cuda:0')
Batch 37, 87.6% of total tokens
encoded shape: torch.Size([2, 600])
torch.Size([2, 600]) tensor([[    1,  6319,  3134,  ..., 16040,  1807, 29958],
        [    1,  4949,  9166,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 600, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8965, -2.2910,  0.4421,  ..., -2.9648, -3.8340, -2.6934],
         [-3.8496, -2.3125,  0.3018,  ..., -3.0039, -3.7617, -2.6973],
         ...,
         [-3.8164, -2.2715,  0.5073,  ..., -2.9766, -3.8047, -2.6719],
         [-3.8691, -2.3203,  0.3198,  ..., -2.9922, -3.7949, -2.6816],
         [-3.9062, -2.3691,  0.4360,  ..., -2.9844, -3.7891, -2.6621]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8828, -2.2852,  0.4746,  ..., -3.0508, -3.8066, -2.6523],
         [-3.9316, -2.3887,  0.3325,  ..., -3.0176, -3.7812, -2.7031],
         ...,
         [-3.8164, -2.0312,  0.3386,  ..., -2.9766, -3.7852, -2.6406],
         [-3.8164, -2.0293,  0.3391,  ..., -2.9746, -3.7832, -2.6387],
         [-3.8184, -2.0312,  0.3384,  ..., -2.9746, -3.7832, -2.6406]]],
       device='cuda:0')
torch.Size([2, 600, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 600, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]]], device='cuda:0')
Batch 38, 88.3% of total tokens
encoded shape: torch.Size([2, 1053])
torch.Size([2, 1053]) tensor([[    1,  4949,  1954,  ...,    13, 29913,    13],
        [    1,  7762,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1053, 32000]) tensor([[[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.8828, -2.2852,  0.4751,  ..., -3.0508, -3.8066, -2.6523],
         [-3.9961, -2.4785,  0.1644,  ..., -2.9355, -3.8242, -2.7266],
         ...,
         [-3.8750, -2.2656,  0.3381,  ..., -2.9414, -3.8711, -2.7070],
         [-3.8828, -2.2676,  0.2502,  ..., -2.9629, -3.8262, -2.6797],
         [-3.8926, -2.3516,  0.5195,  ..., -3.0352, -3.9004, -2.7090]],

        [[-2.7773, -0.5444, -2.4824,  ..., -2.0996, -2.9980, -2.1172],
         [-3.8848, -2.2676,  0.4661,  ..., -3.0195, -3.8242, -2.6602],
         [-2.4102,  0.3120, -4.5391,  ..., -1.5186, -2.4160, -1.8115],
         ...,
         [-3.8164, -2.0820,  0.2092,  ..., -2.9512, -3.7559, -2.6465],
         [-3.8145, -2.0801,  0.2073,  ..., -2.9492, -3.7559, -2.6465],
         [-3.8164, -2.0859,  0.2078,  ..., -2.9531, -3.7578, -2.6484]]],
       device='cuda:0')
torch.Size([2, 1053, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1053, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   856, 30186],
         ...,
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488],
         [30488, 31147, 30879,  ...,   313, 29892, 31488]]], device='cuda:0')
Batch 39, 89.5% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 11474,    13,  ..., 12690, 29918,   978],
        [    1,   849,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8828, -2.2559,  0.4111,  ..., -3.0020, -3.8223, -2.6758],
         [-2.3887,  0.4666, -5.6250,  ..., -1.2314, -2.1074, -1.6602],
         ...,
         [-3.9375, -2.4766,  0.3157,  ..., -3.0547, -3.8125, -2.7480],
         [-3.9199, -2.4043,  0.4609,  ..., -3.0840, -3.8555, -2.7578],
         [-3.9160, -2.3828,  0.2360,  ..., -3.0195, -3.7676, -2.7266]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8477, -2.2402,  0.5132,  ..., -3.0293, -3.8262, -2.5957],
         [-2.4492,  0.4900, -5.2031,  ..., -1.4189, -2.2246, -1.7471],
         ...,
         [-3.4844, -1.7080, -0.0759,  ..., -2.8086, -3.6328, -2.5215],
         [-3.4844, -1.7070, -0.0739,  ..., -2.8086, -3.6309, -2.5195],
         [-3.4824, -1.7090, -0.0756,  ..., -2.8105, -3.6328, -2.5215]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[30488],
         [30488],
         [30879],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30879, 31147, 30488,  ..., 30331, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30555, 30186,   856],
         [30488, 31147, 30879,  ...,   313, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [31147, 30488, 30879,  ..., 30268, 30154, 30300],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 29889],
         [30488, 31147, 30879,  ..., 30331, 30300, 29889],
         [30488, 31147, 30879,  ..., 30331, 30300, 29889]]], device='cuda:0')
Batch 40, 94.5% of total tokens
encoded shape: torch.Size([2, 2186])
torch.Size([2, 2186]) tensor([[    1,  6319,  3134,  ...,     2,     2,     2],
        [    1, 20577, 29992,  ...,   829,  4563, 29958]], device='cuda:0')
torch.Size([2, 2186, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8965, -2.2910,  0.4424,  ..., -2.9648, -3.8340, -2.6934],
         [-3.8496, -2.3125,  0.3027,  ..., -3.0039, -3.7617, -2.6973],
         ...,
         [-3.8516, -2.1055,  0.2725,  ..., -2.9707, -3.7578, -2.6602],
         [-3.8477, -2.0977,  0.2668,  ..., -2.9648, -3.7520, -2.6562],
         [-3.8457, -2.0957,  0.2632,  ..., -2.9648, -3.7520, -2.6562]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8379, -2.2148,  0.3601,  ..., -3.0000, -3.7754, -2.6367],
         [-3.8594, -2.2285,  0.2474,  ..., -2.9512, -3.7773, -2.6680],
         ...,
         [-3.9043, -2.3555,  0.4275,  ..., -3.0254, -3.8496, -2.7148],
         [-3.8945, -2.4141,  0.3425,  ..., -3.0293, -3.8047, -2.7324],
         [-3.9648, -2.4355,  0.5181,  ..., -3.0684, -3.8398, -2.7695]]],
       device='cuda:0')
torch.Size([2, 2186, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 2186, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856],
         [30488, 31147, 30879,  ...,   313, 29892,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30186,   313,   856],
         [30488, 31147, 30879,  ...,   313,   856, 29871]]], device='cuda:0')
Batch 41, 97.4% of total tokens
encoded shape: torch.Size([2, 637])
torch.Size([2, 637]) tensor([[    1,  6319,  3134,  ...,     2,     2,     2],
        [    1,  6319,  1961,  ...,   416,    13, 29913]], device='cuda:0')
torch.Size([2, 637, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8945, -2.2891,  0.4419,  ..., -2.9648, -3.8340, -2.6934],
         [-3.8457, -2.3047,  0.3008,  ..., -3.0000, -3.7578, -2.6934],
         ...,
         [-3.9668, -2.1680,  0.3696,  ..., -3.0254, -3.8242, -2.6934],
         [-3.9648, -2.1680,  0.3733,  ..., -3.0273, -3.8262, -2.6953],
         [-3.9590, -2.1621,  0.3745,  ..., -3.0254, -3.8262, -2.6914]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8945, -2.2891,  0.4419,  ..., -2.9648, -3.8340, -2.6934],
         [-3.9414, -2.3477,  0.4177,  ..., -3.0547, -3.7891, -2.7148],
         ...,
         [-3.9297, -2.3750,  0.4526,  ..., -3.0156, -3.8379, -2.7598],
         [-3.8828, -2.3047,  0.3740,  ..., -2.9805, -3.8594, -2.7168],
         [-3.8652, -2.2910,  0.4558,  ..., -3.0176, -3.8398, -2.7266]]],
       device='cuda:0')
torch.Size([2, 637, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 637, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ..., 30555, 30186,   856]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         ...,
         [30488, 31147, 30879,  ...,   313,   856, 30186],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   856,   313]]], device='cuda:0')
Batch 42, 98.4% of total tokens
encoded shape: torch.Size([2, 1463])
torch.Size([2, 1463]) tensor([[    1, 18252, 21300,  ...,     2,     2,     2],
        [    1, 29871,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1463, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.8340, -2.1719,  0.2710,  ..., -2.9238, -3.7773, -2.6738],
         [-3.8574, -2.2344,  0.2686,  ..., -2.9590, -3.7734, -2.7031],
         ...,
         [-3.5566, -1.7686, -0.0931,  ..., -2.8164, -3.6328, -2.5391],
         [-3.5508, -1.7607, -0.0961,  ..., -2.8125, -3.6289, -2.5352],
         [-3.5645, -1.7793, -0.0994,  ..., -2.8223, -3.6406, -2.5469]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0078, -2.3809,  0.5596,  ..., -3.0293, -3.8496, -2.7051],
         [-2.4590,  0.4316, -5.0547,  ..., -1.4912, -2.2754, -1.8203],
         ...,
         [-3.9297, -2.3945,  0.2969,  ..., -2.9766, -3.8887, -2.7188],
         [-3.9746, -2.4355,  0.3770,  ..., -3.0156, -3.8691, -2.7363],
         [-4.0273, -2.4863,  0.5986,  ..., -3.0703, -3.9531, -2.7871]]],
       device='cuda:0')
torch.Size([2, 1463, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [31147],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 1463, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         [30488, 31147, 30879,  ..., 29892,   856,   313],
         ...,
         [30488, 31147, 30879,  ..., 30331, 29889, 30300],
         [30488, 31147, 30879,  ..., 30331, 29889, 30300],
         [30488, 31147, 30879,  ..., 30331, 29889, 30300]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         [31147, 30488, 30879,  ..., 30331, 30300, 30154],
         ...,
         [30488, 31147, 30879,  ...,   313, 30186,   856],
         [30488, 31147, 30879,  ..., 30555,   856, 30186],
         [30488, 31147, 30879,  ...,   856, 30555, 29871]]], device='cuda:0')
Batch 43, 100.0% of total tokens
encoded shape: torch.Size([2, 3317])
torch.Size([2, 3317]) tensor([[    1,   396,  2856,  ...,     2,     2,     2],
        [    1,  9330, 29879,  ...,   901,  5235,    13]], device='cuda:0')
torch.Size([2, 3317, 32000]) tensor([[[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-3.9922, -2.3340,  0.4207,  ..., -3.0605, -3.8086, -2.7305],
         [-3.8418, -2.2305,  0.3225,  ..., -2.9883, -3.7285, -2.6426],
         ...,
         [-3.1758, -1.1660, -1.2041,  ..., -2.4863, -3.3516, -2.3457],
         [-3.1699, -1.1543, -1.2129,  ..., -2.4824, -3.3477, -2.3418],
         [-3.1719, -1.1602, -1.2119,  ..., -2.4844, -3.3496, -2.3457]],

        [[-2.7734, -0.5366, -2.4863,  ..., -2.0977, -2.9941, -2.1152],
         [-4.0312, -2.4609,  0.3079,  ..., -3.0586, -3.8340, -2.7676],
         [-4.0430, -2.4648,  0.2922,  ..., -3.0527, -3.7793, -2.7773],
         ...,
         [-3.9121, -2.3711,  0.2279,  ..., -3.0586, -3.6895, -2.7422],
         [-3.9062, -2.3574,  0.2362,  ..., -3.0332, -3.7207, -2.7773],
         [-3.8516, -2.2578,  0.5532,  ..., -3.0547, -3.8164, -2.7090]]],
       device='cuda:0')
torch.Size([2, 3317, 1]) tensor([[[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]],

        [[30488],
         [30488],
         [30488],
         ...,
         [30488],
         [30488],
         [30488]]], device='cuda:0')
torch.Size([2, 3317, 10]) tensor([[[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ..., 30555,   856, 29871],
         [30488, 31147, 30879,  ..., 29892,   313,   856],
         ...,
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154],
         [30488, 31147, 30879,  ..., 30331, 30300, 30154]],

        [[30488, 31147, 30879,  ..., 31488, 30300, 30154],
         [30488, 31147, 30879,  ...,   856, 30555, 29899],
         [30488, 31147, 30879,  ...,   856, 30555, 29871],
         ...,
         [30488, 31147, 30879,  ..., 29892,   856,   313],
         [30488, 31147, 30879,  ...,   856, 29892,   313],
         [30488, 31147, 30879,  ...,   313, 30186,   856]]], device='cuda:0')
Batch 0, 0.0% of total tokens
encoded shape: torch.Size([2, 1512])
torch.Size([2, 1512]) tensor([[    1, 29871,    13,  ...,  1315,  1496,    13],
        [    1,   396,   448,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1512, 32000]) tensor([[[-2.5469e+00, -3.0542e-01, -5.0508e+00,  ..., -1.4570e+00,
          -2.4609e+00, -1.9121e+00],
         [-2.5859e+00, -3.2031e-01, -5.3633e+00,  ..., -1.3652e+00,
          -2.4082e+00, -1.8906e+00],
         [-2.2617e+00, -8.9407e-07, -5.3555e+00,  ..., -1.3330e+00,
          -2.3184e+00, -1.7949e+00],
         ...,
         [-2.5918e+00, -4.4824e-01, -5.3555e+00,  ..., -1.4160e+00,
          -2.4375e+00, -1.9512e+00],
         [-2.5859e+00, -3.5962e-01, -5.1406e+00,  ..., -1.4219e+00,
          -2.4238e+00, -1.9570e+00],
         [-2.6152e+00, -4.1504e-01, -4.9375e+00,  ..., -1.4873e+00,
          -2.4941e+00, -1.9668e+00]],

        [[-2.5469e+00, -3.0542e-01, -5.0508e+00,  ..., -1.4570e+00,
          -2.4609e+00, -1.9121e+00],
         [-2.5996e+00, -3.3594e-01, -5.3984e+00,  ..., -1.4004e+00,
          -2.4121e+00, -1.9307e+00],
         [-2.5762e+00, -3.5059e-01, -5.4297e+00,  ..., -1.3594e+00,
          -2.4199e+00, -1.9121e+00],
         ...,
         [-2.6055e+00, -3.2495e-01, -5.1289e+00,  ..., -1.4521e+00,
          -2.4648e+00, -1.9248e+00],
         [-2.6055e+00, -3.2495e-01, -5.1289e+00,  ..., -1.4521e+00,
          -2.4648e+00, -1.9248e+00],
         [-2.6055e+00, -3.2471e-01, -5.1289e+00,  ..., -1.4521e+00,
          -2.4648e+00, -1.9248e+00]]], device='cuda:0')
torch.Size([2, 1512, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1512, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 1, 1.6% of total tokens
encoded shape: torch.Size([2, 794])
torch.Size([2, 794]) tensor([[    1,   396, 29183,  ...,     2,     2,     2],
        [    1, 29871, 30143,  ...,   500,    13, 29913]], device='cuda:0')
torch.Size([2, 794, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.5996, -0.3359, -5.3984,  ..., -1.3994, -2.4121, -1.9307],
         [-2.5859, -0.4209, -5.3672,  ..., -1.3896, -2.4062, -1.9502],
         ...,
         [-2.5820, -0.2561, -5.4062,  ..., -1.3809, -2.4062, -1.8936],
         [-2.5879, -0.2632, -5.4023,  ..., -1.3857, -2.4102, -1.8984],
         [-2.5820, -0.2551, -5.4141,  ..., -1.3799, -2.4062, -1.8955]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.5859, -0.3215, -5.3633,  ..., -1.3643, -2.4102, -1.8906],
         [-2.5684, -0.3467, -5.3047,  ..., -1.3975, -2.4434, -1.8857],
         ...,
         [-2.5645, -0.3601, -5.3047,  ..., -1.4209, -2.4531, -1.9580],
         [-2.5684, -0.3914, -5.3359,  ..., -1.3975, -2.4316, -1.9053],
         [-2.5625, -0.3591, -5.2812,  ..., -1.3926, -2.4336, -1.9131]]],
       device='cuda:0')
torch.Size([2, 794, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 794, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 2, 2.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  4949,    13,  ...,     2,     2,     2],
        [    1, 14775,   478,  ...,  5790,   313,   276]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.2930, -0.0971, -5.2070,  ..., -1.3789, -2.3555, -1.8018],
         ...,
         [-2.6094, -0.3350, -5.0977,  ..., -1.4639, -2.4766, -1.9307],
         [-2.6094, -0.3350, -5.0977,  ..., -1.4639, -2.4766, -1.9307],
         [-2.6035, -0.3269, -5.1016,  ..., -1.4590, -2.4707, -1.9258]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5918, -0.3943, -5.3125,  ..., -1.3857, -2.4434, -1.9443],
         [-2.5645, -0.3845, -5.3945,  ..., -1.3848, -2.4375, -1.9092],
         ...,
         [-2.6074, -0.4106, -5.3242,  ..., -1.3857, -2.3984, -1.9580],
         [-2.6172, -0.4902, -5.3438,  ..., -1.4170, -2.4473, -1.9883],
         [-2.5723, -0.4355, -5.3906,  ..., -1.3936, -2.4629, -1.9668]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 3, 7.2% of total tokens
encoded shape: torch.Size([2, 3838])
torch.Size([2, 3838]) tensor([[    1,  4949, 29871,  ...,    13, 29913,    13],
        [    1,  4949,  9166,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 3838, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.5586, -0.3616, -5.4922,  ..., -1.3418, -2.3770, -1.8623],
         ...,
         [-2.5762, -0.3992, -5.2891,  ..., -1.4189, -2.4707, -1.8965],
         [-2.5527, -0.3455, -5.2539,  ..., -1.3984, -2.4141, -1.9180],
         [-2.5781, -0.4238, -5.1289,  ..., -1.4404, -2.4609, -1.9111]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.5605, -0.3730, -5.4414,  ..., -1.3779, -2.3672, -1.9014],
         ...,
         [-2.5840, -0.3040, -5.1172,  ..., -1.4492, -2.4609, -1.9160],
         [-2.5840, -0.3040, -5.1172,  ..., -1.4492, -2.4609, -1.9170],
         [-2.5840, -0.3042, -5.1172,  ..., -1.4502, -2.4609, -1.9170]]],
       device='cuda:0')
torch.Size([2, 3838, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3838, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 4, 11.2% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  1134,   435,  ...,   313, 15091, 29901],
        [    1,  3577,   432,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5742, -0.4209, -5.4180,  ..., -1.3945, -2.3750, -1.9111],
         [-2.5918, -0.4773, -5.4219,  ..., -1.3770, -2.3730, -1.9082],
         ...,
         [-2.5898, -0.4446, -5.3516,  ..., -1.3809, -2.4375, -1.9297],
         [-2.5840, -0.4246, -5.4297,  ..., -1.3711, -2.4141, -1.9434],
         [-2.5684, -0.4463, -5.4023,  ..., -1.3613, -2.4180, -1.9170]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3674, -5.3359,  ..., -1.4229, -2.4004, -1.8994],
         [-2.5684, -0.4194, -5.4219,  ..., -1.3379, -2.3613, -1.8965],
         ...,
         [-2.5762, -0.2981, -5.1016,  ..., -1.4512, -2.4629, -1.9160],
         [-2.5762, -0.2986, -5.1016,  ..., -1.4521, -2.4629, -1.9160],
         [-2.5762, -0.2976, -5.1016,  ..., -1.4512, -2.4629, -1.9160]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 5, 15.4% of total tokens
encoded shape: torch.Size([2, 490])
torch.Size([2, 490]) tensor([[    1,  1053,   350,   949,  7283,  3774,   515, 19283, 29890,   949,
          7283,  3774, 29889, 19682, 29915,    13,  5215,   350,   949,  7283,
          3774,  2001,   515, 19283, 29890,   949,  7283,  3774, 29899,   667,
         29889, 19682, 29915,    13,    13, 15843,   426,   350,   949,  7283,
          3774, 29892,   350,   949,  7283,  3774,  2001,   500,    13,    13,
         15843,  2322,   350,   949,  7283,  3774,    13,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2],
        [    1, 18787,  4855, 29914,  2109, 29914,  6272,  3017,    13,    13,
          5215,  4390,    13,  5215, 10876,    13,  5215,  2897,    13,    13,
           361,  7431, 29898,  9675, 29889, 19218, 29897,   529, 29871, 29941,
         29901,    13,  1678,  1596,   376, 27573, 29901,  1273, 29879,   529,
          4993, 29958,   529,  7854, 11903,  1273,   313,  9675, 29889, 19218,
         29961, 29900,  1402, 29897,    13,  1678,  1596,   376,   387, 29889,
          1273, 29879, 19592, 29918, 15176, 29889,  3126, 19592, 29889,  3126,
         29908,  1273,   313,  9675, 29889, 19218, 29961, 29900,  1402, 29897,
            13,  1678,  1596,    13,  1678,  1596,   376,  2528, 29879,   738,
          5578,   800,   304,   529,  7854, 29958,   393,  1863,   297,   529,
          4993, 29958,   541,   451,   529,  7854, 11903,    13,  1678, 10876,
         29889, 13322, 29898, 29896, 29897,    13,    13,  4351,  2084,   353,
         10876, 29889, 19218, 29961, 29896, 29962,    13, 22992,  2084,   353,
         10876, 29889, 19218, 29961, 29906, 29962,    13, 18276,   407,   493,
           353, 29743,  2084,   718, 11393,  7050, 29908,    13,    13,  2541,
          1722, 29898,  4351,  2084, 29897,   408,   285, 29901,    13,  1678,
          4765,   353,  4390, 29889,  1359, 29898, 29888, 29897,    13,    13,
          2541,  1722, 29898, 22992,  2084, 29897,   408,   285, 29901,    13,
          1678, 29743,   353,  4390, 29889,  1359, 29898, 29888, 29897,    13,
            13,   517,  2528,   353,  6571,    13,  1454,   413, 29892, 29894,
           297,  4765, 29889,  1524,  7076,  7295,    13,  1678,   565,   413,
           451,   297, 29743, 29901,    13,  4706,  1596,   376,  2528,   292,
          1273, 29879, 29908,  1273,   313, 29895, 29892, 29897,    13,  4706,
           304,  2528, 29961, 29895, 29962,   353,   325,    13,    13, 29937,
          1016, 29915, 29873,   925,  4390, 29889, 29881, 17204,   408,   591,
         29915,   645,  3117,   337, 29899,  2098,   599,   278,  6611,   313,
           392,   896, 29915,   276,    13, 29937,   451,   297,   738,  2183,
          1797,   577,   591,   508, 29915, 29873,   925,  2656, 29918,  8149,
           467, 22871,   963,   304,   278,  1095, 29889,    13,  2541,  1722,
         29898, 22992,  2084, 29897,   408,   565, 29886, 29901,    13,  1678,
           411,  1722, 29898, 18276,   407,   493, 29892,   525, 29893,  1495,
           408,   310, 29886, 29901,    13,  4706,   363,  1196,   297,   565,
         29886, 29901,    13,  9651, 10076,  2986,  1220,   353,  1196, 29889,
         17010,   580,    13,  9651,   565, 10076,  2986,  1220,   297,  6702,
         29912,   742,   525, 10162,  1125,    13, 18884,   310, 29886, 29889,
          3539, 29898,  1220, 29897,    13,  9651, 25342, 10076,  2986,  1220,
         29889,  1975,  2541, 29898,  3788,  1125,    13, 18884,   310, 29886,
         29889,  3539, 29898,  1220, 29897,    13,  9651,  1683, 29901,    13,
         18884,   310, 29886, 29889,  3539,   877,  1678,   525, 29974,   303,
           374,  2986,  1220, 29974,   742,  1495,    13, 18884,   304,  2528,
          5015,   353,  4390, 29889, 29881, 17204, 29898,   517,  2528, 29892,
         29536, 29922, 29946, 29892,  2903,  4097,  7607,   742,   742,   525,
         29901,   525,   511,  9801, 29918,   294, 18869, 29922,  8824, 29892,
          8025,   543,  9420, 29947,  2564, 17010,   703, 29912,  1012, 29876,
          1159,    13, 18884,   310, 29886, 29889,  3539, 14182, 29876,  1159,
            13, 18884,   310, 29886, 29889,  3539, 29898,   517,  2528,  5015,
         29889, 12508,   877,  9420, 29947,  8785,    13, 18884,   310, 29886,
         29889,  3539, 14182, 29876,  1159,    13,    13,   359, 29889,  1267,
           420, 29898, 18276,   407,   493, 29892, 29743,  2084, 29897,    13]],
       device='cuda:0')
torch.Size([2, 490, 32000]) tensor([[[-2.5371, -0.2917, -5.0586,  ..., -1.4482, -2.4512, -1.9033],
         [-2.5762, -0.3972, -5.3633,  ..., -1.4180, -2.4180, -1.8545],
         [-2.5762, -0.3845, -5.4258,  ..., -1.3799, -2.4062, -1.9404],
         ...,
         [-2.5859, -0.2551, -5.3594,  ..., -1.3994, -2.4258, -1.8945],
         [-2.5859, -0.2566, -5.3633,  ..., -1.3994, -2.4258, -1.8945],
         [-2.5859, -0.2561, -5.3672,  ..., -1.3984, -2.4258, -1.8945]],

        [[-2.5371, -0.2917, -5.0586,  ..., -1.4482, -2.4512, -1.9033],
         [-2.5430, -0.3455, -5.4258,  ..., -1.3721, -2.4102, -1.8857],
         [-2.5391, -0.3635, -5.4375,  ..., -1.3955, -2.3984, -1.9004],
         ...,
         [-2.5879, -0.4224, -5.2969,  ..., -1.4385, -2.4473, -1.9385],
         [-2.5820, -0.3765, -5.1367,  ..., -1.4385, -2.4473, -1.9678],
         [-2.6191, -0.4197, -4.9297,  ..., -1.4727, -2.4707, -1.9502]]],
       device='cuda:0')
torch.Size([2, 490, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 490, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 6, 15.9% of total tokens
encoded shape: torch.Size([2, 459])
torch.Size([2, 459]) tensor([[    1,  4949,    13,   334, 14187,  1266, 29871, 29906, 29900, 29896,
         29947, 29899, 29906, 29900, 29906, 29900,   278,  2441,  4148,   470,
         15717, 29889,    13,   334,    13,   334, 10413, 21144,  1090,   278,
         13380, 19245, 29892, 10079, 29871, 29906, 29889, 29900,   313,  1552,
           376, 29931,   293,  1947,  1496,    13,   334,   366,  1122,   451,
           671,   445,   934,  5174,   297,   752, 13036,   411,   278, 19245,
         29889,    13,   334,   887,  1122,  4017,   263,  3509,   310,   278,
         19245,   472,    13,   334,    13,   334,   418,  1732,   597,  1636,
         29889,  4288, 29889,   990, 29914,   506, 11259, 29914, 27888,  1430,
          1660, 29899, 29906, 29889, 29900,    13,   334,    13,   334, 25870,
          3734,   491, 22903,  4307,   470, 15502,   304,   297,  5007, 29892,
          7047,    13,   334, 13235,  1090,   278, 19245,   338, 13235,   373,
           385,   376,  3289,  8519, 29908,   350,  3289,  3235, 29892,    13,
           334,   399,  1806,  8187,  2692,   399,  1718, 29934, 13566, 29059,
          6323,  8707, 29928, 22122, 29903,  8079, 13764, 29979,   476, 22255,
         29892,  2845,  4653,   470,  2411,  2957, 29889,    13,   334,  2823,
           278, 19245,   363,   278,  2702,  4086, 14765,  1076, 11239,   322,
            13,   334, 27028,  1090,   278, 19245, 29889,    13,  3776,    13,
            13,  5113,  2906, 29889, 29885, 18282, 29889, 29878, 29906, 11140,
         29889,  7938, 29889, 23362, 29936,    13,    13,  7918,    13,   334,
          5798,  1934,   363,  9254,  9608,   427,  1830,   267,   313, 29872,
         29889, 29887, 29889,  5381,  7546,  9741,   467,    13,   334,   529,
         29886, 29958,    13,   334,   399, 25614, 29901,   437,  6058,   671,
           372, 11420,  1135, 26633, 20889,   284,   364, 29906, 11140, 29899,
          7938,  1836,    13,  3776,    13,  3597,  2186,   770,  1174,  1830,
           267,   426,    13,    13,  1678,  7762,    13,   268,   334,   450,
          3309,   310,   278,  7023,  2159,  1746, 29892,   372,   338, 29871,
         29941,  6262, 29889,    13,   268,  3776,    13,  1678,   970,  2294,
          2186,   938, 22717, 10721, 29918,  3738, 27286, 29918, 14226,   353,
         29871, 29941, 29936,    13,    13,  1678,   970,  2294,  2186,   938,
           349,  8322, 29918, 23252,  1001, 29918, 14226,   353, 22717, 10721,
         29918,  3738, 27286, 29918, 14226,   718, 29871, 29896, 29936,    13,
            13,  1678,  7762,    13,   268,   334,   450,  4236,  6262,  2159,
           310,  1269,   427, 21367, 29892,   995,   338, 29871, 29896, 29953,
         29955, 29955, 29955, 29906, 29896, 29945, 29889,   313, 29875, 29889,
         29872, 29889,  4236,   995,   310,   938, 29906, 29946, 29892,   313,
         29906,  3579, 29871, 29906, 29946, 29897,   448, 29871, 29896, 29897,
            13,   268,  3776,    13,  1678,   970,  2294,  2186,   938, 18134,
         29918,  1430, 12064,  3927,  4162, 29918, 14226,   353,   313, 29896,
          3532,   313, 14226, 29918,  3738, 27286, 29918, 14226,  3532, 29871,
         29941,   876,   448, 29871, 29896, 29936,    13,    13,  1678,  7762,
            13,   268,   334,   450,  8638,   310,   315, 29899,  3293,  1347,
           470,   315, 29899,  3293,  7581,   848, 29889,    13,   268,  3776,
            13,  1678,   970,  2294,  2186,  7023,   323,  1001, 16173,  1964,
           353, 29871, 29900, 29936,    13,    13,  1678,  2024,  1174,  1830,
           267,   580,   426,    13,  1678,   500,    13, 29913,    13],
        [    1,   525,  1509,  9406,  2670,    13,    13,  5453, 29889, 26500,
           353,  1996,   877,  6904,   275, 29899,   326,  2037,   287,  1495,
           580,    13,    12, 29973,  5792, 29889,   326,   352,    13,    12,
         29901,  1996,   877,  6904,   845,   326,  2157,    13,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 459, 32000]) tensor([[[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5684, -0.3523, -5.3359,  ..., -1.4209, -2.4062, -1.8799],
         [-2.2832, -0.0820, -5.2188,  ..., -1.3691, -2.3457, -1.7930],
         ...,
         [-2.5586, -0.3586, -5.3750,  ..., -1.3926, -2.4375, -1.9297],
         [-2.5488, -0.3237, -5.3008,  ..., -1.3955, -2.4219, -1.8760],
         [-2.5938, -0.4126, -5.0977,  ..., -1.4570, -2.4824, -1.9199]],

        [[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5762, -0.3291, -5.4453,  ..., -1.3857, -2.4004, -1.9072],
         [-2.5586, -0.3901, -5.5039,  ..., -1.3799, -2.3887, -1.9053],
         ...,
         [-2.5918, -0.2478, -5.3086,  ..., -1.4062, -2.4297, -1.9004],
         [-2.5918, -0.2478, -5.3086,  ..., -1.4062, -2.4277, -1.8994],
         [-2.5918, -0.2471, -5.3164,  ..., -1.4053, -2.4277, -1.9004]]],
       device='cuda:0')
torch.Size([2, 459, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 459, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 7, 16.4% of total tokens
encoded shape: torch.Size([2, 965])
torch.Size([2, 965]) tensor([[    1,   849,  5920,  ...,     2,     2,     2],
        [    1,   773,  2184,  ...,   500,    13, 29913]], device='cuda:0')
torch.Size([2, 965, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.3772, -5.2539,  ..., -1.4287, -2.4492, -1.8535],
         [-2.5566, -0.3818, -5.4961,  ..., -1.3613, -2.4141, -1.9111],
         ...,
         [-2.6113, -0.3237, -5.1406,  ..., -1.4541, -2.4668, -1.9258],
         [-2.6113, -0.3235, -5.1445,  ..., -1.4531, -2.4668, -1.9258],
         [-2.6113, -0.3240, -5.1406,  ..., -1.4541, -2.4688, -1.9268]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5547, -0.3875, -5.3984,  ..., -1.3760, -2.4121, -1.8945],
         [-2.5469, -0.4038, -5.4961,  ..., -1.3340, -2.4141, -1.8936],
         ...,
         [-2.5566, -0.3716, -5.4180,  ..., -1.4121, -2.4277, -1.9160],
         [-2.5664, -0.3875, -5.3984,  ..., -1.3867, -2.4199, -1.8936],
         [-2.5605, -0.3596, -5.3477,  ..., -1.3945, -2.4043, -1.9248]]],
       device='cuda:0')
torch.Size([2, 965, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 965, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 8, 17.4% of total tokens
encoded shape: torch.Size([2, 789])
torch.Size([2, 789]) tensor([[    1,   773,  2184,  ...,     2,     2,     2],
        [    1,  6319,  3134,  ...,  7611, 29958,    13]], device='cuda:0')
torch.Size([2, 789, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.5566, -0.3894, -5.3984,  ..., -1.3750, -2.4141, -1.8945],
         [-2.5469, -0.4026, -5.4961,  ..., -1.3340, -2.4141, -1.8936],
         ...,
         [-2.5820, -0.3003, -5.3320,  ..., -1.4092, -2.4121, -1.9180],
         [-2.5820, -0.3005, -5.3320,  ..., -1.4092, -2.4121, -1.9189],
         [-2.5801, -0.3000, -5.3320,  ..., -1.4092, -2.4141, -1.9180]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4570, -2.4609, -1.9131],
         [-2.5801, -0.3755, -5.3516,  ..., -1.3633, -2.4199, -1.9180],
         [-2.5645, -0.4045, -5.4062,  ..., -1.4062, -2.3945, -1.9307],
         ...,
         [-2.5840, -0.4434, -5.2852,  ..., -1.4189, -2.4160, -1.9258],
         [-2.5820, -0.3799, -5.1953,  ..., -1.4092, -2.4180, -1.9346],
         [-2.5918, -0.3818, -5.1367,  ..., -1.4326, -2.4336, -1.9209]]],
       device='cuda:0')
torch.Size([2, 789, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 789, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 9, 18.9% of total tokens
encoded shape: torch.Size([2, 1518])
torch.Size([2, 1518]) tensor([[    1,  1996,   877,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1518, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.4268, -5.3945,  ..., -1.4023, -2.3945, -1.8857],
         [-2.5957, -0.4519, -5.3750,  ..., -1.4258, -2.3867, -1.9238],
         ...,
         [-2.5996, -0.3164, -5.1055,  ..., -1.4561, -2.4668, -1.9229],
         [-2.5996, -0.3167, -5.1055,  ..., -1.4561, -2.4668, -1.9229],
         [-2.6035, -0.3240, -5.1016,  ..., -1.4600, -2.4707, -1.9258]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5684, -0.3528, -5.3398,  ..., -1.4219, -2.4062, -1.8799],
         [-2.2930, -0.0969, -5.2148,  ..., -1.3770, -2.3555, -1.8008],
         ...,
         [-2.5664, -0.3513, -5.3711,  ..., -1.3896, -2.4492, -1.9180],
         [-2.5723, -0.3569, -5.1836,  ..., -1.4316, -2.4297, -1.9473],
         [-2.5742, -0.3840, -5.0625,  ..., -1.4385, -2.4414, -1.9258]]],
       device='cuda:0')
torch.Size([2, 1518, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1518, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 10, 20.4% of total tokens
encoded shape: torch.Size([2, 2811])
torch.Size([2, 2811]) tensor([[    1,  7762, 29930,  ...,  7397,  6987,    13],
        [    1,  4949,  1275,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2811, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5625, -0.3184, -5.3398,  ..., -1.4004, -2.4199, -1.8779],
         [-2.5410, -0.3169, -5.4766,  ..., -1.3701, -2.3633, -1.8799],
         ...,
         [-2.5762, -0.4009, -5.1914,  ..., -1.4375, -2.4258, -1.9199],
         [-2.5645, -0.3433, -5.2461,  ..., -1.4014, -2.3965, -1.9277],
         [-2.5723, -0.3511, -5.1836,  ..., -1.4355, -2.4434, -1.9189]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.5645, -0.3923, -5.4727,  ..., -1.3643, -2.3711, -1.8701],
         ...,
         [-2.5801, -0.2483, -5.3477,  ..., -1.3877, -2.4121, -1.8955],
         [-2.5801, -0.2488, -5.3477,  ..., -1.3877, -2.4121, -1.8955],
         [-2.5801, -0.2483, -5.3477,  ..., -1.3877, -2.4121, -1.8955]]],
       device='cuda:0')
torch.Size([2, 2811, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 2811, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 11, 24.7% of total tokens
encoded shape: torch.Size([2, 1431])
torch.Size([2, 1431]) tensor([[    1,  3577,  1667,  ...,     2,     2,     2],
        [    1,  4949,    13,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 1431, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3679, -5.3398,  ..., -1.4238, -2.4004, -1.8994],
         [-2.5645, -0.3550, -5.3789,  ..., -1.4062, -2.4004, -1.9258],
         ...,
         [-2.6094, -0.3228, -5.1367,  ..., -1.4531, -2.4648, -1.9258],
         [-2.6074, -0.3228, -5.1367,  ..., -1.4521, -2.4668, -1.9258],
         [-2.6074, -0.3225, -5.1367,  ..., -1.4531, -2.4668, -1.9258]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5684, -0.3528, -5.3398,  ..., -1.4219, -2.4062, -1.8799],
         [-2.2930, -0.0969, -5.2148,  ..., -1.3770, -2.3555, -1.8008],
         ...,
         [-2.5664, -0.3308, -5.3438,  ..., -1.4121, -2.4512, -1.9346],
         [-2.5547, -0.3416, -5.2852,  ..., -1.3838, -2.4102, -1.9141],
         [-2.5918, -0.3921, -5.1094,  ..., -1.4404, -2.4727, -1.9277]]],
       device='cuda:0')
torch.Size([2, 1431, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1431, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 12, 26.2% of total tokens
encoded shape: torch.Size([2, 596])
torch.Size([2, 596]) tensor([[   1,  365, 8979,  ...,    2,    2,    2],
        [   1, 1053, 6401,  ..., 2956,  416,   13]], device='cuda:0')
torch.Size([2, 596, 32000]) tensor([[[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5801, -0.3171, -5.3438,  ..., -1.4053, -2.3887, -1.9395],
         [-2.5664, -0.3882, -5.5273,  ..., -1.3809, -2.4180, -1.8965],
         ...,
         [-2.5859, -0.2620, -5.3750,  ..., -1.3916, -2.4121, -1.8975],
         [-2.5859, -0.2617, -5.3750,  ..., -1.3906, -2.4121, -1.8975],
         [-2.5859, -0.2615, -5.3789,  ..., -1.3916, -2.4121, -1.8975]],

        [[-2.5469, -0.3057, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5723, -0.3882, -5.3672,  ..., -1.4141, -2.4121, -1.8506],
         [-2.5977, -0.4189, -5.3984,  ..., -1.3984, -2.4199, -1.9346],
         ...,
         [-2.5820, -0.4146, -5.3281,  ..., -1.3662, -2.3828, -1.9121],
         [-2.5762, -0.3796, -5.2734,  ..., -1.4043, -2.4199, -1.9590],
         [-2.5879, -0.4243, -5.1055,  ..., -1.4629, -2.4785, -1.9131]]],
       device='cuda:0')
torch.Size([2, 596, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 596, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 13, 27.0% of total tokens
encoded shape: torch.Size([2, 844])
torch.Size([2, 844]) tensor([[    1,  6319,  1961,  ...,    13, 29913,    13],
        [    1,  1996,  3497,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 844, 32000]) tensor([[[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5820, -0.3752, -5.3477,  ..., -1.3623, -2.4180, -1.9180],
         [-2.5664, -0.3584, -5.3281,  ..., -1.4268, -2.3945, -1.9189],
         ...,
         [-2.5723, -0.3574, -5.3750,  ..., -1.3848, -2.4707, -1.9424],
         [-2.5605, -0.3359, -5.3086,  ..., -1.4014, -2.4395, -1.9199],
         [-2.5801, -0.3853, -5.2109,  ..., -1.4316, -2.4863, -1.9551]],

        [[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5703, -0.4268, -5.3945,  ..., -1.4023, -2.3945, -1.8857],
         [-2.5449, -0.3560, -5.4336,  ..., -1.3418, -2.3867, -1.9062],
         ...,
         [-2.5957, -0.2874, -5.3086,  ..., -1.4150, -2.4375, -1.9072],
         [-2.5957, -0.2886, -5.3125,  ..., -1.4141, -2.4375, -1.9072],
         [-2.5918, -0.2793, -5.3125,  ..., -1.4111, -2.4336, -1.9033]]],
       device='cuda:0')
torch.Size([2, 844, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 844, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 14, 27.9% of total tokens
encoded shape: torch.Size([2, 1639])
torch.Size([2, 1639]) tensor([[    1,   847,  7775,  ...,    13, 29913,    13],
        [    1,   396,   361,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1639, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5742, -0.3499, -5.4023,  ..., -1.3838, -2.4297, -1.9043],
         [-2.5488, -0.3215, -5.4375,  ..., -1.3740, -2.3887, -1.8975],
         ...,
         [-2.5684, -0.3252, -5.3711,  ..., -1.4004, -2.4590, -1.9014],
         [-2.5547, -0.3271, -5.3086,  ..., -1.3857, -2.4258, -1.9141],
         [-2.5938, -0.4202, -5.0508,  ..., -1.4570, -2.4863, -1.9502]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3367, -5.4023,  ..., -1.3994, -2.4121, -1.9316],
         [-2.5605, -0.3928, -5.4297,  ..., -1.3594, -2.4199, -1.8887],
         ...,
         [-2.6035, -0.3228, -5.1484,  ..., -1.4502, -2.4629, -1.9229],
         [-2.6094, -0.3318, -5.1445,  ..., -1.4541, -2.4668, -1.9268],
         [-2.6055, -0.3240, -5.1484,  ..., -1.4502, -2.4629, -1.9229]]],
       device='cuda:0')
torch.Size([2, 1639, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1639, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 15, 29.7% of total tokens
encoded shape: torch.Size([2, 212])
torch.Size([2, 212]) tensor([[    1,  8707, 18667,  4574,  8098, 29918, 29933, 25282, 29918,  9464,
           353,  6435, 13152,  8452, 29918, 25903,  4574,  8098, 29918, 29933,
         25282, 29918,  9464,  6822, 29923,  4346,  2397,  6716,    13, 29954,
          4174, 29918, 15094,  8618, 23524,  1955, 29918, 24405,  1177, 22122,
         29903,   353,  2427,   262,  2276,  1573, 29897,  4810,  3217,  3301,
         29949,  8452, 29922, 29896,    13, 13152,  8452, 29918, 29933, 25282,
         29918,  9464,   353,  6435, 29933, 25282, 29918,  9464, 29913,    13,
         13152,  8452, 29918, 25903,  4574,  8098, 29918, 29933, 25282, 29918,
          9464,   353,  6435, 13152,  8452, 29918, 29933, 25282, 29918,  9464,
          6822, 12330, 25903,  4574,  8098,  1262, 29898, 29923,  4198, 13845,
         18474, 29918,  7390,  1299, 19094, 29918,  5813, 29897,    13, 13152,
          8452, 29918, 21289,   353,  6435, 29903, 10363, 21289, 29913,    13,
         13152,  8452, 29918, 29911,  1718,  7194, 29918, 29903, 10363, 21289,
           353,  6435, 13152,  8452, 29918, 21289,  6822, 29923,  4346,  2397,
          6716,    13,  8618, 14849,  1783, 29918,  7838,  2797,  1307, 29918,
          1367,  3919, 29902,  3738,  1001,   353,  1638, 29889, 29883,  6235,
           481, 19653, 29889,  5303,  8618, 14849,  1783, 29918,  5813, 29901,
          9600, 29883, 29896, 29900, 29941, 29946, 25378, 29913,    13, 16033,
          5690, 29918, 25580,  9818,   353, 22483,    13, 17171, 29918,  1525,
         22484,  5425, 12064, 29918,  7187, 24290, 29918,  1177, 12336, 29903,
         29918,  1177, 29918,  7187, 24290, 29918, 19689,  8127, 29903,   353,
         22483,    13],
        [    1,   934,  5809,  6594, 29901, 29871, 29906,    13,  2543,   333,
         29901,   263, 29955, 29941, 29896, 29874, 29896, 29874, 29955, 29946,
           915, 29906, 29900, 29874, 29900, 29946, 29874, 29929, 29881, 29955,
          7176, 29883, 29945,   346,  1389,   370, 29906,    13,  2230, 20399,
         29901, 29871, 29896, 29946, 29953, 29955, 29955, 29955, 29896, 29953,
         29945, 29953,    13,   506,  1947,  1542, 29901,  1019,    13, 29924,
          3231, 24192,  9555, 29901,    13, 29871,  7797,  1891,  6594, 29901,
         29871, 29906,    13, 29871,  2322,  1123, 10662, 29901,  5159,    13,
         29871,  8225,  7514, 29901, 29871, 29900,    13, 29871,  9849, 29901,
           426,  8758,  1367, 29901, 29871, 29900, 29913,    13, 29871,  1404,
          1469, 29901, 29871,    13, 29871, 24342,  9534,  1170, 29901, 29871,
            13, 29871, 24342,  9534, 10444,   424, 29901, 29871,    13,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2]], device='cuda:0')
torch.Size([2, 212, 32000]) tensor([[[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5703, -0.4023, -5.4336,  ..., -1.3672, -2.3809, -1.9199],
         [-2.5488, -0.3865, -5.5195,  ..., -1.3564, -2.3438, -1.9287],
         ...,
         [-2.5547, -0.3743, -5.4141,  ..., -1.4014, -2.4277, -1.9453],
         [-2.5430, -0.3342, -5.3594,  ..., -1.3750, -2.3828, -1.9121],
         [-2.5762, -0.3472, -5.2188,  ..., -1.4053, -2.4492, -1.9453]],

        [[-2.5371, -0.2917, -5.0586,  ..., -1.4492, -2.4512, -1.9033],
         [-2.5801, -0.4277, -5.4023,  ..., -1.3965, -2.4648, -1.9141],
         [-2.5703, -0.3943, -5.4375,  ..., -1.4014, -2.4160, -1.9248],
         ...,
         [-2.5879, -0.2993, -5.3320,  ..., -1.4082, -2.4258, -1.9199],
         [-2.5879, -0.2998, -5.3281,  ..., -1.4092, -2.4258, -1.9199],
         [-2.5859, -0.2986, -5.3281,  ..., -1.4082, -2.4258, -1.9180]]],
       device='cuda:0')
torch.Size([2, 212, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 212, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 16, 30.0% of total tokens
encoded shape: torch.Size([2, 1537])
torch.Size([2, 1537]) tensor([[    1, 18252, 21300,  ...,  1420, 29958,    13],
        [    1, 29871, 30143,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1537, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5605, -0.3457, -5.4805,  ..., -1.3486, -2.3965, -1.9053],
         [-2.5547, -0.3228, -5.4336,  ..., -1.3730, -2.4023, -1.9307],
         ...,
         [-2.5625, -0.3857, -5.2969,  ..., -1.4229, -2.4043, -1.9180],
         [-2.5684, -0.3645, -5.2656,  ..., -1.4219, -2.4023, -1.9180],
         [-2.5781, -0.3889, -5.1797,  ..., -1.4561, -2.4414, -1.8975]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5859, -0.3203, -5.3633,  ..., -1.3652, -2.4082, -1.8906],
         [-2.5684, -0.3450, -5.3047,  ..., -1.3965, -2.4414, -1.8857],
         ...,
         [-2.5918, -0.2812, -5.2969,  ..., -1.4131, -2.4336, -1.9014],
         [-2.6016, -0.2964, -5.2891,  ..., -1.4209, -2.4434, -1.9102],
         [-2.5918, -0.2827, -5.2891,  ..., -1.4141, -2.4336, -1.9023]]],
       device='cuda:0')
torch.Size([2, 1537, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1537, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 17, 31.9% of total tokens
encoded shape: torch.Size([2, 1896])
torch.Size([2, 1896]) tensor([[    1,   849, 14187,  ...,    13, 29913,    13],
        [    1,  3577, 29825,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1896, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.3777, -5.2539,  ..., -1.4287, -2.4473, -1.8535],
         [-2.5664, -0.4368, -5.5312,  ..., -1.3730, -2.3828, -1.8584],
         ...,
         [-2.5723, -0.3796, -5.2969,  ..., -1.3887, -2.4668, -1.8955],
         [-2.5566, -0.3430, -5.2422,  ..., -1.3906, -2.4395, -1.9189],
         [-2.5957, -0.4253, -5.1875,  ..., -1.4365, -2.4883, -1.9307]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3677, -5.3359,  ..., -1.4229, -2.4004, -1.8994],
         [-2.5684, -0.4646, -5.3906,  ..., -1.3877, -2.3906, -1.8887],
         ...,
         [-2.6094, -0.3147, -5.2305,  ..., -1.4365, -2.4531, -1.9170],
         [-2.6074, -0.3132, -5.2305,  ..., -1.4365, -2.4531, -1.9170],
         [-2.5977, -0.2988, -5.2344,  ..., -1.4277, -2.4453, -1.9082]]],
       device='cuda:0')
torch.Size([2, 1896, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1896, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 18, 34.1% of total tokens
encoded shape: torch.Size([2, 1753])
torch.Size([2, 1753]) tensor([[    1,  4949,    13,  ..., 29911,  4174,    13],
        [    1,  3883,  1260,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 1753, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.2930, -0.0971, -5.2070,  ..., -1.3789, -2.3555, -1.8018],
         ...,
         [-2.5410, -0.3303, -5.4141,  ..., -1.3516, -2.3809, -1.9150],
         [-2.5762, -0.3838, -5.2812,  ..., -1.4072, -2.4121, -1.9248],
         [-2.5879, -0.4016, -5.1367,  ..., -1.4707, -2.4688, -1.9229]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5371, -0.3740, -5.4883,  ..., -1.3320, -2.3633, -1.8643],
         [-2.5723, -0.4429, -5.3945,  ..., -1.3564, -2.3984, -1.9209],
         ...,
         [-2.6074, -0.3225, -5.1797,  ..., -1.4434, -2.4551, -1.9219],
         [-2.6074, -0.3228, -5.1797,  ..., -1.4434, -2.4551, -1.9229],
         [-2.6074, -0.3230, -5.1797,  ..., -1.4434, -2.4551, -1.9229]]],
       device='cuda:0')
torch.Size([2, 1753, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1753, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 19, 36.1% of total tokens
encoded shape: torch.Size([2, 977])
torch.Size([2, 977]) tensor([[   1,  396, 1678,  ..., 4294,  580,   13],
        [   1,  395, 6779,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 977, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3369, -5.4023,  ..., -1.3994, -2.4121, -1.9316],
         [-2.5605, -0.3357, -5.4297,  ..., -1.3721, -2.4082, -1.8857],
         ...,
         [-2.5508, -0.3823, -5.3750,  ..., -1.3965, -2.4160, -1.9180],
         [-2.5801, -0.3875, -5.0977,  ..., -1.4424, -2.4648, -1.9668],
         [-2.5742, -0.3691, -5.1250,  ..., -1.4053, -2.4062, -1.9355]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.6113, -0.4302, -5.3945,  ..., -1.4131, -2.4238, -1.9219],
         [-2.5566, -0.3853, -5.5039,  ..., -1.3418, -2.3887, -1.8975],
         ...,
         [-2.5820, -0.2629, -5.3789,  ..., -1.3926, -2.4180, -1.8936],
         [-2.5820, -0.2632, -5.3789,  ..., -1.3926, -2.4180, -1.8936],
         [-2.5879, -0.2717, -5.3789,  ..., -1.3965, -2.4219, -1.8975]]],
       device='cuda:0')
torch.Size([2, 977, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 977, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 20, 37.3% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1, 11474,    13,  ..., 29906, 29955, 29945],
        [    1,   396,  7055,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5527, -0.3013, -5.3594,  ..., -1.3809, -2.4238, -1.8926],
         [-2.1992,  0.0380, -5.5430,  ..., -1.2568, -2.2598, -1.7520],
         ...,
         [-2.5723, -0.4788, -5.5430,  ..., -1.3779, -2.4102, -1.9463],
         [-2.5859, -0.4873, -5.5312,  ..., -1.3926, -2.3906, -1.9375],
         [-2.5879, -0.4985, -5.4727,  ..., -1.4229, -2.4199, -1.9277]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3369, -5.4023,  ..., -1.3994, -2.4121, -1.9316],
         [-2.5977, -0.4448, -5.3359,  ..., -1.3916, -2.4238, -1.9209],
         ...,
         [-2.6133, -0.3369, -5.1523,  ..., -1.4531, -2.4668, -1.9268],
         [-2.6133, -0.3369, -5.1523,  ..., -1.4531, -2.4668, -1.9258],
         [-2.6172, -0.3450, -5.1523,  ..., -1.4570, -2.4707, -1.9297]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 21, 42.6% of total tokens
encoded shape: torch.Size([2, 2715])
torch.Size([2, 2715]) tensor([[   1, 1053, 2897,  ..., 1688, 1159,   13],
        [   1, 4949,   13,  ...,    2,    2,    2]], device='cuda:0')
torch.Size([2, 2715, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3896, -5.3672,  ..., -1.4141, -2.4121, -1.8506],
         [-2.5879, -0.3765, -5.3203,  ..., -1.4004, -2.4355, -1.9150],
         ...,
         [-2.6133, -0.5063, -5.3164,  ..., -1.4502, -2.4434, -1.9951],
         [-2.5898, -0.3787, -5.1328,  ..., -1.4336, -2.4609, -1.9629],
         [-2.6309, -0.4507, -4.9766,  ..., -1.4854, -2.4648, -1.9443]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.2930, -0.0971, -5.2070,  ..., -1.3789, -2.3555, -1.8018],
         ...,
         [-2.6094, -0.3213, -5.1875,  ..., -1.4453, -2.4570, -1.9229],
         [-2.6094, -0.3208, -5.1875,  ..., -1.4453, -2.4570, -1.9229],
         [-2.6074, -0.3210, -5.1875,  ..., -1.4453, -2.4570, -1.9229]]],
       device='cuda:0')
torch.Size([2, 2715, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 2715, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 22, 45.9% of total tokens
encoded shape: torch.Size([2, 3157])
torch.Size([2, 3157]) tensor([[    1,   849, 14187,  ...,     2,     2,     2],
        [    1,  3577,  8820,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 3157, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.3772, -5.2539,  ..., -1.4287, -2.4492, -1.8535],
         [-2.5664, -0.4373, -5.5312,  ..., -1.3730, -2.3828, -1.8584],
         ...,
         [-2.6094, -0.3235, -5.1836,  ..., -1.4395, -2.4512, -1.9229],
         [-2.6094, -0.3230, -5.1836,  ..., -1.4404, -2.4512, -1.9229],
         [-2.6094, -0.3232, -5.1836,  ..., -1.4395, -2.4512, -1.9229]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3674, -5.3359,  ..., -1.4229, -2.4004, -1.8994],
         [-2.5645, -0.4302, -5.3867,  ..., -1.3613, -2.3730, -1.9082],
         ...,
         [-2.5840, -0.3999, -5.2969,  ..., -1.4199, -2.4688, -1.9219],
         [-2.5625, -0.3315, -5.2305,  ..., -1.4043, -2.4570, -1.9316],
         [-2.5918, -0.3662, -5.1445,  ..., -1.4141, -2.4980, -1.9541]]],
       device='cuda:0')
torch.Size([2, 3157, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3157, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 23, 49.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   869,  4632,  ...,     2,     2,     2],
        [    1,   849, 27694,  ..., 16299, 13877,  1244]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5938, -0.3782, -5.4023,  ..., -1.4092, -2.4043, -1.8955],
         [-2.5664, -0.4526, -5.4219,  ..., -1.4150, -2.4062, -1.9033],
         ...,
         [-2.5723, -0.2969, -5.0938,  ..., -1.4521, -2.4629, -1.9150],
         [-2.5781, -0.3027, -5.0898,  ..., -1.4570, -2.4688, -1.9189],
         [-2.5820, -0.3105, -5.0898,  ..., -1.4600, -2.4727, -1.9229]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.3772, -5.2539,  ..., -1.4287, -2.4492, -1.8535],
         [-2.5547, -0.3823, -5.4844,  ..., -1.3564, -2.3867, -1.8877],
         ...,
         [-2.5371, -0.2878, -5.5156,  ..., -1.3076, -2.4219, -1.8799],
         [-2.5371, -0.3225, -5.4648,  ..., -1.3506, -2.4238, -1.8887],
         [-2.5410, -0.3198, -5.4883,  ..., -1.3545, -2.3906, -1.9033]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 24, 53.8% of total tokens
encoded shape: torch.Size([2, 3597])
torch.Size([2, 3597]) tensor([[    1,   278,  8118,  ...,     2,     2,     2],
        [    1,   529,  7299,  ...,  2154, 29958,    13]], device='cuda:0')
torch.Size([2, 3597, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5957, -0.3391, -5.4336,  ..., -1.3818, -2.3867, -1.9219],
         [-2.5918, -0.3516, -5.3984,  ..., -1.3975, -2.3965, -1.9277],
         ...,
         [-2.5742, -0.2969, -5.0820,  ..., -1.4561, -2.4668, -1.9160],
         [-2.5742, -0.2966, -5.0820,  ..., -1.4561, -2.4668, -1.9160],
         [-2.5742, -0.2966, -5.0820,  ..., -1.4561, -2.4668, -1.9160]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5742, -0.4302, -5.3633,  ..., -1.4160, -2.3945, -1.8848],
         [-2.5547, -0.3374, -5.4648,  ..., -1.3535, -2.3418, -1.9023],
         ...,
         [-2.5527, -0.4443, -5.3125,  ..., -1.3896, -2.3965, -1.9092],
         [-2.5703, -0.3628, -5.2031,  ..., -1.4014, -2.4043, -1.9297],
         [-2.5703, -0.3875, -5.1328,  ..., -1.4551, -2.4336, -1.9424]]],
       device='cuda:0')
torch.Size([2, 3597, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3597, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 25, 57.4% of total tokens
encoded shape: torch.Size([2, 386])
torch.Size([2, 386]) tensor([[    1, 29871, 30143,   458,   363,   318, 29954,  3120, 29898,  3166,
         29871, 29946, 29889, 29953, 29897,    13, 29937,   361,  1738, 29898,
          3904, 11937, 29918, 29946, 29918, 29900,  3830,  8291, 11937, 29918,
         29946, 29918, 29896,  3830,  8291, 11937, 29918, 29946, 29918, 29906,
          3830,  8291, 11937, 29918, 29946, 29918, 29941,  3830,  8291, 11937,
         29918, 29946, 29918, 29946,  3830,  8291, 11937, 29918, 29946, 29918,
         29945, 29897,    13,    13,  4746,  2184, 29936,   849,  1996,  3013,
           363,  3852, 21536,  2401,    13,  4746, 20872, 12412, 29936,    13,
          4746, 20872, 12412, 29889,  2624,  3924, 29879, 29936,    13,    13,
         22377,   853, 29875, 29934, 29916, 29889,  2308,   335,  5743,    13,
         29912,    13,  1678,   518,  4205,  9536, 15329,   552,  5308, 29962,
            13,  1678,   970,   770, 20215, 15063, 20211,   584, 20215, 20211,
          5160, 29892,   306,  2624,  3924,  4598, 29892,  3553,  1336,  4598,
            13,  1678,   426,    13,  4706,  3323,   622, 29966, 14516,  2624,
          1469, 29958,   373, 15063, 29936,    13,    13,  4706,  1780,  3553,
          1336,  4598, 29889,  2951, 15063, 29898, 14516,  2624,  1469,  1741,
          1469, 29897,    13,  4706,   426,    13,  9651,   565,   313,   265,
         15063,  2804,  1870, 29897,   373, 15063, 29889,  2951,  9190, 29898,
          3696,  1469,   416,    13,  4706,   500,    13,    13,  4706,   970,
           306, 27928, 29966, 14516,  2624,  1469, 29958,  1551, 15063,  2887,
         27928,   580,    13,  4706,   426,    13,  9651,   736,   373, 15063,
         13626,   313,   265, 15063,   353,   716,  3323,   622, 29966, 14516,
          2624,  1469, 29958,  3310,    13,  4706,   500,    13,    13,  4706,
          6364,  5712,  1780,  6981,   895,  2951, 26010,  2951, 14994,  4727,
           580,    13,  4706,   426,    13,  9651,   565,   313,   265, 15063,
          2804,  1870, 29897,    13,  9651,   426,    13, 18884,   373, 15063,
         29889,  2951, 26010,   890,    13,  9651,   500,    13,  4706,   500,
            13,  1678,   500,    13, 29913,    13,    13,    13, 29937, 15224,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2],
        [    1, 29871, 30143, 29914,  7775,  7775,  4189,  2328, 29930,  4706,
          6756,    13, 30732, 30767, 30383,   233,   158,   188,   233,   154,
           176,   232,   144,   138,   795,  6756,    13, 29984, 29984, 30383,
         29906, 29955, 29929, 29900, 29953, 29900, 29945, 29929, 29955, 30004,
            13,   235,   177,   194, 31658, 31196, 31915, 30743, 31201,   235,
           178,   169,   234,   190,   137, 31633,   234,   190,   144, 31436,
         31100, 30923, 30728, 31294, 30383,   259,  6756,    13,  1124,   597,
          7312, 29889,   845,   996, 29916,   348, 26599, 29889,   510, 30004,
            13,  7775,  7775,  4189,  2328,  1068, 29914, 30004,    13,  4746,
          2184, 29889,  5620,  1464,  2104,    13,  4746,  2184, 29889,  7944,
         29889,  4074,   459, 13779,  2104,    13,  4746,  2184, 29889, 13228,
          2104,    13,  4746,  2184, 29889, 13228, 29889, 15737,  6847,  2104,
            13,  4746,  7783, 29889, 29925,  1461,  1575, 29889, 10399,  7734,
         12284, 29889,  3403,  3460, 29889,  9112, 29889,  8614, 29889,  4002,
           647,  2104,    13,  4746,  7783, 29889, 29925,  1461,  1575, 29889,
         10399,  7734, 12284, 29889,  8614, 29889,  4002,   647,  2104,    13,
          4746,  7783, 29889, 29925,  1461,  1575, 29889, 10399,  7734, 12284,
         29889,  1469, 29889,  8614, 29889,  4002,   647,  2104,    13,  4746,
          7783, 29889, 29925,  1461,  1575, 29889, 10399,  7734, 12284, 29889,
          3403,  3460, 29889,  8614, 29889,  4002,   647,  2104,    13, 29961,
         26936,   584, 20999,  4002,   647,  3260, 29898, 18059, 29898,  3403,
          3460,  9112,  8614,  4002,   647,  3260,   511, 20086, 29898,  3403,
          3460,  8614,  4002,   647,  3260, 28166, 30004,    13, 29961, 26936,
           584, 20999,  4002,   647,  3260, 29898, 18059, 29898,  3403,  3460,
          9112,  8614,  4002,   647,  3260,   511, 20086, 29898,  5350, 26545,
          8614,  4002,   647,  3260, 28166, 30004,    13, 29961, 26936,   584,
          9897,  1464, 27293, 29898, 13228,  4276, 29889,  3089,  8140, 12539,
         29892, 19495,  6638,   353,  1565,  4638, 30004,    13, 29961, 26936,
           584, 14223, 27293, 29898, 13228,  4276, 29889,  3089,  8140, 12539,
          4638, 30004,    13, 29961, 26936,   584,   422, 12911, 29898,  4541,
          4638, 30004,    13, 29961, 26936,   584, 13266,  7030,   703, 10399,
          7734,  9538,  4522,  3460,   322,  2799, 15461,   362,  5470,  1019,
          5489, 12037, 13531, 30004,    13, 29961, 26936,   584, 13266,  9868,
           703, 10399,  7734,  9538,  4522,  3460,   322,  2799, 15461,   362,
          5470,  1019,  5489, 12037, 13531, 30004,    13, 29961, 26936,   584,
         13266,  6594,   703, 29946, 29889, 29896, 29889, 29900, 29889, 29900,
         13531, 30004,    13, 29961, 26936,   584, 29408,  7439,   616,   368,
          2308, 16656,  5594,   414, 29962, 30004,    13, 29961, 26936,   584,
         14223,  4300,  3560, 29962, 30004,    13]], device='cuda:0')
torch.Size([2, 386, 32000]) tensor([[[-2.5469, -0.3054, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5957, -0.3350, -5.3594,  ..., -1.3730, -2.4180, -1.8984],
         [-2.5684, -0.3440, -5.3047,  ..., -1.3975, -2.4414, -1.8857],
         ...,
         [-2.5859, -0.2976, -5.3008,  ..., -1.4150, -2.4277, -1.9248],
         [-2.5859, -0.2983, -5.3008,  ..., -1.4150, -2.4277, -1.9238],
         [-2.5859, -0.2996, -5.3008,  ..., -1.4150, -2.4297, -1.9248]],

        [[-2.5469, -0.3054, -5.0547,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5957, -0.3350, -5.3594,  ..., -1.3730, -2.4180, -1.8984],
         [-2.5684, -0.3440, -5.3047,  ..., -1.3975, -2.4414, -1.8857],
         ...,
         [-2.5820, -0.4041, -5.2891,  ..., -1.3887, -2.4082, -1.9033],
         [-2.6016, -0.3667, -5.1289,  ..., -1.4307, -2.4473, -1.9531],
         [-2.5859, -0.4084, -5.1367,  ..., -1.4385, -2.4590, -1.8643]]],
       device='cuda:0')
torch.Size([2, 386, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 386, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 26, 58.1% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   448,  2683,  ..., 29947, 29918, 29941],
        [    1,  4949,    13,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5684, -0.3433, -5.4922,  ..., -1.3574, -2.4121, -1.8682],
         [-2.5703, -0.3860, -5.4102,  ..., -1.3564, -2.4297, -1.9072],
         ...,
         [-2.5742, -0.4492, -5.4727,  ..., -1.3945, -2.4160, -1.8965],
         [-2.6055, -0.4951, -5.3945,  ..., -1.4658, -2.4375, -1.9238],
         [-2.6172, -0.5439, -5.3438,  ..., -1.4668, -2.5000, -1.9609]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.2930, -0.0971, -5.2070,  ..., -1.3789, -2.3555, -1.8018],
         ...,
         [-2.6074, -0.3237, -5.1680,  ..., -1.4424, -2.4512, -1.9229],
         [-2.6074, -0.3235, -5.1680,  ..., -1.4424, -2.4512, -1.9229],
         [-2.6074, -0.3235, -5.1680,  ..., -1.4424, -2.4531, -1.9229]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 27, 63.4% of total tokens
encoded shape: torch.Size([2, 2231])
torch.Size([2, 2231]) tensor([[    1,   274,  2522,  ...,   418,  1095,    13],
        [    1,  5067, 22310,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2231, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5801, -0.4062, -5.3945,  ..., -1.3877, -2.4375, -1.8848],
         [-2.6035, -0.4304, -5.3750,  ..., -1.4160, -2.3848, -1.9395],
         ...,
         [-2.5820, -0.4512, -5.2773,  ..., -1.4297, -2.4531, -1.9258],
         [-2.5566, -0.3848, -5.2969,  ..., -1.4033, -2.4238, -1.9199],
         [-2.5918, -0.4009, -5.1562,  ..., -1.4414, -2.4570, -1.9307]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5723, -0.3623, -5.3633,  ..., -1.3936, -2.4336, -1.8965],
         [-2.5820, -0.4180, -5.4102,  ..., -1.3809, -2.3770, -1.9385],
         ...,
         [-2.6035, -0.3269, -5.1016,  ..., -1.4609, -2.4707, -1.9248],
         [-2.6035, -0.3274, -5.0977,  ..., -1.4619, -2.4707, -1.9248],
         [-2.6035, -0.3267, -5.1016,  ..., -1.4619, -2.4707, -1.9248]]],
       device='cuda:0')
torch.Size([2, 2231, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 2231, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 28, 65.7% of total tokens
encoded shape: torch.Size([2, 1314])
torch.Size([2, 1314]) tensor([[    1,   426,    13,  ...,     2,     2,     2],
        [    1,   849,  1360,  ..., 21560,  7397,    13]], device='cuda:0')
torch.Size([2, 1314, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5762, -0.3569, -5.3828,  ..., -1.3750, -2.3848, -1.8779],
         [-2.2363,  0.0273, -5.4336,  ..., -1.2910, -2.2949, -1.7666],
         ...,
         [-2.5977, -0.2971, -5.2422,  ..., -1.4238, -2.4375, -1.9141],
         [-2.5957, -0.2969, -5.2344,  ..., -1.4238, -2.4375, -1.9131],
         [-2.6055, -0.3113, -5.2344,  ..., -1.4316, -2.4473, -1.9209]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.3772, -5.2539,  ..., -1.4287, -2.4492, -1.8535],
         [-2.5488, -0.3901, -5.4766,  ..., -1.3740, -2.4121, -1.8672],
         ...,
         [-2.5703, -0.3872, -5.3555,  ..., -1.4043, -2.4141, -1.9023],
         [-2.5801, -0.3772, -5.2422,  ..., -1.4180, -2.4297, -1.9229],
         [-2.5723, -0.3750, -5.1445,  ..., -1.4160, -2.4355, -1.9131]]],
       device='cuda:0')
torch.Size([2, 1314, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 1314, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 29, 67.2% of total tokens
encoded shape: torch.Size([2, 812])
torch.Size([2, 812]) tensor([[    1,  6319,  1961,  ...,     2,     2,     2],
        [    1,   448,   807,  ...,  3040, 14636, 23648]], device='cuda:0')
torch.Size([2, 812, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5820, -0.3752, -5.3516,  ..., -1.3623, -2.4180, -1.9180],
         [-2.5664, -0.3584, -5.3281,  ..., -1.4268, -2.3945, -1.9189],
         ...,
         [-2.5859, -0.2522, -5.4297,  ..., -1.3857, -2.4160, -1.8936],
         [-2.5859, -0.2520, -5.4297,  ..., -1.3857, -2.4160, -1.8936],
         [-2.5879, -0.2527, -5.4297,  ..., -1.3867, -2.4160, -1.8945]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5684, -0.3416, -5.4922,  ..., -1.3574, -2.4121, -1.8691],
         [-2.5625, -0.3047, -5.4180,  ..., -1.3662, -2.3945, -1.9014],
         ...,
         [-2.5391, -0.3679, -5.6055,  ..., -1.2939, -2.3809, -1.8896],
         [-2.5508, -0.4136, -5.4648,  ..., -1.3613, -2.4414, -1.9248],
         [-2.5566, -0.3289, -5.3086,  ..., -1.3545, -2.4043, -1.9180]]],
       device='cuda:0')
torch.Size([2, 812, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 812, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 30, 68.4% of total tokens
encoded shape: torch.Size([2, 135])
torch.Size([2, 135]) tensor([[    1,  4780,  1271,   353,   376, 12229, 14153, 29908,    13,    13,
           978,   353,   525, 29887,   326,  1631, 29915,    13,  3259,   353,
           525, 29906, 29900, 29896, 29955, 29874, 29915,    13,    13,  5184,
          3488,   353,   525, 29898,  9290, 16029,    13,  8216,   353,  9995,
         29954, 11601,  3831,  3955, 14348,   313, 29954,  4174, 29897,  2729,
          6516,  5780, 14153,   411, 18555,   341,  2227,  1213, 15945,    13,
            13, 10154, 14153,   353, 28962,  1254, 12665,    13,    13,  2997,
         29918,  2388,   353,  6702, 29954,  4174,   742,   525, 29945, 29889,
         29946, 29889, 29900, 29899, 29906, 29889, 29906, 29953,  1495,    13,
            13, 22594,   353,   518,    13,  1678,  1887, 29918,  2388, 29892,
            13,  1678,  6702,   326,  1631,   742,   525, 29906, 29900, 29896,
         29955, 29889, 29896, 29889, 29896, 29941, 29906,   742, 15516,  1887,
         29918,  2388,   511,    13, 29962,    13,    13,  5453,  1990,   353,
           525, 10154, 14153, 29915,    13],
        [    1,   732,  5751, 29896,   732,    13,  1853,   323, 29936,    13,
         25378,  1544, 29936,    13, 25380,    13,    13, 29911,   426,    13,
         29871,  2023,    13, 29899,  2906, 29918,  2324, 29918, 29873,  1544,
         29936,    13, 29974,  2281,   282,  4912,  1512, 29918, 10141,   334,
         29886, 29918,  3359, 29936,    13, 29871,  2023,    13,  3400,    13,
            13, 29992,  5751, 29906,  4988,  5751, 29896,   732,    13, 29911,
           334, 29879, 29936,    13, 25378,   285,   430, 29936,    13, 25380,
            13,    13, 29899,   269,   976,  2324, 29889, 29888,   430,    13,
         29974,   269,   976, 29886, 29918,  3359,   976, 29888,   430,    13,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2]], device='cuda:0')
torch.Size([2, 135, 32000]) tensor([[[-2.5469, -0.3069, -5.0547,  ..., -1.4561, -2.4609, -1.9111],
         [-2.5938, -0.4170, -5.3750,  ..., -1.3916, -2.4238, -1.9404],
         [-2.6094, -0.4597, -5.3555,  ..., -1.4043, -2.4316, -1.9482],
         ...,
         [-2.5781, -0.4924, -5.3125,  ..., -1.4160, -2.4062, -1.9355],
         [-2.5684, -0.3630, -5.1797,  ..., -1.4082, -2.4258, -1.9443],
         [-2.6055, -0.4294, -5.0664,  ..., -1.4639, -2.4902, -1.9531]],

        [[-2.5469, -0.3069, -5.0547,  ..., -1.4561, -2.4609, -1.9111],
         [-2.5938, -0.3809, -5.3477,  ..., -1.4307, -2.4141, -1.9062],
         [-2.6035, -0.4993, -5.3672,  ..., -1.4004, -2.4141, -1.9395],
         ...,
         [-2.5801, -0.2893, -5.3086,  ..., -1.4160, -2.4160, -1.9189],
         [-2.5781, -0.2861, -5.3125,  ..., -1.4150, -2.4141, -1.9170],
         [-2.5781, -0.2883, -5.3047,  ..., -1.4141, -2.4160, -1.9170]]],
       device='cuda:0')
torch.Size([2, 135, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 135, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 31, 68.6% of total tokens
encoded shape: torch.Size([2, 808])
torch.Size([2, 808]) tensor([[    1,  6319,  1961,  ...,     2,     2,     2],
        [    1,   396,  1724,  ...,   470,  2319, 29889]], device='cuda:0')
torch.Size([2, 808, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5820, -0.3752, -5.3516,  ..., -1.3623, -2.4180, -1.9180],
         [-2.5664, -0.3584, -5.3281,  ..., -1.4268, -2.3945, -1.9189],
         ...,
         [-2.5898, -0.2974, -5.3086,  ..., -1.4092, -2.4277, -1.9209],
         [-2.5840, -0.2893, -5.3125,  ..., -1.4053, -2.4238, -1.9170],
         [-2.5840, -0.2891, -5.3125,  ..., -1.4062, -2.4238, -1.9170]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3359, -5.3984,  ..., -1.4004, -2.4121, -1.9316],
         [-2.5781, -0.3945, -5.3164,  ..., -1.4365, -2.4414, -1.9492],
         ...,
         [-2.5371, -0.3093, -5.4453,  ..., -1.3594, -2.4004, -1.8916],
         [-2.5527, -0.3875, -5.4492,  ..., -1.3643, -2.3770, -1.8691],
         [-2.5352, -0.3472, -5.4531,  ..., -1.3477, -2.3926, -1.8555]]],
       device='cuda:0')
torch.Size([2, 808, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 808, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 32, 70.1% of total tokens
encoded shape: torch.Size([2, 661])
torch.Size([2, 661]) tensor([[    1,   426,    13,  ...,     2,     2,     2],
        [    1,   849, 19511,  ..., 11723, 29894,    13]], device='cuda:0')
torch.Size([2, 661, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3501, -5.3789,  ..., -1.3721, -2.3828, -1.8750],
         [-2.2461,  0.0136, -5.4258,  ..., -1.2988, -2.3047, -1.7744],
         ...,
         [-2.5977, -0.2849, -5.2422,  ..., -1.4238, -2.4395, -1.9121],
         [-2.5977, -0.2852, -5.2461,  ..., -1.4238, -2.4395, -1.9121],
         [-2.5977, -0.2856, -5.2500,  ..., -1.4229, -2.4395, -1.9121]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5840, -0.3772, -5.2539,  ..., -1.4287, -2.4473, -1.8535],
         [-2.5645, -0.3481, -5.4062,  ..., -1.3877, -2.4219, -1.9141],
         ...,
         [-2.5918, -0.4377, -5.2305,  ..., -1.4277, -2.4355, -1.9404],
         [-2.5859, -0.3911, -5.1836,  ..., -1.4189, -2.4082, -1.9248],
         [-2.5957, -0.3965, -5.0820,  ..., -1.4434, -2.4551, -1.9316]]],
       device='cuda:0')
torch.Size([2, 661, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 661, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 33, 70.8% of total tokens
encoded shape: torch.Size([2, 880])
torch.Size([2, 880]) tensor([[    1,   396,   448,  ...,     2,     2,     2],
        [    1,  3577,   260,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 880, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3364, -5.4023,  ..., -1.3994, -2.4121, -1.9316],
         [-2.5762, -0.3503, -5.4258,  ..., -1.3594, -2.4199, -1.9111],
         ...,
         [-2.5938, -0.2729, -5.3008,  ..., -1.4062, -2.4238, -1.9072],
         [-2.5977, -0.2800, -5.3047,  ..., -1.4082, -2.4258, -1.9102],
         [-2.5977, -0.2805, -5.3047,  ..., -1.4082, -2.4258, -1.9102]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3672, -5.3398,  ..., -1.4229, -2.4004, -1.8994],
         [-2.5605, -0.4285, -5.3633,  ..., -1.3965, -2.4219, -1.8740],
         ...,
         [-2.5469, -0.3220, -5.4141,  ..., -1.3838, -2.4297, -1.9326],
         [-2.5703, -0.3440, -5.2500,  ..., -1.4072, -2.4531, -1.9248],
         [-2.5898, -0.4026, -4.9883,  ..., -1.4619, -2.4805, -1.9453]]],
       device='cuda:0')
torch.Size([2, 880, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 880, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 34, 71.7% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,  1053,  9537,  ...,     2,     2,     2],
        [    1,   396, 29871,  ...,  1258,   451,  2767]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3896, -5.3672,  ..., -1.4141, -2.4121, -1.8506],
         [-2.5957, -0.4148, -5.4414,  ..., -1.4307, -2.4102, -1.9482],
         ...,
         [-2.5879, -0.3147, -5.1016,  ..., -1.4580, -2.4707, -1.9229],
         [-2.5840, -0.3069, -5.1016,  ..., -1.4551, -2.4668, -1.9189],
         [-2.5879, -0.3149, -5.1016,  ..., -1.4580, -2.4707, -1.9229]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3369, -5.4023,  ..., -1.3994, -2.4121, -1.9316],
         [-2.5566, -0.3254, -5.4766,  ..., -1.3682, -2.3418, -1.9082],
         ...,
         [-2.6406, -0.5098, -5.3789,  ..., -1.4150, -2.4531, -1.9697],
         [-2.6172, -0.4583, -5.3867,  ..., -1.4170, -2.4180, -1.9434],
         [-2.6113, -0.4875, -5.3594,  ..., -1.4121, -2.4102, -1.9375]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 35, 76.0% of total tokens
encoded shape: torch.Size([2, 3420])
torch.Size([2, 3420]) tensor([[    1,   396,   364,  ...,     2,     2,     2],
        [    1,  4949,   263,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 3420, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3369, -5.4023,  ..., -1.3994, -2.4121, -1.9316],
         [-2.5938, -0.4612, -5.3164,  ..., -1.4287, -2.4043, -1.9355],
         ...,
         [-2.5859, -0.3071, -5.1094,  ..., -1.4531, -2.4648, -1.9170],
         [-2.5957, -0.3223, -5.1055,  ..., -1.4609, -2.4746, -1.9248],
         [-2.5859, -0.3069, -5.1094,  ..., -1.4531, -2.4648, -1.9170]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.5723, -0.4209, -5.3945,  ..., -1.4121, -2.4316, -1.9248],
         ...,
         [-2.5723, -0.4138, -5.3047,  ..., -1.4170, -2.4629, -1.9209],
         [-2.5664, -0.3594, -5.1992,  ..., -1.4170, -2.4434, -1.9463],
         [-2.5820, -0.4104, -5.0898,  ..., -1.4600, -2.4707, -1.9180]]],
       device='cuda:0')
torch.Size([2, 3420, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3420, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 36, 79.5% of total tokens
encoded shape: torch.Size([2, 664])
torch.Size([2, 664]) tensor([[    1,  3577,  2947,  ...,     2,     2,     2],
        [    1,  3577,  1638,  ...,    13, 29913,    13]], device='cuda:0')
torch.Size([2, 664, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3672, -5.3398,  ..., -1.4229, -2.4004, -1.8994],
         [-2.5723, -0.4153, -5.4492,  ..., -1.3467, -2.4160, -1.8691],
         ...,
         [-2.5762, -0.2365, -5.3633,  ..., -1.3887, -2.4160, -1.8877],
         [-2.5820, -0.2443, -5.3711,  ..., -1.3896, -2.4180, -1.8906],
         [-2.5801, -0.2423, -5.3828,  ..., -1.3877, -2.4180, -1.8906]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3672, -5.3398,  ..., -1.4229, -2.4004, -1.8994],
         [-2.5566, -0.3718, -5.4492,  ..., -1.3730, -2.3711, -1.9121],
         ...,
         [-2.5547, -0.3250, -5.4219,  ..., -1.3740, -2.4316, -1.9326],
         [-2.5840, -0.3557, -5.1797,  ..., -1.4170, -2.4434, -1.9355],
         [-2.6016, -0.4163, -5.0117,  ..., -1.4619, -2.4941, -1.9443]]],
       device='cuda:0')
torch.Size([2, 664, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 664, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 37, 80.3% of total tokens
encoded shape: torch.Size([2, 3709])
torch.Size([2, 3709]) tensor([[    1,   396,  6760,  ...,     2,     2,     2],
        [    1,  4949, 29899,  ..., 14751,   416,    13]], device='cuda:0')
torch.Size([2, 3709, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5996, -0.3369, -5.4023,  ..., -1.3994, -2.4121, -1.9316],
         [-2.5527, -0.3188, -5.4062,  ..., -1.3496, -2.3965, -1.8975],
         ...,
         [-2.5996, -0.3279, -5.1133,  ..., -1.4609, -2.4727, -1.9277],
         [-2.5996, -0.3279, -5.1133,  ..., -1.4609, -2.4727, -1.9277],
         [-2.5898, -0.3137, -5.1172,  ..., -1.4531, -2.4648, -1.9199]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.5566, -0.3142, -5.4688,  ..., -1.3486, -2.4062, -1.8838],
         ...,
         [-2.6113, -0.4495, -5.4648,  ..., -1.4004, -2.4102, -1.9521],
         [-2.5586, -0.3591, -5.2891,  ..., -1.3828, -2.4121, -1.9570],
         [-2.5996, -0.4280, -5.0508,  ..., -1.4570, -2.4785, -1.9502]]],
       device='cuda:0')
torch.Size([2, 3709, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3709, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 38, 84.3% of total tokens
encoded shape: torch.Size([2, 472])
torch.Size([2, 472]) tensor([[    1,   396,   361,   299,  1389,  5648, 29924, 29918,  7724, 29918,
         29950, 29918,    13, 29937,  7922,  5648, 29924, 29918,  7724, 29918,
         29950, 29918,    13,    13, 29937,  2856,   529, 23656, 29889, 29882,
         29958,    13, 29937,  2856,   529,  4172,  1982, 29889, 29882, 29958,
            13, 29937,  2856,   529,  1807, 29889, 29882, 29958,    13,    13,
          7724,   334, 29873,  6925, 29918, 29888,  3150, 29898,  3075,  1373,
           334,  9507, 29892,  1040,  1373,   334, 17588, 29892,  1040,  1373,
           334,  8513,   416,    13,    13,  5515, 14187,   278,  8118,   310,
           263,   934,   515,   934,  4386,   376,  4351, 29908,   304,  1373,
          1409,   376,  7854, 29908,  3776,    13,   524,   260,  6925, 29918,
         29888,  8552, 29898,  3090,   334,  7854, 29892,  2159, 29918, 29873,
          2159, 29892, 24080,   334,  4351,   416,    13,    13,  5515,  3617,
           278,  3309,   310,   263,   934,   297,  6262,   313, 18271,   382,
          9800,  2931, 29897,  3776,    13,   524,   260,  6925, 29918,  1579,
          1477, 29898,  7724,   334, 29888,   416,    13,    13, 29937, 15224,
            13,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2],
        [    1,  6319,  3134,  1873,   543, 29896, 29889, 29900, 29908,  8025,
           543, 10496, 29899, 29947, 18943,    13, 14136,    13, 29871, 10413,
         21144,   304,   278, 13380, 18540, 10606,   313,  3289, 29943, 29897,
          1090,   697,   470,   901,    13, 29871, 17737,  3406, 19405,  8571,
          4110, 29889,  2823,   278,  6058, 12107,   934, 13235,   411,    13,
         29871,   445,   664,   363,  5684,  2472, 11211,  3509,  1266, 27428,
         29889,    13, 29871,   450,  3339, 29943,  7794, 11259,   445,   934,
           304,   887,  1090,   278, 13380, 19245, 29892, 10079, 29871, 29906,
         29889, 29900,    13, 29871,   313,  1552,   376, 29931,   293,  1947,
          1496,   366,  1122,   451,   671,   445,   934,  5174,   297,   752,
         13036,   411,    13, 29871,   278, 19245, 29889,   887,  1122,  4017,
           263,  3509,   310,   278, 19245,   472,    13, 29871,  1732,   597,
          1636, 29889,  4288, 29889,   990, 29914,   506, 11259, 29914, 27888,
          1430,  1660, 29899, 29906, 29889, 29900,    13, 29871, 25870,  3734,
           491, 22903,  4307,   470, 15502,   304,   297,  5007, 29892,  7047,
            13, 29871, 13235,  1090,   278, 19245,   338, 13235,   373,   385,
           376,  3289,  8519, 29908,   350,  3289,  3235, 29892,    13, 29871,
           399,  1806,  8187,  2692,   399,  1718, 29934, 13566, 29059,  6323,
          8707, 29928, 22122, 29903,  8079, 13764, 29979,   476, 22255, 29892,
          2845,  4653,   470,  2411,  2957, 29889,    13, 29871,  2823,   278,
         19245,   363,   278,  2702,  4086, 14765,  1076, 11239,   322,    13,
         29871, 27028,  1090,   278, 19245, 29889,    13, 15110,    13, 29966,
          4836,  9463,   543,  1124,   597, 12419, 29889,  4288, 29889,   990,
         29914, 29925,  6488, 29914, 29946, 29889, 29900, 29889, 29900, 29908,
          9463, 29901, 29916,  1039,   543,  1124,   597,  1636, 29889, 29893,
         29941, 29889,   990, 29914, 29906, 29900, 29900, 29896, 29914,  9165,
         12763, 29899,  8758, 29908,   921,  1039, 29901, 11010,  6508,   543,
          1124,   597, 12419, 29889,  4288, 29889,   990, 29914, 29925,  6488,
         29914, 29946, 29889, 29900, 29889, 29900,  2045,   597, 12419, 29889,
          4288, 29889,   990, 29914, 19168, 29914, 12419, 29899, 29946, 29889,
         29900, 29889, 29900, 29889, 19168,  1013,    13,  1678,   529,  4299,
          6594, 29958, 29946, 29889, 29900, 29889, 29900,   829,  4299,  6594,
         29958,    13,    13,  1678,   529,  3560, 29958,    13,  4706,   529,
          9688, 29958,   990, 29889,  4288, 29889, 29876,  6832,   829,  9688,
         29958,    13,  4706,   529,  9680, 29958, 29876,  6832, 29899, 15770,
         29899,  9916,   829,  9680, 29958,    13,  4706,   529,  3259, 29958,
         29896, 29889, 29896, 29941, 29889, 29900, 29899, 19296,  3301,  7068,
          2891,   829,  3259, 29958,    13,  1678,  1533,  3560, 29958,    13,
            13,  1678,   529,  9680, 29958, 29876,  6832, 29899, 29882,  3188,
         29899,  4645, 29899,  5509, 29899,  2754,   829,  9680, 29958,    13,
          1678,   529,  4058,  6751, 29958,  4758,   829,  4058,  6751, 29958,
            13,    13,  1678,   529, 22594, 29958,    13,  4706,   529, 10836,
         29958,    13,  9651,   529,  9688, 29958,   990, 29889,  4288, 29889,
         29876,  6832,   829,  9688, 29958,    13,  9651,   529,  9680, 29958,
         29876,  6832, 29899,  2754,   829,  9680, 29958,    13,  9651,   529,
          6078, 29958, 16123,  2618,   829,  6078, 29958,    13,  4706,  1533,
         10836, 29958,    13,  1678,  1533, 22594, 29958,    13,   829,  4836,
         29958,    13]], device='cuda:0')
torch.Size([2, 472, 32000]) tensor([[[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5996, -0.3359, -5.3984,  ..., -1.4004, -2.4121, -1.9316],
         [-2.5645, -0.4009, -5.4297,  ..., -1.3623, -2.4238, -1.8916],
         ...,
         [-2.5723, -0.2188, -5.5117,  ..., -1.3643, -2.3926, -1.8809],
         [-2.5723, -0.2178, -5.5117,  ..., -1.3643, -2.3945, -1.8809],
         [-2.5723, -0.2188, -5.5117,  ..., -1.3643, -2.3926, -1.8809]],

        [[-2.5371, -0.2920, -5.0547,  ..., -1.4492, -2.4531, -1.9043],
         [-2.5820, -0.3752, -5.3477,  ..., -1.3623, -2.4180, -1.9180],
         [-2.5703, -0.4119, -5.4023,  ..., -1.4102, -2.3984, -1.9346],
         ...,
         [-2.5742, -0.4204, -5.3398,  ..., -1.4150, -2.4297, -1.9463],
         [-2.5723, -0.3545, -5.2148,  ..., -1.3984, -2.4277, -1.9248],
         [-2.5938, -0.4070, -5.1016,  ..., -1.4473, -2.4473, -1.9121]]],
       device='cuda:0')
torch.Size([2, 472, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 472, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 39, 84.9% of total tokens
encoded shape: torch.Size([2, 3227])
torch.Size([2, 3227]) tensor([[    1,   934,  5809,  ...,     2,     2,     2],
        [    1, 11474,    13,  ...,  1444, 29889,    13]], device='cuda:0')
torch.Size([2, 3227, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5762, -0.4192, -5.4062,  ..., -1.3926, -2.4609, -1.9102],
         [-2.5723, -0.3958, -5.4375,  ..., -1.4004, -2.4160, -1.9258],
         ...,
         [-2.5840, -0.3022, -5.1172,  ..., -1.4473, -2.4590, -1.9170],
         [-2.5840, -0.3022, -5.1172,  ..., -1.4473, -2.4590, -1.9170],
         [-2.5840, -0.3025, -5.1172,  ..., -1.4473, -2.4590, -1.9170]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5527, -0.3013, -5.3594,  ..., -1.3809, -2.4238, -1.8926],
         [-2.1992,  0.0380, -5.5430,  ..., -1.2568, -2.2598, -1.7520],
         ...,
         [-2.5391, -0.3538, -5.5547,  ..., -1.3711, -2.3652, -1.8838],
         [-2.5234, -0.3120, -5.2852,  ..., -1.3740, -2.4297, -1.8984],
         [-2.5938, -0.4292, -5.1953,  ..., -1.4639, -2.4844, -1.9814]]],
       device='cuda:0')
torch.Size([2, 3227, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3227, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 40, 88.2% of total tokens
encoded shape: torch.Size([2, 2525])
torch.Size([2, 2525]) tensor([[    1, 29871, 30143,  ...,    13, 30004,    13],
        [    1,   444, 29871,  ...,     2,     2,     2]], device='cuda:0')
torch.Size([2, 2525, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.3210, -5.3672,  ..., -1.3652, -2.4082, -1.8906],
         [-2.5645, -0.3389, -5.3086,  ..., -1.3926, -2.4355, -1.8818],
         ...,
         [-2.5762, -0.3650, -5.1602,  ..., -1.4082, -2.4531, -1.9004],
         [-2.6016, -0.3606, -5.1484,  ..., -1.4160, -2.4336, -1.9453],
         [-2.5840, -0.3442, -5.1953,  ..., -1.4326, -2.4590, -1.9082]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5566, -0.3169, -5.3906,  ..., -1.3740, -2.3789, -1.9189],
         [-2.5488, -0.3525, -5.3984,  ..., -1.3682, -2.3984, -1.8975],
         ...,
         [-2.6074, -0.3318, -5.1172,  ..., -1.4600, -2.4688, -1.9277],
         [-2.6074, -0.3333, -5.1172,  ..., -1.4600, -2.4688, -1.9287],
         [-2.6035, -0.3267, -5.1172,  ..., -1.4551, -2.4648, -1.9238]]],
       device='cuda:0')
torch.Size([2, 2525, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 2525, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 41, 90.9% of total tokens
encoded shape: torch.Size([2, 438])
torch.Size([2, 438]) tensor([[    1,   437,   312,   668,  3472,    13,  1420,    13, 29871,  2343,
            13,  1678, 12700, 29898,  3090,   842,   543,  9420, 29899, 29947,
          1159,    13,  1678,  3611, 24037, 29873,   703, 29882,   431, 29901,
          3257,  1159, 29913,   813,  5670, 12248,   414,    13,  1678,  1544,
         29898,  2674,   543, 13558,   613, 12653, 13802,  9783, 29914, 12071,
         29889,  4268,  1159,    13,  1678,  1544, 29898,  2674,   543, 13558,
           613, 12653, 13802,  9783, 29914, 21476, 13554, 29889,  4268,  1159,
            13,  1678,  1544, 29898,  2674,   543, 13558,   613, 12653, 13802,
          9783, 29914,  8336,  1043, 29889,  4268,  1159,    13,  1678,  1544,
         29898,  2674,   543, 13558,   613, 12653, 13802,  9783, 29914, 15901,
         29879, 29889,  4268,  1159,    13,  1678,  1544, 29898,  2674,   543,
         13558,   613, 12653, 13802, 29882,   431, 29914,  2248, 29889,  4268,
          1159,    13,    13, 29871,  3573,    13,  1678,   869,  2974, 29899,
          6672,    13,   418, 10153, 29889,  2974, 29899,  4144, 29898,  4351,
         13802,  8346, 29914,  4144, 29889,  2732,  1159,    13,   418,   869,
          2974, 29899,   978, 29922,   260,   703,  9435, 29901, 28631, 29889,
          6915,   292,  1159,    13,    13,  1678,   869, 16418, 29899,  6672,
            13,   418,   869, 16418, 29899,  4187,  7453, 29889,  3092, 29899,
         17010,    13,  4706,  2826, 29898, 18279,   467,  1482, 29899,  4836,
         29922,   260,   703, 29882,   431, 29901,  1482,  7653, 29889,  3257,
          1159,    13,  4706,  2826, 29898, 18279,   467,  3150, 29899,  4836,
         29922,   260,   703, 29882,   431, 29901,  3150,  7653,  1159,    13,
          4706,  2826, 29898, 18279,   467,  5628, 29899,  4836, 29922,   260,
           703, 29882,   431, 29901,  5628, 10602, 29889,  3257,  1159,    13,
            13,   418,   869, 11675, 29899,  7611,    13,  4706, 10638, 29922,
           260,   703, 29882,   431, 29901, 11675,  1159,    13,  4706,  1831,
         29889, 11675,    13,    13,  1678,   869, 16418, 29899,  8336, 29899,
          1493,    13,   418,   869,  8336, 29899, 13234,    13,  4706,  1933,
         29922,   260,   703,  9435, 29901, 28631, 29889,  6915,   292,  1159,
            13,    13,  1678,   263, 29898, 12653,   543,  1124,   597,  9136,
         12248,   414, 29899,  1420, 29945, 29889,   510, 29914,   613,  5182,
           543, 29918, 19465,  2564,  2974, 29899, 21720,    13,   418,   891,
          5670, 12248,   414,   813,  4544, 29945, 29871, 29906, 29928, 29974,
         29941, 29928,  3748,  2136,   261,    13,    13,  1678,  2471, 29889,
            13,   418,   565,   313,  7165, 29889, 29876, 25521, 29889,  1792,
         19661, 29889, 19402,   703, 29923,   781,  1617,  1159, 15639,   448,
         29896, 29897,   426,    13,  4706,  1842, 29889,  2587, 29889, 18825,
         17350,  2974, 29899,  6672,  1159,   869, 10892,   353,  1565, 29936,
            13,  4706,  1842, 29889,  2587, 29889, 18825, 17350,  2974, 29899,
         21720,  1159,   869, 10892,   353,  1565, 29936,    13,   418,   500,
            13,  1678,  2471, 29898,  4351, 13802, 29903,   786,  9203, 29889,
          1315,  1159,    13,  1678,  2471, 29898,  4351, 13802, 29903,   786,
          4032, 29889,  1315,  1159,    13,  1678,  2471, 29898,  4351, 13802,
         29882,   431, 29914,  2248, 29889,  1315,  1159,    13],
        [    1,   396,   853, 29885,  2365,  7114,  6455,    13,    13,  3596,
           310,  1438,  2066,   297,   445,  3884,   526,   443, 29885,  2365,
          7114, 29889,  2180,   777,    13, 29888,  9130,  1298,   896,   674,
           367, 11132, 29889,  1763,  4078,   963, 29892,  3113,  5957,   963,
            13,  5062,   278,   421, 29933, 25282, 29918,  5746, 19297, 17101,
         29952,   315,  9984,  7353,   470,  2011,   963,   304,   278,    13,
         29961, 29963, 29911, 29968,  3772, 29875,  1222,  9422, 29962,  2636,
          9810, 29889,    13,    13, 29961, 29963, 29911, 29968,  3772, 29875,
          1222,  9422,  5387,  2045,   597,  3292, 29889,   510, 29914,  5095,
         14762, 29914, 29963, 29911, 29968,  1252,  9422,    13,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
             2,     2,     2,     2,     2,     2,     2,     2]],
       device='cuda:0')
torch.Size([2, 438, 32000]) tensor([[[-2.5391, -0.2922, -5.0586,  ..., -1.4492, -2.4512, -1.9043],
         [-2.5820, -0.4192, -5.3672,  ..., -1.4180, -2.4199, -1.9268],
         [-2.5586, -0.3716, -5.4375,  ..., -1.3828, -2.4004, -1.9082],
         ...,
         [-2.5684, -0.4590, -5.3750,  ..., -1.3730, -2.3984, -1.9404],
         [-2.5684, -0.4175, -5.2188,  ..., -1.4189, -2.4375, -1.9199],
         [-2.5820, -0.4321, -5.1484,  ..., -1.4414, -2.4492, -1.9160]],

        [[-2.5391, -0.2922, -5.0586,  ..., -1.4492, -2.4512, -1.9043],
         [-2.5996, -0.3359, -5.4023,  ..., -1.3994, -2.4121, -1.9307],
         [-2.6211, -0.4368, -5.3633,  ..., -1.3984, -2.4434, -1.9268],
         ...,
         [-2.5723, -0.2179, -5.5000,  ..., -1.3643, -2.3965, -1.8809],
         [-2.5723, -0.2181, -5.4922,  ..., -1.3652, -2.3965, -1.8799],
         [-2.5723, -0.2181, -5.4922,  ..., -1.3652, -2.3965, -1.8789]]],
       device='cuda:0')
torch.Size([2, 438, 1]) tensor([[[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 438, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 42, 91.4% of total tokens
encoded shape: torch.Size([2, 3952])
torch.Size([2, 3952]) tensor([[   1, 1235, 1162,  ...,    2,    2,    2],
        [   1, 1192, 8999,  ..., 6088,   13,   13]], device='cuda:0')
torch.Size([2, 3952, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5820, -0.4016, -5.3867,  ..., -1.4062, -2.4102, -1.8965],
         [-2.5762, -0.4678, -5.4062,  ..., -1.3779, -2.4043, -1.9365],
         ...,
         [-2.6035, -0.3096, -5.2500,  ..., -1.4258, -2.4434, -1.9170],
         [-2.6035, -0.3093, -5.2500,  ..., -1.4258, -2.4434, -1.9160],
         [-2.6035, -0.3091, -5.2500,  ..., -1.4258, -2.4434, -1.9160]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5625, -0.3530, -5.3945,  ..., -1.3701, -2.4258, -1.8955],
         [-2.5664, -0.4021, -5.3516,  ..., -1.4102, -2.4141, -1.8799],
         ...,
         [-2.5918, -0.4365, -5.1211,  ..., -1.4453, -2.4609, -1.9473],
         [-2.5957, -0.4207, -5.0664,  ..., -1.4521, -2.4844, -1.9189],
         [-2.5957, -0.4302, -5.0469,  ..., -1.4736, -2.4688, -1.9150]]],
       device='cuda:0')
torch.Size([2, 3952, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 3952, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 43, 96.8% of total tokens
encoded shape: torch.Size([2, 670])
torch.Size([2, 670]) tensor([[    1,   722,   317,  ...,     2,     2,     2],
        [    1,   835, 13383,  ...,  5113,   876,    13]], device='cuda:0')
torch.Size([2, 670, 32000]) tensor([[[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5879, -0.4006, -5.3477,  ..., -1.4111, -2.3672, -1.8770],
         [-2.5684, -0.4116, -5.4648,  ..., -1.3770, -2.3711, -1.9160],
         ...,
         [-2.5801, -0.2430, -5.4492,  ..., -1.3809, -2.4102, -1.8867],
         [-2.5801, -0.2426, -5.4453,  ..., -1.3809, -2.4102, -1.8867],
         [-2.5801, -0.2438, -5.4414,  ..., -1.3818, -2.4121, -1.8867]],

        [[-2.5469, -0.3054, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5586, -0.3186, -5.4023,  ..., -1.3887, -2.4062, -1.9131],
         [-2.5605, -0.3638, -5.3750,  ..., -1.3711, -2.3926, -1.9326],
         ...,
         [-2.5547, -0.4148, -5.4219,  ..., -1.3555, -2.3809, -1.9053],
         [-2.5547, -0.3528, -5.3086,  ..., -1.3516, -2.4473, -1.9326],
         [-2.5645, -0.3403, -5.2539,  ..., -1.4131, -2.4551, -1.9277]]],
       device='cuda:0')
torch.Size([2, 670, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 670, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Batch 44, 97.7% of total tokens
encoded shape: torch.Size([2, 883])
torch.Size([2, 883]) tensor([[    1,  1203, 10488,  ...,     2,     2,     2],
        [    1, 18252, 21300,  ...,  1420, 29958,    13]], device='cuda:0')
torch.Size([2, 883, 32000]) tensor([[[-2.5469, -0.3071, -5.0547,  ..., -1.4561, -2.4609, -1.9121],
         [-2.5586, -0.3398, -5.4805,  ..., -1.3682, -2.3809, -1.8877],
         [-2.5742, -0.4402, -5.3828,  ..., -1.3936, -2.4004, -1.9355],
         ...,
         [-2.6035, -0.2981, -5.2734,  ..., -1.4189, -2.4375, -1.9150],
         [-2.6035, -0.2939, -5.2734,  ..., -1.4199, -2.4375, -1.9150],
         [-2.5996, -0.2869, -5.2734,  ..., -1.4170, -2.4336, -1.9111]],

        [[-2.5469, -0.3071, -5.0547,  ..., -1.4561, -2.4609, -1.9121],
         [-2.5547, -0.3352, -5.4766,  ..., -1.3467, -2.3945, -1.9004],
         [-2.5547, -0.3228, -5.4336,  ..., -1.3730, -2.4023, -1.9316],
         ...,
         [-2.5703, -0.4165, -5.2891,  ..., -1.4219, -2.4180, -1.9209],
         [-2.5723, -0.3760, -5.1953,  ..., -1.4453, -2.4199, -1.9219],
         [-2.5879, -0.4058, -5.0820,  ..., -1.4785, -2.4355, -1.8994]]],
       device='cuda:0')
torch.Size([2, 883, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 883, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30268, 30300, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268]]], device='cuda:0')
Batch 45, 98.6% of total tokens
encoded shape: torch.Size([2, 4096])
torch.Size([2, 4096]) tensor([[    1,   426,    13,  ..., 29929, 29955, 29906],
        [    1,  4949, 24250,  ..., 29936,    13,  1678]], device='cuda:0')
torch.Size([2, 4096, 32000]) tensor([[[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5762, -0.3569, -5.3828,  ..., -1.3750, -2.3848, -1.8779],
         [-2.2363,  0.0273, -5.4336,  ..., -1.2910, -2.2949, -1.7666],
         ...,
         [-2.5547, -0.3577, -5.4844,  ..., -1.3379, -2.3730, -1.9160],
         [-2.5645, -0.3604, -5.4531,  ..., -1.3564, -2.3750, -1.9248],
         [-2.5684, -0.3933, -5.4258,  ..., -1.3789, -2.3945, -1.9189]],

        [[-2.5469, -0.3052, -5.0508,  ..., -1.4570, -2.4609, -1.9121],
         [-2.5703, -0.3530, -5.3359,  ..., -1.4219, -2.4062, -1.8799],
         [-2.5918, -0.5215, -5.3984,  ..., -1.3887, -2.3770, -1.9219],
         ...,
         [-2.5488, -0.3672, -5.4336,  ..., -1.3711, -2.4277, -1.9238],
         [-2.5918, -0.4246, -5.3242,  ..., -1.4336, -2.4629, -1.9326],
         [-2.5859, -0.4756, -5.3945,  ..., -1.3828, -2.4570, -1.9189]]],
       device='cuda:0')
torch.Size([2, 4096, 1]) tensor([[[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]],

        [[31147],
         [31147],
         [31147],
         ...,
         [31147],
         [31147],
         [31147]]], device='cuda:0')
torch.Size([2, 4096, 10]) tensor([[[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]],

        [[31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         ...,
         [31147, 30488, 30879,  ..., 30300, 30268, 30154],
         [31147, 30488, 30879,  ..., 30300, 30154, 30268],
         [31147, 30488, 30879,  ..., 30300, 30268, 30154]]], device='cuda:0')
Written to json file succesfully for 46 batches!

JOB STATISTICS
==============
Job ID: 4199336
Cluster: snellius
User/Group: tvdweij/tvdweij
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:27:00 core-walltime
Job Wall-clock time: 00:08:10
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 40.00 GB (40.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
